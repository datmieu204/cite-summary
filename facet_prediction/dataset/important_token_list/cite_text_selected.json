[
    "00",
    "00 kipper",
    "12 untagged",
    "18",
    "18 confusion",
    "1988 rich",
    "1989 dang",
    "1989 jackendoff",
    "1990",
    "1990 levin",
    "1993 1994",
    "1993 dorr",
    "1993 pinker",
    "1993 tong",
    "1994 required",
    "1994 words",
    "1995b",
    "1996 difficult",
    "1996 golding",
    "1996 luo",
    "1996 taken",
    "1996 testify",
    "1996 uses",
    "1997 dang",
    "1997 merlo",
    "1998 argue",
    "1998 compare",
    "1998 dorr",
    "1998 example",
    "1998 merlo",
    "1999 dang",
    "1s",
    "2000 dang",
    "2002 dorow",
    "2002a bean",
    "2003 addition",
    "2003 investigate",
    "2003 joanis",
    "2003 yao",
    "2004 hierarchical",
    "2004 mihalcea",
    "2004 otter",
    "2004 wikipedia",
    "2005 claims",
    "2005 critical",
    "2005 wan",
    "2005 zhang",
    "2006 assumed",
    "2006 contextual",
    "2006 diab",
    "2006 pa",
    "2006 uses",
    "2006 zhao",
    "2007 bitam",
    "2007 bitam\u00e2",
    "2007 green",
    "2007 tam",
    "2008 examples",
    "2008 provides",
    "2010 french",
    "2010 geographical",
    "2010 ruiz",
    "2010 used",
    "2011 data",
    "2011 shown",
    "2in",
    "2in large",
    "435",
    "435 uni\ufb01ed",
    "55",
    "75",
    "75 agreement",
    "76",
    "90",
    "95",
    "95 word",
    "98",
    "98 00",
    "98 percent",
    "accepted",
    "accepted standard",
    "accuracy",
    "ace rdc",
    "acts",
    "acts statements",
    "actual implementation",
    "adaptation tam",
    "adding additional",
    "addition commonly",
    "addition significant",
    "additional information",
    "additional level",
    "adopted topics",
    "agree",
    "agree sekine",
    "agree unique",
    "agreement",
    "agreement native",
    "aim",
    "aim capture",
    "al 00",
    "al 1998",
    "al 98",
    "algorithms based",
    "algorithms task",
    "alignment improved",
    "analyses",
    "analyses word",
    "analysis developed",
    "analysis tam",
    "anaphor resolution",
    "anaphoricity",
    "anaphoricity determination",
    "andradev",
    "andradev 2004",
    "answering otterbacher",
    "appears specific",
    "applicability",
    "applicability general",
    "application various",
    "approach inspired",
    "approach suffers",
    "approaches anaphor",
    "arabic msa",
    "arabic parser",
    "arabic parsing",
    "argue",
    "argue syntactic",
    "argue use",
    "association syntactic",
    "assumed parallel",
    "atr",
    "atr 98",
    "attracted",
    "attracted considerable",
    "automatically derived",
    "avoid eliminate",
    "avoid need",
    "bacher",
    "bacher et",
    "backchannels",
    "backchannels detected",
    "balance",
    "balance iv",
    "based correlation",
    "based detec",
    "based qa",
    "based query",
    "based refined",
    "based spoken",
    "basis reordering",
    "basis works",
    "bb",
    "bb task",
    "began recent",
    "berkeley",
    "berkeley parser",
    "better method",
    "bilingual",
    "bilingual lsa",
    "biology",
    "biology challenges",
    "bitam",
    "bitam model",
    "bitam\u00e2",
    "bitam\u00e2 zhao",
    "brill",
    "brill brill",
    "brill marcus",
    "brown corpus",
    "called inter",
    "called kogure",
    "calls redundant",
    "capture",
    "capture close",
    "capture struc",
    "cardie 2002a",
    "cases additional",
    "caused",
    "caused subdivide",
    "challenge",
    "challenge relation",
    "challenges",
    "challenges kim",
    "chi",
    "chi geman",
    "chinese speakers",
    "claims",
    "claims different",
    "class caused",
    "classes",
    "classes adding",
    "classes aim",
    "classes dang",
    "classes provides",
    "classes sim\u00e2",
    "classes useful",
    "classes verbs",
    "classification called",
    "classification creating",
    "classifications",
    "classifications aim",
    "classifications verbs",
    "classifier dl",
    "classifier used",
    "clear regular",
    "close",
    "close relation",
    "close relationship",
    "clustering tasks",
    "combination gol95",
    "commonly accepted",
    "compare",
    "compare methods",
    "compare number",
    "complete",
    "complete set",
    "composite",
    "composite kernel",
    "computational linguistics",
    "conditional",
    "conferences muc",
    "confusable",
    "confusable disambiguation",
    "confusion sets",
    "conjunctions",
    "conjunctions dbz99",
    "consequently strategies",
    "considerable",
    "considerable linguistics",
    "considerable research",
    "consistence",
    "consistence topics",
    "constitute",
    "constitute mixture",
    "constraint having",
    "constructed",
    "constructed based",
    "context free",
    "contexts topical",
    "contexts words",
    "contribute successful",
    "contributes",
    "contributes performance",
    "cope",
    "cope real",
    "copy operations",
    "copying called",
    "coreference systems",
    "corpora differ",
    "corpus mitkov",
    "corpus used",
    "correct word",
    "correction",
    "correction developed",
    "correctness",
    "cost",
    "cost predicting",
    "creating",
    "creating intersective",
    "critical",
    "critical performance",
    "cssc",
    "cssc tested",
    "ct 1996",
    "current classification",
    "cut based",
    "cut mincut",
    "cutoff",
    "cutoff value",
    "dang",
    "dang et",
    "data brown",
    "data pre",
    "dbz99",
    "dbz99 decision",
    "decide word",
    "decisions",
    "decisions domain",
    "decreasing",
    "decreasing weights",
    "definition",
    "definition different",
    "degraded",
    "dependency kernel",
    "dependency path",
    "derived based",
    "descriptions gerdemann",
    "destructive unification",
    "detec",
    "detec tor",
    "detected",
    "detected using",
    "determination",
    "determination modules",
    "developed atr",
    "developed basis",
    "developing",
    "developing principled",
    "devoted",
    "devoted graph",
    "de\u00e2",
    "diab 2007",
    "dialog act",
    "dialogue",
    "dialogue acts",
    "differ",
    "differ facing",
    "differ sproat",
    "different verb",
    "difficult",
    "difficult compare",
    "difficult effectively",
    "difficult set",
    "disambiguation",
    "disambiguation investigated",
    "discover",
    "discover wider",
    "discussing",
    "discussing application",
    "dl",
    "dl similar",
    "document pair",
    "domain membership",
    "dorr",
    "dorr 1997",
    "effect",
    "effect translation",
    "effect troll",
    "effectively capture",
    "effort",
    "elapsed",
    "elapsed time",
    "eliminate",
    "eliminate redundant",
    "endoff",
    "endoff 1990",
    "english number",
    "ensured",
    "ensured inside",
    "entity evaluation",
    "erkan",
    "erkan andradev",
    "errors",
    "errors spelling",
    "estimated tagged",
    "estimated treebank",
    "estimator",
    "estimator tight",
    "et 1998",
    "evaluating",
    "evaluating performance",
    "evaluation began",
    "evaluation tasks",
    "evans 1996",
    "evidence hypothesis",
    "example refined",
    "example ureaplasma",
    "example zhou",
    "examples similar",
    "exhaustive",
    "exhaustive typing",
    "existing learning",
    "experiments shown",
    "exploits",
    "exploits systematic",
    "exponentially",
    "exponentially decreasing",
    "extended senses",
    "extraction data",
    "extraction methods",
    "f1",
    "facing",
    "facing task",
    "feature combination",
    "feature space",
    "features contribute",
    "features contributes",
    "federico",
    "federico 2011",
    "finally coreference",
    "fine tuned",
    "finite\u00e2",
    "finite\u00e2 state",
    "follow pantel",
    "following lee",
    "following setting",
    "follows success",
    "form linear",
    "frames",
    "frames verb",
    "french green",
    "frequency estimator",
    "frequent speech",
    "function exponentially",
    "functional",
    "functional form",
    "fung 1994",
    "fung wu",
    "gabbard",
    "gabbard marcus",
    "geman",
    "geman 1998",
    "general feature",
    "general nlp",
    "generally precursor",
    "geographical",
    "geographical locations",
    "gerdemann king",
    "german pos",
    "given sentence",
    "goh",
    "goh et",
    "gol95",
    "golding",
    "golding 1995",
    "golding golding",
    "golding schabes",
    "grained tags",
    "graph unification",
    "great",
    "great effect",
    "green",
    "green et",
    "green manning",
    "hard",
    "hard decide",
    "hard decisions",
    "having",
    "having semantic",
    "having senses",
    "help document",
    "hierarchical structured",
    "hierarchy",
    "hierarchy dang",
    "hpsg",
    "hpsg based",
    "hpsg theories",
    "human",
    "human agreement",
    "human judges",
    "hypothesis tokenization",
    "identical",
    "identical data",
    "implementation weighted",
    "implements",
    "implements exhaustive",
    "improve performance",
    "improve smt",
    "improved help",
    "improvement",
    "improvement relation",
    "improvement simple",
    "improves quality",
    "including majority",
    "includingfact",
    "includingfact based",
    "incorporated anaphoricity",
    "indirectly",
    "indirectly improves",
    "inefficient",
    "inefficient copy",
    "inference rules",
    "inferencing",
    "inferencing descriptions",
    "information great",
    "information indirectly",
    "information lost",
    "information verbnet",
    "input consists",
    "inside",
    "inside verbnet",
    "inspired",
    "inspired recent",
    "inspired work",
    "instance bilingual",
    "inter sective",
    "intersections",
    "intersections levin\u00e2",
    "intersective classes",
    "investigate",
    "investigate applicability",
    "investigated string",
    "iv oov",
    "jack",
    "jack endoff",
    "jackendoff",
    "jackendoff 1990",
    "japanese analysis",
    "judge",
    "judges",
    "judges differ",
    "kernel",
    "kernel zhou",
    "key",
    "kind",
    "kind inferencing",
    "king 1993",
    "kipper",
    "kipper et",
    "knowledge mitkov",
    "kogure",
    "kogure 90",
    "kogure kogure",
    "koike",
    "koike et",
    "kulick",
    "kulick gabbard",
    "learning algorithms",
    "learning alignment",
    "length word",
    "level hierarchy",
    "level information",
    "levin",
    "levin 1993",
    "levin class",
    "levin classes",
    "levin classification",
    "levin\u00e2",
    "levin\u00e2 original",
    "lexi",
    "lexi constructed",
    "lexical semantic",
    "lexicon",
    "lexicon exploits",
    "lexrank",
    "lexrank otterbacher",
    "lexrank proposed",
    "limited corpus",
    "limited shallow",
    "lin 2002",
    "linear function",
    "linguistics",
    "linguistics computational",
    "linguistics jack",
    "linguistics pinker",
    "link",
    "link syntax",
    "list classifier",
    "lists functional",
    "locations",
    "locations zhou",
    "long specialized",
    "lost",
    "lost pairwise",
    "lower",
    "lsa",
    "lsa adaptation",
    "luo roukos",
    "luperfoy",
    "luperfoy 1988",
    "major challenge",
    "majority vote",
    "manning",
    "manning 2010",
    "marcken",
    "marcken 1996",
    "marcus",
    "marcus 2006",
    "marcus golding",
    "mbl",
    "mbl using",
    "meaningful",
    "meaningful sproat",
    "membership",
    "membership levin",
    "membership used",
    "mentioned",
    "mentioned work",
    "merlo",
    "merlo stevenson",
    "message understanding",
    "method avoid",
    "method proposed",
    "method requires",
    "methods general",
    "methods hard",
    "methods required",
    "methods speech",
    "metric value",
    "mihalcea tarau",
    "ml",
    "model estimated",
    "model learning",
    "model optimize",
    "model zhao",
    "modeling",
    "modeling improve",
    "modeling received",
    "modern",
    "modern chinese",
    "module used",
    "modules ng",
    "motivates",
    "motivates levin",
    "msa",
    "msa results",
    "muc",
    "muc objective",
    "multiple human",
    "mycoplasma",
    "mycoplasma pathogenic",
    "native",
    "native chinese",
    "native speakers",
    "need",
    "need hard",
    "nlp example",
    "np bean",
    "number methods",
    "number voting",
    "objective",
    "objective standardize",
    "observation basis",
    "obtained rftagger",
    "oov performance",
    "operations",
    "operations unfications",
    "optimal berkeley",
    "optimize",
    "optimize stage",
    "original classes",
    "otter",
    "otter bacher",
    "otterbacher",
    "otterbacher et",
    "pa",
    "pa rameterizations",
    "packages",
    "packages stanford",
    "pair constitute",
    "pairs document",
    "pairwise clustering",
    "palmer",
    "palmer 1999",
    "palmer 2000",
    "pantel lin",
    "papers discussing",
    "parallel sentence",
    "parameters model",
    "parser green",
    "parser petrov",
    "parsing koike",
    "particular translation",
    "parvum",
    "parvum mycoplasma",
    "patb",
    "patb kulick",
    "path length",
    "pathogenic",
    "pathogenic biology",
    "pcfg",
    "pcfg estimated",
    "percent",
    "percent elapsed",
    "perform limited",
    "performance",
    "performance goh",
    "performance improvement",
    "performance using",
    "performance word",
    "performed reasonably",
    "petrov et",
    "phenomena arabic",
    "pinker",
    "pinker 1989",
    "pipeline",
    "played",
    "played np",
    "plify",
    "plify definition",
    "polynomial interpolation",
    "practical effect",
    "practical use",
    "pre processed",
    "precursor mentioned",
    "predefined cutoff",
    "predicting",
    "predicting single",
    "previous approaches",
    "previously showed",
    "principled",
    "principled classifications",
    "problem zhou",
    "processed packages",
    "properties",
    "properties verbs",
    "proposed balance",
    "proposed cope",
    "proposed kogure",
    "proposed otterbacher",
    "proved pcfg",
    "provided goldberg",
    "provides",
    "provides class",
    "provides clear",
    "provides morphological",
    "provides stronger",
    "qa",
    "qa text",
    "quality smt",
    "query",
    "query sensitive",
    "question",
    "question topic",
    "questions backchannels",
    "rameterizations",
    "rameterizations arabic",
    "random",
    "random walk",
    "rate",
    "rdc",
    "real",
    "real word",
    "reasonably using",
    "received",
    "received use",
    "recent message",
    "recent studies",
    "redundant",
    "redundant copying",
    "refined",
    "refined current",
    "refined version",
    "regarding correct",
    "regular association",
    "relation feature",
    "relation syntax",
    "relationship",
    "relationship syntax",
    "reliable",
    "removed",
    "removed using",
    "reordering method",
    "reported patb",
    "reported zhou",
    "required discover",
    "required standard",
    "requires predefined",
    "research linguistics",
    "resolution fine",
    "resolution performed",
    "retrieval question",
    "rich luperfoy",
    "role played",
    "roles ensured",
    "roukos 1996",
    "ruiz",
    "ruiz federico",
    "rules lin",
    "scale hpsg",
    "scarcity",
    "schabes",
    "schabes 1993",
    "schabes powers",
    "scheme combination",
    "sections",
    "sections language",
    "sective",
    "sective levin",
    "segmenting text",
    "selected decision",
    "semantic classes",
    "semantic properties",
    "semantic representations",
    "semantics",
    "semantics motivates",
    "semantics verbs",
    "sense disambiguation",
    "senses",
    "senses extended",
    "senses golding",
    "sensitive",
    "sensitive lexrank",
    "sentence contexts",
    "sentence retrieval",
    "sentences translated",
    "set analyses",
    "setting zhao",
    "shallow",
    "shallow knowledge",
    "shallow parsing",
    "share membership",
    "showed optimal",
    "shown 75",
    "shown particular",
    "shows performance",
    "significant information",
    "similar classifier",
    "similar phenomena",
    "similar stolcke",
    "similarities",
    "similarly sproat",
    "simple destructive",
    "sim\u00e2",
    "sim\u00e2 plify",
    "single feature",
    "single standard",
    "smt",
    "smt instance",
    "smt performance",
    "source practical",
    "space unsupervised",
    "speakers",
    "speakers regarding",
    "specialized",
    "specialized conjunctions",
    "specific heuristics",
    "specific topical",
    "spelling",
    "spelling correction",
    "spoken",
    "spoken japanese",
    "sproat ct",
    "stage svm",
    "standard evaluating",
    "standard fung",
    "standard hpsg",
    "standardize",
    "standardize evaluation",
    "standards 435",
    "statements questions",
    "statistic",
    "stevenson 2001",
    "stolcke",
    "stolcke et",
    "strategic",
    "strategic unification",
    "strategies proposed",
    "strategy provides",
    "string papers",
    "stronger",
    "stronger kind",
    "strube",
    "struc",
    "struc tured",
    "structured",
    "structured syntactic",
    "studies zhao",
    "su use",
    "subdivide",
    "subdivide use",
    "success methods",
    "successful unification",
    "successfully incorporated",
    "suffers",
    "suffers kogure",
    "summarization erkan",
    "sundheim 1995b",
    "svm result",
    "switchboard similar",
    "syntactic frames",
    "syntax",
    "syntax semantics",
    "systematic",
    "systematic link",
    "systems successfully",
    "tagged 12",
    "tags obtained",
    "taken evidence",
    "tam",
    "tam et",
    "tarau",
    "tarau 2004",
    "task example",
    "task segmenting",
    "task yarowsky",
    "tasks sundheim",
    "technique previous",
    "tense",
    "test corpora",
    "tested identical",
    "testify",
    "testify native",
    "text summarization",
    "text words",
    "theories",
    "tight",
    "time devoted",
    "tion given",
    "tokeniza",
    "tokeniza tion",
    "tokenization source",
    "tomabechi",
    "tomabechi approach",
    "tong",
    "tong evans",
    "topic",
    "topic model",
    "topic modeling",
    "topic sensitive",
    "topical contexts",
    "topics",
    "topics following",
    "topics zhao",
    "tor",
    "tor trained",
    "trained switchboard",
    "training sections",
    "transducer sproat",
    "translated",
    "translated consistence",
    "translation appears",
    "translation selection",
    "treatments",
    "treatments strategic",
    "treebank relative",
    "troll implements",
    "tuned",
    "tuned perform",
    "tured",
    "tured parse",
    "typing",
    "typing strategy",
    "understanding",
    "understanding conferences",
    "unfications",
    "unfications unnecessary",
    "unification developed",
    "unification kogure",
    "unification tomabechi",
    "unification treatments",
    "unique",
    "unique tokeniza",
    "uni\ufb01ed",
    "uni\ufb01ed single",
    "unnecessary",
    "unnecessary features",
    "unsupervised verb",
    "untagged 11",
    "upper",
    "ureaplasma",
    "ureaplasma parvum",
    "use intersections",
    "use minimum",
    "use smt",
    "use syntactic",
    "used anaphora",
    "used golding",
    "used shallow",
    "used spelling",
    "used topic",
    "used yarowsky",
    "useful developing",
    "uses bilingual",
    "uses multiple",
    "using cut",
    "using latent",
    "using limited",
    "using long",
    "using sentence",
    "value",
    "value difficult",
    "value used",
    "variety paraphrases",
    "verb",
    "verb classes",
    "verb clustering",
    "verb senses",
    "verbnet",
    "verbnet lexi",
    "verbnet provides",
    "verbs",
    "verbs attracted",
    "verbs share",
    "verbs verb",
    "version levin",
    "vote scheme",
    "w1",
    "walk",
    "walk model",
    "wan",
    "wan yang",
    "weighted finite\u00e2",
    "weights cost",
    "wider",
    "wider variety",
    "wikipedia",
    "wikipedia ponzetto",
    "word errors",
    "word extraction",
    "word meaningful",
    "word provided",
    "word relation",
    "words dependency",
    "words having",
    "words test",
    "work arabic",
    "work confusable",
    "work pang",
    "works brill",
    "wu 1994",
    "wu fung",
    "xing",
    "xing 2006",
    "xing 2007",
    "yang 2008",
    "yao et",
    "zhao",
    "zhao xing"
]