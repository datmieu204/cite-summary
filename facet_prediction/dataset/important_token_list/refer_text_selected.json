[
    "18",
    "18 confusion",
    "19",
    "1979",
    "1998 starting",
    "220",
    "220 noisy",
    "49 55",
    "55",
    "55 precision",
    "63",
    "63 49",
    "75",
    "75 99",
    "76",
    "76 average",
    "7th",
    "7th message",
    "89",
    "8c",
    "92",
    "92 f1",
    "93",
    "94",
    "95",
    "96",
    "97",
    "98",
    "99",
    "99 interhuman",
    "able",
    "able make",
    "able use",
    "accent",
    "accent restoration",
    "access",
    "access detailed",
    "account",
    "account single",
    "accurate word",
    "achieves",
    "achieves best",
    "achieves performance",
    "added",
    "added dictionary",
    "addition used",
    "additional",
    "additional features",
    "addressed natural",
    "adduced",
    "adduced produc\u00e2",
    "admixture",
    "admixture model",
    "advantage",
    "advantage completely",
    "advantage pre",
    "agree",
    "agree perfectly",
    "agreement",
    "agreement human",
    "agreement st",
    "aim present",
    "algorithm available",
    "algorithm results",
    "algorithm trained",
    "alignment",
    "alignment smt",
    "ambiguity arabic",
    "amounts",
    "amounts labelled",
    "analyze",
    "analyze modern",
    "anaphors specific",
    "annotated data",
    "annotated pos",
    "answering",
    "answering ner",
    "applicability impede",
    "application fine",
    "application settings",
    "applications information",
    "applied",
    "applied accent",
    "approach task",
    "arabic",
    "arabic henceforth",
    "arabic parsing",
    "arabic significant",
    "arabic unusual",
    "art",
    "art machine",
    "article twofold",
    "aspect",
    "assignment words",
    "assumed constitute",
    "assumption",
    "assumption syntactic",
    "automatic",
    "automatic classification",
    "automatic unsupervised",
    "automatically classify",
    "automatically corpora",
    "automatically determining",
    "available",
    "available evidence",
    "available training",
    "average",
    "average agreement",
    "balance",
    "balance vocabulary",
    "base phrase",
    "based ners",
    "based training",
    "based translation",
    "based word",
    "baseline",
    "baseline method",
    "baselines",
    "baselines evaluations",
    "believe",
    "believe methods",
    "benefit",
    "benefit needing",
    "best performance",
    "best previous",
    "better arabic",
    "better reason",
    "bigrams standard",
    "biguation",
    "biguation task",
    "bilingual",
    "bilingual lexicon",
    "bilingual topic",
    "bilingual translation",
    "bitam",
    "bitam facilitate",
    "bitam models",
    "boundary",
    "boundary countries",
    "boxer open",
    "broad set",
    "brown",
    "brown corpus",
    "build",
    "build question",
    "capture",
    "capture topic",
    "captured",
    "captured chunking",
    "carry",
    "cascading",
    "cascading segmentation",
    "case person",
    "cases",
    "cases estimated",
    "chinese sentence",
    "choices",
    "choices subword",
    "choose",
    "choose svms",
    "chunking",
    "chunking information",
    "cities",
    "class does",
    "classes",
    "classes comprise",
    "classes contain",
    "classes wordnet",
    "classifica",
    "classifica tion",
    "classification das",
    "classification joanis",
    "classification schemes",
    "classifiers work",
    "classify verbs",
    "clear definition",
    "clustering scenario",
    "coarse",
    "coarse grained",
    "combination",
    "combination simple",
    "combining",
    "combining context",
    "combining diverse",
    "communities",
    "community",
    "community good",
    "comparable",
    "comparable best",
    "comparable corpora",
    "compare performance",
    "comparison",
    "comparison english",
    "comparison systems",
    "completely",
    "completely automatic",
    "components",
    "components divided",
    "comprehensive framework",
    "comprise",
    "comprise verbs",
    "computing",
    "computing reasoning",
    "concern",
    "concern mainly",
    "condition",
    "condition speech",
    "conditional probabilitieswith",
    "conference muc7",
    "configuration",
    "confusion sets",
    "constantly updated",
    "constitute",
    "constitute mixture",
    "constitutes",
    "constitutes correct",
    "contain",
    "contain equally",
    "context",
    "context dialogue",
    "context sensitive",
    "context transliteration",
    "contextual",
    "contextual role",
    "contribute",
    "conversation",
    "conversation context",
    "conversational",
    "coordination",
    "coordination ambiguity",
    "copying",
    "coreference",
    "coreference resolution",
    "corpora",
    "corpora combining",
    "corpora used",
    "corpus kucera",
    "corpus required",
    "corpus suffers",
    "correct",
    "correct segmentation",
    "correction",
    "correction performance",
    "correction task",
    "correction ve",
    "correctly bilingual",
    "correlated",
    "correlated da",
    "countries",
    "countries states",
    "create knowledge",
    "create new",
    "creating",
    "creating paraphrase",
    "currently investigated",
    "curse",
    "curse dimensionality",
    "cutoff",
    "da",
    "da identity",
    "das founded",
    "data disambiguated",
    "data subtypes",
    "defined regions",
    "definition constitutes",
    "degree",
    "degree tense",
    "democratic",
    "democratic option",
    "demonstrate",
    "demonstrate human",
    "derlying",
    "derlying semantics",
    "describes refinements",
    "detailed",
    "detailed syntactic",
    "determining good",
    "developed using",
    "development minimally",
    "dialogue structure",
    "differ meaningful",
    "different heuristics",
    "different levels",
    "difficult",
    "difficulty",
    "dimensionality",
    "direct",
    "direct reflection",
    "directly",
    "directly achieves",
    "disambiguation algorithm",
    "disam\u00e2",
    "disam\u00e2 biguation",
    "discourse level",
    "discover paraphrase",
    "discover wider",
    "discovery maintain",
    "divided",
    "divided smaller",
    "document pair",
    "does employ",
    "does fact",
    "domain spend",
    "domain tool",
    "effect",
    "effect cascading",
    "efforts",
    "efforts discover",
    "employ",
    "employ ny",
    "encoding",
    "encoding information",
    "english classifica",
    "english parsing",
    "english portuguese",
    "english substantial",
    "entities",
    "entities gpe",
    "entities types",
    "entropy",
    "entropy framework",
    "equally",
    "equally useful",
    "errors",
    "errors parsing",
    "errors table",
    "estimated probability",
    "estimation conditional",
    "evaluation",
    "evaluation shall",
    "evaluation shows",
    "evaluations",
    "evaluations analysis",
    "evaluations differ",
    "evaluative",
    "evaluative score",
    "event relationship",
    "evidence",
    "evidence available",
    "evidence ve",
    "example anaphors",
    "exhibit",
    "exhibit wide",
    "experi",
    "experi ment",
    "experiments report",
    "explicit logical",
    "extraction question",
    "extraction shallow",
    "extraction task",
    "f1",
    "facilitate",
    "facilitate topic",
    "facilities",
    "facilities geopolitical",
    "fact indicate",
    "factors",
    "factors analyze",
    "feature space",
    "features encoding",
    "features generality",
    "features performs",
    "figures",
    "figures given",
    "focus",
    "focus work",
    "focused",
    "focused sentence",
    "follows topic",
    "force",
    "formalism",
    "formalism bilingual",
    "formalism parallel",
    "formulated 7th",
    "founded",
    "founded known",
    "founder",
    "founder type",
    "frames",
    "frames direct",
    "framework able",
    "framework modeling",
    "framework provides",
    "fundamental",
    "fundamental assumption",
    "g3",
    "gains",
    "gender",
    "gender case",
    "general classification",
    "general issue",
    "generality",
    "generality feature",
    "genre resolved",
    "geographically",
    "geographically defined",
    "geopolitical",
    "geopolitical entities",
    "given based",
    "given chinese",
    "given text",
    "gives rise",
    "global information",
    "goal",
    "goal article",
    "goal build",
    "gold segmentation",
    "good",
    "good cutoff",
    "good implementations",
    "gpe",
    "gpe geographically",
    "grained pos",
    "grained stts",
    "granularity",
    "granularity sentence",
    "guidance",
    "guidance membership",
    "hand",
    "hand aim",
    "hand specific",
    "henceforth",
    "henceforth msa",
    "heuristics discover",
    "hidden topics",
    "high quality",
    "human",
    "human judges",
    "human subjects",
    "humans",
    "humans 75",
    "hypothesizes",
    "hypothesizes improvements",
    "identity",
    "impede",
    "impede utility",
    "implementations",
    "implementations algorithm",
    "importance automatically",
    "improvements",
    "improvements obtained",
    "indian",
    "indian derived",
    "indicate",
    "indicate political",
    "indicate shared",
    "infereneing",
    "influence",
    "influence factors",
    "information correlated",
    "information directly",
    "information levin",
    "information number",
    "information parse",
    "interhuman",
    "interhuman agreement",
    "investigate",
    "investigate influence",
    "investigated",
    "investigated model",
    "iob tagger",
    "issue test",
    "joanis",
    "joanis stevenson",
    "judges",
    "judges 76",
    "judges agree",
    "judgments",
    "judgments human",
    "kinds",
    "kinds efforts",
    "knowledge coreference",
    "knowledge parsing",
    "knowledge patterns",
    "known statistical",
    "kucera",
    "labelled data",
    "lack",
    "lack clear",
    "languages english",
    "lappin",
    "large",
    "large levin",
    "leading",
    "leading curse",
    "learning based",
    "learning communities",
    "learning research",
    "level coordination",
    "levels",
    "levels linguistic",
    "levels propose",
    "levin",
    "levin class",
    "levin classes",
    "lexical disam\u00e2",
    "lexicon needs",
    "lexrank",
    "lexrank method",
    "limita",
    "limita tions",
    "linguistic granularity",
    "linguistic knowledge",
    "locations",
    "locations facilities",
    "logical representations",
    "long",
    "long time",
    "looking",
    "looking person",
    "mada",
    "mada produces",
    "mainly",
    "mainly explicit",
    "maintain",
    "maintain benefit",
    "major",
    "major problem",
    "make use",
    "mathematically",
    "mathematically principled",
    "maximum entropy",
    "meaningful",
    "meaningful comparison",
    "measure",
    "measure advantage",
    "measure combining",
    "mechanism",
    "mechanism using",
    "membership",
    "membership levin",
    "ment",
    "ment based",
    "menter",
    "menter segmenters",
    "message",
    "message understanding",
    "method 18",
    "method judgments",
    "method million",
    "method starting",
    "methods developed",
    "methods particular",
    "million",
    "million word",
    "minimally",
    "minimally supervised",
    "mining",
    "mining new",
    "mixture",
    "mixture hidden",
    "model advantage",
    "model bitam",
    "model paper",
    "modeling automatic",
    "models concern",
    "models proposed",
    "modern",
    "modern standard",
    "mood",
    "motion",
    "msa",
    "msa simply",
    "muc6",
    "muc6 muc7",
    "muc7",
    "muc7 1998",
    "muc7 test",
    "multiple choices",
    "names quick",
    "needing",
    "needing noisy",
    "needs",
    "needs constantly",
    "ner",
    "ner provide",
    "ner useful",
    "ners",
    "ners muc6",
    "new",
    "new approach",
    "new domain",
    "new statistical",
    "new word",
    "new words",
    "nlp applications",
    "node g3",
    "noisy",
    "noisy features",
    "nonlexical",
    "nonlexical information",
    "noun vs",
    "np",
    "number gender",
    "number words",
    "ny",
    "ny type",
    "obtained",
    "obtained taking",
    "ofthe",
    "ofthe lexrank",
    "open",
    "open domain",
    "opportunity",
    "opportunity presents",
    "option",
    "option tagger",
    "order create",
    "order machine",
    "organizations",
    "organizations locations",
    "orthographic",
    "orthographic words",
    "pair",
    "pair assumed",
    "pair follows",
    "pairs document",
    "pairwise voting",
    "paper describes",
    "paper maximum",
    "paper propose",
    "paper shows",
    "paper takes",
    "parallel",
    "parallel sentence",
    "paraphrase",
    "paraphrase automatically",
    "paraphrase knowledge",
    "parse trees",
    "parsing 92",
    "parsing baselines",
    "parsing errors",
    "parsing results",
    "particular importance",
    "pattern simply",
    "patterns hand",
    "perfectly",
    "perfectly segment",
    "performance",
    "performance 63",
    "performance baseline",
    "performance comparable",
    "performance figures",
    "performance method",
    "performs supervised",
    "person",
    "person degree",
    "person organization",
    "persons",
    "persons organizations",
    "phrase chunking",
    "piece",
    "piece evidence",
    "plays event",
    "point hypothesizes",
    "political boundary",
    "portuguese",
    "possibility",
    "possibility segmentation",
    "possible",
    "possible semantic",
    "pre tagged",
    "prefer",
    "prefer compare",
    "present comprehensive",
    "presents",
    "presents comparison",
    "previous machine",
    "previous systems",
    "previous works",
    "previously shown",
    "principled way",
    "probabilities given",
    "probabilitieswith",
    "probabilitieswith decision",
    "probability tight",
    "problem",
    "problem seg\u00e2",
    "problem styles",
    "problem unknown",
    "processing machine",
    "produces",
    "produces high",
    "produc\u00e2",
    "produc\u00e2 tive",
    "propose",
    "propose new",
    "proposed capture",
    "provide users",
    "provides mathematically",
    "purpose svms",
    "quality segmentation",
    "question",
    "question answering",
    "question focused",
    "quick",
    "quick information",
    "quite",
    "quite successfully",
    "range",
    "range possible",
    "rates vocabulary",
    "readily",
    "readily adduced",
    "reason",
    "reason choose",
    "reasoning",
    "reasoning semantic",
    "recall",
    "recall measure",
    "recognition task",
    "recognizer conversation",
    "recognizer ner",
    "refinements currently",
    "reflection",
    "reflection derlying",
    "regions",
    "regions indicate",
    "related",
    "related lexical",
    "relationship",
    "remain",
    "remain large",
    "remains problem",
    "rendered",
    "rendered difficult",
    "report",
    "reported",
    "reported applied",
    "represent state",
    "representations semantics",
    "research community",
    "researchers",
    "researchers creating",
    "resolved quite",
    "restoration",
    "restoration related",
    "results accurate",
    "results principled",
    "retrieval",
    "retrieval mechanism",
    "rise",
    "rise automatic",
    "role",
    "role knowledge",
    "role represents",
    "scenario",
    "scenario verb",
    "score prefer",
    "scripts",
    "segment",
    "segment given",
    "segmentation",
    "segmentation effect",
    "segmentation errors",
    "segmentation given",
    "segmentation multiple",
    "segmenters",
    "segmenters remains",
    "seg\u00e2 menter",
    "seman",
    "seman tic",
    "semantic components",
    "semantics",
    "semantics machine",
    "senses access",
    "sensitive",
    "sensitive spelling",
    "sensitive version",
    "sentence general",
    "sentence pairs",
    "sentence retrieval",
    "sentence word",
    "set 220",
    "sets",
    "settings",
    "shall",
    "shall demonstrate",
    "shallow",
    "shallow captured",
    "shared",
    "shared seman",
    "sharing different",
    "shot",
    "shown broad",
    "shown maximum",
    "shows",
    "shows achieves",
    "shows combination",
    "shows mada",
    "shows performance",
    "significant source",
    "significantly",
    "simple feature",
    "simply",
    "simply added",
    "simply arabic",
    "single evaluative",
    "single strongest",
    "small annotated",
    "smaller",
    "smaller subclasses",
    "smt",
    "sophisticated",
    "sophisticated linguistic",
    "source parsing",
    "space leading",
    "specific bilingual",
    "specific genre",
    "specific tasks",
    "speech assignment",
    "speech recognizer",
    "spelling",
    "spelling correction",
    "spend",
    "spend long",
    "st",
    "st humans",
    "standard arabic",
    "standard decision",
    "starting addressed",
    "starting point",
    "state art",
    "states",
    "states cities",
    "statistical",
    "statistical formalism",
    "stevenson 2003",
    "strongest",
    "strongest piece",
    "structure nonlexical",
    "stts",
    "stts tagset",
    "styles",
    "styles evaluation",
    "subclasses",
    "substantial amounts",
    "substructures",
    "subtype",
    "subtype founder",
    "subtypes",
    "subtypes subtype",
    "success",
    "success rate",
    "successfully",
    "successfully sophisticated",
    "suffers",
    "suffers small",
    "suggest",
    "suggest cases",
    "suggests useful",
    "supervised verb",
    "svms purpose",
    "svms represent",
    "syntactic aspect",
    "syntactic frames",
    "syntactic information",
    "systems rendered",
    "systems troll",
    "table",
    "table 8c",
    "table shows",
    "tagged training",
    "tagger possibility",
    "tagger trained",
    "tagger vote",
    "tagpair",
    "tags coarse",
    "tagset",
    "tagset additional",
    "takes",
    "takes yarowsky",
    "taking",
    "taking account",
    "task",
    "task context",
    "task formulated",
    "task framework",
    "task mining",
    "task word",
    "tasks order",
    "tense",
    "tense mood",
    "test",
    "test appropriate",
    "test corpora",
    "test data",
    "test preferred",
    "text single",
    "tic components",
    "tight",
    "time create",
    "tion levin",
    "tions",
    "tions applicability",
    "tive pattern",
    "tool computing",
    "topic",
    "topic admixture",
    "topic based",
    "topic sensitive",
    "topic specific",
    "topical translation",
    "topics",
    "topics word",
    "trained",
    "trained data",
    "training classifiers",
    "training method",
    "translate",
    "translate new",
    "translation english",
    "translation model",
    "translation models",
    "translation propose",
    "translation translate",
    "translations",
    "translations comparable",
    "transliteration",
    "transliteration information",
    "treat",
    "treat context",
    "tree",
    "tree learning",
    "trees application",
    "trees relation",
    "troll",
    "troll does",
    "twofold",
    "twofold hand",
    "type infereneing",
    "type role",
    "types persons",
    "understanding conference",
    "unfortunately usually",
    "unknown words",
    "unlike",
    "unlike previous",
    "unrestricted text",
    "unsupervised clustering",
    "unsupervised word",
    "unusual",
    "unusual opportunity",
    "updated",
    "updated new",
    "use contextual",
    "use global",
    "used balance",
    "used evaluations",
    "useful",
    "useful guidance",
    "useful nlp",
    "useful wordnet",
    "users looking",
    "using different",
    "using topic",
    "usually clear",
    "utility",
    "utility general",
    "variety paraphrases",
    "ve",
    "ve treat",
    "verb classification",
    "verbs",
    "verbs exhibit",
    "verbs languages",
    "version",
    "version ofthe",
    "vocabulary",
    "vocabulary rates",
    "vote",
    "vote majority",
    "vs discourse",
    "way",
    "way automatically",
    "way condition",
    "wide",
    "wide range",
    "wider",
    "wider variety",
    "word alignment",
    "word brown",
    "word disambiguation",
    "word levels",
    "word pair",
    "word translations",
    "wordnet limita",
    "wordnet senses",
    "words correctly",
    "words fung",
    "words readily",
    "words unrestricted",
    "work",
    "work reported",
    "work use",
    "works topical",
    "written chinese",
    "yarowsky",
    "yarowsky method",
    "yielded"
]