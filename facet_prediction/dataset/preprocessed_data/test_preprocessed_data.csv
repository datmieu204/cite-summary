refer_id,cite_id,refer_sids,refer_text,cite_sids,cite_text,cite_maker_sids,number,label,refer_sec_poss,refer_sec_pos_avg,refer_sec_pos_avg_nom,refer_sid_avg,refer_sid_avg_nom,refer_ssid_avg,refer_ssid_avg_nom,cite_sec_poss,cite_sec_pos_avg_nom,cite_sid_avg,cite_sid_avg_nom,cite_ssid_avg,cite_ssid_avg_nom,refer_sections,cite_sections
A00-2018,N10-1002,"[90, 91]","we created a parser based upon the maximumentropy-inspired model of the last section, smoothed using standard deleted interpolation.
as the generative model is top-down and we use a standard bottom-up best-first probabilistic chart parser [2,7], we use the chart parser as a first pass to generate candidate possible parses to be evaluated in the second pass by our probabilistic model.",[0],"as a benchmark vpc extraction system, we use the charniak parser (charniak, 2000)",[0],2,method,4_4,4.0,0.5714285714285714,90.5,0.4738219895287958,1.5,0.07500000000000001,0,0.0,0.0,0.0,0.0,0.0,"4 the experiment, 4 the experiment",abstract
A00-2018,W11-0610,[5],"we present a new parser for parsing down to penn tree-bank style parse trees [16] that achieves 90.1% average precision/recall for sentences of length < 40, and 89.5% for sentences of length < 100, when trained and tested on the previously established [5,9,10,15,17] &quot;standard&quot; sections of the wall street journal tree-bank.",[0],"each of these scores can be calculated from a provided syntactic parse tree, and to generate these we made use of the charniakparser (charniak, 2000), also trained on the switch board tree bank",[0],3,method,1,1.0,0.14285714285714285,5.0,0.02617801047120419,1.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
A00-2018,W06-3119,[90],"we created a parser based upon the maximumentropy-inspired model of the last section, smoothed using standard deleted interpolation.",[0],"we then use charniak? s parser (charniak, 2000) to generate the most likely parse tree for each english target sentence in the training corpus",[0],4,method,4,4.0,0.5714285714285714,90.0,0.4712041884816754,1.0,0.05,0,0.0,0.0,0.0,0.0,0.0,4 the experiment,abstract
A00-2018,N03-2024,"[48, 49, 51]","maximum-entropy models have two benefits for a parser builder.
first, as already implicit in our discussion, factoring the probability computation into a sequence of values corresponding to various &quot;features&quot; suggests that the probability model should be easily changeable — just change the set of features used.
second, and this is a point we have not yet mentioned, the features used in these models need have no particular independence of one another.",[0],"we were interested in the occurrence of features such as type and number of premodifiers, presence and type of post modifiers, and form of name reference for people. we constructed a large, automatically annotated corpus by merging the output of charniak? s statistical parser (charniak, 2000) with that of the ibm named entity recognition system nominator (wacholder et al,1997)",[0],5,method,3_3_3,3.0,0.42857142857142855,49.333333333333336,0.25828970331588136,18.333333333333332,0.3160919540229885,0,0.0,0.0,0.0,0.0,0.0,"3 maximum-entropy-inspired parsing, 3 maximum-entropy-inspired parsing, 3 maximum-entropy-inspired parsing",abstract
A00-2018,N06-1039,"[90, 91, 92, 93, 94]","we created a parser based upon the maximumentropy-inspired model of the last section, smoothed using standard deleted interpolation.
as the generative model is top-down and we use a standard bottom-up best-first probabilistic chart parser [2,7], we use the chart parser as a first pass to generate candidate possible parses to be evaluated in the second pass by our probabilistic model.
for runs with the generative model based upon markov grammar statistics, the first pass uses the same statistics, but conditioned only on standard pcfg information.
this allows the second pass to see expansions not present in the training corpus.
we use the gathered statistics for all observed words, even those with very low counts, though obviously our deleted interpolation smoothing gives less emphasis to observed probabilities for rare words.",[0],"after getting a set of basic clusters, we pass them to an existing statistical parser (charniak, 2000) and rule-based tree normalizer to obtain a glarfstructure for each sentence in every article",[0],6,method,4_4_4_4_4,4.0,0.5714285714285714,92.0,0.4816753926701571,3.0,0.15,0,0.0,0.0,0.0,0.0,0.0,"4 the experiment, 4 the experiment, 4 the experiment, 4 the experiment, 4 the experiment",abstract
A00-2018,C04-1180,[0],“na”,[0],"the levels of accuracy and robustness recently achieved by statistical parsers (e.g. collins (1999), charniak (2000)) have led to their use in a number of nlp applications, such as question-answering (pasca and harabagiu, 2001), machine translation (charniak et al, 2003), sentence simplification (carroll et al, 1999), and a linguist? s search engine (resnik and elkiss, 2003)",[0],7,result,0,0.0,0.0,0.0,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
A00-2018,W05-0638,[90],"we created a parser based upon the maximumentropy-inspired model of the last section, smoothed using standard deleted interpolation.",[0],"in conll-2005, full parsing trees are provided by two full parsers: the collins parser (collins, 1999) and the charniak parser (charniak, 2000)",[0],8,method,4,4.0,0.5714285714285714,90.0,0.4712041884816754,1.0,0.05,0,0.0,0.0,0.0,0.0,0.0,4 the experiment,abstract
A00-2018,P05-1065,"[90, 91, 92, 93, 94]","we created a parser based upon the maximumentropy-inspired model of the last section, smoothed using standard deleted interpolation.
as the generative model is top-down and we use a standard bottom-up best-first probabilistic chart parser [2,7], we use the chart parser as a first pass to generate candidate possible parses to be evaluated in the second pass by our probabilistic model.
for runs with the generative model based upon markov grammar statistics, the first pass uses the same statistics, but conditioned only on standard pcfg information.
this allows the second pass to see expansions not present in the training corpus.
we use the gathered statistics for all observed words, even those with very low counts, though obviously our deleted interpolation smoothing gives less emphasis to observed probabilities for rare words.",[0],"we also use a standard statistical parser (charniak, 2000) to provide syntactic analysis",[0],9,method,4_4_4_4_4,4.0,0.5714285714285714,92.0,0.4816753926701571,3.0,0.15,0,0.0,0.0,0.0,0.0,0.0,"4 the experiment, 4 the experiment, 4 the experiment, 4 the experiment, 4 the experiment",abstract
A00-2018,P05-1065,"[38, 39, 40]","to compute a probability in a log-linear model one first defines a set of &quot;features&quot;, functions from the space of configurations over which one is trying to compute probabilities to integers that denote the number of times some pattern occurs in the input.
in our work we assume that any feature can occur at most once, so features are boolean-valued: 0 if the pattern does not occur, 1 if it does.
in the parser we further assume that features are chosen from certain feature schemata and that every feature is a boolean conjunction of sub-features.",[0],"for each article, we calculated the per cent age of a) all word instances (tokens) and b) all unique words (types) not on these lists, resulting in three token oov rate features and three type oov rate features per article. the parse features are generated using the charniak parser (charniak, 2000) trained on the standard wall street journal treebank corpus",[0],10,method,3_3_3,3.0,0.42857142857142855,39.0,0.20418848167539266,8.0,0.13793103448275865,0,0.0,0.0,0.0,0.0,0.0,"3 maximum-entropy-inspired parsing, 3 maximum-entropy-inspired parsing, 3 maximum-entropy-inspired parsing",abstract
A00-2018,P04-1040,[174],we have presented a lexicalized markov grammar parsing model that achieves (using the now standard training/testing/development sections of the penn treebank) an average precision/recall of 91.1% on sentences of length < 40 and 89.5% on sentences of length < 100.,[0],"the evaluation of the transformed output of the parsers of charniak (2000) and collins (1999) gives 90 %unlabelled and 84 %labelled accuracy with respect to dependencies, when measured against a dependency corpus derived from the penn treebank.the paper is organized as follows",[0],11,result,6,6.0,0.8571428571428571,174.0,0.9109947643979057,1.0,0.058823529411764705,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
A00-2018,P04-1040,[85],"as partition-function calculation is typically the major on-line computational problem for maximum-entropy models, this simplifies the model significantly.",[0],"as an alternative to hard coded heuristics, blaheta and charniak (2000) proposed to recover the penn functional tags automatically",[0],13,method,3,3.0,0.42857142857142855,85.0,0.44502617801047123,54.0,0.9310344827586207,0,0.0,0.0,0.0,0.0,0.0,3 maximum-entropy-inspired parsing,abstract
A00-2018,N06-1022,"[63, 143, 146]","as we discuss in more detail in section 5, several different features in the context surrounding c are useful to include in h: the label, head pre-terminal and head of the parent of c (denoted as lp, tp, hp), the label of c's left sibling (lb for &quot;before&quot;), and the label of the grandparent of c (la).the first is simply that if we first guess the pre-terminal, when we go to guess the head the first thing we can condition upon is the pre-terminal, i.e., we compute p(h i t).the second major reason why first guessing the pre-terminal makes so much difference is that it can be used when backing off the lexical head in computing the probability of the rule expansion.",[0],"the parser of charniak (2000) is also a two-stage ctf model, where the first stage is a smoothed markov grammar (it uses up to three previous constituents as context), and the second stage is a lexicalized markov grammar with extra annotations about parents and grandparents",[0],17,method,3_5_5,4.333333333333333,0.6190476190476191,117.33333333333333,0.6143106457242583,34.333333333333336,0.5536997126436781,0,0.0,0.0,0.0,0.0,0.0,"3 maximum-entropy-inspired parsing, 5 discussion, 5 discussion",abstract
A00-2018,N06-1022,"[78, 79]","with some prior knowledge, non-zero values can greatly speed up this process because fewer iterations are required for convergence. we comment on this because in our example we can substantially speed up the process by choosing values picked so that, when the maximum-entropy equation is expressed in the form of equation 4, the gi have as their initial values the values of the corresponding terms in equation 7.",[0],"most recently, mcdonald et al (2005) have implemented a dependency parser with good accuracy (it is almost as good at dependency parsing as charniak (2000)) and very impressive speed (it is about ten times faster than collins (1997) and four times faster than charniak (2000))",[0],18,method,3_3,3.0,0.42857142857142855,78.5,0.4109947643979058,47.5,0.8189655172413792,0,0.0,0.0,0.0,0.0,0.0,"3 maximum-entropy-inspired parsing, 3 maximum-entropy-inspired parsing",abstract
A00-2018,H05-1035,[90],"we created a parser based upon the maximumentropy-inspired model of the last section, smoothed using standard deleted interpolation.",[0],"the feature set contains complex information extracted automatically from candidate syntax trees generated by parsing (charniak, 2000), trees that will be improved by more accurate pp-attachment decisions",[0],19,method,4,4.0,0.5714285714285714,90.0,0.4712041884816754,1.0,0.05,,,,,,,4 the experiment,
A00-2018,P04-1042,[174],we have presented a lexicalized markov grammar parsing model that achieves (using the now standard training/testing/development sections of the penn treebank) an average precision/recall of 91.1% on sentences of length < 40 and 89.5% on sentences of length < 100.,[0],"note that the dependency figures of dienes lag behind even the parsed results for johnson? s model; this may well be due to the fact that dienes built his model as an extension of collins (1999), which lags behind charniak (2000) by about 1.3-1.5% .manual investigation of errors on english gold standard data revealed two major issues that suggest further potential for improvement in performance without further increase in algorithmic complexity or training set size",[0],20,result,6,6.0,0.8571428571428571,174.0,0.9109947643979057,1.0,0.058823529411764705,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
A00-2018,N10-1002,[17],in section 5 we present some results in which the possible expansions of a constituent are fixed in advanced by extracting a tree-bank grammar [3] from the training corpus.,[0],"as a benchmark vpc extraction system, we use the charniak parser (charniak, 2000)",[0],2,method,2,2.0,0.2857142857142857,17.0,0.08900523560209424,6.0,0.3,0,0.0,0.0,0.0,0.0,0.0,2 the generative model,abstract
A00-2018,W11-0610,[5],"we present a new parser for parsing down to penn tree-bank style parse trees [16] that achieves 90.1% average precision/recall for sentences of length < 40, and 89.5% for sentences of length < 100, when trained and tested on the previously established [5,9,10,15,17] &quot;standard&quot; sections of the wall street journal tree-bank.",[0],"each of these scores can be calculated from a provided syntactic parse tree, and to generate these we made use of the charniakparser (charniak, 2000), also trained on the switch board tree bank",[0],3,method,1,1.0,0.14285714285714285,5.0,0.02617801047120419,1.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
A00-2018,W06-3119,[17],in section 5 we present some results in which the possible expansions of a constituent are fixed in advanced by extracting a tree-bank grammar [3] from the training corpus.,[0],"we then use charniak? s parser (charniak, 2000) to generate the most likely parse tree for each english target sentence in the training corpus",[0],4,method,2,2.0,0.2857142857142857,17.0,0.08900523560209424,6.0,0.3,0,0.0,0.0,0.0,0.0,0.0,2 the generative model,abstract
A00-2018,N03-2024,[120],"second, char97 uses unsupervised learning in that the original system was run on about thirty million words of unparsed text, the output was taken as &quot;correct&quot;, and statistics were collected on the resulting parses.",[0],"we were interested in the occurrence of features such as type and number of premodifiers, presence and type of post modifiers, and form of name reference for people. we constructed a large, automatically annotated corpus by merging the output of charniak? s statistical parser (charniak, 2000) with that of the ibm named entity recognition system nominator (wacholder et al,1997)",[0],5,method,5,5.0,0.7142857142857143,120.0,0.6282722513089005,11.0,0.171875,0,0.0,0.0,0.0,0.0,0.0,5 discussion,abstract
A00-2018,N06-1039,[119],(it is &quot;soft&quot; clustering in that a word can belong to more than one cluster with different weights - the weights express the probability of producing the word given that one is going to produce a word from that cluster.),[0],"after getting a set of basic clusters, we pass them to an existing statistical parser (charniak, 2000) and rule-based tree normalizer to obtain a glarfstructure for each sentence in every article",[0],6,method,5,5.0,0.7142857142857143,119.0,0.6230366492146597,10.0,0.15625,0,0.0,0.0,0.0,0.0,0.0,5 discussion,abstract
A00-2018,C04-1180,[95],"we guess the preterminals of words that are not observed in the training data using statistics on capitalization, hyphenation, word endings (the last two letters), and the probability that a given pre-terminal is realized using a previously unobserved word.",[0],"the levels of accuracy and robustness recently achieved by statistical parsers (e.g. collins (1999), charniak (2000)) have led to their use in a number of nlp applications, such as question-answering (pasca and harabagiu, 2001), machine translation (charniak et al, 2003), sentence simplification (carroll et al, 1999), and a linguist? s search engine (resnik and elkiss, 2003)",[0],7,method,4,4.0,0.5714285714285714,95.0,0.4973821989528796,6.0,0.3,0,0.0,0.0,0.0,0.0,0.0,4 the experiment,abstract
A00-2018,W05-0638,[175],"this corresponds to an error reduction of 13% over the best previously published single parser results on this test set, those of collins [9].",[0],"in conll-2005, full parsing trees are provided by two full parsers: the collins parser (collins, 1999) and the charniak parser (charniak, 2000)",[0],8,method,6,6.0,0.8571428571428571,175.0,0.9162303664921466,2.0,0.11764705882352941,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
A00-2018,P05-1065,[92],"for runs with the generative model based upon markov grammar statistics, the first pass uses the same statistics, but conditioned only on standard pcfg information.",[0],"we also use a standard statistical parser (charniak, 2000) to provide syntactic analysis",[0],9,method,4,4.0,0.5714285714285714,92.0,0.4816753926701571,3.0,0.15,0,0.0,0.0,0.0,0.0,0.0,4 the experiment,abstract
A00-2018,P05-1065,[1],"we present a new parser for parsing down to penn tree-bank style parse trees that achieves 90.1% average precision/recall for sentences of 40 and less, and for of length 100 and less when trained and tested on the previously established [5,9,10,15,17] &quot;standard&quot; sections of the wall street journal treebank.",[0],"for each article, we calculated the per cent age of a) all word instances (tokens) and b) all unique words (types) not on these lists, resulting in three token oov rate features and three type oov rate features per article. the parse features are generated using the charniak parser (charniak, 2000) trained on the standard wall street journal treebank corpus",[0],10,method,0,0.0,0.0,1.0,0.005235602094240838,1.0,0.2,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
A00-2018,P04-1040,[126],"this is indicated in figure 2, where the model labeled &quot;best&quot; has precision of 89.8% and recall of 89.6% for an average of 89.7%, 0.4% lower than the results on the official test corpus.",[0],"the evaluation of the transformed output of the parsers of charniak (2000) and collins (1999) gives 90 %unlabelled and 84 %labelled accuracy with respect to dependencies, when measured against a dependency corpus derived from the penn treebank.the paper is organized as follows",[0],11,method,5,5.0,0.7142857142857143,126.0,0.6596858638743456,17.0,0.265625,0,0.0,0.0,0.0,0.0,0.0,5 discussion,abstract
A00-2018,P04-1040,[12],"the model assigns a probability to a parse by a top-down process of considering each constituent c in ir and for each c first guessing the pre-terminal of c, t(c) (t for &quot;tag&quot;), then the lexical head of c, h(c), and then the expansion of c into further constituents e(c).",[0],"blaheta and charniak (2000) presented the first method for assigning pennfunctional tags to constituents identified by a parser. pattern-matching approaches were used in (john son, 2002) and (jijkoun, 2003) to recover non-local dependencies in phrase trees",[0],12,method,2,2.0,0.2857142857142857,12.0,0.06282722513089005,1.0,0.05,0,0.0,0.0,0.0,0.0,0.0,2 the generative model,abstract
A00-2018,P04-1040,[174],we have presented a lexicalized markov grammar parsing model that achieves (using the now standard training/testing/development sections of the penn treebank) an average precision/recall of 91.1% on sentences of length < 40 and 89.5% on sentences of length < 100.,[0],"as an alternative to hard coded heuristics, blaheta and charniak (2000) proposed to recover the penn functional tags automatically",[0],13,method,6,6.0,0.8571428571428571,174.0,0.9109947643979057,1.0,0.058823529411764705,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
A00-2018,N06-1022,[63],"as we discuss in more detail in section 5, several different features in the context surrounding c are useful to include in h: the label, head pre-terminal and head of the parent of c (denoted as lp, tp, hp), the label of c's left sibling (lb for &quot;before&quot;), and the label of the grandparent of c (la).",[0],"the parser of charniak (2000) is also a two-stage ctf model, where the first stage is a smoothed markov grammar (it uses up to three previous constituents as context), and the second stage is a lexicalized markov grammar with extra annotations about parents and grandparents",[0],17,method,3,3.0,0.42857142857142855,63.0,0.3298429319371728,32.0,0.5517241379310345,0,0.0,0.0,0.0,0.0,0.0,3 maximum-entropy-inspired parsing,abstract
A00-2018,N06-1022,[78],"with some prior knowledge, non-zero values can greatly speed up this process because fewer iterations are required for convergence.",[0],"most recently, mcdonald et al (2005) have implemented a dependency parser with good accuracy (it is almost as good at dependency parsing as charniak (2000)) and very impressive speed (it is about ten times faster than collins (1997) and four times faster than charniak (2000))",[0],18,method,3,3.0,0.42857142857142855,78.0,0.4083769633507853,47.0,0.8103448275862069,0,0.0,0.0,0.0,0.0,0.0,3 maximum-entropy-inspired parsing,abstract
A00-2018,H05-1035,[91],"as the generative model is top-down and we use a standard bottom-up best-first probabilistic chart parser [2,7], we use the chart parser as a first pass to generate candidate possible parses to be evaluated in the second pass by our probabilistic model.",[0],"the feature set contains complex information extracted automatically from candidate syntax trees generated by parsing (charniak, 2000), trees that will be improved by more accurate pp-attachment decisions",[0],19,method,4,4.0,0.5714285714285714,91.0,0.47643979057591623,2.0,0.1,,,,,,,4 the experiment,
A00-2018,P04-1042,[180],"from our perspective, perhaps the two most important numbers to come out of this research are the overall error reduction of 13% over the results in [9] and the intermediateresult improvement of nearly 2% on labeled precision/recall due to the simple idea of guessing the head's pre-terminal before guessing the head.",[0],"note that the dependency figures of dienes lag behind even the parsed results for johnson? s model; this may well be due to the fact that dienes built his model as an extension of collins (1999), which lags behind charniak (2000) by about 1.3-1.5% .manual investigation of errors on english gold standard data revealed two major issues that suggest further potential for improvement in performance without further increase in algorithmic complexity or training set size",[0],20,method,6,6.0,0.8571428571428571,180.0,0.9424083769633508,7.0,0.4117647058823529,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
A00-2018,N10-1002,[5],"we present a new parser for parsing down to penn tree-bank style parse trees [16] that achieves 90.1% average precision/recall for sentences of length < 40, and 89.5% for sentences of length < 100, when trained and tested on the previously established [5,9,10,15,17] &quot;standard&quot; sections of the wall street journal tree-bank.",[0],"as a benchmark vpc extraction system, we use the charniak parser (charniak, 2000)",[0],2,method,1,1.0,0.14285714285714285,5.0,0.02617801047120419,1.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
A00-2018,W11-0610,[5],"we present a new parser for parsing down to penn tree-bank style parse trees [16] that achieves 90.1% average precision/recall for sentences of length < 40, and 89.5% for sentences of length < 100, when trained and tested on the previously established [5,9,10,15,17] &quot;standard&quot; sections of the wall street journal tree-bank.",[0],"each of these scores can be calculated from a provided syntactic parse tree, and to generate these we made use of the charniakparser (charniak, 2000), also trained on the switch board tree bank",[0],3,method,1,1.0,0.14285714285714285,5.0,0.02617801047120419,1.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
A00-2018,W06-3119,[91],"as the generative model is top-down and we use a standard bottom-up best-first probabilistic chart parser [2,7], we use the chart parser as a first pass to generate candidate possible parses to be evaluated in the second pass by our probabilistic model.",[0],"we then use charniak? s parser (charniak, 2000) to generate the most likely parse tree for each english target sentence in the training corpus",[0],4,method,4,4.0,0.5714285714285714,91.0,0.47643979057591623,2.0,0.1,0,0.0,0.0,0.0,0.0,0.0,4 the experiment,abstract
A00-2018,N03-2024,[39],"in our work we assume that any feature can occur at most once, so features are boolean-valued: 0 if the pattern does not occur, 1 if it does.",[0],"we were interested in the occurrence of features such as type and number of premodifiers, presence and type of post modifiers, and form of name reference for people. we constructed a large, automatically annotated corpus by merging the output of charniak? s statistical parser (charniak, 2000) with that of the ibm named entity recognition system nominator (wacholder et al,1997)",[0],5,method,3,3.0,0.42857142857142855,39.0,0.20418848167539266,8.0,0.13793103448275862,0,0.0,0.0,0.0,0.0,0.0,3 maximum-entropy-inspired parsing,abstract
A00-2018,C04-1180,[162],"given we are already at the 88% level of accuracy, we judge a 0.6% improvement to be very much worth while.",[0],"the levels of accuracy and robustness recently achieved by statistical parsers (e.g. collins (1999), charniak (2000)) have led to their use in a number of nlp applications, such as question-answering (pasca and harabagiu, 2001), machine translation (charniak et al, 2003), sentence simplification (carroll et al, 1999), and a linguist? s search engine (resnik and elkiss, 2003)",[0],7,method,5,5.0,0.7142857142857143,162.0,0.8481675392670157,53.0,0.828125,0,0.0,0.0,0.0,0.0,0.0,5 discussion,abstract
A00-2018,W05-0638,[87],"in a pure maximum-entropy model this is done by feature selection, as in ratnaparkhi's maximum-entropy parser [17].",[0],"in conll-2005, full parsing trees are provided by two full parsers: the collins parser (collins, 1999) and the charniak parser (charniak, 2000)",[0],8,method,3,3.0,0.42857142857142855,87.0,0.45549738219895286,56.0,0.9655172413793104,0,0.0,0.0,0.0,0.0,0.0,3 maximum-entropy-inspired parsing,abstract
A00-2018,P05-1065,[91],"as the generative model is top-down and we use a standard bottom-up best-first probabilistic chart parser [2,7], we use the chart parser as a first pass to generate candidate possible parses to be evaluated in the second pass by our probabilistic model.",[0],"we also use a standard statistical parser (charniak, 2000) to provide syntactic analysis",[0],9,method,4,4.0,0.5714285714285714,91.0,0.47643979057591623,2.0,0.1,0,0.0,0.0,0.0,0.0,0.0,4 the experiment,abstract
A00-2018,P05-1065,[176],"that the previous three best parsers on this test [5,9,17] all perform within a percentage point of each other, despite quite different basic mechanisms, led some researchers to wonder if there might be some maximum level of parsing performance that could be obtained using the treebank for training, and to conjecture that perhaps we were at it.",[0],"for each article, we calculated the per cent age of a) all word instances (tokens) and b) all unique words (types) not on these lists, resulting in three token oov rate features and three type oov rate features per article. the parse features are generated using the charniak parser (charniak, 2000) trained on the standard wall street journal treebank corpus",[0],10,method,6,6.0,0.8571428571428571,176.0,0.9214659685863874,3.0,0.17647058823529413,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
A00-2018,P04-1040,[174],we have presented a lexicalized markov grammar parsing model that achieves (using the now standard training/testing/development sections of the penn treebank) an average precision/recall of 91.1% on sentences of length < 40 and 89.5% on sentences of length < 100.,[0],"the evaluation of the transformed output of the parsers of charniak (2000) and collins (1999) gives 90 %unlabelled and 84 %labelled accuracy with respect to dependencies, when measured against a dependency corpus derived from the penn treebank.the paper is organized as follows",[0],11,method,6,6.0,0.8571428571428571,174.0,0.9109947643979057,1.0,0.058823529411764705,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
A00-2018,P04-1040,[101],"in keeping with the standard methodology [5, 9,10,15,17], we used the penn wall street journal tree-bank [16] with sections 2-21 for training, section 23 for testing, and section 24 for development (debugging and tuning).",[0],"blaheta and charniak (2000) presented the first method for assigning pennfunctional tags to constituents identified by a parser. pattern-matching approaches were used in (john son, 2002) and (jijkoun, 2003) to recover non-local dependencies in phrase trees",[0],12,method,4,4.0,0.5714285714285714,101.0,0.5287958115183246,12.0,0.6,0,0.0,0.0,0.0,0.0,0.0,4 the experiment,abstract
A00-2018,P04-1040,[155],"for example, in the penn treebank a vp with both main and auxiliary verbs has the structure shown in figure 3.",[0],"as an alternative to hard coded heuristics, blaheta and charniak (2000) proposed to recover the penn functional tags automatically",[0],13,method,5,5.0,0.7142857142857143,155.0,0.8115183246073299,46.0,0.71875,0,0.0,0.0,0.0,0.0,0.0,5 discussion,abstract
A00-2018,P04-1040,[17],in section 5 we present some results in which the possible expansions of a constituent are fixed in advanced by extracting a tree-bank grammar [3] from the training corpus.,[0],"thus, it is informative to compare our results with those reported in (blaheta and charniak, 2000) for this same task",[0],14,method,2,2.0,0.2857142857142857,17.0,0.08900523560209424,6.0,0.3,0,0.0,0.0,0.0,0.0,0.0,2 the generative model,abstract
A00-2018,P04-1040,[162],"given we are already at the 88% level of accuracy, we judge a 0.6% improvement to be very much worth while.",[0],"method accuracy p r f blaheta 98.6 87.2 87.4 87.3 this paper 94.7 90.2 86.9 88.5 the difference in the accuracy is due to two reasons. first, because of the different definition of a correctly identified constituent in the parser? s output, we apply our method to a greater portion of all labels produced by the parser (95% vs. 89% reported in (blaheta and charniak, 2000))",[0],15,method,5,5.0,0.7142857142857143,162.0,0.8481675392670157,53.0,0.828125,0,0.0,0.0,0.0,0.0,0.0,5 discussion,abstract
A00-2018,N06-1022,[40],in the parser we further assume that features are chosen from certain feature schemata and that every feature is a boolean conjunction of sub-features.,[0],"the parser of charniak (2000) is also a two-stage ctf model, where the first stage is a smoothed markov grammar (it uses up to three previous constituents as context), and the second stage is a lexicalized markov grammar with extra annotations about parents and grandparents",[0],17,method,3,3.0,0.42857142857142855,40.0,0.2094240837696335,9.0,0.15517241379310345,0,0.0,0.0,0.0,0.0,0.0,3 maximum-entropy-inspired parsing,abstract
A00-2018,N06-1022,[79],"we comment on this because in our example we can substantially speed up the process by choosing values picked so that, when the maximum-entropy equation is expressed in the form of equation 4, the gi have as their initial values the values of the corresponding terms in equation 7.",[0],"most recently, mcdonald et al (2005) have implemented a dependency parser with good accuracy (it is almost as good at dependency parsing as charniak (2000)) and very impressive speed (it is about ten times faster than collins (1997) and four times faster than charniak (2000))",[0],18,method,3,3.0,0.42857142857142855,79.0,0.41361256544502617,48.0,0.8275862068965517,0,0.0,0.0,0.0,0.0,0.0,3 maximum-entropy-inspired parsing,abstract
A00-2018,H05-1035,[40],in the parser we further assume that features are chosen from certain feature schemata and that every feature is a boolean conjunction of sub-features.,[0],"the feature set contains complex information extracted automatically from candidate syntax trees generated by parsing (charniak, 2000), trees that will be improved by more accurate pp-attachment decisions",[0],19,method,3,3.0,0.42857142857142855,40.0,0.2094240837696335,9.0,0.15517241379310345,,,,,,,3 maximum-entropy-inspired parsing,
A00-2018,P04-1042,[175],"this corresponds to an error reduction of 13% over the best previously published single parser results on this test set, those of collins [9].",[0],"note that the dependency figures of dienes lag behind even the parsed results for johnson? s model; this may well be due to the fact that dienes built his model as an extension of collins (1999), which lags behind charniak (2000) by about 1.3-1.5% .manual investigation of errors on english gold standard data revealed two major issues that suggest further potential for improvement in performance without further increase in algorithmic complexity or training set size",[0],20,method,6,6.0,0.8571428571428571,175.0,0.9162303664921466,2.0,0.11764705882352941,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
A00-2030,W01-0510,[4],"in this paper, we report adapting a lexicalized, probabilistic context-free parser with head rules (lpcfg-hr) to information extraction.",[0],"section 5 compares our approach tooth ers in the literature, in particular that of (miller et al., 2000)",[0],1,method,1,1.0,0.07142857142857142,4.0,0.035398230088495575,2.0,0.25,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
A00-2030,W01-0510,"[33, 34]","our integrated model represents syntax and semantics jointly using augmented parse trees.
in these trees, the standard treebank structures are augmented to convey semantic information, that is, entities and relations.",[0],"the basic approach we described is very similar to the one presented in (miller et al, 2000) however there are a few major di erences: in our approach the augmentation of the syn tactic tags with semantic tags is straightforward due to the fact that the semantic constituents are matched exactly 5. the approach in (miller",[0],2,method,4_4,4.0,0.2857142857142857,33.5,0.29646017699115046,1.5,0.1875,0,0.0,0.0,0.0,0.0,0.0,"4 representing syntax and semantics jointly, 4 representing syntax and semantics jointly",abstract
A00-2030,W01-0510,"[49, 50]","by necessity, we adopted the strategy of hand marking only the semantics.
figure 4 shows an example of the semantic annotation, which was the only type of manual annotation we performed.",[0],"the semantic annotation required by our task is much simpler than that employed by (miller et al, 2000)",[0],3,method,5_5,5.0,0.35714285714285715,49.5,0.43805309734513276,9.5,0.8636363636363636,0,0.0,0.0,0.0,0.0,0.0,"5 creating the training data, 5 creating the training data",abstract
A00-2030,W01-0510,"[33, 34]","our integrated model represents syntax and semantics jointly using augmented parse trees.
in these trees, the standard treebank structures are augmented to convey semantic information, that is, entities and relations.",[0],"one possibly bene cial extension of our work suggested by (miller et al, 2000) would be to add semantic tags describing relations between entities (slots), in which case the semantic constraints would not be structured strictly on the two levels used in the current approach, respectively frame and slot level",[0],4,method,4_4,4.0,0.2857142857142857,33.5,0.29646017699115046,1.5,0.1875,0,0.0,0.0,0.0,0.0,0.0,"4 representing syntax and semantics jointly, 4 representing syntax and semantics jointly",abstract
A00-2030,W01-0510,[10],"instead, our parsing algorithm, trained on the upenn treebank, was run on the new york times source to create unsupervised syntactic training which was constrained to be consistent with semantic annotation.",[0],"similar to the approach in (miller et al, 2000 )weinitialized the slm statistics from the upenn tree bank parse trees (about 1mwds of training data) at the rst training stage, see section 3",[0],5,method,1,1.0,0.07142857142857142,10.0,0.08849557522123894,8.0,1.0,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
A00-2030,P14-1078,[16],"for the following example, the the template relations (tr) task involves identifying instances of three relations in the text: tr builds on te in that tr reports binary relations between elements of te.",[0],"rule-based methods (miller et al, 2000) employ a number of linguistic rules to capture relation patterns",[0],6,method,2,2.0,0.14285714285714285,16.0,0.1415929203539823,6.0,0.8571428571428571,0,0.0,0.0,0.0,0.0,0.0,2 information extraction tasks,abstract
A00-2030,P05-1061,"[33, 34]","our integrated model represents syntax and semantics jointly using augmented parse trees.
in these trees, the standard treebank structures are augmented to convey semantic information, that is, entities and relations.",[0],"one interesting system that does not belong to the above class is that of miller et al (2000), who take the view that relation extraction is just a form of probabilistic parsing where parse trees are augmented to identify all relations",[0],7,method,4_4,4.0,0.2857142857142857,33.5,0.29646017699115046,1.5,0.1875,0,0.0,0.0,0.0,0.0,0.0,"4 representing syntax and semantics jointly, 4 representing syntax and semantics jointly",abstract
A00-2030,P05-1053,"[33, 34]","our integrated model represents syntax and semantics jointly using augmented parse trees.
in these trees, the standard treebank structures are augmented to convey semantic information, that is, entities and relations.",[0],"miller et al (2000) augmented syntactic full parse trees with semantic information corresponding to entities and relations, and built generative models for the augmented trees",[0],8,method,4_4,4.0,0.2857142857142857,33.5,0.29646017699115046,1.5,0.1875,0,0.0,0.0,0.0,0.0,0.0,"4 representing syntax and semantics jointly, 4 representing syntax and semantics jointly",abstract
A00-2030,P05-1053,"[23, 24]","an integrated model can limit the propagation of errors by making all decisions jointly.
for this reason, we focused on designing an integrated model in which tagging, namefinding, parsing, and semantic interpretation decisions all have the opportunity to mutually influence each other.",[0],"complicated relation extraction tasks may also impose a big challenge to the modeling approach used by miller et al (2000) which integrates various tasks such as part-of-speech tagging, named entity recognition, template element extraction and relation extraction, in a single model",[0],9,method,3_3,3.0,0.21428571428571427,23.5,0.2079646017699115,6.5,0.43333333333333335,0,0.0,0.0,0.0,0.0,0.0,"3 integrated sentential processing, 3 integrated sentential processing",abstract
A00-2030,H05-1094,"[23, 24]","an integrated model can limit the propagation of errors by making all decisions jointly.
for this reason, we focused on designing an integrated model in which tagging, namefinding, parsing, and semantic interpretation decisions all have the opportunity to mutually influence each other.",[0],"(miller et al, 2000) have combined entity recognition, parsing, and relation extraction into a jointly-trained single statistical parsing model that achieves improved performance on all the subtasks. part of the contribution of the current work is to suggest that joint decoding can be effective even when joint training is not possible because jointly-labeled data is unavailable",[0],10,method,3_3,3.0,0.21428571428571427,23.5,0.2079646017699115,6.5,0.43333333333333335,0,0.0,0.0,0.0,0.0,0.0,"3 integrated sentential processing, 3 integrated sentential processing",abstract
A00-2030,P04-1054,"[23, 24, 33, 34]","an integrated model can limit the propagation of errors by making all decisions jointly.
for this reason, we focused on designing an integrated model in which tagging, namefinding, parsing, and semantic interpretation decisions all have the opportunity to mutually influence each other.our integrated model represents syntax and semantics jointly using augmented parse trees.
in these trees, the standard treebank structures are augmented to convey semantic information, that is, entities and relations.",[0],miller et al (2000) propose an integrated statistical parsing technique that augments parse trees with semantic labels denoting entity and relation types,[0],11,method,3_3_4_4,3.5,0.24999999999999997,28.5,0.252212389380531,4.0,0.3104166666666667,0,0.0,0.0,0.0,0.0,0.0,"3 integrated sentential processing, 3 integrated sentential processing, 4 representing syntax and semantics jointly, 4 representing syntax and semantics jointly",abstract
A00-2030,P04-1054,"[33, 34]","our integrated model represents syntax and semantics jointly using augmented parse trees.
in these trees, the standard treebank structures are augmented to convey semantic information, that is, entities and relations.",[0],"whereasmiller et al (2000) use a generative model to produce parse information as well as relation information, we hypothesize that a technique discriminatively trained to classify relations will achieve better performance",[0],12,method,4_4,4.0,0.2857142857142857,33.5,0.29646017699115046,1.5,0.1875,0,0.0,0.0,0.0,0.0,0.0,"4 representing syntax and semantics jointly, 4 representing syntax and semantics jointly",abstract
A00-2030,W05-0602,"[60, 61]","in our statistical model, trees are generated according to a process similar to that described in (collins 1996, 1997).
the detailed probability structure differs, however, in that it was designed to jointly perform part-of-speech tagging, name finding, syntactic parsing, and relation finding in a single process.",[0],"the syntactic model in (miller et al, 2000) is similar to collins?, but doesnot use features like sub cat frames and distance measures",[0],13,method,8_8,8.0,0.5714285714285714,60.5,0.5353982300884956,1.5,0.07894736842105263,0,0.0,0.0,0.0,0.0,0.0,"7 model structure, 7 model structure",abstract
A00-2030,N07-2041,[33],our integrated model represents syntax and semantics jointly using augmented parse trees.,[0],"similar to the approach in (miller et al, 2000) and (kulick et al, 2004), our parser integrates both syntactic and semantic annotations into a single annotation as shown in figure 2",[0],14,method,4,4.0,0.2857142857142857,33.0,0.2920353982300885,1.0,0.125,0,0.0,0.0,0.0,0.0,0.0,4 representing syntax and semantics jointly,abstract
A00-2030,W10-2924,"[33, 34]","our integrated model represents syntax and semantics jointly using augmented parse trees.
in these trees, the standard treebank structures are augmented to convey semantic information, that is, entities and relations.",[0],miller et al (2000) adapt a probabilistic context-free parser for information extraction by augmenting syntactic labels with entity and relation labels,[0],15,method,4_4,4.0,0.2857142857142857,33.5,0.29646017699115046,1.5,0.1875,0,0.0,0.0,0.0,0.0,0.0,"4 representing syntax and semantics jointly, 4 representing syntax and semantics jointly",abstract
A00-2030,W06-0508,"[33, 34]","our integrated model represents syntax and semantics jointly using augmented parse trees.
in these trees, the standard treebank structures are augmented to convey semantic information, that is, entities and relations.",[0],"most of the approaches for relation extraction rely on the mapping of syntactic dependencies, such as svo, onto semantic relations, using either pattern matching or other strategies, such as probabilistic parsing for trees augmented with annotations for entities and relations (miller et al 2000), or clustering of semantically similar syntactic dependencies, according to their selectional restrictions (gamallo et al, 2002)",[0],16,method,4_4,4.0,0.2857142857142857,33.5,0.29646017699115046,1.5,0.1875,0,0.0,0.0,0.0,0.0,0.0,"4 representing syntax and semantics jointly, 4 representing syntax and semantics jointly",abstract
A00-2030,P07-1055,"[11, 12, 16]","we evaluated the new approach to information extraction on two of the tasks of the seventh message understanding conference (muc-7) and reported in (marsh, 1998).
the template element (te) task identifies organizations, persons, locations, and some artifacts (rocket and airplane-related artifacts).for the following example, the the template relations (tr) task involves identifying instances of three relations in the text: tr builds on te in that tr reports binary relations between elements of te.",[0],"this includes parsing and relation extraction (miller et al, 2000), entity labeling and relation extraction (roth and yih, 2004), and part-of-speech tagging and chunking (sutton et al, 2004)",[0],17,method,2_2_2,2.0,0.14285714285714285,13.0,0.11504424778761062,3.0,0.42857142857142855,0,0.0,0.0,0.0,0.0,0.0,"2 information extraction tasks, 2 information extraction tasks, 2 information extraction tasks",abstract
A00-2030,W05-0636,[105],"a single model proved capable of performing all necessary sentential processing, both syntactic and semantic.",[0],"for example, miller et al (2000) showed that performing parsing and information extraction in a joint model improves performance on both tasks",[0],18,result,12,12.0,0.8571428571428571,105.0,0.9292035398230089,2.0,0.4,0,0.0,0.0,0.0,0.0,0.0,11 conclusions,abstract
A00-2030,N06-1037,"[60, 61]","in our statistical model, trees are generated according to a process similar to that described in (collins 1996, 1997).
the detailed probability structure differs, however, in that it was designed to jointly perform part-of-speech tagging, name finding, syntactic parsing, and relation finding in a single process.",[0],miller et al (2000) address the task of relation extraction from the statistical parsing viewpoint,[0],19,method,8_8,8.0,0.5714285714285714,60.5,0.5353982300884956,1.5,0.07894736842105263,0,0.0,0.0,0.0,0.0,0.0,"7 model structure, 7 model structure",abstract
A00-2030,D11-1132,[16],"for the following example, the the template relations (tr) task involves identifying instances of three relations in the text: tr builds on te in that tr reports binary relations between elements of te.",[0],"rule-based methods (miller et al, 2000) employ a number of linguistic rules to capture relation patterns",[0],20,method,2,2.0,0.14285714285714285,16.0,0.1415929203539823,6.0,0.8571428571428571,0,0.0,0.0,0.0,0.0,0.0,2 information extraction tasks,abstract
A00-2030,W01-0510,[18],almost all approaches to information extraction — even at the sentence level — are based on the divide-and-conquer strategy of reducing a complex problem to a set of simpler ones.,[0],"section 5 compares our approach tooth ers in the literature, in particular that of (miller et al., 2000)",[0],1,method,3,3.0,0.21428571428571427,18.0,0.1592920353982301,1.0,0.06666666666666667,0,0.0,0.0,0.0,0.0,0.0,3 integrated sentential processing,abstract
A00-2030,W01-0510,[100],"given multiple constituents that cover identical spans in the chart, only those constituents with probabilities within a while our focus throughout the project was on te and tr, we became curious about how well the model did at part-of-speech tagging, syntactic parsing, and at name finding.",[0],"the basic approach we described is very similar to the one presented in (miller et al, 2000) however there are a few major di erences: in our approach the augmentation of the syn tactic tags with semantic tags is straightforward due to the fact that the semantic constituents are matched exactly 5. the approach in (miller",[0],2,method,11,11.0,0.7857142857142857,100.0,0.8849557522123894,5.0,0.625,0,0.0,0.0,0.0,0.0,0.0,10 experimental results,abstract
A00-2030,W01-0510,[52],"in this section, we describe the algorithm that was used to automatically produce augmented trees, starting with a) human-generated semantic annotations and b) machinegenerated syntactic parse trees.",[0],"the semantic annotation required by our task is much simpler than that employed by (miller et al, 2000)",[0],3,method,6,6.0,0.42857142857142855,52.0,0.46017699115044247,1.0,0.3333333333333333,0,0.0,0.0,0.0,0.0,0.0,6 tree augmentation,abstract
A00-2030,W01-0510,[34],"in these trees, the standard treebank structures are augmented to convey semantic information, that is, entities and relations.",[0],"one possibly bene cial extension of our work suggested by (miller et al, 2000) would be to add semantic tags describing relations between entities (slots), in which case the semantic constraints would not be structured strictly on the two levels used in the current approach, respectively frame and slot level",[0],4,method,4,4.0,0.2857142857142857,34.0,0.3008849557522124,2.0,0.25,0,0.0,0.0,0.0,0.0,0.0,4 representing syntax and semantics jointly,abstract
A00-2030,W01-0510,[1],"since 1995, a few statistical parsing algorithms have demonstrated a breakthrough in parsing accuracy, as measured against the upenn treebank as a gold standard.",[0],"similar to the approach in (miller et al, 2000 )weinitialized the slm statistics from the upenn tree bank parse trees (about 1mwds of training data) at the rst training stage, see section 3",[0],5,method,0,0.0,0.0,1.0,0.008849557522123894,1.0,0.3333333333333333,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
A00-2030,P14-1078,[61],"the detailed probability structure differs, however, in that it was designed to jointly perform part-of-speech tagging, name finding, syntactic parsing, and relation finding in a single process.",[0],"rule-based methods (miller et al, 2000) employ a number of linguistic rules to capture relation patterns",[0],6,method,8,8.0,0.5714285714285714,61.0,0.5398230088495575,2.0,0.10526315789473684,0,0.0,0.0,0.0,0.0,0.0,7 model structure,abstract
A00-2030,P05-1061,[104],"we have demonstrated, at least for one problem, that a lexicalized, probabilistic context-free parser with head rules (lpcfghr) can be used effectively for information extraction.",[0],"one interesting system that does not belong to the above class is that of miller et al (2000), who take the view that relation extraction is just a form of probabilistic parsing where parse trees are augmented to identify all relations",[0],7,method,12,12.0,0.8571428571428571,104.0,0.9203539823008849,1.0,0.2,0,0.0,0.0,0.0,0.0,0.0,11 conclusions,abstract
A00-2030,P05-1053,[32],"because generative statistical models had already proven successful for each of the first three stages, we were optimistic that some of their properties — especially their ability to learn from large amounts of data, and their robustness when presented with unexpected inputs — would also benefit semantic analysis.",[0],"miller et al (2000) augmented syntactic full parse trees with semantic information corresponding to entities and relations, and built generative models for the augmented trees",[0],8,method,3,3.0,0.21428571428571427,32.0,0.2831858407079646,15.0,1.0,0,0.0,0.0,0.0,0.0,0.0,3 integrated sentential processing,abstract
A00-2030,P05-1053,[2],"in this paper we report adapting a lexic al ized, probabilistic context-free parser to information extraction and evaluate this new technique on muc-7 template elements and template relations.",[0],"complicated relation extraction tasks may also impose a big challenge to the modeling approach used by miller et al (2000) which integrates various tasks such as part-of-speech tagging, named entity recognition, template element extraction and relation extraction, in a single model",[0],9,method,0,0.0,0.0,2.0,0.017699115044247787,2.0,0.6666666666666666,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
A00-2030,H05-1094,[61],"the detailed probability structure differs, however, in that it was designed to jointly perform part-of-speech tagging, name finding, syntactic parsing, and relation finding in a single process.",[0],"(miller et al, 2000) have combined entity recognition, parsing, and relation extraction into a jointly-trained single statistical parsing model that achieves improved performance on all the subtasks. part of the contribution of the current work is to suggest that joint decoding can be effective even when joint training is not possible because jointly-labeled data is unavailable",[0],10,method,8,8.0,0.5714285714285714,61.0,0.5398230088495575,2.0,0.10526315789473684,0,0.0,0.0,0.0,0.0,0.0,7 model structure,abstract
A00-2030,P04-1054,[33],our integrated model represents syntax and semantics jointly using augmented parse trees.,[0],miller et al (2000) propose an integrated statistical parsing technique that augments parse trees with semantic labels denoting entity and relation types,[0],11,method,4,4.0,0.2857142857142857,33.0,0.2920353982300885,1.0,0.125,0,0.0,0.0,0.0,0.0,0.0,4 representing syntax and semantics jointly,abstract
A00-2030,P04-1054,[34],"in these trees, the standard treebank structures are augmented to convey semantic information, that is, entities and relations.",[0],"whereasmiller et al (2000) use a generative model to produce parse information as well as relation information, we hypothesize that a technique discriminatively trained to classify relations will achieve better performance",[0],12,method,4,4.0,0.2857142857142857,34.0,0.3008849557522124,2.0,0.25,0,0.0,0.0,0.0,0.0,0.0,4 representing syntax and semantics jointly,abstract
A00-2030,W05-0602,[3],"since 1995, a few statistical parsing algorithms (magerman, 1995; collins, 1996 and 1997; charniak, 1997; rathnaparki, 1997) demonstrated a breakthrough in parsing accuracy, as measured against the university of pennsylvania treebank as a gold standard.",[0],"the syntactic model in (miller et al, 2000) is similar to collins?, but doesnot use features like sub cat frames and distance measures",[0],13,method,1,1.0,0.07142857142857142,3.0,0.02654867256637168,1.0,0.125,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
A00-2030,N07-2041,[52],"in this section, we describe the algorithm that was used to automatically produce augmented trees, starting with a) human-generated semantic annotations and b) machinegenerated syntactic parse trees.",[0],"similar to the approach in (miller et al, 2000) and (kulick et al, 2004), our parser integrates both syntactic and semantic annotations into a single annotation as shown in figure 2",[0],14,method,6,6.0,0.42857142857142855,52.0,0.46017699115044247,1.0,0.3333333333333333,0,0.0,0.0,0.0,0.0,0.0,6 tree augmentation,abstract
A00-2030,W10-2924,[104],"we have demonstrated, at least for one problem, that a lexicalized, probabilistic context-free parser with head rules (lpcfghr) can be used effectively for information extraction.",[0],miller et al (2000) adapt a probabilistic context-free parser for information extraction by augmenting syntactic labels with entity and relation labels,[0],15,method,12,12.0,0.8571428571428571,104.0,0.9203539823008849,1.0,0.2,0,0.0,0.0,0.0,0.0,0.0,11 conclusions,abstract
A00-2030,W06-0508,[104],"we have demonstrated, at least for one problem, that a lexicalized, probabilistic context-free parser with head rules (lpcfghr) can be used effectively for information extraction.",[0],"most of the approaches for relation extraction rely on the mapping of syntactic dependencies, such as svo, onto semantic relations, using either pattern matching or other strategies, such as probabilistic parsing for trees augmented with annotations for entities and relations (miller et al 2000), or clustering of semantically similar syntactic dependencies, according to their selectional restrictions (gamallo et al, 2002)",[0],16,method,12,12.0,0.8571428571428571,104.0,0.9203539823008849,1.0,0.2,0,0.0,0.0,0.0,0.0,0.0,11 conclusions,abstract
A00-2030,P07-1055,[2],"in this paper we report adapting a lexic al ized, probabilistic context-free parser to information extraction and evaluate this new technique on muc-7 template elements and template relations.",[0],"this includes parsing and relation extraction (miller et al, 2000), entity labeling and relation extraction (roth and yih, 2004), and part-of-speech tagging and chunking (sutton et al, 2004)",[0],17,method,0,0.0,0.0,2.0,0.017699115044247787,2.0,0.6666666666666666,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
A00-2030,W05-0636,[104],"we have demonstrated, at least for one problem, that a lexicalized, probabilistic context-free parser with head rules (lpcfghr) can be used effectively for information extraction",[0],"for example, miller et al (2000) showed that performing parsing and information extraction in a joint model improves performance on both tasks",[0],18,method,12,12.0,0.8571428571428571,104.0,0.9203539823008849,1.0,0.2,0,0.0,0.0,0.0,0.0,0.0,11 conclusions,abstract
A00-2030,N06-1037,[2],"in this paper we report adapting a lexic al ized, probabilistic context-free parser to information extraction and evaluate this new technique on muc-7 template elements and template relations.",[0],miller et al (2000) address the task of relation extraction from the statistical parsing viewpoint,[0],19,method,0,0.0,0.0,2.0,0.017699115044247787,2.0,0.6666666666666666,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
A00-2030,D11-1132,[61],"the detailed probability structure differs, however, in that it was designed to jointly perform part-of-speech tagging, name finding, syntactic parsing, and relation finding in a single process.",[0],"rule-based methods (miller et al, 2000) employ a number of linguistic rules to capture relation patterns",[0],20,method,8,8.0,0.5714285714285714,61.0,0.5398230088495575,2.0,0.10526315789473684,0,0.0,0.0,0.0,0.0,0.0,7 model structure,abstract
A00-2030,W01-0510,[11],"we evaluated the new approach to information extraction on two of the tasks of the seventh message understanding conference (muc-7) and reported in (marsh, 1998).",[0],"section 5 compares our approach tooth ers in the literature, in particular that of (miller et al., 2000)",[0],1,method,2,2.0,0.14285714285714285,11.0,0.09734513274336283,1.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,2 information extraction tasks,abstract
A00-2030,W01-0510,[52],"in this section, we describe the algorithm that was used to automatically produce augmented trees, starting with a) human-generated semantic annotations and b) machinegenerated syntactic parse trees.",[0],"the basic approach we described is very similar to the one presented in (miller et al, 2000) however there are a few major di erences: in our approach the augmentation of the syn tactic tags with semantic tags is straightforward due to the fact that the semantic constituents are matched exactly 5. the approach in (miller",[0],2,method,6,6.0,0.42857142857142855,52.0,0.46017699115044247,1.0,0.3333333333333333,0,0.0,0.0,0.0,0.0,0.0,6 tree augmentation,abstract
A00-2030,W01-0510,[50],"figure 4 shows an example of the semantic annotation, which was the only type of manual annotation we performed.",[0],"the semantic annotation required by our task is much simpler than that employed by (miller et al, 2000)",[0],3,method,5,5.0,0.35714285714285715,50.0,0.4424778761061947,10.0,0.9090909090909091,0,0.0,0.0,0.0,0.0,0.0,5 creating the training data,abstract
A00-2030,W01-0510,[34],"in these trees, the standard treebank structures are augmented to convey semantic information, that is, entities and relations.",[0],"one possibly bene cial extension of our work suggested by (miller et al, 2000) would be to add semantic tags describing relations between entities (slots), in which case the semantic constraints would not be structured strictly on the two levels used in the current approach, respectively frame and slot level",[0],4,method,4,4.0,0.2857142857142857,34.0,0.3008849557522124,2.0,0.25,0,0.0,0.0,0.0,0.0,0.0,4 representing syntax and semantics jointly,abstract
A00-2030,W01-0510,[106],we were able to use the penn treebank to estimate the syntactic parameters; no additional syntactic training was required.,[0],"similar to the approach in (miller et al, 2000 )weinitialized the slm statistics from the upenn tree bank parse trees (about 1mwds of training data) at the rst training stage, see section 3",[0],5,method,12,12.0,0.8571428571428571,106.0,0.9380530973451328,3.0,0.6,0,0.0,0.0,0.0,0.0,0.0,11 conclusions,abstract
A00-2030,P14-1078,[6],"in this paper, we report adapting a lexicalized, probabilistic context-free parser with head rules (lpcfg-hr) to information extraction.",[0],"rule-based methods (miller et al, 2000) employ a number of linguistic rules to capture relation patterns",[0],6,method,1,1.0,0.07142857142857142,6.0,0.05309734513274336,4.0,0.5,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
A00-2030,P05-1061,[6],"in this paper, we report adapting a lexicalized, probabilistic context-free parser with head rules (lpcfg-hr) to information extraction.",[0],"one interesting system that does not belong to the above class is that of miller et al (2000), who take the view that relation extraction is just a form of probabilistic parsing where parse trees are augmented to identify all relations",[0],7,method,1,1.0,0.07142857142857142,6.0,0.05309734513274336,4.0,0.5,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
A00-2030,P05-1053,[34],"in these trees, the standard treebank structures are augmented to convey semantic information, that is, entities and relations.",[0],"miller et al (2000) augmented syntactic full parse trees with semantic information corresponding to entities and relations, and built generative models for the augmented trees",[0],8,method,4,4.0,0.2857142857142857,34.0,0.3008849557522124,2.0,0.25,0,0.0,0.0,0.0,0.0,0.0,4 representing syntax and semantics jointly,abstract
A00-2030,P05-1053,[12],"the template element (te) task identifies organizations, persons, locations, and some artifacts (rocket and airplane-related artifacts).",[0],"complicated relation extraction tasks may also impose a big challenge to the modeling approach used by miller et al (2000) which integrates various tasks such as part-of-speech tagging, named entity recognition, template element extraction and relation extraction, in a single model",[0],9,method,2,2.0,0.14285714285714285,12.0,0.10619469026548672,2.0,0.2857142857142857,0,0.0,0.0,0.0,0.0,0.0,2 information extraction tasks,abstract
A00-2030,H05-1094,[3],"since 1995, a few statistical parsing algorithms (magerman, 1995; collins, 1996 and 1997; charniak, 1997; rathnaparki, 1997) demonstrated a breakthrough in parsing accuracy, as measured against the university of pennsylvania treebank as a gold standard.",[0],"(miller et al, 2000) have combined entity recognition, parsing, and relation extraction into a jointly-trained single statistical parsing model that achieves improved performance on all the subtasks. part of the contribution of the current work is to suggest that joint decoding can be effective even when joint training is not possible because jointly-labeled data is unavailable",[0],10,method,1,1.0,0.07142857142857142,3.0,0.02654867256637168,1.0,0.125,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
A00-2030,P04-1054,[34],"in these trees, the standard treebank structures are augmented to convey semantic information, that is, entities and relations.",[0],miller et al (2000) propose an integrated statistical parsing technique that augments parse trees with semantic labels denoting entity and relation types,[0],11,method,4,4.0,0.2857142857142857,34.0,0.3008849557522124,2.0,0.25,0,0.0,0.0,0.0,0.0,0.0,4 representing syntax and semantics jointly,abstract
A00-2030,P04-1054,[32],"because generative statistical models had already proven successful for each of the first three stages, we were optimistic that some of their properties — especially their ability to learn from large amounts of data, and their robustness when presented with unexpected inputs — would also benefit semantic analysis.",[0],"whereasmiller et al (2000) use a generative model to produce parse information as well as relation information, we hypothesize that a technique discriminatively trained to classify relations will achieve better performance",[0],12,method,3,3.0,0.21428571428571427,32.0,0.2831858407079646,15.0,1.0,0,0.0,0.0,0.0,0.0,0.0,3 integrated sentential processing,abstract
A00-2030,W05-0602,[10],"instead, our parsing algorithm, trained on the upenn treebank, was run on the new york times source to create unsupervised syntactic training which was constrained to be consistent with semantic annotation.",[0],"the syntactic model in (miller et al, 2000) is similar to collins?, but doesnot use features like sub cat frames and distance measures",[0],13,method,1,1.0,0.07142857142857142,10.0,0.08849557522123894,8.0,1.0,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
A00-2030,N07-2041,[94],"given a new sentence, the outcome of this search process is a tree structure that encodes both the syntactic and semantic structure of the sentence.",[0],"similar to the approach in (miller et al, 2000) and (kulick et al, 2004), our parser integrates both syntactic and semantic annotations into a single annotation as shown in figure 2",[0],14,method,10,10.0,0.7142857142857143,94.0,0.831858407079646,13.0,0.9285714285714286,0,0.0,0.0,0.0,0.0,0.0,9 searching the model,abstract
A00-2030,W10-2924,[6],"in this paper, we report adapting a lexicalized, probabilistic context-free parser with head rules (lpcfg-hr) to information extraction.",[0],miller et al (2000) adapt a probabilistic context-free parser for information extraction by augmenting syntactic labels with entity and relation labels,[0],15,method,1,1.0,0.07142857142857142,6.0,0.05309734513274336,4.0,0.5,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
A00-2030,W06-0508,[104],"we have demonstrated, at least for one problem, that a lexicalized, probabilistic context-free parser with head rules (lpcfghr) can be used effectively for information extraction.",[0],"most of the approaches for relation extraction rely on the mapping of syntactic dependencies, such as svo, onto semantic relations, using either pattern matching or other strategies, such as probabilistic parsing for trees augmented with annotations for entities and relations (miller et al 2000), or clustering of semantically similar syntactic dependencies, according to their selectional restrictions (gamallo et al, 2002)",[0],16,method,12,12.0,0.8571428571428571,104.0,0.9203539823008849,1.0,0.2,0,0.0,0.0,0.0,0.0,0.0,11 conclusions,abstract
A00-2030,P07-1055,[26],"we were already using a generative statistical model for part-of-speech tagging (weischedel et al. 1993), and more recently, had begun using a generative statistical model for name finding (bikel et al.",[0],"this includes parsing and relation extraction (miller et al, 2000), entity labeling and relation extraction (roth and yih, 2004), and part-of-speech tagging and chunking (sutton et al, 2004)",[0],17,method,3,3.0,0.21428571428571427,26.0,0.23008849557522124,9.0,0.6,0,0.0,0.0,0.0,0.0,0.0,3 integrated sentential processing,abstract
A00-2030,W05-0636,[6],"in this paper, we report adapting a lexicalized, probabilistic context-free parser with head rules (lpcfg-hr) to information extraction.",[0],"for example, miller et al (2000) showed that performing parsing and information extraction in a joint model improves performance on both tasks",[0],18,method,1,1.0,0.07142857142857142,6.0,0.05309734513274336,4.0,0.5,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
A00-2030,N06-1037,[19],"currently, the prevailing architecture for dividing sentential processing is a four-stage pipeline consisting of: since we were interested in exploiting recent advances in parsing, replacing the syntactic analysis stage of the standard pipeline with a modern statistical parser was an obvious possibility.",[0],miller et al (2000) address the task of relation extraction from the statistical parsing viewpoint,[0],19,method,3,3.0,0.21428571428571427,19.0,0.168141592920354,2.0,0.13333333333333333,0,0.0,0.0,0.0,0.0,0.0,3 integrated sentential processing,abstract
A97-1014,E99-1016,[168],we will closely coordinate the further development of our corpus with the annotation work in verbmobil and with other german efforts in corpus annotation.,[0],"this type of model is used to facilitate the syntactic annotation of the negra corpus of german newspaper texts (skut et al, 1997)",[0],1,aim,6,6.0,0.75,168.0,0.9545454545454546,10.0,0.7142857142857143,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
A97-1014,E99-1016,[168],we will closely coordinate the further development of our corpus with the annotation work in verbmobil and with other german efforts in corpus annotation.,[0],"for our experiments, we use the negra corpus (skut et al, 1997)",[0],2,aim,6,6.0,0.75,168.0,0.9545454545454546,10.0,0.7142857142857143,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
A97-1014,E12-1047,[151],"for evaluation, the already annotated sentences were divided into two disjoint sets, one for training (90% of the corpus), the other one for testing (10%).",[0],"as data we use version 2 of the negra (skut et al1997) tree bank, with the common training ,devel 1 10 100 1000 10000 100000 3 4 5 6 7 8 9 frequenc y parsing complexity head-driven optimal head-driven figure 6: the distribution of parsing complexity among productions in markovized, head-driven grammars read off from negra-25",[0],3,method,5,5.0,0.625,151.0,0.8579545454545454,32.0,0.8205128205128205,0,0.0,0.0,0.0,0.0,0.0,5 the annotation tool,abstract
A97-1014,I05-6010,[15],"existing treebank annotation schemes exhibit a fairly uniform architecture, as they all have to meet the same basic requirements, namely: descriptivity: grammatical phenomena are to be described rather than explained.",[0],according to skut et al (1997) tree banks have to meet the following requirements: 1,[0],5,result,2,2.0,0.25,15.0,0.08522727272727272,5.0,0.1111111111111111,0,0.0,0.0,0.0,0.0,0.0,2 motivation,abstract
A97-1014,C10-1061,[47],argument structure can be represented in terms of unordered trees (with crossing branches).,[0],"in contrast, some other tree banks, such as the german negra and tiger tree banks allow annotation with crossing branches (skut et al, 1997) .non-local dependencies can then be expressed directly by grouping all dependent elements under a single node",[0],7,method,2,2.0,0.25,47.0,0.26704545454545453,37.0,0.8222222222222222,0,0.0,0.0,0.0,0.0,0.0,2 motivation,abstract
A97-1014,C10-1061,[167],"in the second phase of the project verbmobil a. treebank for :30,000 german spoken sentences as well as for the same amount of english and japanese sentences will be created.",[0],"our data source is the german negra tree bank (skut et al, 1997)",[0],8,method,6,6.0,0.75,167.0,0.9488636363636364,9.0,0.6428571428571429,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
A97-1014,P05-1039,[168],we will closely coordinate the further development of our corpus with the annotation work in verbmobil and with other german efforts in corpus annotation.,[0],"the parsing models we present are trained and tested on the negra corpus (skut et al, 1997), a hand parsed corpus of german newspaper text containing approximately 20,000 sentences",[0],9,aim,6,6.0,0.75,168.0,0.9545454545454546,10.0,0.7142857142857143,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
A97-1014,P03-1013,[4],the work reported in this paper aims at providing syntactically annotated corpora (treebanks') for stochastic grammar induction.,[0],"the present paper addresses this question by proposing a probabilistic parsing model trained on negra (skut et al, 1997), a syntactically annotated corpus for german",[0],10,aim,1,1.0,0.125,4.0,0.022727272727272728,1.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
A97-1014,P03-1013,[160],these differences can be illustrated by a comparison with the penn treebank annotation scheme.,[0],"the annotation scheme (skut et al, 1997) is modeled to a certain extent on that of the penn treebank (marcuset al, 1993), with crucial differences",[0],11,method,6,6.0,0.75,160.0,0.9090909090909091,2.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
A97-1014,W04-1505,[127],"as the need for certain functionalities becomes obvious with growing annotation experience, we have decided to implement the tool in two stages.",[0],"german is con sider ably more in ectional which means that discarding functional information is more harmful, and which explains why the negra an notation has been conceived to be quite at (skut et al, 1997)",[0],13,method,5,5.0,0.625,127.0,0.7215909090909091,8.0,0.20512820512820512,0,0.0,0.0,0.0,0.0,0.0,5 the annotation tool,abstract
A97-1014,C04-1074,[39],"consider the german sentence (1) daran wird ihn anna erkennen, &di er weint at-it will him anna recognise that he cries 'anna will recognise him at his cry' a sample constituent structure is given below: the fairly short sentence contains three non-local dependencies, marked by co-references between traces and the corresponding nodes.",[0],"the factors used in the algorithms and the algorithms themselves are evaluated on a germancorpus annotated with syntactic and co reference in formation (negra) (skut et al, 1997)",[0],14,method,2,2.0,0.25,39.0,0.2215909090909091,29.0,0.6444444444444445,0,0.0,0.0,0.0,0.0,0.0,2 motivation,abstract
A97-1014,P11-2067,[72],"in order to avoid inconsistencies, the corpus is annotated in two stages: basic annotation and nfirtellte714.",[0],"ckk uses the dubey and keller (2003) parser, which is trained on the negra corpus (skut et al, 1997)",[0],16,method,3,3.0,0.375,72.0,0.4090909090909091,17.0,0.53125,0,0.0,0.0,0.0,0.0,0.0,3 the annotation scheme,abstract
A97-1014,W08-1007,[4],the work reported in this paper aims at providing syntactically annotated corpora (treebanks') for stochastic grammar induction.,[0],"earlier studies by dubey and keller (2003) and dubey (2005) using the negratreebank (skut et al, 1997) reports that lexicaliza tion of pcfgs decrease the parsing accuracy when parsing negra? s flat constituent structures",[0],17,aim,1,1.0,0.125,4.0,0.022727272727272728,1.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
A97-1014,D07-1066,[4],the work reported in this paper aims at providing syntactically annotated corpora (treebanks') for stochastic grammar induction.,[0],"a comparison of unlexicalised pcfg parsing (ku ?bler, 2005) trained and evaluated on the german negra (skut et al, 1997) and the tu? ba d/z (telljohann et al, 2004) tree banks using lopar (schmid, 2000) shows a difference in parsing results of about 16%, using the parseval metric (black et al, 1991)",[0],19,aim,1,1.0,0.125,4.0,0.022727272727272728,1.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
A97-1014,E99-1016,[168],we will closely coordinate the further development of our corpus with the annotation work in verbmobil and with other german efforts in corpus annotation.,[0],"this type of model is used to facilitate the syntactic annotation of the negra corpus of german newspaper texts (skut et al, 1997)",[0],1,method,6,6.0,0.75,168.0,0.9545454545454546,10.0,0.7142857142857143,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
A97-1014,E99-1016,[165],"in addition the approach provides empirical material for psycholinguistic investigation, since preferences for the choice of certain syntactic constructions, linea.rizations, and attachments that have been observed in online experiments of language production and comprehension can now be put in relation with the frequency of these alternatives in larger amounts of texts.",[0],"for our experiments, we use the negra corpus (skut et al, 1997)",[0],2,method,6,6.0,0.75,165.0,0.9375,7.0,0.5,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
A97-1014,E12-1047,[145],this amount of data suffices as training material to reliably assign the grammatical functions if the user determines the elements of a phrase and its type (step 1 of the list above).,[0],"as data we use version 2 of the negra (skut et al1997) tree bank, with the common training ,devel 1 10 100 1000 10000 100000 3 4 5 6 7 8 9 frequenc y parsing complexity head-driven optimal head-driven figure 6: the distribution of parsing complexity among productions in markovized, head-driven grammars read off from negra-25",[0],3,method,5,5.0,0.625,145.0,0.8238636363636364,26.0,0.6666666666666666,0,0.0,0.0,0.0,0.0,0.0,5 the annotation tool,abstract
A97-1014,I05-6010,[15],"existing treebank annotation schemes exhibit a fairly uniform architecture, as they all have to meet the same basic requirements, namely: descriptivity: grammatical phenomena are to be described rather than explained.",[0],according to skut et al (1997) tree banks have to meet the following requirements: 1,[0],5,method,2,2.0,0.25,15.0,0.08522727272727272,5.0,0.1111111111111111,0,0.0,0.0,0.0,0.0,0.0,2 motivation,abstract
A97-1014,W04-1506,[41],"apart from this rather technical problem, two further arguments speak against phrase structure as the structural pivot of the annotation scheme: finally, the structural handling of free word order means stating well-formedness constraints on structures involving many trace-filler dependencies, which has proved tedious.",[0],"that could best deal with the free word order displayed by basque syntax (skut et al, 1997)",[0],6,method,2,2.0,0.25,41.0,0.23295454545454544,31.0,0.6888888888888889,0,0.0,0.0,0.0,0.0,0.0,2 motivation,abstract
A97-1014,C10-1061,[47],argument structure can be represented in terms of unordered trees (with crossing branches).,[0],"in contrast, some other tree banks, such as the german negra and tiger tree banks allow annotation with crossing branches (skut et al, 1997) .non-local dependencies can then be expressed directly by grouping all dependent elements under a single node",[0],7,method,2,2.0,0.25,47.0,0.26704545454545453,37.0,0.8222222222222222,0,0.0,0.0,0.0,0.0,0.0,2 motivation,abstract
A97-1014,C10-1061,[167],"in the second phase of the project verbmobil a. treebank for :30,000 german spoken sentences as well as for the same amount of english and japanese sentences will be created.",[0],"our data source is the german negra tree bank (skut et al, 1997)",[0],8,method,6,6.0,0.75,167.0,0.9488636363636364,9.0,0.6428571428571429,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
A97-1014,P05-1039,[167],"in the second phase of the project verbmobil a. treebank for :30,000 german spoken sentences as well as for the same amount of english and japanese sentences will be created.",[0],"the parsing models we present are trained and tested on the negra corpus (skut et al, 1997), a hand parsed corpus of german newspaper text containing approximately 20,000 sentences",[0],9,method,6,6.0,0.75,167.0,0.9488636363636364,9.0,0.6428571428571429,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
A97-1014,P03-1013,[39],"consider the german sentence (1) daran wird ihn anna erkennen, &di er weint at-it will him anna recognise that he cries 'anna will recognise him at his cry' a sample constituent structure is given below: the fairly short sentence contains three non-local dependencies, marked by co-references between traces and the corresponding nodes.",[0],"the present paper addresses this question by proposing a probabilistic parsing model trained on negra (skut et al, 1997), a syntactically annotated corpus for german",[0],10,method,2,2.0,0.25,39.0,0.2215909090909091,29.0,0.6444444444444445,0,0.0,0.0,0.0,0.0,0.0,2 motivation,abstract
A97-1014,P03-1013,[160],these differences can be illustrated by a comparison with the penn treebank annotation scheme.,[0],"the annotation scheme (skut et al, 1997) is modeled to a certain extent on that of the penn treebank (marcuset al, 1993), with crucial differences",[0],11,method,6,6.0,0.75,160.0,0.9090909090909091,2.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
A97-1014,W04-1505,[166],syntactically annotated corpora of german have been missing until now.,[0],"german is con sider ably more in ectional which means that discarding functional information is more harmful, and which explains why the negra an notation has been conceived to be quite at (skut et al, 1997)",[0],13,method,6,6.0,0.75,166.0,0.9431818181818182,8.0,0.5714285714285714,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
A97-1014,C04-1074,[166],syntactically annotated corpora of german have been missing until now.,[0],"the factors used in the algorithms and the algorithms themselves are evaluated on a germancorpus annotated with syntactic and co reference in formation (negra) (skut et al, 1997)",[0],14,method,6,6.0,0.75,166.0,0.9431818181818182,8.0,0.5714285714285714,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
A97-1014,P11-2067,[143],sentences annotated in previous steps are used as training material for further processing.,[0],"ckk uses the dubey and keller (2003) parser, which is trained on the negra corpus (skut et al, 1997)",[0],16,method,5,5.0,0.625,143.0,0.8125,24.0,0.6153846153846154,0,0.0,0.0,0.0,0.0,0.0,5 the annotation tool,abstract
A97-1014,W08-1007,[71],"however, there is a trade-off between the granularity of information encoded in the labels and the speed and accuracy of annotation.",[0],"earlier studies by dubey and keller (2003) and dubey (2005) using the negratreebank (skut et al, 1997) reports that lexicaliza tion of pcfgs decrease the parsing accuracy when parsing negra? s flat constituent structures",[0],17,method,3,3.0,0.375,71.0,0.4034090909090909,16.0,0.5,0,0.0,0.0,0.0,0.0,0.0,3 the annotation scheme,abstract
A97-1014,P06-1109,[167],"in the second phase of the project verbmobil a. treebank for :30,000 german spoken sentences as well as for the same amount of english and japanese sentences will be created.",[0],we next tested uml-dop on two additional domains which were also used in klein and manning (2004) and bod (2006): the german negra10 (skut et al 1997) and the chinese ctb10 (xue et al 2002) both containing 2200+ sentences? 10 words after removing punctuation,[0],18,method,6,6.0,0.75,167.0,0.9488636363636364,9.0,0.6428571428571429,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
A97-1014,D07-1066,[151],"for evaluation, the already annotated sentences were divided into two disjoint sets, one for training (90% of the corpus), the other one for testing (10%).",[0],"a comparison of unlexicalised pcfg parsing (ku ?bler, 2005) trained and evaluated on the german negra (skut et al, 1997) and the tu? ba d/z (telljohann et al, 2004) tree banks using lopar (schmid, 2000) shows a difference in parsing results of about 16%, using the parseval metric (black et al, 1991)",[0],19,method,5,5.0,0.625,151.0,0.8579545454545454,32.0,0.8205128205128205,0,0.0,0.0,0.0,0.0,0.0,5 the annotation tool,abstract
A97-1014,E99-1016,[72],"in order to avoid inconsistencies, the corpus is annotated in two stages: basic annotation and nfirtellte714.",[0],"this type of model is used to facilitate the syntactic annotation of the negra corpus of german newspaper texts (skut et al, 1997)",[0],1,method,3,3.0,0.375,72.0,0.4090909090909091,17.0,0.53125,0,0.0,0.0,0.0,0.0,0.0,3 the annotation scheme,abstract
A97-1014,E99-1016,[144],"we distinguish five degrees of automation: so far, about 1100 sentences of our corpus have been annotated.",[0],"for our experiments, we use the negra corpus (skut et al, 1997)",[0],2,method,5,5.0,0.625,144.0,0.8181818181818182,25.0,0.6410256410256411,0,0.0,0.0,0.0,0.0,0.0,5 the annotation tool,abstract
A97-1014,E12-1047,[14],corpora annotated with syntactic structures are commonly referred to as trctbank.5.,[0],"as data we use version 2 of the negra (skut et al1997) tree bank, with the common training ,devel 1 10 100 1000 10000 100000 3 4 5 6 7 8 9 frequenc y parsing complexity head-driven optimal head-driven figure 6: the distribution of parsing complexity among productions in markovized, head-driven grammars read off from negra-25",[0],3,method,2,2.0,0.25,14.0,0.07954545454545454,4.0,0.08888888888888889,0,0.0,0.0,0.0,0.0,0.0,2 motivation,abstract
A97-1014,I05-6010,[15],"existing treebank annotation schemes exhibit a fairly uniform architecture, as they all have to meet the same basic requirements, namely: descriptivity: grammatical phenomena are to be described rather than explained.",[0],according to skut et al (1997) tree banks have to meet the following requirements: 1,[0],5,method,2,2.0,0.25,15.0,0.08522727272727272,5.0,0.1111111111111111,0,0.0,0.0,0.0,0.0,0.0,2 motivation,abstract
A97-1014,W04-1506,[36],"as for free word order languages, the following features may cause problems: sition between the two poles.",[0],"that could best deal with the free word order displayed by basque syntax (skut et al, 1997)",[0],6,method,2,2.0,0.25,36.0,0.20454545454545456,26.0,0.5777777777777777,0,0.0,0.0,0.0,0.0,0.0,2 motivation,abstract
A97-1014,C10-1061,[24],the typical treebank architecture is as follows: structures: a context-free backbone is augmented with trace-filler representations of non-local dependencies.,[0],"in contrast, some other tree banks, such as the german negra and tiger tree banks allow annotation with crossing branches (skut et al, 1997) .non-local dependencies can then be expressed directly by grouping all dependent elements under a single node",[0],7,method,2,2.0,0.25,24.0,0.13636363636363635,14.0,0.3111111111111111,0,0.0,0.0,0.0,0.0,0.0,2 motivation,abstract
A97-1014,C10-1061,[160],these differences can be illustrated by a comparison with the penn treebank annotation scheme.,[0],"our data source is the german negra tree bank (skut et al, 1997)",[0],8,method,6,6.0,0.75,160.0,0.9090909090909091,2.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
A97-1014,P05-1039,[151],"for evaluation, the already annotated sentences were divided into two disjoint sets, one for training (90% of the corpus), the other one for testing (10%).",[0],"the parsing models we present are trained and tested on the negra corpus (skut et al, 1997), a hand parsed corpus of german newspaper text containing approximately 20,000 sentences",[0],9,method,5,5.0,0.625,151.0,0.8579545454545454,32.0,0.8205128205128205,0,0.0,0.0,0.0,0.0,0.0,5 the annotation tool,abstract
A97-1014,P03-1013,[4],the work reported in this paper aims at providing syntactically annotated corpora (treebanks') for stochastic grammar induction.,[0],"the present paper addresses this question by proposing a probabilistic parsing model trained on negra (skut et al, 1997), a syntactically annotated corpus for german",[0],10,method,1,1.0,0.125,4.0,0.022727272727272728,1.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
A97-1014,P03-1013,[160],these differences can be illustrated by a comparison with the penn treebank annotation scheme.,[0],"the annotation scheme (skut et al, 1997) is modeled to a certain extent on that of the penn treebank (marcuset al, 1993), with crucial differences",[0],11,method,6,6.0,0.75,160.0,0.9090909090909091,2.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
A97-1014,W04-1505,[167],"in the second phase of the project verbmobil a. treebank for :30,000 german spoken sentences as well as for the same amount of english and japanese sentences will be created.",[0],"german is con sider ably more in ectional which means that discarding functional information is more harmful, and which explains why the negra an notation has been conceived to be quite at (skut et al, 1997)",[0],13,method,6,6.0,0.75,167.0,0.9488636363636364,9.0,0.6428571428571429,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
A97-1014,C04-1074,[39],"consider the german sentence (1) daran wird ihn anna erkennen, &di er weint at-it will him anna recognise that he cries 'anna will recognise him at his cry' a sample constituent structure is given below: the fairly short sentence contains three non-local dependencies, marked by co-references between traces and the corresponding nodes.",[0],"the factors used in the algorithms and the algorithms themselves are evaluated on a germancorpus annotated with syntactic and co reference in formation (negra) (skut et al, 1997)",[0],14,method,2,2.0,0.25,39.0,0.2215909090909091,29.0,0.6444444444444445,0,0.0,0.0,0.0,0.0,0.0,2 motivation,abstract
A97-1014,P11-2067,[151],"for evaluation, the already annotated sentences were divided into two disjoint sets, one for training (90% of the corpus), the other one for testing (10%).",[0],"ckk uses the dubey and keller (2003) parser, which is trained on the negra corpus (skut et al, 1997)",[0],16,method,5,5.0,0.625,151.0,0.8579545454545454,32.0,0.8205128205128205,0,0.0,0.0,0.0,0.0,0.0,5 the annotation tool,abstract
A97-1014,W08-1007,[71],"however, there is a trade-off between the granularity of information encoded in the labels and the speed and accuracy of annotation.",[0],"earlier studies by dubey and keller (2003) and dubey (2005) using the negratreebank (skut et al, 1997) reports that lexicaliza tion of pcfgs decrease the parsing accuracy when parsing negra? s flat constituent structures",[0],17,method,3,3.0,0.375,71.0,0.4034090909090909,16.0,0.5,0,0.0,0.0,0.0,0.0,0.0,3 the annotation scheme,abstract
A97-1014,P06-1109,[144],"we distinguish five degrees of automation: so far, about 1100 sentences of our corpus have been annotated.",[0],we next tested uml-dop on two additional domains which were also used in klein and manning (2004) and bod (2006): the german negra10 (skut et al 1997) and the chinese ctb10 (xue et al 2002) both containing 2200+ sentences? 10 words after removing punctuation,[0],18,method,5,5.0,0.625,144.0,0.8181818181818182,25.0,0.6410256410256411,0,0.0,0.0,0.0,0.0,0.0,5 the annotation tool,abstract
A97-1014,D07-1066,[160],these differences can be illustrated by a comparison with the penn treebank annotation scheme.,[0],"a comparison of unlexicalised pcfg parsing (ku ?bler, 2005) trained and evaluated on the german negra (skut et al, 1997) and the tu? ba d/z (telljohann et al, 2004) tree banks using lopar (schmid, 2000) shows a difference in parsing results of about 16%, using the parseval metric (black et al, 1991)",[0],19,method,6,6.0,0.75,160.0,0.9090909090909091,2.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
D09-1092,P14-1004,[193],"we analyzed the characteristics of pltm in comparison to monolingual lda, and demonstrated that it is possible to discover aligned topics.",[0],"this configuration is similar to polylda (mimno et al, 2009) or linklda (yano et al, 2009), such that utterances from different parties are treated as different languages or blog-post and comments pairs",[0],1,result,6,6.0,0.75,193.0,0.965,2.0,0.4,0,0.0,0.0,0.0,0.0,0.0,6 conclusions,abstract
D09-1092,P10-1044,[114],"ideally, the “glue” documents in g will be sufficient to align the topics across languages, and will cause comparable documents in s to have similar distributions over topics even though they are modeled independently.",[0],"our particular model, linklda, has been applied to a few nlp tasks such as simultaneously modeling the words appearing in blog posts and users who will likely respond to them (yano et al, 2009), modeling topic-aligned articles in different languages (mimno et al, 2009), and word sense induction (brody and lapata, 2009)",[0],2,aim,4,4.0,0.5,114.0,0.57,63.0,0.5478260869565217,0,0.0,0.0,0.0,0.0,0.0,4 results on parallel text,abstract
D09-1092,P11-2084,[138],we then add the cartesian product of these sets for every topic to a set of candidate translations c. we report the number of elements of c that appear in the reference lexica.,[0],"(mimno et al, 2009) retrieve a list of potential translations simply by selecting a small number n of the most probable words in both languages and then add the cartesian product of these sets for every topic to a set of candidate translations",[0],3,method,4,4.0,0.5,138.0,0.69,87.0,0.7565217391304347,0,0.0,0.0,0.0,0.0,0.0,4 results on parallel text,abstract
D09-1092,E12-1014,[18],"in this paper, we use two polylingual corpora to answer various critical questions related to polylingual topic models.",[0],"our wikipedia-based topic similarity feature, w (f, e), is similar in spirit to polylingualtopic models (mimno et al 2009), but it is scalable to full bilingual lexicon induction",[0],4,method,1,1.0,0.125,18.0,0.09,14.0,0.7,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
D09-1092,D11-1086,[55],"the europarl corpus consists of parallel texts in eleven western european languages: danish, german, greek, english, spanish, finnish, french, italian, dutch, portuguese and swedish.",[0],"of english document and the second half of its aligned foreign language document (mimno et al,2009)",[0],5,method,4,4.0,0.5,55.0,0.275,4.0,0.034782608695652174,0,0.0,0.0,0.0,0.0,0.0,4 results on parallel text,abstract
D09-1092,N12-1007,[192],we introduced a polylingual topic model (pltm) that discovers topics aligned across multiple languages.,[0],"since the pltm is not a contribution of this paper, we refer the interested reader to (mimno et al, 2009) for more details",[0],6,result,6,6.0,0.75,192.0,0.96,1.0,0.2,0,0.0,0.0,0.0,0.0,0.0,6 conclusions,abstract
D09-1092,N12-1007,[119],"the lower the divergence, the more similar the distributions are to each other.",[0],"evaluation corpus the automatic evaluation of cross-lingual co reference systems requires annotated 10mimno et al (2009) showed that so long as the proportion of topically-aligned to non-aligned documents exceeded 0.25, the topic distributions (as measured by mean jensen-shannon divergence between distributions) did not degrade significantly",[0],7,result,4,4.0,0.5,119.0,0.595,68.0,0.591304347826087,0,0.0,0.0,0.0,0.0,0.0,4 results on parallel text,abstract
D09-1092,D10-1025,[148],"to evaluate this scenario, we train pltm on a set of document tuples from europarl, infer topic distributions for a set of held-out documents, and then measure our ability to align documents in one language with their translations in another language.",[0],"similarly, polylingual topic models (pltm) (mimno et al, 2009) generalized lda to tuples of documents from multiple languages",[0],8,method,4,4.0,0.5,148.0,0.74,97.0,0.8434782608695652,0,0.0,0.0,0.0,0.0,0.0,4 results on parallel text,abstract
D09-1092,D10-1025,[193],"we analyzed the characteristics of pltm in comparison to monolingual lda, and demonstrated that it is possible to discover aligned topics.",[0],"our baseline joint plsa model (jplsa) is closely related to the poly-lingual lda model of (mimno et al, 2009)",[0],9,result,6,6.0,0.75,193.0,0.965,2.0,0.4,0,0.0,0.0,0.0,0.0,0.0,6 conclusions,abstract
D09-1092,D10-1025,[184],"interestingly, we find that almost all languages in our corpus, including several pairs that have historically been in conflict, show average js divergences of between approximately 0.08 and 0.12 for t = 400, consistent with our findings for europarl translations.",[0],"we describe the model for two languages, but it is straightforward to generalize to more than two languages, as in (mimno et al, 2009)",[0],10,result,5,5.0,0.625,184.0,0.92,18.0,0.72,0,0.0,0.0,0.0,0.0,0.0,5 results on comparable texts,abstract
D09-1092,D10-1025,[193],"we analyzed the characteristics of pltm in comparison to monolingual lda, and demonstrated that it is possible to discover aligned topics.",[0],"j=1 p (z2j|?) p (w 2 j| ?z2j) the difference between the jplsa model and the poly-lingual topic model of (mimno et al, 2009) is that we merge the vocabularies in the two languages and learn topic-specific word distributions over these merged vocabularies, instead of having pairs of topic-specific word distributions, one for each language, like in (mimno et al, 2009)",[0],11,result,6,6.0,0.75,193.0,0.965,2.0,0.4,0,0.0,0.0,0.0,0.0,0.0,6 conclusions,abstract
D09-1092,D10-1025,[163],"performance continues to improve with longer documents, most likely due to better topic inference.",[0],"another difference between our model and the poly-lingual lda model of (mimno et al, 2009) is that we use maximum aposteriori (map) instead of bayesian inference",[0],12,result,4,4.0,0.5,163.0,0.815,112.0,0.9739130434782609,0,0.0,0.0,0.0,0.0,0.0,4 results on parallel text,abstract
D09-1092,D10-1025,[184],"interestingly, we find that almost all languages in our corpus, including several pairs that have historically been in conflict, show average js divergences of between approximately 0.08 and 0.12 for t = 400, consistent with our findings for europarl translations.",[0],"for computing distance we used the l1-norm of the difference, which worked a bit better than the jensen shannon divergence between the topic vectors used in (mimno et al, 2009)",[0],13,result,5,5.0,0.625,184.0,0.92,18.0,0.72,0,0.0,0.0,0.0,0.0,0.0,5 results on comparable texts,abstract
D09-1092,D10-1025,[148],"to evaluate this scenario, we train pltm on a set of document tuples from europarl, infer topic distributions for a set of held-out documents, and then measure our ability to align documents in one language with their translations in another language.",[0],"in previously reported work, (mimno et al, 2009) evaluate parallel document retrieval using pltm on europarl speeches in english and spanish, using training and test sets of size similar to ours",[0],15,method,4,4.0,0.5,148.0,0.74,97.0,0.8434782608695652,0,0.0,0.0,0.0,0.0,0.0,4 results on parallel text,abstract
D09-1092,W12-3117,[184],"interestingly, we find that almost all languages in our corpus, including several pairs that have historically been in conflict, show average js divergences of between approximately 0.08 and 0.12 for t = 400, consistent with our findings for europarl translations.",[0],"we assume that a higher dimensionality can lead to a better repartitioning of the vocabulary over the topics. multilingual lda has been used before in natural language processing ,e.g .polylingual topic models (mimno et al, 2009) or multilingual topic models for unaligned text (boyd-graber and blei, 2009)",[0],16,result,5,5.0,0.625,184.0,0.92,18.0,0.72,0,0.0,0.0,0.0,0.0,0.0,5 results on comparable texts,abstract
D09-1092,W11-2133,[193],"we analyzed the characteristics of pltm in comparison to monolingual lda, and demonstrated that it is possible to discover aligned topics.",[0],"ji =wjk? m j i? m k=1w j k, (1) where m j is the topic distribution of document j and wk is the number of occurrences of phrase pair xk in document j. mimno et al (2009) extend the original concept of lda to support polylingual topic models (pltm), both on parallel (such as europarl) and partly comparable documents (such as wikipediaarticles)",[0],17,result,6,6.0,0.75,193.0,0.965,2.0,0.4,0,0.0,0.0,0.0,0.0,0.0,6 conclusions,abstract
D09-1092,W11-2133,[192],we introduced a polylingual topic model (pltm) that discovers topics aligned across multiple languages.,[0],tuple-specific topic distributions arelearned using lda with distinct topic-word concentration parameters? l. mimno et al (2009) show that pltm sufficiently aligns topics in parallel corpora,[0],18,result,6,6.0,0.75,192.0,0.96,1.0,0.2,0,0.0,0.0,0.0,0.0,0.0,6 conclusions,abstract
D09-1092,P14-2110,[105],"an important application for polylingual topic modeling is to use small numbers of comparable document tuples to link topics in larger collections of distinct, non-comparable documents in multiple languages.",[0],"a good candidate for multilingual topic analyses are polylin gual topic models (mimno et al, 2009), which learn topics for multiple languages, creating tuples of language specific distributions over monolingual vocabularies for each topic",[0],19,method,4,4.0,0.5,105.0,0.525,54.0,0.46956521739130436,0,0.0,0.0,0.0,0.0,0.0,4 results on parallel text,abstract
D09-1092,P14-2110,[10],we demonstrate its utility and explore its characteristics using two polylingual corpora: proceedings of the european parliament (in eleven languages) and a collection of wikipedia articles (in twelve languages).,[0],"3csldato train a polylingual topic model on social media, we make two modifications to the model of mimno et al (2009): add a token specific language variable, and a process for identifying aligned top ics. first ,polylingual topic models require parallel or comparable corpora in which each document has an assigned language",[0],20,method,1,1.0,0.125,10.0,0.05,6.0,0.3,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
D09-1092,P14-1004,[32],"outside of the field of topic modeling, kawaba et al. (kawaba et al., 2008) use a wikipedia-based model to perform sentiment analysis of blog posts.",[0],"this configuration is similar to polylda (mimno et al, 2009) or linklda (yano et al, 2009), such that utterances from different parties are treated as different languages or blog-post and comments pairs",[0],1,method,2,2.0,0.25,32.0,0.16,8.0,0.8,0,0.0,0.0,0.0,0.0,0.0,2 related work,abstract
D09-1092,P10-1044,[39],"additionally, pltm assumes that each “topic” consists of a set of discrete distributions over words—one for each language l = 1, ... , l. in other words, rather than using a single set of topics φ = {φ1, ... , φt}, as in lda, there are l sets of language-specific topics, φ1, ... , φl, each of which is drawn from a language-specific symmetric dirichlet with concentration parameter βl.",[0],"our particular model, linklda, has been applied to a few nlp tasks such as simultaneously modeling the words appearing in blog posts and users who will likely respond to them (yano et al, 2009), modeling topic-aligned articles in different languages (mimno et al, 2009), and word sense induction (brody and lapata, 2009)",[0],2,method,3,3.0,0.375,39.0,0.195,5.0,0.29411764705882354,0,0.0,0.0,0.0,0.0,0.0,3 polylingual topic model,abstract
D09-1092,P11-2084,[138],we then add the cartesian product of these sets for every topic to a set of candidate translations c. we report the number of elements of c that appear in the reference lexica.,[0],"(mimno et al, 2009) retrieve a list of potential translations simply by selecting a small number n of the most probable words in both languages and then add the cartesian product of these sets for every topic to a set of candidate translations",[0],3,method,4,4.0,0.5,138.0,0.69,87.0,0.7565217391304347,0,0.0,0.0,0.0,0.0,0.0,4 results on parallel text,abstract
D09-1092,E12-1014,[196],"when applied to comparable document collections such as wikipedia, pltm supports data-driven analysis of differences and similarities across all languages for readers who understand any one language.",[0],"our wikipedia-based topic similarity feature, w (f, e), is similar in spirit to polylingualtopic models (mimno et al 2009), but it is scalable to full bilingual lexicon induction",[0],4,method,6,6.0,0.75,196.0,0.98,5.0,1.0,0,0.0,0.0,0.0,0.0,0.0,6 conclusions,abstract
D09-1092,D11-1086,[111],"in order to simulate this scenario we create a set of variations of the europarl corpus by treating some documents as if they have no parallel/comparable texts – i.e., we put each of these documents in a single-document tuple.",[0],"of english document and the second half of its aligned foreign language document (mimno et al,2009)",[0],5,method,4,4.0,0.5,111.0,0.555,60.0,0.5217391304347826,0,0.0,0.0,0.0,0.0,0.0,4 results on parallel text,abstract
D09-1092,N12-1007,[128],although the pltm is clearly not a substitute for a machine translation system—it has no way to represent syntax or even multi-word phrases—it is clear from the examples in figure 2 that the sets of high probability words in different languages for a given topic are likely to include translations.,[0],"since the pltm is not a contribution of this paper, we refer the interested reader to (mimno et al, 2009) for more details",[0],6,method,4,4.0,0.5,128.0,0.64,77.0,0.6695652173913044,0,0.0,0.0,0.0,0.0,0.0,4 results on parallel text,abstract
D09-1092,N12-1007,[122],divergence drops significantly when the proportion of “glue” tuples increases from 0.01 to 0.25.,[0],"evaluation corpus the automatic evaluation of cross-lingual co reference systems requires annotated 10mimno et al (2009) showed that so long as the proportion of topically-aligned to non-aligned documents exceeded 0.25, the topic distributions (as measured by mean jensen-shannon divergence between distributions) did not degrade significantly",[0],7,method,4,4.0,0.5,122.0,0.61,71.0,0.6173913043478261,0,0.0,0.0,0.0,0.0,0.0,4 results on parallel text,abstract
D09-1092,D10-1025,[35],"the polylingual topic model (pltm) is an extension of latent dirichlet allocation (lda) (blei et al., 2003) for modeling polylingual document tuples.",[0],"similarly, polylingual topic models (pltm) (mimno et al, 2009) generalized lda to tuples of documents from multiple languages",[0],8,method,3,3.0,0.375,35.0,0.175,1.0,0.058823529411764705,0,0.0,0.0,0.0,0.0,0.0,3 polylingual topic model,abstract
D09-1092,D10-1025,[110],"continuing with the example above, one might extract a set of connected wikipedia articles related to the focus of the journal and then train pltm on a joint corpus consisting of journal papers and wikipedia articles.",[0],"our baseline joint plsa model (jplsa) is closely related to the poly-lingual lda model of (mimno et al, 2009)",[0],9,method,4,4.0,0.5,110.0,0.55,59.0,0.5130434782608696,0,0.0,0.0,0.0,0.0,0.0,4 results on parallel text,abstract
D09-1092,D10-1025,[30],"however, they evaluate their model on only two languages (english and chinese), and do not use the model to detect differences between languages.",[0],"we describe the model for two languages, but it is straightforward to generalize to more than two languages, as in (mimno et al, 2009)",[0],10,method,2,2.0,0.25,30.0,0.15,6.0,0.6,0,0.0,0.0,0.0,0.0,0.0,2 related work,abstract
D09-1092,D10-1025,[146],"in addition to enhancing lexicons by aligning topic-specific vocabulary, pltm may also be useful for adapting machine translation systems to new domains by finding translations or near translations in an unstructured corpus.",[0],"j=1 p (z2j|?) p (w 2 j| ?z2j) the difference between the jplsa model and the poly-lingual topic model of (mimno et al, 2009) is that we merge the vocabularies in the two languages and learn topic-specific word distributions over these merged vocabularies, instead of having pairs of topic-specific word distributions, one for each language, like in (mimno et al, 2009)",[0],11,method,4,4.0,0.5,146.0,0.73,95.0,0.8260869565217391,0,0.0,0.0,0.0,0.0,0.0,4 results on parallel text,abstract
D09-1092,D10-1025,[77],"maximum topic probability in document although the posterior distribution over topics for each tuple is not concentrated on one topic, it is worth checking that this is not simply because the model is assigning a single topic to the 1we use the r density function. tokens in each of the languages.",[0],"another difference between our model and the poly-lingual lda model of (mimno et al, 2009) is that we use maximum aposteriori (map) instead of bayesian inference",[0],12,method,4,4.0,0.5,77.0,0.385,26.0,0.22608695652173913,0,0.0,0.0,0.0,0.0,0.0,4 results on parallel text,abstract
D09-1092,D10-1025,[156],we use both jensen-shannon divergence and cosine distance.,[0],"for computing distance we used the l1-norm of the difference, which worked a bit better than the jensen shannon divergence between the topic vectors used in (mimno et al, 2009)",[0],13,method,4,4.0,0.5,156.0,0.78,105.0,0.9130434782608695,0,0.0,0.0,0.0,0.0,0.0,4 results on parallel text,abstract
D09-1092,D10-1025,[31],they also provide little analysis of the differences between polylingual and single-language topic models.,[0],"documents are defined as speeches by a single speaker, as in (mimno et al, 2009) .4 for the wikipedia set, we use 43,380 training documents, 8,675 development documents, and 8,675 final test set documents. for both corpora, the terms are extracted by word breaking all documents, removing the top 50 most frequent terms and keeping the next 20,000 most frequent terms",[0],14,method,2,2.0,0.25,31.0,0.155,7.0,0.7,0,0.0,0.0,0.0,0.0,0.0,2 related work,abstract
D09-1092,D10-1025,[19],"we employ a set of direct translations, the europarl corpus, to evaluate whether pltm can accurately infer topics when documents genuinely contain the same content.",[0],"in previously reported work, (mimno et al, 2009) evaluate parallel document retrieval using pltm on europarl speeches in english and spanish, using training and test sets of size similar to ours",[0],15,method,1,1.0,0.125,19.0,0.095,15.0,0.75,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
D09-1092,W12-3117,[131],"we evaluate sets of high-probability words in each topic and multilingual “synsets” by comparing them to entries in human-constructed bilingual dictionaries, as done by haghighi et al. (2008).",[0],"we assume that a higher dimensionality can lead to a better repartitioning of the vocabulary over the topics. multilingual lda has been used before in natural language processing ,e.g .polylingual topic models (mimno et al, 2009) or multilingual topic models for unaligned text (boyd-graber and blei, 2009)",[0],16,method,4,4.0,0.5,131.0,0.655,80.0,0.6956521739130435,0,0.0,0.0,0.0,0.0,0.0,4 results on parallel text,abstract
D09-1092,W11-2133,[196],"when applied to comparable document collections such as wikipedia, pltm supports data-driven analysis of differences and similarities across all languages for readers who understand any one language.",[0],"ji =wjk? m j i? m k=1w j k, (1) where m j is the topic distribution of document j and wk is the number of occurrences of phrase pair xk in document j. mimno et al (2009) extend the original concept of lda to support polylingual topic models (pltm), both on parallel (such as europarl) and partly comparable documents (such as wikipediaarticles)",[0],17,method,6,6.0,0.75,196.0,0.98,5.0,1.0,0,0.0,0.0,0.0,0.0,0.0,6 conclusions,abstract
D09-1092,W11-2133,[192],we introduced a polylingual topic model (pltm) that discovers topics aligned across multiple languages.,[0],tuple-specific topic distributions arelearned using lda with distinct topic-word concentration parameters? l. mimno et al (2009) show that pltm sufficiently aligns topics in parallel corpora,[0],18,method,6,6.0,0.75,192.0,0.96,1.0,0.2,0,0.0,0.0,0.0,0.0,0.0,6 conclusions,abstract
D09-1092,P14-2110,[195],"additionally, pltm can support the creation of bilingual lexica for low resource language pairs, providing candidate translations for more computationally intense alignment processes without the sentence-aligned translations typically used in such tasks.",[0],"a good candidate for multilingual topic analyses are polylin gual topic models (mimno et al, 2009), which learn topics for multiple languages, creating tuples of language specific distributions over monolingual vocabularies for each topic",[0],19,method,6,6.0,0.75,195.0,0.975,4.0,0.8,0,0.0,0.0,0.0,0.0,0.0,6 conclusions,abstract
D09-1092,P14-2110,[6],"topic models have been used for analyzing topic trends in research literature (mann et al., 2006; hall et al., 2008), inferring captions for images (blei and jordan, 2003), social network analysis in email (mccallum et al., 2005), and expanding queries with topically related words in information retrieval (wei and croft, 2006).",[0],"3csldato train a polylingual topic model on social media, we make two modifications to the model of mimno et al (2009): add a token specific language variable, and a process for identifying aligned top ics. first ,polylingual topic models require parallel or comparable corpora in which each document has an assigned language",[0],20,method,1,1.0,0.125,6.0,0.03,2.0,0.1,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
D09-1092,P14-1004,[17],we argue that topic modeling is both a useful and appropriate tool for leveraging correspondences between semantically comparable documents in multiple different languages.,[0],"this configuration is similar to polylda (mimno et al, 2009) or linklda (yano et al, 2009), such that utterances from different parties are treated as different languages or blog-post and comments pairs",[0],1,method,1,1.0,0.125,17.0,0.085,13.0,0.65,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
D09-1092,P10-1044,[20],we also explore how the characteristics of different languages affect topic model performance.,[0],"our particular model, linklda, has been applied to a few nlp tasks such as simultaneously modeling the words appearing in blog posts and users who will likely respond to them (yano et al, 2009), modeling topic-aligned articles in different languages (mimno et al, 2009), and word sense induction (brody and lapata, 2009)",[0],2,method,1,1.0,0.125,20.0,0.1,16.0,0.8,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
D09-1092,P11-2084,[138],we then add the cartesian product of these sets for every topic to a set of candidate translations c. we report the number of elements of c that appear in the reference lexica.,[0],"(mimno et al, 2009) retrieve a list of potential translations simply by selecting a small number n of the most probable words in both languages and then add the cartesian product of these sets for every topic to a set of candidate translations",[0],3,method,4,4.0,0.5,138.0,0.69,87.0,0.7565217391304347,0,0.0,0.0,0.0,0.0,0.0,4 results on parallel text,abstract
D09-1092,E12-1014,[10],we demonstrate its utility and explore its characteristics using two polylingual corpora: proceedings of the european parliament (in eleven languages) and a collection of wikipedia articles (in twelve languages).,[0],"our wikipedia-based topic similarity feature, w (f, e), is similar in spirit to polylingualtopic models (mimno et al 2009), but it is scalable to full bilingual lexicon induction",[0],4,method,1,1.0,0.125,10.0,0.05,6.0,0.3,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
D09-1092,D11-1086,[55],"the europarl corpus consists of parallel texts in eleven western european languages: danish, german, greek, english, spanish, finnish, french, italian, dutch, portuguese and swedish.",[0],"of english document and the second half of its aligned foreign language document (mimno et al,2009)",[0],5,method,4,4.0,0.5,55.0,0.275,4.0,0.034782608695652174,0,0.0,0.0,0.0,0.0,0.0,4 results on parallel text,abstract
D09-1092,N12-1007,[9],"sid=""9"" ssid=""5"">in this paper, we present the polylingual topic model (pltm).",[0],"since the pltm is not a contribution of this paper, we refer the interested reader to (mimno et al, 2009) for more details",[0],6,method,1,1.0,0.125,9.0,0.045,5.0,0.25,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
D09-1092,N12-1007,[118],we calculate the jensen-shannon divergence between the topic distributions for each pair of individual documents in s that were originally part of the same tuple prior to separation.,[0],"evaluation corpus the automatic evaluation of cross-lingual co reference systems requires annotated 10mimno et al (2009) showed that so long as the proportion of topically-aligned to non-aligned documents exceeded 0.25, the topic distributions (as measured by mean jensen-shannon divergence between distributions) did not degrade significantly",[0],7,method,4,4.0,0.5,118.0,0.59,67.0,0.5826086956521739,0,0.0,0.0,0.0,0.0,0.0,4 results on parallel text,abstract
D09-1092,D10-1025,[35],"the polylingual topic model (pltm) is an extension of latent dirichlet allocation (lda) (blei et al., 2003) for modeling polylingual document tuples.",[0],"similarly, polylingual topic models (pltm) (mimno et al, 2009) generalized lda to tuples of documents from multiple languages",[0],8,method,3,3.0,0.375,35.0,0.175,1.0,0.058823529411764705,0,0.0,0.0,0.0,0.0,0.0,3 polylingual topic model,abstract
D09-1092,D10-1025,[35],"the polylingual topic model (pltm) is an extension of latent dirichlet allocation (lda) (blei et al., 2003) for modeling polylingual document tuples.",[0],"our baseline joint plsa model (jplsa) is closely related to the poly-lingual lda model of (mimno et al, 2009)",[0],9,method,3,3.0,0.375,35.0,0.175,1.0,0.058823529411764705,0,0.0,0.0,0.0,0.0,0.0,3 polylingual topic model,abstract
D09-1092,D10-1025,[55],"the europarl corpus consists of parallel texts in eleven western european languages: danish, german, greek, english, spanish, finnish, french, italian, dutch, portuguese and swedish.",[0],"we describe the model for two languages, but it is straightforward to generalize to more than two languages, as in (mimno et al, 2009)",[0],10,method,4,4.0,0.5,55.0,0.275,4.0,0.034782608695652174,0,0.0,0.0,0.0,0.0,0.0,4 results on parallel text,abstract
D09-1092,D10-1025,[102],"in contrast, pltm assigns a significant number of tokens to almost all 800 topics, in very similar proportions in both languages.",[0],"j=1 p (z2j|?) p (w 2 j| ?z2j) the difference between the jplsa model and the poly-lingual topic model of (mimno et al, 2009) is that we merge the vocabularies in the two languages and learn topic-specific word distributions over these merged vocabularies, instead of having pairs of topic-specific word distributions, one for each language, like in (mimno et al, 2009)",[0],11,method,4,4.0,0.5,102.0,0.51,51.0,0.4434782608695652,0,0.0,0.0,0.0,0.0,0.0,4 results on parallel text,abstract
D09-1092,D10-1025,[38],"this is unlike lda, in which each document is assumed to have its own document-specific distribution over topics.",[0],"another difference between our model and the poly-lingual lda model of (mimno et al, 2009) is that we use maximum aposteriori (map) instead of bayesian inference",[0],12,method,3,3.0,0.375,38.0,0.19,4.0,0.23529411764705882,0,0.0,0.0,0.0,0.0,0.0,3 polylingual topic model,abstract
D09-1092,D10-1025,[156],we use both jensen-shannon divergence and cosine distance.,[0],"for computing distance we used the l1-norm of the difference, which worked a bit better than the jensen shannon divergence between the topic vectors used in (mimno et al, 2009)",[0],13,method,4,4.0,0.5,156.0,0.78,105.0,0.9130434782608695,0,0.0,0.0,0.0,0.0,0.0,4 results on parallel text,abstract
D09-1092,D10-1025,[36],"each tuple is a set of documents that are loosely equivalent to each other, but written in different languages, e.g., corresponding wikipedia articles in french, english and german.",[0],"documents are defined as speeches by a single speaker, as in (mimno et al, 2009) .4 for the wikipedia set, we use 43,380 training documents, 8,675 development documents, and 8,675 final test set documents. for both corpora, the terms are extracted by word breaking all documents, removing the top 50 most frequent terms and keeping the next 20,000 most frequent terms",[0],14,method,3,3.0,0.375,36.0,0.18,2.0,0.11764705882352941,0,0.0,0.0,0.0,0.0,0.0,3 polylingual topic model,abstract
D09-1092,D10-1025,[170],"first, we explore whether comparable document tuples support the alignment of fine-grained topics, as demonstrated earlier using parallel documents.",[0],"in previously reported work, (mimno et al, 2009) evaluate parallel document retrieval using pltm on europarl speeches in english and spanish, using training and test sets of size similar to ours",[0],15,method,5,5.0,0.625,170.0,0.85,4.0,0.16,0,0.0,0.0,0.0,0.0,0.0,5 results on comparable texts,abstract
D09-1092,W12-3117,[29],"a recent extended abstract, developed concurrently by ni et al. (ni et al., 2009), discusses a multilingual topic model similar to the one presented here.",[0],"we assume that a higher dimensionality can lead to a better repartitioning of the vocabulary over the topics. multilingual lda has been used before in natural language processing ,e.g .polylingual topic models (mimno et al, 2009) or multilingual topic models for unaligned text (boyd-graber and blei, 2009)",[0],16,method,2,2.0,0.25,29.0,0.145,5.0,0.5,0,0.0,0.0,0.0,0.0,0.0,2 related work,abstract
D09-1092,W11-2133,[170],"first, we explore whether comparable document tuples support the alignment of fine-grained topics, as demonstrated earlier using parallel documents.",[0],"ji =wjk? m j i? m k=1w j k, (1) where m j is the topic distribution of document j and wk is the number of occurrences of phrase pair xk in document j. mimno et al (2009) extend the original concept of lda to support polylingual topic models (pltm), both on parallel (such as europarl) and partly comparable documents (such as wikipediaarticles)",[0],17,method,5,5.0,0.625,170.0,0.85,4.0,0.16,0,0.0,0.0,0.0,0.0,0.0,5 results on comparable texts,abstract
D09-1092,W11-2133,[168],"however, the growth of the web, and in particular wikipedia, has made comparable text corpora – documents that are topically similar but are not direct translations of one another – considerably more abundant than true parallel corpora.",[0],tuple-specific topic distributions arelearned using lda with distinct topic-word concentration parameters? l. mimno et al (2009) show that pltm sufficiently aligns topics in parallel corpora,[0],18,method,5,5.0,0.625,168.0,0.84,2.0,0.08,0,0.0,0.0,0.0,0.0,0.0,5 results on comparable texts,abstract
D09-1092,P14-2110,[29],"a recent extended abstract, developed concurrently by ni et al. (ni et al., 2009), discusses a multilingual topic model similar to the one presented here.",[0],"a good candidate for multilingual topic analyses are polylin gual topic models (mimno et al, 2009), which learn topics for multiple languages, creating tuples of language specific distributions over monolingual vocabularies for each topic",[0],19,method,2,2.0,0.25,29.0,0.145,5.0,0.5,0,0.0,0.0,0.0,0.0,0.0,2 related work,abstract
D09-1092,P14-2110,[110],"continuing with the example above, one might extract a set of connected wikipedia articles related to the focus of the journal and then train pltm on a joint corpus consisting of journal papers and wikipedia articles.",[0],"3csldato train a polylingual topic model on social media, we make two modifications to the model of mimno et al (2009): add a token specific language variable, and a process for identifying aligned top ics. first ,polylingual topic models require parallel or comparable corpora in which each document has an assigned language",[0],20,method,4,4.0,0.5,110.0,0.55,59.0,0.5130434782608696,0,0.0,0.0,0.0,0.0,0.0,4 results on parallel text,abstract
D10-1044,P11-2074,[144],in this paper we have proposed an approach for instance-weighting phrase pairs in an out-of-domain corpus in order to improve in-domain performance.,[0],"another popular task in smt is domain adaptation (foster et al, 2010)",[0],1,method,6,6.0,0.8571428571428571,144.0,0.935064935064935,1.0,0.1,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
D10-1044,P12-1048,"[95, 96]","phrase tables were extracted from the in and out training corpora (not the dev as was used for instance weighting models), and phrase pairs in the intersection of the in and out phrase tables were used as positive examples, with two alternate definitions of negative examples: the classifier trained using the 2nd definition had higher accuracy on a development set.
we used it to score all phrase pairs in the out table, in order to provide a feature for the instance-weighting model.",[0],"in addition, discriminative weighting methods were proposed to assign appropriate weights to the sentences from training corpus (matsoukas et al, 2009) or the phrase pairs of phrase table (foster et al, 2010)",[0],2,method,3_3,3.0,0.42857142857142855,95.5,0.6201298701298701,32.5,0.9848484848484849,0,0.0,0.0,0.0,0.0,0.0,"3 instance weighting, 3 instance weighting",abstract
D10-1044,D12-1129,[9],in this paper we study the problem of using a parallel corpus from a background domain (out) to improve performance on a target domain (in) for which a smaller amount of parallel training material—though adequate for reasonable performance—is also available.,[0],"domain knowledge also has the potential to improve open-text applications such as summarization (ceylan et al 2010) and machine translation (foster et al., 2010) .research in word sense disambiguation (navigli, 2009, wsd), the task aimed at the automatic labeling of text with word senses, has been oriented towards domain text understanding for several years now",[0],3,method,1,1.0,0.14285714285714285,9.0,0.05844155844155844,6.0,0.18181818181818182,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
D10-1044,P14-2093,[62],"to approximate these baselines, we implemented a very simple sentence selection algorithm in which parallel sentence pairs from out are ranked by the perplexity of their target half according to the in language model.",[0],"yasuda et al (2008) and foster et al (2010) ranked the sentence pairs in the general-domain corpus according to the perplexity scores of sentences, which are computed with respect to in-domain language models",[0],4,method,2,2.0,0.2857142857142857,62.0,0.4025974025974026,26.0,0.9629629629629629,0,0.0,0.0,0.0,0.0,0.0,2 baseline smt adaptation techniques,abstract
D10-1044,E12-1055,[28],we train linear mixture models for conditional phrase pair probabilities over in and out so as to maximize the likelihood of an empirical joint phrase-pair distribution extracted from a development set.,[0],"however, such confounding factors do not affect the optimization algorithm, which works with a fixed set of phrase pairs, and merely varies? .our main technical contributions are as fol lows: additionally to perplexity optimization for linear interpolation, which was first applied by foster et al (2010), we propose perplexity optimization for weighted counts (equation 3), and a modified implementation of linear interpolation. also, we independently perform perplexity minimization for all four features of the standard smttranslation model: the phrase translation probabilities p (t|s) and p (s|t), and the lexical weights lex (t|s) and lex (s|t)",[0],5,method,1,1.0,0.14285714285714285,28.0,0.18181818181818182,25.0,0.7575757575757576,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
D10-1044,E12-1055,[23],our second contribution is to apply instance weighting at the level of phrase pairs.,[0],"matsoukas et al (2009) propose an approach where each sentence is weighted according to a classifier, and foster et al (2010) ex tend this approach by weighting individual phrase pairs",[0],6,method,1,1.0,0.14285714285714285,23.0,0.14935064935064934,20.0,0.6060606060606061,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
D10-1044,E12-1055,[144],in this paper we have proposed an approach for instance-weighting phrase pairs in an out-of-domain corpus in order to improve in-domain performance.,[0],"these more fine-grained methods need not be seen as alternatives to coarse-grained ones. foster et al (2010) combine the two, applying linear interpolation to combine the instance 542 weighted out-of-domain model with an in-domain model",[0],7,method,6,6.0,0.8571428571428571,144.0,0.935064935064935,1.0,0.1,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
D10-1044,E12-1055,[9],in this paper we study the problem of using a parallel corpus from a background domain (out) to improve performance on a target domain (in) for which a smaller amount of parallel training material—though adequate for reasonable performance—is also available.,[0],"we expand on work by (foster et al 2010) in establishing translation model perplexity minimization as a robust baseline for a weighted combination of translationmodels.15 we demonstrate perplexity optimization for weighted counts, which are a natural extension of unadapted mle training, but are of little prominence in domain adaptation research",[0],9,method,1,1.0,0.14285714285714285,9.0,0.05844155844155844,6.0,0.18181818181818182,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
D10-1044,P12-1099,[28],we train linear mixture models for conditional phrase pair probabilities over in and out so as to maximize the likelihood of an empirical joint phrase-pair distribution extracted from a development set.,[0],"in addition to the basic approach of concatenation of in-domain and out-of-domain data, we also trained a log-linear mixture model (foster and kuhn, 2007) 940 as well as the linear mixture model of (foster et al, 2010) for conditional phrase-pair probabilities over in and out",[0],10,method,1,1.0,0.14285714285714285,28.0,0.18181818181818182,25.0,0.7575757575757576,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
D10-1044,P12-1099,[75],"however, it is robust, efficient, and easy to implement.4 to perform the maximization in (7), we used the popular l-bfgs algorithm (liu and nocedal, 1989), which requires gradient information.",[0],"m ?mpm (e? |f?) for efficiency and stability, we use the emalgorithm to find??, rather than l-bfgs as in (foster et al., 2010)",[0],12,method,3,3.0,0.42857142857142855,75.0,0.487012987012987,12.0,0.36363636363636365,0,0.0,0.0,0.0,0.0,0.0,3 instance weighting,abstract
D10-1044,P12-1099,[31],"for comparison to information-retrieval inspired baselines, eg (l¨u et al., 2007), we select sentences from out using language model perplexities from in.",[0],"foster et al (2010), however, uses a different approach to select related sentences from out",[0],13,method,1,1.0,0.14285714285714285,31.0,0.2012987012987013,28.0,0.8484848484848485,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
D10-1044,P12-1099,[22],"within this framework, we use features intended to capture degree of generality, including the output from an svm classifier that uses the intersection between in and out as positive examples.",[0],foster et al (2010) propose asimilar method for machine translation that uses features to capture degrees of generality,[0],14,method,1,1.0,0.14285714285714285,22.0,0.14285714285714285,19.0,0.5757575757575758,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
D10-1044,P13-1126,[23],our second contribution is to apply instance weighting at the level of phrase pairs.,[0],"as in (foster et al, 2010), this approach works at the level of phrase pairs",[0],15,method,1,1.0,0.14285714285714285,23.0,0.14935064935064934,20.0,0.6060606060606061,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
D10-1044,D11-1033,[62],"to approximate these baselines, we implemented a very simple sentence selection algorithm in which parallel sentence pairs from out are ranked by the perplexity of their target half according to the in language model.",[0],"the ranking of the sentences in a general-domain corpus according to in-domain perplexity has also been applied to machine translation by both yasuda et al (2008), and foster et al (2010)",[0],16,method,2,2.0,0.2857142857142857,62.0,0.4025974025974026,26.0,0.9629629629629629,0,0.0,0.0,0.0,0.0,0.0,2 baseline smt adaptation techniques,abstract
D10-1044,D11-1033,"[119, 120]","the 2nd block contains the ir system, which was tuned by selecting text in multiples of the size of the emea training corpus, according to dev set performance.
this significantly underperforms log-linear combination.",[0],"foster et al (2010) do not mention what percentage of the corpus they select for their ir-baseline, but they concatenate the data to their in-domain corpus and re port a decrease in performance",[0],17,result,4_4,4.0,0.5714285714285714,119.5,0.775974025974026,23.5,0.6714285714285715,0,0.0,0.0,0.0,0.0,0.0,"4 experiments, 4 experiments",abstract
D10-1044,D11-1033,"[23, 24]","our second contribution is to apply instance weighting at the level of phrase pairs.
sentence pairs are the natural instances for smt, but sentences often contain a mix of domain-specific and general language.",[0],"foster et al (2010) further perform this on extracted phrase pairs, not just sentences",[0],18,method,1_1,1.0,0.14285714285714285,23.5,0.1525974025974026,20.5,0.6212121212121212,0,0.0,0.0,0.0,0.0,0.0,"1 introduction, 1 introduction",abstract
D10-1044,P14-1012,[40],"we focus here instead on adapting the two most important features: the language model (lm), which estimates the probability p(wih) of a target word w following an ngram h; and the translation models (tm) p(slt) and p(t1s), which give the probability of source phrase s translating to target phrase t, and vice versa.",[0],"to address the first shortcoming, we adapt and extend some simple but effective phrase features as the input features for new dnn feature learning, and these features have been shown significant improvement for smt, such as, phrase pair similarity (zhao et al, 2004), phrase frequency, phrase length (hopkins and may, 2011), and phrase generative probability (foster et al, 2010), which also show further improvement for new phrase feature learning in our experiments",[0],19,method,2,2.0,0.2857142857142857,40.0,0.2597402597402597,4.0,0.14814814814814814,0,0.0,0.0,0.0,0.0,0.0,2 baseline smt adaptation techniques,abstract
D10-1044,P11-2074,[9.0],in this paper we study the problem of using a parallel corpus from a background domain (out) to improve performance on a target domain (in) for which a smaller amount of parallel training material—though adequate for reasonable performance—is also available.,[0],"another popular task in smt is domain adaptation (foster et al, 2010)",[0],1,method,1,1.0,0.14285714285714285,9.0,0.05844155844155844,6.0,0.18181818181818182,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
D10-1044,D12-1129,[9.0],in this paper we study the problem of using a parallel corpus from a background domain (out) to improve performance on a target domain (in) for which a smaller amount of parallel training material—though adequate for reasonable performance—is also available.,[0],"domain knowledge also has the potential to improve open-text applications such as summarization (ceylan et al 2010) and machine translation (foster et al., 2010) .research in word sense disambiguation (navigli, 2009, wsd), the task aimed at the automatic labeling of text with word senses, has been oriented towards domain text understanding for several years now",[0],3,aim,1,1.0,0.14285714285714285,9.0,0.05844155844155844,6.0,0.18181818181818182,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
D10-1044,P14-2093,[62.0],"to approximate these baselines, we implemented a very simple sentence selection algorithm in which parallel sentence pairs from out are ranked by the perplexity of their target half according to the in language model.",[0],"yasuda et al (2008) and foster et al (2010) ranked the sentence pairs in the general-domain corpus according to the perplexity scores of sentences, which are computed with respect to in-domain language models",[0],4,method,2,2.0,0.2857142857142857,62.0,0.4025974025974026,26.0,0.9629629629629629,0,0.0,0.0,0.0,0.0,0.0,2 baseline smt adaptation techniques,abstract
D10-1044,E12-1055,[71.0],"finally, we incorporate the instance-weighting model into a general linear combination, and learn weights and mixing parameters simultaneously. where cλ(s, t) is a modified count for pair (s, t) in out, u(s|t) is a prior distribution, and y is a prior weight.",[0],"however, such confounding factors do not affect the optimization algorithm, which works with a fixed set of phrase pairs, and merely varies? .our main technical contributions are as fol lows: additionally to perplexity optimization for linear interpolation, which was first applied by foster et al (2010), we propose perplexity optimization for weighted counts (equation 3), and a modified implementation of linear interpolation. also, we independently perform perplexity minimization for all four features of the standard smttranslation model: the phrase translation probabilities p (t|s) and p (s|t), and the lexical weights lex (t|s) and lex (s|t)",[0],5,method,3,3.0,0.42857142857142855,71.0,0.461038961038961,8.0,0.24242424242424243,0,0.0,0.0,0.0,0.0,0.0,3 instance weighting,abstract
D10-1044,E12-1055,[96.0],"we used it to score all phrase pairs in the out table, in order to provide a feature for the instance-weighting model.",[0],"matsoukas et al (2009) propose an approach where each sentence is weighted according to a classifier, and foster et al (2010) ex tend this approach by weighting individual phrase pairs",[0],6,aim,3,3.0,0.42857142857142855,96.0,0.6233766233766234,33.0,1.0,0,0.0,0.0,0.0,0.0,0.0,3 instance weighting,abstract
D10-1044,E12-1055,[71.0],"finally, we incorporate the instance-weighting model into a general linear combination, and learn weights and mixing parameters simultaneously. where cλ(s, t) is a modified count for pair (s, t) in out, u(s|t) is a prior distribution, and y is a prior weight.",[0],"these more fine-grained methods need not be seen as alternatives to coarse-grained ones. foster et al (2010) combine the two, applying linear interpolation to combine the instance 542 weighted out-of-domain model with an in-domain model",[0],7,result,3,3.0,0.42857142857142855,71.0,0.461038961038961,8.0,0.24242424242424243,0,0.0,0.0,0.0,0.0,0.0,3 instance weighting,abstract
D10-1044,E12-1055,[144.0],in this paper we have proposed an approach for instance-weighting phrase pairs in an out-of-domain corpus in order to improve in-domain performance.,[0],note that both data sets have a relatively high ratio of in-domain to out-of-domain parallel training data (1:20 for de? en and 1:5 for ht? en) previous research has been performed with ratios of 1:100 (foster et al 2010) or 1:400 (axelrod et al 2011),[0],8,result,6,6.0,0.8571428571428571,144.0,0.935064935064935,1.0,0.1,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
D10-1044,E12-1055,[62.0],"to approximate these baselines, we implemented a very simple sentence selection algorithm in which parallel sentence pairs from out are ranked by the perplexity of their target half according to the in language model.",[0],"we expand on work by (foster et al 2010) in establishing translation model perplexity minimization as a robust baseline for a weighted combination of translationmodels.15 we demonstrate perplexity optimization for weighted counts, which are a natural extension of unadapted mle training, but are of little prominence in domain adaptation research",[0],9,method,2,2.0,0.2857142857142857,62.0,0.4025974025974026,26.0,0.9629629629629629,0,0.0,0.0,0.0,0.0,0.0,2 baseline smt adaptation techniques,abstract
D10-1044,P12-1099,[45.0],"an easy way to achieve this is to put the domain-specific lms and tms into the top-level log-linear model and learn optimal weights with mert (och, 2003).",[0],"in addition to the basic approach of concatenation of in-domain and out-of-domain data, we also trained a log-linear mixture model (foster and kuhn, 2007) 940 as well as the linear mixture model of (foster et al, 2010) for conditional phrase-pair probabilities over in and out",[0],10,method,2,2.0,0.2857142857142857,45.0,0.2922077922077922,9.0,0.3333333333333333,0,0.0,0.0,0.0,0.0,0.0,2 baseline smt adaptation techniques,abstract
D10-1044,P12-1099,[75.0],"however, it is robust, efficient, and easy to implement.4 to perform the maximization in (7), we used the popular l-bfgs algorithm (liu and nocedal, 1989), which requires gradient information.",[0],"m ?mpm (e? |f?) for efficiency and stability, we use the emalgorithm to find??, rather than l-bfgs as in (foster et al., 2010)",[0],12,method,3,3.0,0.42857142857142855,75.0,0.487012987012987,12.0,0.36363636363636365,0,0.0,0.0,0.0,0.0,0.0,3 instance weighting,abstract
D10-1044,P12-1099,[22.0],"within this framework, we use features intended to capture degree of generality, including the output from an svm classifier that uses the intersection between in and out as positive examples.",[0],foster et al (2010) propose asimilar method for machine translation that uses features to capture degrees of generality,[0],14,method,1,1.0,0.14285714285714285,22.0,0.14285714285714285,19.0,0.5757575757575758,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
D10-1044,P13-1126,[96.0],"we used it to score all phrase pairs in the out table, in order to provide a feature for the instance-weighting model.",[0],"as in (foster et al, 2010), this approach works at the level of phrase pairs",[0],15,aim,3,3.0,0.42857142857142855,96.0,0.6233766233766234,33.0,1.0,0,0.0,0.0,0.0,0.0,0.0,3 instance weighting,abstract
D10-1044,D11-1033,[62.0],"to approximate these baselines, we implemented a very simple sentence selection algorithm in which parallel sentence pairs from out are ranked by the perplexity of their target half according to the in language model.",[0],"the ranking of the sentences in a general-domain corpus according to in-domain perplexity has also been applied to machine translation by both yasuda et al (2008), and foster et al (2010)",[0],16,method,2,2.0,0.2857142857142857,62.0,0.4025974025974026,26.0,0.9629629629629629,0,0.0,0.0,0.0,0.0,0.0,2 baseline smt adaptation techniques,abstract
D10-1044,D11-1033,[42.0],the natural baseline approach is to concatenate data from in and out.,[0],"foster et al (2010) do not mention what percentage of the corpus they select for their ir-baseline, but they concatenate the data to their in-domain corpus and re port a decrease in performance",[0],17,aim,2,2.0,0.2857142857142857,42.0,0.2727272727272727,6.0,0.2222222222222222,0,0.0,0.0,0.0,0.0,0.0,2 baseline smt adaptation techniques,abstract
D10-1044,D11-1033,[96.0],"we used it to score all phrase pairs in the out table, in order to provide a feature for the instance-weighting model.",[0],"foster et al (2010) further perform this on extracted phrase pairs, not just sentences",[0],18,aim,3,3.0,0.42857142857142855,96.0,0.6233766233766234,33.0,1.0,0,0.0,0.0,0.0,0.0,0.0,3 instance weighting,abstract
D10-1044,P11-2074,[4],domain adaptation is a common concern when optimizing empirical nlp applications.,[0],"another popular task in smt is domain adaptation (foster et al, 2010)",[0],1,method,1,1.0,0.14285714285714285,4.0,0.025974025974025976,1.0,0.030303030303030304,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
D10-1044,P12-1048,[132],"we have already mentioned the closely related work by matsoukas et al (2009) on discriminative corpus weighting, and jiang and zhai (2007) on (nondiscriminative) instance weighting.",[0],"in addition, discriminative weighting methods were proposed to assign appropriate weights to the sentences from training corpus (matsoukas et al, 2009) or the phrase pairs of phrase table (foster et al, 2010)",[0],2,method,5,5.0,0.7142857142857143,132.0,0.8571428571428571,1.0,0.08333333333333333,0,0.0,0.0,0.0,0.0,0.0,5 related work,abstract
D10-1044,D12-1129,[7],"for developers of statistical machine translation (smt) systems, an additional complication is the heterogeneous nature of smt components (word-alignment model, language model, translation model, etc.",[0],"domain knowledge also has the potential to improve open-text applications such as summarization (ceylan et al 2010) and machine translation (foster et al., 2010) .research in word sense disambiguation (navigli, 2009, wsd), the task aimed at the automatic labeling of text with word senses, has been oriented towards domain text understanding for several years now",[0],3,method,1,1.0,0.14285714285714285,7.0,0.045454545454545456,4.0,0.12121212121212122,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
D10-1044,P14-2093,[62],"to approximate these baselines, we implemented a very simple sentence selection algorithm in which parallel sentence pairs from out are ranked by the perplexity of their target half according to the in language model.",[0],"yasuda et al (2008) and foster et al (2010) ranked the sentence pairs in the general-domain corpus according to the perplexity scores of sentences, which are computed with respect to in-domain language models",[0],4,method,2,2.0,0.2857142857142857,62.0,0.4025974025974026,26.0,0.9629629629629629,0,0.0,0.0,0.0,0.0,0.0,2 baseline smt adaptation techniques,abstract
D10-1044,E12-1055,[50],"linear weights are difficult to incorporate into the standard mert procedure because they are “hidden” within a top-level probability that represents the linear combination.1 following previous work (foster and kuhn, 2007), we circumvent this problem by choosing weights to optimize corpus loglikelihood, which is roughly speaking the training criterion used by the lm and tm themselves.",[0],"however, such confounding factors do not affect the optimization algorithm, which works with a fixed set of phrase pairs, and merely varies? .our main technical contributions are as fol lows: additionally to perplexity optimization for linear interpolation, which was first applied by foster et al (2010), we propose perplexity optimization for weighted counts (equation 3), and a modified implementation of linear interpolation. also, we independently perform perplexity minimization for all four features of the standard smttranslation model: the phrase translation probabilities p (t|s) and p (s|t), and the lexical weights lex (t|s) and lex (s|t)",[0],5,method,2,2.0,0.2857142857142857,50.0,0.3246753246753247,14.0,0.5185185185185185,0,0.0,0.0,0.0,0.0,0.0,2 baseline smt adaptation techniques,abstract
D10-1044,E12-1055,[152],we will also directly compare with a baseline similar to the matsoukas et al approach in order to measure the benefit from weighting phrase pairs (or ngrams) rather than full sentences.,[0],"matsoukas et al (2009) propose an approach where each sentence is weighted according to a classifier, and foster et al (2010) ex tend this approach by weighting individual phrase pairs",[0],6,method,6,6.0,0.8571428571428571,152.0,0.987012987012987,9.0,0.9,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
D10-1044,E12-1055,[144],in this paper we have proposed an approach for instance-weighting phrase pairs in an out-of-domain corpus in order to improve in-domain performance.,[0],"these more fine-grained methods need not be seen as alternatives to coarse-grained ones. foster et al (2010) combine the two, applying linear interpolation to combine the instance 542 weighted out-of-domain model with an in-domain model",[0],7,method,6,6.0,0.8571428571428571,144.0,0.935064935064935,1.0,0.1,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
D10-1044,E12-1055,[9],in this paper we study the problem of using a parallel corpus from a background domain (out) to improve performance on a target domain (in) for which a smaller amount of parallel training material—though adequate for reasonable performance—is also available.,[0],note that both data sets have a relatively high ratio of in-domain to out-of-domain parallel training data (1:20 for de? en and 1:5 for ht? en) previous research has been performed with ratios of 1:100 (foster et al 2010) or 1:400 (axelrod et al 2011),[0],8,method,1,1.0,0.14285714285714285,9.0,0.05844155844155844,6.0,0.18181818181818182,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
D10-1044,E12-1055,[75],"however, it is robust, efficient, and easy to implement.4 to perform the maximization in (7), we used the popular l-bfgs algorithm (liu and nocedal, 1989), which requires gradient information.",[0],"we expand on work by (foster et al 2010) in establishing translation model perplexity minimization as a robust baseline for a weighted combination of translationmodels.15 we demonstrate perplexity optimization for weighted counts, which are a natural extension of unadapted mle training, but are of little prominence in domain adaptation research",[0],9,method,3,3.0,0.42857142857142855,75.0,0.487012987012987,12.0,0.36363636363636365,0,0.0,0.0,0.0,0.0,0.0,3 instance weighting,abstract
D10-1044,P12-1099,[28],we train linear mixture models for conditional phrase pair probabilities over in and out so as to maximize the likelihood of an empirical joint phrase-pair distribution extracted from a development set.,[0],"in addition to the basic approach of concatenation of in-domain and out-of-domain data, we also trained a log-linear mixture model (foster and kuhn, 2007) 940 as well as the linear mixture model of (foster et al, 2010) for conditional phrase-pair probabilities over in and out",[0],10,method,1,1.0,0.14285714285714285,28.0,0.18181818181818182,25.0,0.7575757575757576,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
D10-1044,P12-1099,[97],we carried out translation experiments in two different settings.,[0],m ?mpm (e? |f?) our technique for setting? m is similar to that outlined in foster et al (2010),[0],11,method,4,4.0,0.5714285714285714,97.0,0.6298701298701299,1.0,0.02857142857142857,0,0.0,0.0,0.0,0.0,0.0,4 experiments,abstract
D10-1044,P12-1099,[75],"however, it is robust, efficient, and easy to implement.4 to perform the maximization in (7), we used the popular l-bfgs algorithm (liu and nocedal, 1989), which requires gradient information.",[0],"m ?mpm (e? |f?) for efficiency and stability, we use the emalgorithm to find??, rather than l-bfgs as in (foster et al., 2010)",[0],12,method,3,3.0,0.42857142857142855,75.0,0.487012987012987,12.0,0.36363636363636365,0,0.0,0.0,0.0,0.0,0.0,3 instance weighting,abstract
D10-1044,P12-1099,[143],"other work includes transferring latent topic distributions from source to target language for lm adaptation, (tam et al., 2007) and adapting features at the sentence level to different categories of sentence (finch and sumita, 2008).",[0],"foster et al (2010), however, uses a different approach to select related sentences from out",[0],13,method,5,5.0,0.7142857142857143,143.0,0.9285714285714286,12.0,1.0,0,0.0,0.0,0.0,0.0,0.0,5 related work,abstract
D10-1044,P12-1099,[153],"finally, we intend to explore more sophisticated instanceweighting features for capturing the degree of generality of phrase pairs.",[0],foster et al (2010) propose asimilar method for machine translation that uses features to capture degrees of generality,[0],14,method,6,6.0,0.8571428571428571,153.0,0.9935064935064936,10.0,1.0,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
D10-1044,P13-1126,[144],in this paper we have proposed an approach for instance-weighting phrase pairs in an out-of-domain corpus in order to improve in-domain performance.,[0],"as in (foster et al, 2010), this approach works at the level of phrase pairs",[0],15,method,6,6.0,0.8571428571428571,144.0,0.935064935064935,1.0,0.1,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
D10-1044,D11-1033,[62],"to approximate these baselines, we implemented a very simple sentence selection algorithm in which parallel sentence pairs from out are ranked by the perplexity of their target half according to the in language model.",[0],"the ranking of the sentences in a general-domain corpus according to in-domain perplexity has also been applied to machine translation by both yasuda et al (2008), and foster et al (2010)",[0],16,method,2,2.0,0.2857142857142857,62.0,0.4025974025974026,26.0,0.9629629629629629,0,0.0,0.0,0.0,0.0,0.0,2 baseline smt adaptation techniques,abstract
D10-1044,D11-1033,[141],"moving beyond directly related work, major themes in smt adaptation include the ir (hildebrand et al., 2005; l¨u et al., 2007; zhao et al., 2004) and mixture (finch and sumita, 2008; foster and kuhn, 2007; koehn and schroeder, 2007; l¨u et al., 2007) approaches for lms and tms described above, as well as methods for exploiting monolingual in-domain text, typically by translating it automatically and then performing self training (bertoldi and federico, 2009; ueffing et al., 2007; schwenk and senellart, 2009).",[0],"foster et al (2010) do not mention what percentage of the corpus they select for their ir-baseline, but they concatenate the data to their in-domain corpus and re port a decrease in performance",[0],17,method,5,5.0,0.7142857142857143,141.0,0.9155844155844156,10.0,0.8333333333333334,0,0.0,0.0,0.0,0.0,0.0,5 related work,abstract
D10-1044,D11-1033,[28],we train linear mixture models for conditional phrase pair probabilities over in and out so as to maximize the likelihood of an empirical joint phrase-pair distribution extracted from a development set.,[0],"foster et al (2010) further perform this on extracted phrase pairs, not just sentences",[0],18,method,1,1.0,0.14285714285714285,28.0,0.18181818181818182,25.0,0.7575757575757576,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
D10-1044,P14-1012,[37],"standard smt systems have a hierarchical parameter structure: top-level log-linear weights are used to combine a small set of complex features, interpreted as log probabilities, many of which have their own internal parameters and objectives.",[0],"to address the first shortcoming, we adapt and extend some simple but effective phrase features as the input features for new dnn feature learning, and these features have been shown significant improvement for smt, such as, phrase pair similarity (zhao et al, 2004), phrase frequency, phrase length (hopkins and may, 2011), and phrase generative probability (foster et al, 2010), which also show further improvement for new phrase feature learning in our experiments",[0],19,method,2,2.0,0.2857142857142857,37.0,0.24025974025974026,1.0,0.037037037037037035,0,0.0,0.0,0.0,0.0,0.0,2 baseline smt adaptation techniques,abstract
E03-1005,N06-1045,[105],"the derivation with the smallest sum, or highest rank, is taken as the final best derivation producing the best parse tree in simplicity-dop.3 although bod (2000b) reports that simplicity dop is outperformed by likelihood-dop, its results are still rather impressive for such a simple model.",[0],"data-oriented parsing (dop)? s methodology is to calculate weighted derivations, but as noted in (bod, 2003), it is the highest ranking parse, not derivation, that is desired",[0],2,method,3,3.0,0.5,105.0,0.7142857142857143,8.0,0.36363636363636365,0,0.0,0.0,0.0,0.0,0.0,3 a new notion of the best parse tree,abstract
E03-1005,D07-1058,[145],this paper showed that a pcfg-reduction of dop in combination with a new notion of the best parse tree results in fast processing times and very competitive accuracy on the wall street journal treebank.,[0],"goodman? s transform, in com bi nation with a range of heuristics, allowed bod (2003) to run the dop model on the penn treebank wsj benchmark and obtain some of the best results obtained with a generative model",[0],3,method,5,5.0,0.8333333333333334,145.0,0.9863945578231292,10.0,0.9090909090909091,,,,,,,5 conclusion,
E03-1005,D07-1058,[80],dop1 has a serious bias: its subtree estimator provides more probability to nodes with more subtrees (bonnema et al. 1999).,[0],"zuidema (2006a) shows that also the estimator (bod, 2003) uses is biased and inconsistent, and will, even in the limit of infinite data, not correctly identify many possible distributions over trees",[0],4,method,2,2.0,0.3333333333333333,80.0,0.54421768707483,32.0,0.6530612244897959,,,,,,,2 pcfg-reductions of dop,
E03-1005,P11-1086,[143],"while sl-dop and ls-dop have been compared before in bod (2002), especially in the context of musical parsing, this paper presents the the dop approach is based on two distinctive features: (1) the use of corpus fragments rather than grammar rules, and (2) the use of arbitrarily large fragments rather than restricted ones.",[0],"second, we compare against a composed-rule system, which is analogous to the data oriented parsing (dop) approach in parsing (bod, 2003)",[0],5,method,5,5.0,0.8333333333333334,143.0,0.9727891156462585,8.0,0.7272727272727273,0,0.0,0.0,0.0,0.0,0.0,5 conclusion,abstract
E03-1005,P04-1013,"[140, 141]",the highest accuracy is obtained by sl-dop at 12 n 14: an lp of 90.8% and an lr of 90.7%.this is roughly an 11% relative reduction in error rate over charniak (2000) and bods pcfg-reduction reported in table 1.,[0],"our best performing model is more accurate than all these previous models except (bod, 2003)",[0],6,result,5_5,5.0,0.8333333333333334,140.5,0.95578231292517,5.5,0.5,0,0.0,0.0,0.0,0.0,0.0,"5 conclusion, 5 conclusion",abstract
E03-1005,P04-1013,[140],the highest accuracy is obtained by sl-dop at 12 n 14: an lp of 90.8% and an lr of 90.7%.,[0],"we find that the discriminative probability model is much worse than the generative one, but that training to optimize the discriminative criteria results in improved performance. performance of the latter model on the standard test set achieves 90.1% f-measure on constituents, which is the second best current ac curacy level, and only 0.6% below the current best (bod, 2003) .this paper has also proposed a neural network training method which optimizes a discriminative criteria even when the parameters being estimated are those of a generative probability model",[0],7,result,5,5.0,0.8333333333333334,140.0,0.9523809523809523,5.0,0.45454545454545453,0,0.0,0.0,0.0,0.0,0.0,5 conclusion,abstract
E03-1005,E06-2025,"[102, 103]","in case the shortest derivation is not unique, bod (2000b) proposes to back off to a frequency ordering of the subtrees.
that is, all subtrees of each root label are assigned a rank according to their frequency in the treebank: the most frequent subtree (or subtrees) of each root label gets rank 1, the second most frequent subtree gets rank 2, etc.",[0],"similarly, (bod, 2003) changes the way frequenciesfi are counted, with a similar effect",[0],10,method,3_3,3.0,0.5,102.5,0.6972789115646258,5.5,0.25,0,0.0,0.0,0.0,0.0,0.0,"3 a new notion of the best parse tree, 3 a new notion of the best parse tree",abstract
E03-1005,W06-2905,[140],the highest accuracy is obtained by sl-dop at 12 n 14: an lp of 90.8% and an lr of 90.7%.,[0],"(henceforth, stsgs), which can represent single words, contiguous and noncontiguous mwes, context-free rules or complete parse trees in a unified representation. my approach is closely related to work in statistical parsing known as data-oriented parsing (dop), an empirically highly successful approach with labeled recall and precision scores on the penn tree bank that are among the best currently obtained (bod, 2003)",[0],12,result,5,5.0,0.8333333333333334,140.0,0.9523809523809523,5.0,0.45454545454545453,0,0.0,0.0,0.0,0.0,0.0,5 conclusion,abstract
E03-1005,P05-1022,[140],the highest accuracy is obtained by sl-dop at 12 n 14: an lp of 90.8% and an lr of 90.7%.,[0],"this result is only slightly higher than the highest reported result for this test-set, bod? s (.907) (bod,2003)",[0],14,result,5,5.0,0.8333333333333334,140.0,0.9523809523809523,5.0,0.45454545454545453,0,0.0,0.0,0.0,0.0,0.0,5 conclusion,abstract
E03-1005,P07-1051,[46],"most previous notions of best parse tree in dop1 were based on a probabilistic metric, with bod (2000b) as a notable exception, who used a simplicity metric based on the shortest derivation.",[0],"this assumption is in consonance with the principle of simplicity, but there are also empirical reasons for the shortest derivation assumption: in bod (2003) and hearne and way (2006), it is shown that dop models that select the preferred parse of a test sentence using the shortest derivation criterion perform very well",[0],16,method,1,1.0,0.16666666666666666,46.0,0.3129251700680272,43.0,0.9555555555555556,0,0.0,0.0,0.0,0.0,0.0,1 introduction: a little history,abstract
E03-1005,P07-1051,"[85, 86]","for example, bod (2001) samples a fixed number of subtrees of each depth, which has the effect of assigning roughly equal weight to each node in the training data, and roughly exponentially less probability for larger trees (see goodman 2002: 12).
bod reports state-of-the-art results with this method, and observes no decrease in parse accuracy when larger subtrees are included (using subtrees up to depth 14).",[0],"but equally important is the fact that this new dop* model does not suffer from a decrease in parse accuracy if larger subtrees are included, whereas the original dop model needs to be redressed by a correction factor to maintain this property (bod 2003)",[0],17,method,2_2,2.0,0.3333333333333333,85.5,0.5816326530612245,37.5,0.7653061224489796,0,0.0,0.0,0.0,0.0,0.0,"2 pcfg-reductions of dop, 2 pcfg-reductions of dop",abstract
E03-1005,W04-0305,[140],the highest accuracy is obtained by sl-dop at 12 n 14: an lp of 90.8% and an lr of 90.7%.,[0],"a moderately larger vocabulary version (4215 tag-word pairs) of this parser achieves 89.8% f-measure on section 0, where the best current result on the testing set is 90.7% (bod, 2003)",[0],19,result,5,5.0,0.8333333333333334,140.0,0.9523809523809523,5.0,0.45454545454545453,0,0.0,0.0,0.0,0.0,0.0,5 conclusion,abstract
E03-1005,P06-1109,[115],the only thing that needs to be changed for simplicity-dop is that all subtrees should be assigned equal probabilities.,[0],the probability of a parse tree t is the sum of the 1 this subtree probability is redressed by a simple correction factor discussed in goodman (2003: 136) and bod (2003),[0],20,method,3,3.0,0.5,115.0,0.782312925170068,18.0,0.8181818181818182,0,0.0,0.0,0.0,0.0,0.0,3 a new notion of the best parse tree,abstract
E03-1005,N06-1045,[105.0],"the derivation with the smallest sum, or highest rank, is taken as the final best derivation producing the best parse tree in simplicity-dop.3 although bod (2000b) reports that simplicity dop is outperformed by likelihood-dop, its results are still rather impressive for such a simple model.",[0],"data-oriented parsing (dop)? s methodology is to calculate weighted derivations, but as noted in (bod, 2003), it is the highest ranking parse, not derivation, that is desired",[0],2,result,3,3.0,0.5,105.0,0.7142857142857143,8.0,0.36363636363636365,0,0.0,0.0,0.0,0.0,0.0,3 a new notion of the best parse tree,abstract
E03-1005,D07-1058,[41.0],this paper presents the first published results with goodman's pcfg-reductions of both bonnema et al. 's (1999) and bod's (2001) estimators on the wsj.,[0],"goodman? s transform, in com bi nation with a range of heuristics, allowed bod (2003) to run the dop model on the penn treebank wsj benchmark and obtain some of the best results obtained with a generative model",[0],3,aim,1,1.0,0.16666666666666666,41.0,0.2789115646258503,38.0,0.8444444444444444,,,,,,,1 introduction: a little history,
E03-1005,D07-1058,[80.0],dop1 has a serious bias: its subtree estimator provides more probability to nodes with more subtrees (bonnema et al. 1999).,[0],"zuidema (2006a) shows that also the estimator (bod, 2003) uses is biased and inconsistent, and will, even in the limit of infinite data, not correctly identify many possible distributions over trees",[0],4,result,2,2.0,0.3333333333333333,80.0,0.54421768707483,32.0,0.6530612244897959,,,,,,,2 pcfg-reductions of dop,
E03-1005,P11-1086,[143.0],"while sl-dop and ls-dop have been compared before in bod (2002), especially in the context of musical parsing, this paper presents the the dop approach is based on two distinctive features: (1) the use of corpus fragments rather than grammar rules, and (2) the use of arbitrarily large fragments rather than restricted ones.",[0],"second, we compare against a composed-rule system, which is analogous to the data oriented parsing (dop) approach in parsing (bod, 2003)",[0],5,method,5,5.0,0.8333333333333334,143.0,0.9727891156462585,8.0,0.7272727272727273,0,0.0,0.0,0.0,0.0,0.0,5 conclusion,abstract
E03-1005,P04-1013,[146.0],this paper also re-affirmed that the coarsegrained approach of using all subtrees from a treebank outperforms the fine-grained approach of specifically modeling lexical-syntactic depen dencies (as e.g. in collins 1999 and charniak 2000).,[0],"our best performing model is more accurate than all these previous models except (bod, 2003)",[0],6,method,5,5.0,0.8333333333333334,146.0,0.9931972789115646,11.0,1.0,0,0.0,0.0,0.0,0.0,0.0,5 conclusion,abstract
E03-1005,P04-1013,[140.0],the highest accuracy is obtained by sl-dop at 12 n 14: an lp of 90.8% and an lr of 90.7%.,[0],"we find that the discriminative probability model is much worse than the generative one, but that training to optimize the discriminative criteria results in improved performance. performance of the latter model on the standard test set achieves 90.1% f-measure on constituents, which is the second best current ac curacy level, and only 0.6% below the current best (bod, 2003) .this paper has also proposed a neural network training method which optimizes a discriminative criteria even when the parameters being estimated are those of a generative probability model",[0],7,result,5,5.0,0.8333333333333334,140.0,0.9523809523809523,5.0,0.45454545454545453,0,0.0,0.0,0.0,0.0,0.0,5 conclusion,abstract
E03-1005,W06-2905,[105.0],"the derivation with the smallest sum, or highest rank, is taken as the final best derivation producing the best parse tree in simplicity-dop.3 although bod (2000b) reports that simplicity dop is outperformed by likelihood-dop, its results are still rather impressive for such a simple model.",[0],"(henceforth, stsgs), which can represent single words, contiguous and noncontiguous mwes, context-free rules or complete parse trees in a unified representation. my approach is closely related to work in statistical parsing known as data-oriented parsing (dop), an empirically highly successful approach with labeled recall and precision scores on the penn tree bank that are among the best currently obtained (bod, 2003)",[0],12,result,3,3.0,0.5,105.0,0.7142857142857143,8.0,0.36363636363636365,0,0.0,0.0,0.0,0.0,0.0,3 a new notion of the best parse tree,abstract
E03-1005,P05-1022,[140.0],the highest accuracy is obtained by sl-dop at 12 n 14: an lp of 90.8% and an lr of 90.7%.,[0],"this result is only slightly higher than the highest reported result for this test-set, bod? s (.907) (bod,2003)",[0],14,result,5,5.0,0.8333333333333334,140.0,0.9523809523809523,5.0,0.45454545454545453,0,0.0,0.0,0.0,0.0,0.0,5 conclusion,abstract
E03-1005,P07-1051,[100.0],"in bod (2000b), an alternative notion for the best parse tree was proposed based on a simplicity criterion: instead of producing the most probable tree, this model produced the tree generated by the shortest derivation with the fewest training subtrees.",[0],"this assumption is in consonance with the principle of simplicity, but there are also empirical reasons for the shortest derivation assumption: in bod (2003) and hearne and way (2006), it is shown that dop models that select the preferred parse of a test sentence using the shortest derivation criterion perform very well",[0],16,result,3,3.0,0.5,100.0,0.6802721088435374,3.0,0.13636363636363635,0,0.0,0.0,0.0,0.0,0.0,3 a new notion of the best parse tree,abstract
E03-1005,P07-1051,[30.0],bod (2000a) solved this problem by training the subtree probabilities by a maximum likelihood procedure based on expectation-maximization.,[0],"but equally important is the fact that this new dop* model does not suffer from a decrease in parse accuracy if larger subtrees are included, whereas the original dop model needs to be redressed by a correction factor to maintain this property (bod 2003)",[0],17,method,1,1.0,0.16666666666666666,30.0,0.20408163265306123,27.0,0.6,0,0.0,0.0,0.0,0.0,0.0,1 introduction: a little history,abstract
E03-1005,W04-0305,[140.0],the highest accuracy is obtained by sl-dop at 12 n 14: an lp of 90.8% and an lr of 90.7%.,[0],"a moderately larger vocabulary version (4215 tag-word pairs) of this parser achieves 89.8% f-measure on section 0, where the best current result on the testing set is 90.7% (bod, 2003)",[0],19,result,5,5.0,0.8333333333333334,140.0,0.9523809523809523,5.0,0.45454545454545453,0,0.0,0.0,0.0,0.0,0.0,5 conclusion,abstract
E03-1005,P06-1109,[30.0],bod (2000a) solved this problem by training the subtree probabilities by a maximum likelihood procedure based on expectation-maximization.,[0],the probability of a parse tree t is the sum of the 1 this subtree probability is redressed by a simple correction factor discussed in goodman (2003: 136) and bod (2003),[0],20,method,1,1.0,0.16666666666666666,30.0,0.20408163265306123,27.0,0.6,0,0.0,0.0,0.0,0.0,0.0,1 introduction: a little history,abstract
E03-1005,N06-1045,[20],"thus the major innovations of dop are: 2. the use of arbitrarily large fragments rather than restricted ones both have gained or are gaining wide usage, and are also becoming relevant for theoretical linguistics (see bod et al. 2003a).",[0],"data-oriented parsing (dop)? s methodology is to calculate weighted derivations, but as noted in (bod, 2003), it is the highest ranking parse, not derivation, that is desired",[0],2,method,1,1.0,0.16666666666666666,20.0,0.1360544217687075,17.0,0.37777777777777777,0,0.0,0.0,0.0,0.0,0.0,1 introduction: a little history,abstract
E03-1005,D07-1058,[74],goodman's main theorem is that this construction produces pcfg derivations isomorphic to dop derivations with equal probability.,[0],"goodman? s transform, in com bi nation with a range of heuristics, allowed bod (2003) to run the dop model on the penn treebank wsj benchmark and obtain some of the best results obtained with a generative model",[0],3,method,2,2.0,0.3333333333333333,74.0,0.5034013605442177,26.0,0.5306122448979592,,,,,,,2 pcfg-reductions of dop,
E03-1005,D07-1058,[44],"but while bod's estimator obtains state-of-the-art results on the wsj, comparable to charniak (2000) and collins (2000), bonnema et al. 's estimator performs worse and is comparable to collins (1996).",[0],"zuidema (2006a) shows that also the estimator (bod, 2003) uses is biased and inconsistent, and will, even in the limit of infinite data, not correctly identify many possible distributions over trees",[0],4,method,1,1.0,0.16666666666666666,44.0,0.29931972789115646,41.0,0.9111111111111111,,,,,,,1 introduction: a little history,
E03-1005,P11-1086,[143],"while sl-dop and ls-dop have been compared before in bod (2002), especially in the context of musical parsing, this paper presents the the dop approach is based on two distinctive features: (1) the use of corpus fragments rather than grammar rules, and (2) the use of arbitrarily large fragments rather than restricted ones.",[0],"second, we compare against a composed-rule system, which is analogous to the data oriented parsing (dop) approach in parsing (bod, 2003)",[0],5,method,5,5.0,0.8333333333333334,143.0,0.9727891156462585,8.0,0.7272727272727273,0,0.0,0.0,0.0,0.0,0.0,5 conclusion,abstract
E03-1005,P04-1013,[145],this paper showed that a pcfg-reduction of dop in combination with a new notion of the best parse tree results in fast processing times and very competitive accuracy on the wall street journal treebank.,[0],"our best performing model is more accurate than all these previous models except (bod, 2003)",[0],6,method,5,5.0,0.8333333333333334,145.0,0.9863945578231292,10.0,0.9090909090909091,0,0.0,0.0,0.0,0.0,0.0,5 conclusion,abstract
E03-1005,P04-1013,[134],"this may be explained by the fact our best results in bod (2001) were obtained by testing various subtree restrictions until the highest accuracy was obtained, while in the current experiment we used all subtrees as given by the pcfg-reduction.",[0],"we find that the discriminative probability model is much worse than the generative one, but that training to optimize the discriminative criteria results in improved performance. performance of the latter model on the standard test set achieves 90.1% f-measure on constituents, which is the second best current ac curacy level, and only 0.6% below the current best (bod, 2003) .this paper has also proposed a neural network training method which optimizes a discriminative criteria even when the parameters being estimated are those of a generative probability model",[0],7,method,4,4.0,0.6666666666666666,134.0,0.9115646258503401,15.0,0.9375,0,0.0,0.0,0.0,0.0,0.0,4 experiments,abstract
E03-1005,E06-2025,[22],dop1 combines subtrees from a treebank by means of node-substitution and computes the probability of a tree from the normalized frequencies of the subtrees (see section 2 for a full definition).,[0],"similarly, (bod, 2003) changes the way frequenciesfi are counted, with a similar effect",[0],10,method,1,1.0,0.16666666666666666,22.0,0.14965986394557823,19.0,0.4222222222222222,0,0.0,0.0,0.0,0.0,0.0,1 introduction: a little history,abstract
E03-1005,W06-2905,[133],it should be mentioned that the best precision and recall scores reported in bod (2001) are slightly better than the ones reported here (the difference is only 0.2% for sentences 100 words).,[0],"(henceforth, stsgs), which can represent single words, contiguous and noncontiguous mwes, context-free rules or complete parse trees in a unified representation. my approach is closely related to work in statistical parsing known as data-oriented parsing (dop), an empirically highly successful approach with labeled recall and precision scores on the penn tree bank that are among the best currently obtained (bod, 2003)",[0],12,method,4,4.0,0.6666666666666666,133.0,0.9047619047619048,14.0,0.875,0,0.0,0.0,0.0,0.0,0.0,4 experiments,abstract
E03-1005,W06-2905,[25],"many implementations of dop1 therefore estimate the most probable parse by monte carlo techniques (bod 1998; chappelier & rajman 2000), or by viterbi n-best search (bod 2001), or by restricting the set of subtrees (sima'an 1999; chappelier et al. 2002).",[0],"shown are results were only elementary trees with scores higher than 0.3 and 0.1 respectively are used. however, more interesting is a qualitative analysis of the stsg induced, which shows that ,un like dop1, push-n-pull arrives at a grammar that gives high weights (and scores) to those elementary3we approximated the most probable parse as follows (fol lowing (bod, 2003))",[0],13,method,1,1.0,0.16666666666666666,25.0,0.17006802721088435,22.0,0.4888888888888889,0,0.0,0.0,0.0,0.0,0.0,1 introduction: a little history,abstract
E03-1005,P05-1022,[38],"although bod's method obtains very competitive results on the wall street journal (wsj) task, the parsing time was reported to be over 200 seconds per sentence (bod 2003).",[0],"this result is only slightly higher than the highest reported result for this test-set, bod? s (.907) (bod,2003)",[0],14,method,1,1.0,0.16666666666666666,38.0,0.2585034013605442,35.0,0.7777777777777778,0,0.0,0.0,0.0,0.0,0.0,1 introduction: a little history,abstract
E03-1005,P07-1051,[100],"in bod (2000b), an alternative notion for the best parse tree was proposed based on a simplicity criterion: instead of producing the most probable tree, this model produced the tree generated by the shortest derivation with the fewest training subtrees.",[0],"this assumption is in consonance with the principle of simplicity, but there are also empirical reasons for the shortest derivation assumption: in bod (2003) and hearne and way (2006), it is shown that dop models that select the preferred parse of a test sentence using the shortest derivation criterion perform very well",[0],16,method,3,3.0,0.5,100.0,0.6802721088435374,3.0,0.13636363636363635,0,0.0,0.0,0.0,0.0,0.0,3 a new notion of the best parse tree,abstract
E03-1005,P07-1051,[32],"however, ml-dop suffers from overlearning if the subtrees are trained on the same treebank trees as they are derived from.",[0],"but equally important is the fact that this new dop* model does not suffer from a decrease in parse accuracy if larger subtrees are included, whereas the original dop model needs to be redressed by a correction factor to maintain this property (bod 2003)",[0],17,method,1,1.0,0.16666666666666666,32.0,0.21768707482993196,29.0,0.6444444444444445,0,0.0,0.0,0.0,0.0,0.0,1 introduction: a little history,abstract
E03-1005,P07-1051,[130],"while the pcfg reduction of bod (2001) obtains state-of-the-art results on the wsj, comparable to charniak (2000), bonnema et al. 's estimator performs worse and is comparable to collins (1996).",[0],"of course, it is well-known that a supervised parser? s f-score decreases if it is transferred to another domain: for example, the (non-binarized) wsj-trained dop model in bod (2003) decreases from around 91% to 85.5% f score if tested on the brown corpus",[0],18,method,4,4.0,0.6666666666666666,130.0,0.8843537414965986,11.0,0.6875,0,0.0,0.0,0.0,0.0,0.0,4 experiments,abstract
E03-1005,W04-0305,[140],the highest accuracy is obtained by sl-dop at 12 n 14: an lp of 90.8% and an lr of 90.7%.,[0],"a moderately larger vocabulary version (4215 tag-word pairs) of this parser achieves 89.8% f-measure on section 0, where the best current result on the testing set is 90.7% (bod, 2003)",[0],19,method,5,5.0,0.8333333333333334,140.0,0.9523809523809523,5.0,0.45454545454545453,0,0.0,0.0,0.0,0.0,0.0,5 conclusion,abstract
E03-1005,P06-1109,[27],"goodman (1996, 1998) developed a polynomial time pcfg-reduction of dop1 whose size is linear in the size of the training set, thus converting the exponential number of subtrees to a compact grammar.",[0],the probability of a parse tree t is the sum of the 1 this subtree probability is redressed by a simple correction factor discussed in goodman (2003: 136) and bod (2003),[0],20,method,1,1.0,0.16666666666666666,27.0,0.1836734693877551,24.0,0.5333333333333333,0,0.0,0.0,0.0,0.0,0.0,1 introduction: a little history,abstract
J01-2004,W05-0104,[372],"the small size of our training data, as well as the fact that we are rescoring n-best lists, rather than working directly on lattices, makes comparison with the other models not particularly informative.",[0],"second, their language models were used to rescore n-best speech lists (supplied by brian roark, see roark (2001))",[0],1,method,5,5.0,0.625,372.0,0.8963855421686747,128.0,0.8951048951048951,0,0.0,0.0,0.0,0.0,0.0,5.,abstract
J01-2004,P08-1013,[17],this paper will examine language modeling for speech recognition from a natural language processing point of view.,[0],"other linguistically inspired language models like chelba and jelinek (2000) and roark (2001) have been applied to continuous speech recognition. these models have in common that they explicitly or implicitly use a context-free grammar induced from a tree bank, with the exception of chelba and jelinek (2000)",[0],2,method,2,2.0,0.25,17.0,0.04096385542168675,5.0,0.16666666666666666,0,0.0,0.0,0.0,0.0,0.0,1.,abstract
J01-2004,P04-1015,[21],"first, the top-down parsing algorithm builds a set of rooted candidate parse trees from left to right over the string, which allows it to calculate a generative probability for each prefix string from the probabilistic grammar, and hence a conditional probability for each word given the previous words and the probabilistic grammar.",[0],"theperceptron approach was implemented with the same feature set as that of an existing generative model (roark, 2001a), and experimental results show that it gives competitive performance to the generative model on parsing the penn tree bank",[0],4,method,2,2.0,0.25,21.0,0.05060240963855422,9.0,0.3,0,0.0,0.0,0.0,0.0,0.0,1.,abstract
J01-2004,P04-1015,[21],"first, the top-down parsing algorithm builds a set of rooted candidate parse trees from left to right over the string, which allows it to calculate a generative probability for each prefix string from the probabilistic grammar, and hence a conditional probability for each word given the previous words and the probabilistic grammar.",[0],"we implemented the perceptron approach with the same feature set as that of an existing generative model (roark, 2001a), and show that the per ceptron model gives performance competitive to that of the generative model on parsing the penn tree bank, thus demonstrating that an unnormalized discriminative parsing model can be applied with heuristic search",[0],5,method,2,2.0,0.25,21.0,0.05060240963855422,9.0,0.3,0,0.0,0.0,0.0,0.0,0.0,1.,abstract
J01-2004,P04-1015,[302],"in the beam search approach outlined above, we can estimate the string's probability in the same manner, by summing the probabilities of the parses that the algorithm finds.",[0],"one way around this problem is to adopt a two-pass approach, where gen (x) is the top n analyses under some initial model, as in the re ranking approach of collins (2000) .in the current paper we explore alternatives to rerank ing approaches, namely heuristic methods for finding the arg max, specifically incremental beam-search strategies related to the parsers of roark (2001a) and ratnaparkhi (1999)",[0],6,method,5,5.0,0.625,302.0,0.727710843373494,58.0,0.40559440559440557,0,0.0,0.0,0.0,0.0,0.0,5.,abstract
J01-2004,P04-1015,[31],"thus, our top-down parser allows for the incremental calculation of generative conditional word probabilities, a property it shares with other left-to-right parsers with rooted derivations such as earley parsers (earley 1970) or left-corner parsers (rosenkrantz and lewis 11 1970).",[0],"approach the parser is an incremental beam-search parser very similar to the sort described in roark (2001a; 2004), with some changes in the search strategy to accommodate the perceptron feature weights",[0],7,method,2,2.0,0.25,31.0,0.0746987951807229,19.0,0.6333333333333333,0,0.0,0.0,0.0,0.0,0.0,1.,abstract
J01-2004,P04-1015,"[79, 80]","this underspecification of the nonterminal predictions (e.g., vp-vbd in the example in figure 2, as opposed to np), allows lexical items to become part of the left context, and so be used to condition production probabilities, even the production probabilities of constituents that dominate them in the unfactored tree.
it also brings words further downstream into the look-ahead at the point of specification.",[0],"unlike in roark (2001a; 2004), there is no look-ahead statistic, so we modified the feature set from those papers to explicitly include the lexical item and pos tag of the next word",[0],9,method,3_3,3.0,0.375,79.5,0.19156626506024096,37.5,0.6944444444444444,0,0.0,0.0,0.0,0.0,0.0,"2., 2.",abstract
J01-2004,P05-1022,[21],"first, the top-down parsing algorithm builds a set of rooted candidate parse trees from left to right over the string, which allows it to calculate a generative probability for each prefix string from the probabilistic grammar, and hence a conditional probability for each word given the previous words and the probabilistic grammar.",[0],"a good example of this is the roark parser (roark, 2001) which works left-to right through the sentence, and abjures dynamic programming in favor of a beam search, keeping some large number of possibilities to extend by adding the next word, and then re-pruning",[0],10,method,2,2.0,0.25,21.0,0.05060240963855422,9.0,0.3,0,0.0,0.0,0.0,0.0,0.0,1.,abstract
J01-2004,P05-1022,[138],"our approach is found to yield very accurate parses efficiently, and, in addition, to lend itself straightforwardly to estimating word probabilities on-line, that is, in a single pass from left to right.",[0],"at the end one has a beam-width? s number of best parses (roark, 2001) .the collins parser (collins, 1997) does use dynamic programming in its search",[0],11,method,4,4.0,0.5,138.0,0.3325301204819277,42.0,0.28378378378378377,0,0.0,0.0,0.0,0.0,0.0,3.,abstract
J01-2004,P05-1022,[291],"also, the parser returns a set of candidate parses, from which we have been choosing the top ranked; if we use an oracle to choose the parse with the highest accuracy from among the candidates (which averaged 70.0 in number per sentence), we find an average labeled precision/recall of 94.1, for sentences of length < 100.",[0],"to put this in perspective, roark (roark, 2001) reports oracle results of 0.941 (with the same experimental setup) using his parser to return a variable number of parses",[0],12,method,5,5.0,0.625,291.0,0.7012048192771084,47.0,0.32867132867132864,0,0.0,0.0,0.0,0.0,0.0,5.,abstract
J01-2004,P04-1006,[372],"the small size of our training data, as well as the fact that we are rescoring n-best lists, rather than working directly on lattices, makes comparison with the other models not particularly informative.",[0],"we ran the first stage parser with 4-timesoverparsing for each string in 7the n? best lists were provided by brian roark (roark, 2001) 8a local-tree is an explicit expansion of an edge and its children",[0],13,method,5,5.0,0.625,372.0,0.8963855421686747,128.0,0.8951048951048951,0,0.0,0.0,0.0,0.0,0.0,5.,abstract
J01-2004,P05-1063,"[209, 210]","this parser is essentially a stochastic version of the top-down parser described in aho, sethi, and ullman (1986).
it uses a pcfg with a conditional probability model of the sort defined in the previous section.",[0],"incremental top down and left-corner parsing (roark, 2001a; roark, 2001b) and head-driven parsing (charniak, 2001) approaches have directly used generative pcfg models as language models",[0],14,method,4_4,4.0,0.5,209.5,0.5048192771084338,113.5,0.7668918918918919,0,0.0,0.0,0.0,0.0,0.0,"3., 3.",abstract
J01-2004,W10-2009,[372],"the small size of our training data, as well as the fact that we are rescoring n-best lists, rather than working directly on lattices, makes comparison with the other models not particularly informative.",[0],"levy, on the other hand ,argued that studies of probabilistic parsing reveal that typically a small number of analyses are as signed the majority of probability mass (roark, 2001)",[0],15,method,5,5.0,0.625,372.0,0.8963855421686747,128.0,0.8951048951048951,0,0.0,0.0,0.0,0.0,0.0,5.,abstract
J01-2004,D09-1034,"[20, 21, 32]","two features of our top-down parsing approach will emerge as key to its success.
first, the top-down parsing algorithm builds a set of rooted candidate parse trees from left to right over the string, which allows it to calculate a generative probability for each prefix string from the probabilistic grammar, and hence a conditional probability for each word given the previous words and the probabilistic grammar.a second key feature of our approach is that top-down guidance improves the efficiency of the search as more and more conditioning events are extracted from the derivation for use in the probabilistic model.",[0],"we modified the roark (2001) parser to calculate the discussed measures 1, and the empirical results in? 4 show several things, including: 1) using a fully lexicalized parser to calculate syntactic surprisal and entropy provides higher predictive utility for reading times than these measures calculated via unlexicalized parsing (as in demberg and keller); and 2) syntactic entropy is a useful predictor of reading time",[0],18,method,2_2_2,2.0,0.25,24.333333333333332,0.05863453815261044,12.333333333333334,0.41111111111111115,0,0.0,0.0,0.0,0.0,0.0,"1., 1., 1.",abstract
J01-2004,D09-1034,[31],"first, the top-down parsing algorithm builds a set of rooted candidate parse trees from left to right over the string, which allows it to calculate a generative probability for each prefix string from the probabilistic grammar, and hence a conditional probability for each word given the previous words and the probabilistic grammar.",[0],"in this section, we review relevant details of the roark (2001) incremental top-down parser, as configured for use here",[0],19,method,2,2.0,0.25,31.0,0.0746987951807229,19.0,0.6333333333333333,0,0.0,0.0,0.0,0.0,0.0,1.,abstract
J01-2004,D09-1034,[33],"because the rooted partial derivation is fully connected, all of the conditioning information that might be extracted from the top-down left context has already been specified, and a conditional probability model built on this information will not impose any additional burden on the search.",[0],"at each word in the string, the roark (2001) top-down parser provides access to the weighted set of partial analyses in the beam; the set of complete derivations consistent with these is not immediately accessible, hence additional work is re quired to calculate such measures. let h (d) be the entropy over a set of derivations d, calculated as follows: h (d)=? x d? d? (d) p d?? d? (d?) log? (d) p d?? d? (d?) (10) if the set of derivations d= d (g, w [1, i]) is a set of partial derivations for string w [1, i], then h (d) is a measure of uncertainty over the partial derivations ,i.e., the uncertainty regarding the correct analysis of what has already been processed",[0],20,method,2,2.0,0.25,33.0,0.07951807228915662,21.0,0.7,0,0.0,0.0,0.0,0.0,0.0,1.,abstract
J01-2004,W05-0104,[372.0],"the small size of our training data, as well as the fact that we are rescoring n-best lists, rather than working directly on lattices, makes comparison with the other models not particularly informative.",[0],"second, their language models were used to rescore n-best speech lists (supplied by brian roark, see roark (2001))",[0],1,method,5,5.0,0.625,372.0,0.8963855421686747,128.0,0.8951048951048951,0,0.0,0.0,0.0,0.0,0.0,5.,abstract
J01-2004,P08-1013,[15.0],"in the past few years, however, some improvements have been made over these language models through the use of statistical methods of natural language processing, and the development of innovative, linguistically well-motivated techniques for improving language models for speech recognition is generating more interest among computational linguists.",[0],"other linguistically inspired language models like chelba and jelinek (2000) and roark (2001) have been applied to continuous speech recognition. these models have in common that they explicitly or implicitly use a context-free grammar induced from a tree bank, with the exception of chelba and jelinek (2000)",[0],2,result,2,2.0,0.25,15.0,0.03614457831325301,3.0,0.1,0,0.0,0.0,0.0,0.0,0.0,1.,abstract
J01-2004,P04-1015,[31.0],"thus, our top-down parser allows for the incremental calculation of generative conditional word probabilities, a property it shares with other left-to-right parsers with rooted derivations such as earley parsers (earley 1970) or left-corner parsers (rosenkrantz and lewis 11 1970).",[0],"theperceptron approach was implemented with the same feature set as that of an existing generative model (roark, 2001a), and experimental results show that it gives competitive performance to the generative model on parsing the penn tree bank",[0],4,result,2,2.0,0.25,31.0,0.0746987951807229,19.0,0.6333333333333333,0,0.0,0.0,0.0,0.0,0.0,1.,abstract
J01-2004,P04-1015,[31.0],"thus, our top-down parser allows for the incremental calculation of generative conditional word probabilities, a property it shares with other left-to-right parsers with rooted derivations such as earley parsers (earley 1970) or left-corner parsers (rosenkrantz and lewis 11 1970).",[0],"we implemented the perceptron approach with the same feature set as that of an existing generative model (roark, 2001a), and show that the per ceptron model gives performance competitive to that of the generative model on parsing the penn tree bank, thus demonstrating that an unnormalized discriminative parsing model can be applied with heuristic search",[0],5,result,2,2.0,0.25,31.0,0.0746987951807229,19.0,0.6333333333333333,0,0.0,0.0,0.0,0.0,0.0,1.,abstract
J01-2004,P04-1015,[31.0],"thus, our top-down parser allows for the incremental calculation of generative conditional word probabilities, a property it shares with other left-to-right parsers with rooted derivations such as earley parsers (earley 1970) or left-corner parsers (rosenkrantz and lewis 11 1970).",[0],"one way around this problem is to adopt a two-pass approach, where gen (x) is the top n analyses under some initial model, as in the re ranking approach of collins (2000) .in the current paper we explore alternatives to rerank ing approaches, namely heuristic methods for finding the arg max, specifically incremental beam-search strategies related to the parsers of roark (2001a) and ratnaparkhi (1999)",[0],6,result,2,2.0,0.25,31.0,0.0746987951807229,19.0,0.6333333333333333,0,0.0,0.0,0.0,0.0,0.0,1.,abstract
J01-2004,P04-1015,[31.0],"thus, our top-down parser allows for the incremental calculation of generative conditional word probabilities, a property it shares with other left-to-right parsers with rooted derivations such as earley parsers (earley 1970) or left-corner parsers (rosenkrantz and lewis 11 1970).",[0],"approach the parser is an incremental beam-search parser very similar to the sort described in roark (2001a; 2004), with some changes in the search strategy to accommodate the perceptron feature weights",[0],7,result,2,2.0,0.25,31.0,0.0746987951807229,19.0,0.6333333333333333,0,0.0,0.0,0.0,0.0,0.0,1.,abstract
J01-2004,P04-1015,[215.0],"the first word in the string remaining to be parsed, w1, we will call the look-ahead word.",[0],"unlike in roark (2001a; 2004), there is no look-ahead statistic, so we modified the feature set from those papers to explicitly include the lexical item and pos tag of the next word",[0],9,method,4,4.0,0.5,215.0,0.5180722891566265,119.0,0.8040540540540541,0,0.0,0.0,0.0,0.0,0.0,3.,abstract
J01-2004,P05-1022,[302.0],"in the beam search approach outlined above, we can estimate the string's probability in the same manner, by summing the probabilities of the parses that the algorithm finds.",[0],"a good example of this is the roark parser (roark, 2001) which works left-to right through the sentence, and abjures dynamic programming in favor of a beam search, keeping some large number of possibilities to extend by adding the next word, and then re-pruning",[0],10,method,5,5.0,0.625,302.0,0.727710843373494,58.0,0.40559440559440557,0,0.0,0.0,0.0,0.0,0.0,5.,abstract
J01-2004,P04-1006,[372.0],"the small size of our training data, as well as the fact that we are rescoring n-best lists, rather than working directly on lattices, makes comparison with the other models not particularly informative.",[0],"we ran the first stage parser with 4-timesoverparsing for each string in 7the n? best lists were provided by brian roark (roark, 2001) 8a local-tree is an explicit expansion of an edge and its children",[0],13,result,5,5.0,0.625,372.0,0.8963855421686747,128.0,0.8951048951048951,0,0.0,0.0,0.0,0.0,0.0,5.,abstract
J01-2004,P05-1063,[31.0],"thus, our top-down parser allows for the incremental calculation of generative conditional word probabilities, a property it shares with other left-to-right parsers with rooted derivations such as earley parsers (earley 1970) or left-corner parsers (rosenkrantz and lewis 11 1970).",[0],"incremental top down and left-corner parsing (roark, 2001a; roark, 2001b) and head-driven parsing (charniak, 2001) approaches have directly used generative pcfg models as language models",[0],14,result,2,2.0,0.25,31.0,0.0746987951807229,19.0,0.6333333333333333,0,0.0,0.0,0.0,0.0,0.0,1.,abstract
J01-2004,W10-2009,[100.0],"the approach that we will subsequently present uses the probabilistic grammar as its language model, but only includes probability mass from those parses that are found, that is, it uses the parser to find a subset of the total set of parses (hopefully most of the high-probability parses) and uses the sum of their probabilities as an estimate of the true probability given the grammar.",[0],"levy, on the other hand ,argued that studies of probabilistic parsing reveal that typically a small number of analyses are as signed the majority of probability mass (roark, 2001)",[0],15,method,4,4.0,0.5,100.0,0.24096385542168675,4.0,0.02702702702702703,0,0.0,0.0,0.0,0.0,0.0,3.,abstract
J01-2004,D09-1034,[31.0],"thus, our top-down parser allows for the incremental calculation of generative conditional word probabilities, a property it shares with other left-to-right parsers with rooted derivations such as earley parsers (earley 1970) or left-corner parsers (rosenkrantz and lewis 11 1970).",[0],"in this section, we review relevant details of the roark (2001) incremental top-down parser, as configured for use here",[0],19,result,2,2.0,0.25,31.0,0.0746987951807229,19.0,0.6333333333333333,0,0.0,0.0,0.0,0.0,0.0,1.,abstract
J01-2004,D09-1034,[21.0],"first, the top-down parsing algorithm builds a set of rooted candidate parse trees from left to right over the string, which allows it to calculate a generative probability for each prefix string from the probabilistic grammar, and hence a conditional probability for each word given the previous words and the probabilistic grammar.",[0],"at each word in the string, the roark (2001) top-down parser provides access to the weighted set of partial analyses in the beam; the set of complete derivations consistent with these is not immediately accessible, hence additional work is re quired to calculate such measures. let h (d) be the entropy over a set of derivations d, calculated as follows: h (d)=? x d? d? (d) p d?? d? (d?) log? (d) p d?? d? (d?) (10) if the set of derivations d= d (g, w [1, i]) is a set of partial derivations for string w [1, i], then h (d) is a measure of uncertainty over the partial derivations ,i.e., the uncertainty regarding the correct analysis of what has already been processed",[0],20,method,2,2.0,0.25,21.0,0.05060240963855422,9.0,0.3,0,0.0,0.0,0.0,0.0,0.0,1.,abstract
J01-2004,W05-0104,[372],"the small size of our training data, as well as the fact that we are rescoring n-best lists, rather than working directly on lattices, makes comparison with the other models not particularly informative.",[0],"second, their language models were used to rescore n-best speech lists (supplied by brian roark, see roark (2001))",[0],1,method,5,5.0,0.625,372.0,0.8963855421686747,128.0,0.8951048951048951,0,0.0,0.0,0.0,0.0,0.0,5.,abstract
J01-2004,P08-1013,"[40, 41, 42]","the following section will provide some background in probabilistic context-free grammars and language modeling for speech recognition.
there will also be a brief review of previous work using syntactic information for language modeling, before we introduce our model in section 4.
three parse trees: (a) a complete parse tree; (b) a complete parse tree with an explicit stop symbol; and (c) a partial parse tree.",[0],"other linguistically inspired language models like chelba and jelinek (2000) and roark (2001) have been applied to continuous speech recognition. these models have in common that they explicitly or implicitly use a context-free grammar induced from a tree bank, with the exception of chelba and jelinek (2000)",[0],2,method,2_2_2,2.0,0.25,41.0,0.09879518072289156,29.0,0.9666666666666667,0,0.0,0.0,0.0,0.0,0.0,"1., 1., 1.",abstract
J01-2004,P04-1015,[25],"a parser that is not left to right, but which has rooted derivations, e.g., a headfirst parser, will be able to calculate generative joint probabilities for entire strings; however, it will not be able to calculate probabilities for each word conditioned on previously generated words, unless each derivation generates the words in the string in exactly the same order.",[0],"theperceptron approach was implemented with the same feature set as that of an existing generative model (roark, 2001a), and experimental results show that it gives competitive performance to the generative model on parsing the penn tree bank",[0],4,method,2,2.0,0.25,25.0,0.060240963855421686,13.0,0.43333333333333335,0,0.0,0.0,0.0,0.0,0.0,1.,abstract
J01-2004,P04-1015,[364],"we follow chelba (2000) in dealing with this problem: for parsing purposes, we use the penn treebank tokenization; for interpolation with the provided trigram model, and for evaluation, the lattice tokenization is used.",[0],"we implemented the perceptron approach with the same feature set as that of an existing generative model (roark, 2001a), and show that the per ceptron model gives performance competitive to that of the generative model on parsing the penn tree bank, thus demonstrating that an unnormalized discriminative parsing model can be applied with heuristic search",[0],5,method,5,5.0,0.625,364.0,0.8771084337349397,120.0,0.8391608391608392,0,0.0,0.0,0.0,0.0,0.0,5.,abstract
J01-2004,P04-1015,[302],"in the beam search approach outlined above, we can estimate the string's probability in the same manner, by summing the probabilities of the parses that the algorithm finds.",[0],"one way around this problem is to adopt a two-pass approach, where gen (x) is the top n analyses under some initial model, as in the re ranking approach of collins (2000) .in the current paper we explore alternatives to rerank ing approaches, namely heuristic methods for finding the arg max, specifically incremental beam-search strategies related to the parsers of roark (2001a) and ratnaparkhi (1999)",[0],6,method,5,5.0,0.625,302.0,0.727710843373494,58.0,0.40559440559440557,0,0.0,0.0,0.0,0.0,0.0,5.,abstract
J01-2004,P04-1015,[31],"thus, our top-down parser allows for the incremental calculation of generative conditional word probabilities, a property it shares with other left-to-right parsers with rooted derivations such as earley parsers (earley 1970) or left-corner parsers (rosenkrantz and lewis 11 1970).",[0],"approach the parser is an incremental beam-search parser very similar to the sort described in roark (2001a; 2004), with some changes in the search strategy to accommodate the perceptron feature weights",[0],7,method,2,2.0,0.25,31.0,0.0746987951807229,19.0,0.6333333333333333,0,0.0,0.0,0.0,0.0,0.0,1.,abstract
J01-2004,P04-1015,[231],"since we do not know the pos for the word, we must sum the lap for all pos for a pcfg g, a stack s = ao an$ (which we will write an and a look-ahead terminal item wi, we define the look-ahead probability as follows: we recursively estimate this with two empirically observed conditional probabilities for every nonterminal a,: 13(a, w,a) and p(a, c).",[0],"unlike in roark (2001a; 2004), there is no look-ahead statistic, so we modified the feature set from those papers to explicitly include the lexical item and pos tag of the next word",[0],9,method,4,4.0,0.5,231.0,0.5566265060240964,135.0,0.9121621621621622,0,0.0,0.0,0.0,0.0,0.0,3.,abstract
J01-2004,P05-1022,[297],the differences between a k-best and a beam-search parser (not to mention the use of dynamic programming) make a running time difference unsurprising.,[0],"a good example of this is the roark parser (roark, 2001) which works left-to right through the sentence, and abjures dynamic programming in favor of a beam search, keeping some large number of possibilities to extend by adding the next word, and then re-pruning",[0],10,method,5,5.0,0.625,297.0,0.7156626506024096,53.0,0.3706293706293706,0,0.0,0.0,0.0,0.0,0.0,5.,abstract
J01-2004,P05-1022,[133],"statistically based heuristic best-first or beam-search strategies (caraballo and charniak 1998; charniak, goldwater, and johnson 1998; goodman 1997) have yielded an enormous improvement in the quality and speed of parsers, even without any guarantee that the parse returned is, in fact, that with the maximum likelihood for the probability model.",[0],"at the end one has a beam-width? s number of best parses (roark, 2001) .the collins parser (collins, 1997) does use dynamic programming in its search",[0],11,method,4,4.0,0.5,133.0,0.3204819277108434,37.0,0.25,0,0.0,0.0,0.0,0.0,0.0,3.,abstract
J01-2004,P05-1022,[291],"also, the parser returns a set of candidate parses, from which we have been choosing the top ranked; if we use an oracle to choose the parse with the highest accuracy from among the candidates (which averaged 70.0 in number per sentence), we find an average labeled precision/recall of 94.1, for sentences of length < 100.",[0],"to put this in perspective, roark (roark, 2001) reports oracle results of 0.941 (with the same experimental setup) using his parser to return a variable number of parses",[0],12,method,5,5.0,0.625,291.0,0.7012048192771084,47.0,0.32867132867132864,0,0.0,0.0,0.0,0.0,0.0,5.,abstract
J01-2004,P04-1006,[355],"in order to get a sense of whether these perplexity reduction results can translate to improvement in a speech recognition task, we performed a very small preliminary experiment on n-best lists.",[0],"we ran the first stage parser with 4-timesoverparsing for each string in 7the n? best lists were provided by brian roark (roark, 2001) 8a local-tree is an explicit expansion of an edge and its children",[0],13,method,5,5.0,0.625,355.0,0.8554216867469879,111.0,0.7762237762237763,0,0.0,0.0,0.0,0.0,0.0,5.,abstract
J01-2004,P05-1063,[59],"a pcfg is a cfg with a probability assigned to each rule; specifically, each righthand side has a probability given the left-hand side of the rule.",[0],"incremental top down and left-corner parsing (roark, 2001a; roark, 2001b) and head-driven parsing (charniak, 2001) approaches have directly used generative pcfg models as language models",[0],14,method,3,3.0,0.375,59.0,0.14216867469879518,17.0,0.3148148148148148,0,0.0,0.0,0.0,0.0,0.0,2.,abstract
J01-2004,W10-2009,[100],"the approach that we will subsequently present uses the probabilistic grammar as its language model, but only includes probability mass from those parses that are found, that is, it uses the parser to find a subset of the total set of parses (hopefully most of the high-probability parses) and uses the sum of their probabilities as an estimate of the true probability given the grammar.",[0],"levy, on the other hand ,argued that studies of probabilistic parsing reveal that typically a small number of analyses are as signed the majority of probability mass (roark, 2001)",[0],15,method,4,4.0,0.5,100.0,0.24096385542168675,4.0,0.02702702702702703,0,0.0,0.0,0.0,0.0,0.0,3.,abstract
J01-2004,D09-1034,[108],"another approach that uses syntactic structure for language modeling has been to use a shift-reduce parser to &quot;surface&quot; c-commanding phrasal headwords or part-of-speech (pos) tags from arbitrarily far back in the prefix string, for use in a trigram-like model.",[0],"we modified the roark (2001) parser to calculate the discussed measures 1, and the empirical results in? 4 show several things, including: 1) using a fully lexicalized parser to calculate syntactic surprisal and entropy provides higher predictive utility for reading times than these measures calculated via unlexicalized parsing (as in demberg and keller); and 2) syntactic entropy is a useful predictor of reading time",[0],18,method,4,4.0,0.5,108.0,0.26024096385542167,12.0,0.08108108108108109,0,0.0,0.0,0.0,0.0,0.0,3.,abstract
J01-2004,D09-1034,[31],"thus, our top-down parser allows for the incremental calculation of generative conditional word probabilities, a property it shares with other left-to-right parsers with rooted derivations such as earley parsers (earley 1970) or left-corner parsers (rosenkrantz and lewis 11 1970).",[0],"in this section, we review relevant details of the roark (2001) incremental top-down parser, as configured for use here",[0],19,method,2,2.0,0.25,31.0,0.0746987951807229,19.0,0.6333333333333333,0,0.0,0.0,0.0,0.0,0.0,1.,abstract
J01-2004,D09-1034,[31],"thus, our top-down parser allows for the incremental calculation of generative conditional word probabilities, a property it shares with other left-to-right parsers with rooted derivations such as earley parsers (earley 1970) or left-corner parsers (rosenkrantz and lewis 11 1970).",[0],"at each word in the string, the roark (2001) top-down parser provides access to the weighted set of partial analyses in the beam; the set of complete derivations consistent with these is not immediately accessible, hence additional work is re quired to calculate such measures. let h (d) be the entropy over a set of derivations d, calculated as follows: h (d)=? x d? d? (d) p d?? d? (d?) log? (d) p d?? d? (d?) (10) if the set of derivations d= d (g, w [1, i]) is a set of partial derivations for string w [1, i], then h (d) is a measure of uncertainty over the partial derivations ,i.e., the uncertainty regarding the correct analysis of what has already been processed",[0],20,method,2,2.0,0.25,31.0,0.0746987951807229,19.0,0.6333333333333333,0,0.0,0.0,0.0,0.0,0.0,1.,abstract
P04-1036,W04-0837,[8],the first sense heuristic which is often used as a baseline for supervised wsd systems outperforms many of these systems which take surrounding context into account.,[0],"the first sense heuristic which is often used as a baseline for supervised wsd systems outperforms many of these systems which take surrounding con text into account (mccarthy et al, 2004)",[0],1,method,1,1.0,0.1111111111111111,8.0,0.041237113402061855,1.0,0.02702702702702703,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P04-1036,W04-0837,[15],"whilst a first sense heuristic based on a sense-tagged corpus such as semcor is clearly useful, there is a strong case for obtaining a first, or predominant, sense from untagged corpus data so that a wsd system can be tuned to the genre or domain at hand.",[0],"association for computational linguistics for the semantic analysis of text, barcelona, spain, july 2004 senseval-3: third international workshop on the evaluation of systems pos precision recall baseline noun 95 73 45 verb 79 43 22 adjective 88 59 44 adverb 91 72 59 all pos 90 63 41table 2: the senseval-2 first sense on the sen seval-2 english all-words data system can be tuned to a given genre or domain (mccarthy et al, 2004) and also because there will be words that occur with insufficient frequency inthe hand-tagged resources available",[0],2,method,1,1.0,0.1111111111111111,15.0,0.07731958762886598,8.0,0.21621621621621623,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P04-1036,W04-0837,[41],in this paper we describe and evaluate a method for ranking senses of nouns to obtain the predominant sense of a word using the neighbours from automatically acquired thesauruses.,[0],"the method is described in (mccarthy et al, 2004), which we summarise here",[0],3,method,1,1.0,0.1111111111111111,41.0,0.211340206185567,34.0,0.918918918918919,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P04-1036,I08-2105,[4],we present work on the use of a thesaurus acquired from raw textual corpora and the wordnet similarity package to find predominant noun senses automatically.,[0],"mccarthy et al (2004) use a corpus and word similarities to induce a ranking of word senses from an untagged corpus to be used in wsd.we build upon this previous research, and pro pose an unsupervised wsd method in which senses for two grammatically related words in the sentence will be connected through directed edges",[0],5,method,0,0.0,0.0,4.0,0.020618556701030927,4.0,0.5,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
P04-1036,I08-2105,[15],"whilst a first sense heuristic based on a sense-tagged corpus such as semcor is clearly useful, there is a strong case for obtaining a first, or predominant, sense from untagged corpus data so that a wsd system can be tuned to the genre or domain at hand.",[0],"previous re search in inducing sense rankings from an untagged corpus (mccarthy et al, 2004), and inducing selectional preferences at the word level (for other applications) (erk, 2007) will provide the starting point for research in this direction",[0],6,method,1,1.0,0.1111111111111111,15.0,0.07731958762886598,8.0,0.21621621621621623,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P04-1036,I08-2105,"[180, 181]","the automatically acquired predominant senses were evaluated against the hand-tagged resources semcor and the senseval-2 english all-words task giving us a wsd precision of 64% on an all-nouns task.
this is just 5% lower than results using the first sense in the manually labelled semcor, and we obtain 67% precision on polysemous nouns that are not in semcor.",[0],"mccarthy et al (2004) report a disambiguation precision of 53.0% and recall of 49.0% on the senseval-2 test data, using an approach that derives sense ranking based on word similarity and distributional analysis in a corpus",[0],7,result,7_7,7.0,0.7777777777777778,180.5,0.9304123711340206,3.5,0.25,0,0.0,0.0,0.0,0.0,0.0,"7 conclusions, 7 conclusions",abstract
P04-1036,P06-1012,[126],we demonstrate that choosing texts from a particular domain has a significant influence on the sense ranking.,[0],"research by (mccarthy et al, 2004) highlighted that the sense priors of a word in a corpus depend on the domain from which the corpus is drawn",[0],8,method,5,5.0,0.5555555555555556,126.0,0.6494845360824743,3.0,0.10344827586206896,0,0.0,0.0,0.0,0.0,0.0,5 experiments with domain specific corpora,abstract
P04-1036,P06-1012,[48],to find the first sense of a word ( ) we take each sense in turn and obtain a score reflecting the prevalence which is used for ranking.,[0],"in addition, we implemented the unsupervised method of (mccarthy et al, 2004), which cal cu lates a prevalence score for each sense of a word to predict the predominant sense",[0],9,method,2,2.0,0.2222222222222222,48.0,0.24742268041237114,4.0,0.14814814814814814,0,0.0,0.0,0.0,0.0,0.0,2 method,abstract
P04-1036,P10-1155,[169],this method obtains precision of 61% and recall 51%.,[0],"mccarthy et al (2004) reported that the best results were obtained using k= 50 neighbors and the wordnet similarityjcn measure (jiang and conrath, 1997)",[0],11,result,6,6.0,0.6666666666666666,169.0,0.8711340206185567,17.0,0.68,0,0.0,0.0,0.0,0.0,0.0,6 related work,abstract
P04-1036,W12-3401,[171],"in contrast, we use the neighbours lists and wordnet similarity measures to impose a prevalence ranking on the wordnet senses.",[0],"in doing so, we provide first results on the application to french parsing of wordnet automatic sense ranking (asr), using the method of mccarthy et al (2004)",[0],12,method,6,6.0,0.6666666666666666,171.0,0.8814432989690721,19.0,0.76,0,0.0,0.0,0.0,0.0,0.0,6 related work,abstract
P04-1036,W12-3401,[171],"in contrast, we use the neighbours lists and wordnet similarity measures to impose a prevalence ranking on the wordnet senses.",[0],"to define an appropriate categorical distribution over synsets for each 2 lemma x in our source vocabulary, we first use the wordnet resource to identify the set sx of different senses of x. we then use a distributional thesaurus to perform asr, which determines the prevalence with respect to x of each sense s? sx, following the approach of mccarthy et al (2004)",[0],13,method,6,6.0,0.6666666666666666,171.0,0.8814432989690721,19.0,0.76,0,0.0,0.0,0.0,0.0,0.0,6 related work,abstract
P04-1036,W12-3401,[115],"our automatically acquired predominant sense performs nearly as well as the first sense provided by semcor, which is very encouraging given that our method only uses raw text, with no manual labelling.",[0],"as explained in section 2.2, asr is performed using the method of mccarthy et al (2004)",[0],14,method,4,4.0,0.4444444444444444,115.0,0.5927835051546392,13.0,0.6190476190476191,0,0.0,0.0,0.0,0.0,0.0,4 experiment on senseval-2 english all words data,abstract
P04-1036,S12-1097,[8],the first sense heuristic which is often used as a baseline for supervised wsd systems outperforms many of these systems which take surrounding context into account.,[0],"this approach is commonly used as a baseline for word sense disambiguation (mccarthy et al, 2004)",[0],16,method,1,1.0,0.1111111111111111,8.0,0.041237113402061855,1.0,0.02702702702702703,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P04-1036,W10-2803,[126],we demonstrate that choosing texts from a particular domain has a significant influence on the sense ranking.,[0],"more radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (mccarthy et al, 2004), or to work directly with para phrases (mccarthy and navigli, 2009)",[0],17,method,5,5.0,0.5555555555555556,126.0,0.6494845360824743,3.0,0.10344827586206896,0,0.0,0.0,0.0,0.0,0.0,5 experiments with domain specific corpora,abstract
P04-1036,W08-2107,"[180, 181]","the automatically acquired predominant senses were evaluated against the hand-tagged resources semcor and the senseval-2 english all-words task giving us a wsd precision of 64% on an all-nouns task.
this is just 5% lower than results using the first sense in the manually labelled semcor, and we obtain 67% precision on polysemous nouns that are not in semcor.",[0],"in addition, we can also infer a positive contribution of the frequency of a sense with the choice of the first synset returned by word net resulting in a reasonable wsd heuristic (which is compatible with the results by mccarthy et al (2004))",[0],18,result,7_7,7.0,0.7777777777777778,180.5,0.9304123711340206,3.5,0.25,0,0.0,0.0,0.0,0.0,0.0,"7 conclusions, 7 conclusions",abstract
P04-1036,D07-1026,[180],the automatically acquired predominant senses were evaluated against the hand-tagged resources semcor and the senseval-2 english all-words task giving us a wsd precision of 64% on an all-nouns task.,[0],"it is worthwhile to remark here that, being the ible algorithm fully unsupervised, improving the most frequent baseline is an excellent result, rarely achieved in the literature on unsupervised methods for wsd (mccarthy et al, 2004)",[0],19,method,7,7.0,0.7777777777777778,180.0,0.9278350515463918,3.0,0.21428571428571427,0,0.0,0.0,0.0,0.0,0.0,7 conclusions,abstract
P04-1036,W12-2429,[41],in this paper we describe and evaluate a method for ranking senses of nouns to obtain the predominant sense of a word using the neighbours from automatically acquired thesauruses.,[0],"the first, most frequent sense (mfs) (mccarthy et al, 2004), is widely used baseline for supervised wsd systems",[0],20,method,1,1.0,0.1111111111111111,41.0,0.211340206185567,34.0,0.918918918918919,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P04-1036,W04-0837,[8],the first sense heuristic which is often used as a baseline for supervised wsd systems outperforms many of these systems which take surrounding context into account.,[0],"the first sense heuristic which is often used as a baseline for supervised wsd systems outperforms many of these systems which take surrounding con text into account (mccarthy et al, 2004)",[0],1,result,1,1.0,0.1111111111111111,8.0,0.041237113402061855,1.0,0.02702702702702703,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P04-1036,W04-0837,[15],"whilst a first sense heuristic based on a sense-tagged corpus such as semcor is clearly useful, there is a strong case for obtaining a first, or predominant, sense from untagged corpus data so that a wsd system can be tuned to the genre or domain at hand.",[0],"association for computational linguistics for the semantic analysis of text, barcelona, spain, july 2004 senseval-3: third international workshop on the evaluation of systems pos precision recall baseline noun 95 73 45 verb 79 43 22 adjective 88 59 44 adverb 91 72 59 all pos 90 63 41table 2: the senseval-2 first sense on the sen seval-2 english all-words data system can be tuned to a given genre or domain (mccarthy et al, 2004) and also because there will be words that occur with insufficient frequency inthe hand-tagged resources available",[0],2,method,1,1.0,0.1111111111111111,15.0,0.07731958762886598,8.0,0.21621621621621623,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P04-1036,W04-0837,[68],"we are of course able to apply the method to other versions of wordnet. synset, is incremented with the frequency counts from the corpus of all words belonging to that synset, directly or via the hyponymy relation.",[0],"the method is described in (mccarthy et al, 2004), which we summarise here",[0],3,result,2,2.0,0.2222222222222222,68.0,0.35051546391752575,24.0,0.8888888888888888,0,0.0,0.0,0.0,0.0,0.0,2 method,abstract
P04-1036,I08-2105,[83],the results in table 1 show the accuracy of the ranking with respect to semcor over the entire set of 2595 polysemous nouns in semcor with the jcn and lesk wordnet similarity measures.,[0],"mccarthy et al (2004) use a corpus and word similarities to induce a ranking of word senses from an untagged corpus to be used in wsd.we build upon this previous research, and pro pose an unsupervised wsd method in which senses for two grammatically related words in the sentence will be connected through directed edges",[0],5,result,3,3.0,0.3333333333333333,83.0,0.42783505154639173,12.0,0.3870967741935484,0,0.0,0.0,0.0,0.0,0.0,3 experiment with semcor,abstract
P04-1036,I08-2105,[15],"whilst a first sense heuristic based on a sense-tagged corpus such as semcor is clearly useful, there is a strong case for obtaining a first, or predominant, sense from untagged corpus data so that a wsd system can be tuned to the genre or domain at hand.",[0],"previous re search in inducing sense rankings from an untagged corpus (mccarthy et al, 2004), and inducing selectional preferences at the word level (for other applications) (erk, 2007) will provide the starting point for research in this direction",[0],6,result,1,1.0,0.1111111111111111,15.0,0.07731958762886598,8.0,0.21621621621621623,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P04-1036,I08-2105,[101],"thus, if we used the sense ranking as a heuristic for an “all nouns” task we would expect to get precision in the region of 60%.",[0],"mccarthy et al (2004) report a disambiguation precision of 53.0% and recall of 49.0% on the senseval-2 test data, using an approach that derives sense ranking based on word similarity and distributional analysis in a corpus",[0],7,method,3,3.0,0.3333333333333333,101.0,0.520618556701031,30.0,0.967741935483871,0,0.0,0.0,0.0,0.0,0.0,3 experiment with semcor,abstract
P04-1036,P06-1012,[126],we demonstrate that choosing texts from a particular domain has a significant influence on the sense ranking.,[0],"research by (mccarthy et al, 2004) highlighted that the sense priors of a word in a corpus depend on the domain from which the corpus is drawn",[0],8,result,5,5.0,0.5555555555555556,126.0,0.6494845360824743,3.0,0.10344827586206896,0,0.0,0.0,0.0,0.0,0.0,5 experiments with domain specific corpora,abstract
P04-1036,P06-1012,[8],the first sense heuristic which is often used as a baseline for supervised wsd systems outperforms many of these systems which take surrounding context into account.,[0],"in addition, we implemented the unsupervised method of (mccarthy et al, 2004), which cal cu lates a prevalence score for each sense of a word to predict the predominant sense",[0],9,result,1,1.0,0.1111111111111111,8.0,0.041237113402061855,1.0,0.02702702702702703,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P04-1036,P10-1155,[83],the results in table 1 show the accuracy of the ranking with respect to semcor over the entire set of 2595 polysemous nouns in semcor with the jcn and lesk wordnet similarity measures.,[0],"mccarthy et al (2004) reported that the best results were obtained using k= 50 neighbors and the wordnet similarityjcn measure (jiang and conrath, 1997)",[0],11,result,3,3.0,0.3333333333333333,83.0,0.42783505154639173,12.0,0.3870967741935484,0,0.0,0.0,0.0,0.0,0.0,3 experiment with semcor,abstract
P04-1036,W12-3401,[126],we demonstrate that choosing texts from a particular domain has a significant influence on the sense ranking.,[0],"in doing so, we provide first results on the application to french parsing of wordnet automatic sense ranking (asr), using the method of mccarthy et al (2004)",[0],12,result,5,5.0,0.5555555555555556,126.0,0.6494845360824743,3.0,0.10344827586206896,0,0.0,0.0,0.0,0.0,0.0,5 experiments with domain specific corpora,abstract
P04-1036,W12-3401,[46],"this provides the nearest neighbours to each target word, along with the distributional similarity score between the target word and its neighbour.",[0],"to define an appropriate categorical distribution over synsets for each 2 lemma x in our source vocabulary, we first use the wordnet resource to identify the set sx of different senses of x. we then use a distributional thesaurus to perform asr, which determines the prevalence with respect to x of each sense s? sx, following the approach of mccarthy et al (2004)",[0],13,result,2,2.0,0.2222222222222222,46.0,0.23711340206185566,2.0,0.07407407407407407,0,0.0,0.0,0.0,0.0,0.0,2 method,abstract
P04-1036,W12-3401,[126],we demonstrate that choosing texts from a particular domain has a significant influence on the sense ranking.,[0],"as explained in section 2.2, asr is performed using the method of mccarthy et al (2004)",[0],14,result,5,5.0,0.5555555555555556,126.0,0.6494845360824743,3.0,0.10344827586206896,0,0.0,0.0,0.0,0.0,0.0,5 experiments with domain specific corpora,abstract
P04-1036,S12-1097,[8],the first sense heuristic which is often used as a baseline for supervised wsd systems outperforms many of these systems which take surrounding context into account.,[0],"this approach is commonly used as a baseline for word sense disambiguation (mccarthy et al, 2004)",[0],16,result,1,1.0,0.1111111111111111,8.0,0.041237113402061855,1.0,0.02702702702702703,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P04-1036,W10-2803,[105],"we use an allwords task because the predominant senses will reflect the sense distributions of all nouns within the documents, rather than a lexical sample task, where the target words are manually determined and the results will depend on the skew of the words in the sample.",[0],"more radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (mccarthy et al, 2004), or to work directly with para phrases (mccarthy and navigli, 2009)",[0],17,result,4,4.0,0.4444444444444444,105.0,0.5412371134020618,3.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,4 experiment on senseval-2 english all words data,abstract
P04-1036,W08-2107,[13],the high performance of the first sense baseline is due to the skewed frequency distribution of word senses.,[0],"in addition, we can also infer a positive contribution of the frequency of a sense with the choice of the first synset returned by word net resulting in a reasonable wsd heuristic (which is compatible with the results by mccarthy et al (2004))",[0],18,method,1,1.0,0.1111111111111111,13.0,0.06701030927835051,6.0,0.16216216216216217,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P04-1036,D07-1026,[13],the high performance of the first sense baseline is due to the skewed frequency distribution of word senses.,[0],"it is worthwhile to remark here that, being the ible algorithm fully unsupervised, improving the most frequent baseline is an excellent result, rarely achieved in the literature on unsupervised methods for wsd (mccarthy et al, 2004)",[0],19,method,1,1.0,0.1111111111111111,13.0,0.06701030927835051,6.0,0.16216216216216217,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P04-1036,W12-2429,[8],the first sense heuristic which is often used as a baseline for supervised wsd systems outperforms many of these systems which take surrounding context into account.,[0],"the first, most frequent sense (mfs) (mccarthy et al, 2004), is widely used baseline for supervised wsd systems",[0],20,result,1,1.0,0.1111111111111111,8.0,0.041237113402061855,1.0,0.02702702702702703,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P04-1036,W04-0837,[8],the first sense heuristic which is often used as a baseline for supervised wsd systems outperforms many of these systems which take surrounding context into account.,[0],"the first sense heuristic which is often used as a baseline for supervised wsd systems outperforms many of these systems which take surrounding con text into account (mccarthy et al, 2004)",[0],1,method,1,1.0,0.1111111111111111,8.0,0.041237113402061855,1.0,0.02702702702702703,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P04-1036,W04-0837,[82],"we also calculate the wsd accuracy that would be obtained on semcor, when using our first sense in all contexts ( ).",[0],"association for computational linguistics for the semantic analysis of text, barcelona, spain, july 2004 senseval-3: third international workshop on the evaluation of systems pos precision recall baseline noun 95 73 45 verb 79 43 22 adjective 88 59 44 adverb 91 72 59 all pos 90 63 41table 2: the senseval-2 first sense on the sen seval-2 english all-words data system can be tuned to a given genre or domain (mccarthy et al, 2004) and also because there will be words that occur with insufficient frequency inthe hand-tagged resources available",[0],2,method,3,3.0,0.3333333333333333,82.0,0.422680412371134,11.0,0.3548387096774194,0,0.0,0.0,0.0,0.0,0.0,3 experiment with semcor,abstract
P04-1036,W04-0837,[64],"we briefly summarise the two measures here; for a more detailed summary see (patwardhan et al., 2003).",[0],"the method is described in (mccarthy et al, 2004), which we summarise here",[0],3,method,2,2.0,0.2222222222222222,64.0,0.32989690721649484,20.0,0.7407407407407407,0,0.0,0.0,0.0,0.0,0.0,2 method,abstract
P04-1036,I08-2105,[172],"we believe automatic ranking techniques such as ours will be useful for systems that rely on wordnet, for example those that use it for lexical acquisition or wsd.",[0],"mccarthy et al (2004) use a corpus and word similarities to induce a ranking of word senses from an untagged corpus to be used in wsd.we build upon this previous research, and pro pose an unsupervised wsd method in which senses for two grammatically related words in the sentence will be connected through directed edges",[0],5,method,6,6.0,0.6666666666666666,172.0,0.8865979381443299,20.0,0.8,0,0.0,0.0,0.0,0.0,0.0,6 related work,abstract
P04-1036,I08-2105,[153],"most research in wsd concentrates on using contextual features, typically neighbouring words, to help determine the correct sense of a target word.",[0],"previous re search in inducing sense rankings from an untagged corpus (mccarthy et al, 2004), and inducing selectional preferences at the word level (for other applications) (erk, 2007) will provide the starting point for research in this direction",[0],6,method,6,6.0,0.6666666666666666,153.0,0.788659793814433,1.0,0.04,0,0.0,0.0,0.0,0.0,0.0,6 related work,abstract
P04-1036,I08-2105,[1],word sense disambiguation the heuristic of choosing the most common sense is extremely powerful because the distribution of the senses of a word is often skewed.,[0],"mccarthy et al (2004) report a disambiguation precision of 53.0% and recall of 49.0% on the senseval-2 test data, using an approach that derives sense ranking based on word similarity and distributional analysis in a corpus",[0],7,method,0,0.0,0.0,1.0,0.005154639175257732,1.0,0.125,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
P04-1036,P06-1012,[165],"lapata and brew obtain their priors for verb classes directly from subcategorisation evidence in a parsed corpus, whereas we use parsed data to find distributionally similar words (nearest neighbours) to the target word which reflect the different senses of the word and have associated distributional similarity scores which can be used for ranking the senses according to prevalence.",[0],"research by (mccarthy et al, 2004) highlighted that the sense priors of a word in a corpus depend on the domain from which the corpus is drawn",[0],8,method,6,6.0,0.6666666666666666,165.0,0.8505154639175257,13.0,0.52,0,0.0,0.0,0.0,0.0,0.0,6 related work,abstract
P04-1036,P06-1012,[171],"in contrast, we use the neighbours lists and wordnet similarity measures to impose a prevalence ranking on the wordnet senses.",[0],"in addition, we implemented the unsupervised method of (mccarthy et al, 2004), which cal cu lates a prevalence score for each sense of a word to predict the predominant sense",[0],9,method,6,6.0,0.6666666666666666,171.0,0.8814432989690721,19.0,0.76,0,0.0,0.0,0.0,0.0,0.0,6 related work,abstract
P04-1036,P10-1155,[89],"since both measures gave comparable results we restricted our remaining experiments to jcn because this gave good results for finding the predominant sense, and is much more efficient than lesk, given the precompilation of the ic files.",[0],"mccarthy et al (2004) reported that the best results were obtained using k= 50 neighbors and the wordnet similarityjcn measure (jiang and conrath, 1997)",[0],11,method,3,3.0,0.3333333333333333,89.0,0.4587628865979381,18.0,0.5806451612903226,0,0.0,0.0,0.0,0.0,0.0,3 experiment with semcor,abstract
P04-1036,W12-3401,[172],"we believe automatic ranking techniques such as ours will be useful for systems that rely on wordnet, for example those that use it for lexical acquisition or wsd.",[0],"in doing so, we provide first results on the application to french parsing of wordnet automatic sense ranking (asr), using the method of mccarthy et al (2004)",[0],12,method,6,6.0,0.6666666666666666,172.0,0.8865979381443299,20.0,0.8,0,0.0,0.0,0.0,0.0,0.0,6 related work,abstract
P04-1036,W12-3401,[189],"additionally, we need to determine whether senses which do not occur in a wide variety of grammatical contexts fare badly using distributional measures of similarity, and what can be done to combat this problem using relation specific thesauruses.",[0],"to define an appropriate categorical distribution over synsets for each 2 lemma x in our source vocabulary, we first use the wordnet resource to identify the set sx of different senses of x. we then use a distributional thesaurus to perform asr, which determines the prevalence with respect to x of each sense s? sx, following the approach of mccarthy et al (2004)",[0],13,method,7,7.0,0.7777777777777778,189.0,0.9742268041237113,12.0,0.8571428571428571,0,0.0,0.0,0.0,0.0,0.0,7 conclusions,abstract
P04-1036,W12-3401,[87],"again, the automatic ranking outperforms this by a large margin.",[0],"as explained in section 2.2, asr is performed using the method of mccarthy et al (2004)",[0],14,method,3,3.0,0.3333333333333333,87.0,0.4484536082474227,16.0,0.5161290322580645,0,0.0,0.0,0.0,0.0,0.0,3 experiment with semcor,abstract
P04-1036,S12-1097,[1],word sense disambiguation the heuristic of choosing the most common sense is extremely powerful because the distribution of the senses of a word is often skewed.,[0],"this approach is commonly used as a baseline for word sense disambiguation (mccarthy et al, 2004)",[0],16,method,0,0.0,0.0,1.0,0.005154639175257732,1.0,0.125,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
P04-1036,W10-2803,[89],"since both measures gave comparable results we restricted our remaining experiments to jcn because this gave good results for finding the predominant sense, and is much more efficient than lesk, given the precompilation of the ic files.",[0],"more radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (mccarthy et al, 2004), or to work directly with para phrases (mccarthy and navigli, 2009)",[0],17,method,3,3.0,0.3333333333333333,89.0,0.4587628865979381,18.0,0.5806451612903226,0,0.0,0.0,0.0,0.0,0.0,3 experiment with semcor,abstract
P04-1036,W08-2107,[137],"additionally, we evaluated our method quantitatively using the subject field codes (sfc) resource (magnini and cavagli`a, 2000) which annotates wordnet synsets with domain labels.",[0],"in addition, we can also infer a positive contribution of the frequency of a sense with the choice of the first synset returned by word net resulting in a reasonable wsd heuristic (which is compatible with the results by mccarthy et al (2004))",[0],18,method,5,5.0,0.5555555555555556,137.0,0.7061855670103093,14.0,0.4827586206896552,0,0.0,0.0,0.0,0.0,0.0,5 experiments with domain specific corpora,abstract
P04-1036,D07-1026,[63],"we experimented using six of these to provide the in equation 1 above and obtained results well over our baseline, but because of space limitations give results for the two which perform the best.",[0],"it is worthwhile to remark here that, being the ible algorithm fully unsupervised, improving the most frequent baseline is an excellent result, rarely achieved in the literature on unsupervised methods for wsd (mccarthy et al, 2004)",[0],19,method,2,2.0,0.2222222222222222,63.0,0.3247422680412371,19.0,0.7037037037037037,0,0.0,0.0,0.0,0.0,0.0,2 method,abstract
P04-1036,W12-2429,[159],"magnini and cavagli`a (2000) have identified wordnet word senses with particular domains, and this has proven useful for high precision wsd (magnini et al., 2001); indeed in section 5 we used these domain labels for evaluation.",[0],"the first, most frequent sense (mfs) (mccarthy et al, 2004), is widely used baseline for supervised wsd systems",[0],20,method,6,6.0,0.6666666666666666,159.0,0.8195876288659794,7.0,0.28,0,0.0,0.0,0.0,0.0,0.0,6 related work,abstract
P04-1036,W04-0837,[8],the first sense heuristic which is often used as a baseline for supervised wsd systems outperforms many of these systems which take surrounding context into account.,[0],"the first sense heuristic which is often used as a baseline for supervised wsd systems outperforms many of these systems which take surrounding con text into account (mccarthy et al, 2004)",[0],1,method,1,1.0,0.1111111111111111,8.0,0.041237113402061855,1.0,0.02702702702702703,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P04-1036,W04-0837,[15],"whilst a first sense heuristic based on a sense-tagged corpus such as semcor is clearly useful, there is a strong case for obtaining a first, or predominant, sense from untagged corpus data so that a wsd system can be tuned to the genre or domain at hand.",[0],"association for computational linguistics for the semantic analysis of text, barcelona, spain, july 2004 senseval-3: third international workshop on the evaluation of systems pos precision recall baseline noun 95 73 45 verb 79 43 22 adjective 88 59 44 adverb 91 72 59 all pos 90 63 41table 2: the senseval-2 first sense on the sen seval-2 english all-words data system can be tuned to a given genre or domain (mccarthy et al, 2004) and also because there will be words that occur with insufficient frequency inthe hand-tagged resources available",[0],2,method,1,1.0,0.1111111111111111,15.0,0.07731958762886598,8.0,0.21621621621621623,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P04-1036,W04-0837,[45],in order to find the predominant sense of a target word we use a thesaurus acquired from automatically parsed text based on the method of lin (1998).,[0],"the method is described in (mccarthy et al, 2004), which we summarise here",[0],3,method,2,2.0,0.2222222222222222,45.0,0.23195876288659795,1.0,0.037037037037037035,0,0.0,0.0,0.0,0.0,0.0,2 method,abstract
P04-1036,I08-2105,[66],"it uses the glosses of semantically related (according to wordnet) senses too. jcn (jiang and conrath, 1997) this score uses corpus data to populate classes (synsets) in the wordnet hierarchy with frequency counts.",[0],"mccarthy et al (2004) use a corpus and word similarities to induce a ranking of word senses from an untagged corpus to be used in wsd.we build upon this previous research, and pro pose an unsupervised wsd method in which senses for two grammatically related words in the sentence will be connected through directed edges",[0],5,method,2,2.0,0.2222222222222222,66.0,0.3402061855670103,22.0,0.8148148148148148,0,0.0,0.0,0.0,0.0,0.0,2 method,abstract
P04-1036,I08-2105,[126],we demonstrate that choosing texts from a particular domain has a significant influence on the sense ranking.,[0],"previous re search in inducing sense rankings from an untagged corpus (mccarthy et al, 2004), and inducing selectional preferences at the word level (for other applications) (erk, 2007) will provide the starting point for research in this direction",[0],6,method,5,5.0,0.5555555555555556,126.0,0.6494845360824743,3.0,0.10344827586206896,0,0.0,0.0,0.0,0.0,0.0,5 experiments with domain specific corpora,abstract
P04-1036,I08-2105,[101],"thus, if we used the sense ranking as a heuristic for an “all nouns” task we would expect to get precision in the region of 60%.",[0],"mccarthy et al (2004) report a disambiguation precision of 53.0% and recall of 49.0% on the senseval-2 test data, using an approach that derives sense ranking based on word similarity and distributional analysis in a corpus",[0],7,method,3,3.0,0.3333333333333333,101.0,0.520618556701031,30.0,0.967741935483871,0,0.0,0.0,0.0,0.0,0.0,3 experiment with semcor,abstract
P04-1036,P06-1012,[126],we demonstrate that choosing texts from a particular domain has a significant influence on the sense ranking.,[0],"research by (mccarthy et al, 2004) highlighted that the sense priors of a word in a corpus depend on the domain from which the corpus is drawn",[0],8,method,5,5.0,0.5555555555555556,126.0,0.6494845360824743,3.0,0.10344827586206896,0,0.0,0.0,0.0,0.0,0.0,5 experiments with domain specific corpora,abstract
P04-1036,P06-1012,[115],"our automatically acquired predominant sense performs nearly as well as the first sense provided by semcor, which is very encouraging given that our method only uses raw text, with no manual labelling.",[0],"in addition, we implemented the unsupervised method of (mccarthy et al, 2004), which cal cu lates a prevalence score for each sense of a word to predict the predominant sense",[0],9,method,4,4.0,0.4444444444444444,115.0,0.5927835051546392,13.0,0.6190476190476191,0,0.0,0.0,0.0,0.0,0.0,4 experiment on senseval-2 english all words data,abstract
P04-1036,P10-1155,[89],"since both measures gave comparable results we restricted our remaining experiments to jcn because this gave good results for finding the predominant sense, and is much more efficient than lesk, given the precompilation of the ic files.",[0],"mccarthy et al (2004) reported that the best results were obtained using k= 50 neighbors and the wordnet similarityjcn measure (jiang and conrath, 1997)",[0],11,method,3,3.0,0.3333333333333333,89.0,0.4587628865979381,18.0,0.5806451612903226,0,0.0,0.0,0.0,0.0,0.0,3 experiment with semcor,abstract
P04-1036,W12-3401,[137],"additionally, we evaluated our method quantitatively using the subject field codes (sfc) resource (magnini and cavagli`a, 2000) which annotates wordnet synsets with domain labels.",[0],"in doing so, we provide first results on the application to french parsing of wordnet automatic sense ranking (asr), using the method of mccarthy et al (2004)",[0],12,method,5,5.0,0.5555555555555556,137.0,0.7061855670103093,14.0,0.4827586206896552,0,0.0,0.0,0.0,0.0,0.0,5 experiments with domain specific corpora,abstract
P04-1036,W12-3401,[75],"75 ssid=""4"">we generated a thesaurus entry for all polysemous nouns which occurred in semcor with a frequency 2, and in the bnc with a frequency 10 in the grammatical relations listed in section 2.1 above.",[0],"to define an appropriate categorical distribution over synsets for each 2 lemma x in our source vocabulary, we first use the wordnet resource to identify the set sx of different senses of x. we then use a distributional thesaurus to perform asr, which determines the prevalence with respect to x of each sense s? sx, following the approach of mccarthy et al (2004)",[0],13,method,3,3.0,0.3333333333333333,75.0,0.3865979381443299,4.0,0.12903225806451613,0,0.0,0.0,0.0,0.0,0.0,3 experiment with semcor,abstract
P04-1036,W12-3401,[155],"a major benefit of our work, rather than reliance on hand-tagged training data such as semcor, is that this method permits us to produce predominant senses for the domain and text type required.",[0],"as explained in section 2.2, asr is performed using the method of mccarthy et al (2004)",[0],14,method,6,6.0,0.6666666666666666,155.0,0.7989690721649485,3.0,0.12,0,0.0,0.0,0.0,0.0,0.0,6 related work,abstract
P04-1036,S12-1097,[8],the first sense heuristic which is often used as a baseline for supervised wsd systems outperforms many of these systems which take surrounding context into account.,[0],"this approach is commonly used as a baseline for word sense disambiguation (mccarthy et al, 2004)",[0],16,method,1,1.0,0.1111111111111111,8.0,0.041237113402061855,1.0,0.02702702702702703,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P04-1036,W10-2803,[155],"a major benefit of our work, rather than reliance on hand-tagged training data such as semcor, is that this method permits us to produce predominant senses for the domain and text type required.",[0],"more radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (mccarthy et al, 2004), or to work directly with para phrases (mccarthy and navigli, 2009)",[0],17,method,6,6.0,0.6666666666666666,155.0,0.7989690721649485,3.0,0.12,0,0.0,0.0,0.0,0.0,0.0,6 related work,abstract
P04-1036,W08-2107,[68],"we are of course able to apply the method to other versions of wordnet. synset, is incremented with the frequency counts from the corpus of all words belonging to that synset, directly or via the hyponymy relation.",[0],"in addition, we can also infer a positive contribution of the frequency of a sense with the choice of the first synset returned by word net resulting in a reasonable wsd heuristic (which is compatible with the results by mccarthy et al (2004))",[0],18,method,2,2.0,0.2222222222222222,68.0,0.35051546391752575,24.0,0.8888888888888888,0,0.0,0.0,0.0,0.0,0.0,2 method,abstract
P04-1036,D07-1026,[13],the high performance of the first sense baseline is due to the skewed frequency distribution of word senses.,[0],"it is worthwhile to remark here that, being the ible algorithm fully unsupervised, improving the most frequent baseline is an excellent result, rarely achieved in the literature on unsupervised methods for wsd (mccarthy et al, 2004)",[0],19,method,1,1.0,0.1111111111111111,13.0,0.06701030927835051,6.0,0.16216216216216217,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P04-1036,W12-2429,[8],the first sense heuristic which is often used as a baseline for supervised wsd systems outperforms many of these systems which take surrounding context into account.,[0],"the first, most frequent sense (mfs) (mccarthy et al, 2004), is widely used baseline for supervised wsd systems",[0],20,method,1,1.0,0.1111111111111111,8.0,0.041237113402061855,1.0,0.02702702702702703,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P05-1013,W05-1505,[20],"in this paper, we show how non-projective dependency parsing can be achieved by combining a datadriven projective parser with special graph transformation techniques.",[0],"recent work by nivre and nilsson introduces a technique where the projectivization transformation is encoded in the non-terminals of constituents during parsing (nivre and nilsson, 2005)",[0],1,method,1,1.0,0.125,20.0,0.17543859649122806,16.0,0.64,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P05-1013,P08-1006,[24],"we call this pseudoprojective dependency parsing, since it is based on a notion of pseudo-projectivity (kahane et al., 1998).",[0],"1http: //sourceforge.net/projects/mstparser figure 1: conll-x dependency tree figure 2: penn treebank-style phrase structure tree ksdep sagae and tsujii (2007)? s dependencyparser,2 based on a probabilistic shift-reduce algorithm extended by the pseudo-projective parsing technique (nivre and nilsson, 2005)",[0],2,method,1,1.0,0.125,24.0,0.21052631578947367,20.0,0.8,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P05-1013,W10-1401,[106],"however, the accuracy is considerably higher than previously reported results for robust non-projective parsing of czech, with a best performance of 73% uas (holan, 2004).",[0],"bengoetxea and gojenola (2010) discuss non-projective dependencies in basque and show that the pseudo-projective transformation of (nivre and nilsson, 2005) improves accuracy for dependency parsing of basque",[0],3,method,5,5.0,0.625,106.0,0.9298245614035088,17.0,0.8947368421052632,0,0.0,0.0,0.0,0.0,0.0,5 experiment 2: memory-based parsing,abstract
P05-1013,P12-3029,[86],"as expected, the most informative encoding, head+path, gives the highest accuracy with over 99% of all non-projective arcs being recovered correctly in both data sets.",[0],"for tree banks with non-projective trees weuse the pseudo-projective parsing technique to trans form the tree bank into projective structures (nivre and nilsson, 2005)",[0],4,method,4,4.0,0.5,86.0,0.7543859649122807,13.0,0.8125,0,0.0,0.0,0.0,0.0,0.0,4 experiment 1: treebank transformation,abstract
P05-1013,W10-1403,[20],"in this paper, we show how non-projective dependency parsing can be achieved by combining a datadriven projective parser with special graph transformation techniques.",[0],"it uses graph transformation to handle non-projective trees (nivre and nilsson, 2005)",[0],5,method,1,1.0,0.125,20.0,0.17543859649122806,16.0,0.64,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P05-1013,D08-1008,[36],"as observed by kahane et al. (1998), any (nonprojective) dependency graph can be transformed into a projective one by a lifting operation, which replaces each non-projective arc wj wk by a projective arc wi —* wk such that wi —*∗ wj holds in the original graph.",[0],"to simplify implementation, we instead opted for the pseudo-projective approach (nivre and nilsson,2005), in which non projective links are lifted upwards in the tree to achieve projectivity, and special trace labels are used to enable recovery of the non projective links at parse time",[0],6,method,2,2.0,0.25,36.0,0.3157894736842105,7.0,0.21875,0,0.0,0.0,0.0,0.0,0.0,2 dependency graph transformations,abstract
P05-1013,D07-1013,[109],"we have presented a new method for non-projective dependency parsing, based on a combination of data-driven projective dependency parsing and graph transformation techniques.",[0],",wn in o (n) time, producing a projective dependency graph satisfying conditions 1? 4 in section 2.1, possibly after adding arcs (0, i ,lr) for every node i 6= 0 that is a root in the output graph (where lr is a special label for root modifiers) .nivre and nilsson (2005) showed how the restriction to projective dependency graphs could be lifted by using graph transformation techniques to pre process training data and post-process parser output, so-called pseudo-projective parsing. to learn transition scores, these systems use discriminative learning methods ,e.g., memory-based learning or support vector machines",[0],7,method,6,6.0,0.75,109.0,0.956140350877193,1.0,0.5,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
P05-1013,D07-1119,[36],"as observed by kahane et al. (1998), any (nonprojective) dependency graph can be transformed into a projective one by a lifting operation, which replaces each non-projective arc wj wk by a projective arc wi —* wk such that wi —*∗ wj holds in the original graph.",[0],"for handling non-projective relations, nivre and nilsson (2005) suggested applying a preprocessing step to a dependency parser, which consists in lifting non-projective arcs to their head repeatedly, until the tree becomes pseudo-projective",[0],8,method,2,2.0,0.25,36.0,0.3157894736842105,7.0,0.21875,0,0.0,0.0,0.0,0.0,0.0,2 dependency graph transformations,abstract
P05-1013,N07-1050,[23],"by applying an inverse transformation to the output of the parser, arcs with non-standard labels can be lowered to their proper place in the dependency graph, giving rise 1the dependency graph has been modified to make the final period a dependent of the main verb instead of being a dependent of a special root node for the sentence. to non-projective structures.",[0],"whereas most of the early approaches were limited to strictly projective dependency structures, where the projection of a syntactic head must be continuous, attention has recently shifted to the analysis of non-projective structures, which are required for linguistically adequate representations, especially in languages with free or flexible word order. the most popular strategy for capturing non projective structures in data-driven dependency parsing is to apply some kind of post-processing to the output of a strictly projective dependency parser, as in pseudo-projective parsing (nivre and nilsson, 2005), corrective modeling (hall and nova? k, 2005), or approximate non-projective parsing (mcdonald and pereira, 2006)",[0],9,method,1,1.0,0.125,23.0,0.20175438596491227,19.0,0.76,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P05-1013,W09-1207,[24],"we call this pseudoprojective dependency parsing, since it is based on a notion of pseudo-projectivity (kahane et al., 1998).",[0],"troduced in (nivre and nilsson, 2005) to handle the non-projective languages including czech, german and english",[0],10,method,1,1.0,0.125,24.0,0.21052631578947367,20.0,0.8,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P05-1013,E09-1034,"[80, 81]","as shown in table 3, the proportion of sentences containing some non-projective dependency ranges from about 15% in ddt to almost 25% in pdt.
however, the overall percentage of non-projective arcs is less than 2% in pdt and less than 1% in ddt.",[0],"non projective (nivre and nilsson, 2005), we char ac terise a sense in which the structures appearing in tree banks can be viewed as being only? slightly? ill-nested",[0],11,method,4_4,4.0,0.5,80.5,0.706140350877193,7.5,0.46875,0,0.0,0.0,0.0,0.0,0.0,"4 experiment 1: treebank transformation, 4 experiment 1: treebank transformation",abstract
P05-1013,W09-1218,[24],"we call this pseudoprojective dependency parsing, since it is based on a notion of pseudo-projectivity (kahane et al., 1998).",[0],"in order to avoid losing the benefits of higher-order parsing, we considered applying pseudo-projective transformation (nivre and nilsson, 2005)",[0],12,method,1,1.0,0.125,24.0,0.21052631578947367,20.0,0.8,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P05-1013,C08-1081,[20],"in this paper, we show how non-projective dependency parsing can be achieved by combining a datadriven projective parser with special graph transformation techniques.",[0],"pseudo-projective parsing for recovering non projective structures (nivre and nilsson, 2005)",[0],13,method,1,1.0,0.125,20.0,0.17543859649122806,16.0,0.64,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P05-1013,C08-1081,[24],"we call this pseudoprojective dependency parsing, since it is based on a notion of pseudo-projectivity (kahane et al., 1998).",[0],"although the parser only derives projective graphs, the fact that these graphs are labeled allows non-projective dependencies to be captured using the pseudo-projective approach of nivre and nilsson (2005) (section 3.4)",[0],14,method,1,1.0,0.125,24.0,0.21052631578947367,20.0,0.8,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P05-1013,C08-1081,[20],"in this paper, we show how non-projective dependency parsing can be achieved by combining a datadriven projective parser with special graph transformation techniques.",[0],pseudo-projective parsing was proposed by nivreand nilsson (2005) as a way of dealing with non projective structures in a projective data-driven parser,[0],15,method,1,1.0,0.125,20.0,0.17543859649122806,16.0,0.64,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P05-1013,C08-1081,[49],"the baseline simply retains the original labels for all arcs, regardless of whether they have been lifted or not, and the number of distinct labels is therefore simply the number n of distinct dependency types.2 in the first encoding scheme, called head, we use a new label d↑h for each lifted arc, where d is the dependency relation between the syntactic head and the dependent in the non-projective representation, and h is the dependency relation that the syntactic head has to its own head in the underlying structure.",[0],"weprojectivize training data by a minimal transformation, lifting non-projective arcs one step at a time, and extending the arc label of lifted arcs using the encoding scheme called head by nivre and nilsson (2005), which means that a lifted arc is assigned the label r? h, where r is the original label and h is the label of the original head in the non-projective dependency graph",[0],16,method,2,2.0,0.25,49.0,0.4298245614035088,20.0,0.625,0,0.0,0.0,0.0,0.0,0.0,2 dependency graph transformations,abstract
P05-1013,D11-1006,[109],"we have presented a new method for non-projective dependency parsing, based on a combination of data-driven projective dependency parsing and graph transformation techniques.",[0],"for tree banks with non-projective trees we use the pseudo-projective parsing technique to transform the tree bank into projective structures (nivre and nilsson, 2005)",[0],17,method,6,6.0,0.75,109.0,0.956140350877193,1.0,0.5,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
P05-1013,P11-2121,[14],"while the proportion of sentences containing non-projective dependencies is often 15–25%, the total proportion of non-projective arcs is normally only 1–2%.",[0],"since the number of non-projective dependencies is much smaller than the number of projective dependencies (nivre and nilsson, 2005), it is not efficient to perform non-projective parsing for all cases",[0],18,method,1,1.0,0.125,14.0,0.12280701754385964,10.0,0.4,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P05-1013,D07-1111,[20],"in this paper, we show how non-projective dependency parsing can be achieved by combining a datadriven projective parser with special graph transformation techniques.",[0],"the resulting algorithm is projective, and nonprojectivity is handled by pseudo-projective trans formations as described in (nivre and nilsson, 2005)",[0],20,method,1,1.0,0.125,20.0,0.17543859649122806,16.0,0.64,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P05-1013,W05-1505,[49.0],"the baseline simply retains the original labels for all arcs, regardless of whether they have been lifted or not, and the number of distinct labels is therefore simply the number n of distinct dependency types.2 in the first encoding scheme, called head, we use a new label d↑h for each lifted arc, where d is the dependency relation between the syntactic head and the dependent in the non-projective representation, and h is the dependency relation that the syntactic head has to its own head in the underlying structure.",[0],"recent work by nivre and nilsson introduces a technique where the projectivization transformation is encoded in the non-terminals of constituents during parsing (nivre and nilsson, 2005)",[0],1,method,2,2.0,0.25,49.0,0.4298245614035088,20.0,0.625,0,0.0,0.0,0.0,0.0,0.0,2 dependency graph transformations,abstract
P05-1013,P08-1006,[109.0],"we have presented a new method for non-projective dependency parsing, based on a combination of data-driven projective dependency parsing and graph transformation techniques.",[0],"1http: //sourceforge.net/projects/mstparser figure 1: conll-x dependency tree figure 2: penn treebank-style phrase structure tree ksdep sagae and tsujii (2007)? s dependencyparser,2 based on a probabilistic shift-reduce algorithm extended by the pseudo-projective parsing technique (nivre and nilsson, 2005)",[0],2,method,6,6.0,0.75,109.0,0.956140350877193,1.0,0.5,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
P05-1013,W10-1401,[95.0],the second main result is that the pseudo-projective approach to parsing (using special arc labels to guide an inverse transformation) gives a further improvement of about one percentage point on attachment score.,[0],"bengoetxea and gojenola (2010) discuss non-projective dependencies in basque and show that the pseudo-projective transformation of (nivre and nilsson, 2005) improves accuracy for dependency parsing of basque",[0],3,result,5,5.0,0.625,95.0,0.8333333333333334,6.0,0.3157894736842105,0,0.0,0.0,0.0,0.0,0.0,5 experiment 2: memory-based parsing,abstract
P05-1013,P12-3029,[79.0],"in the first part of the experiment, dependency graphs from the treebanks were projectivized using the algorithm described in section 2.",[0],"for tree banks with non-projective trees weuse the pseudo-projective parsing technique to trans form the tree bank into projective structures (nivre and nilsson, 2005)",[0],4,method,4,4.0,0.5,79.0,0.6929824561403509,6.0,0.375,0,0.0,0.0,0.0,0.0,0.0,4 experiment 1: treebank transformation,abstract
P05-1013,W10-1403,[109.0],"we have presented a new method for non-projective dependency parsing, based on a combination of data-driven projective dependency parsing and graph transformation techniques.",[0],"it uses graph transformation to handle non-projective trees (nivre and nilsson, 2005)",[0],5,result,6,6.0,0.75,109.0,0.956140350877193,1.0,0.5,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
P05-1013,D08-1008,[38.0],projectivizing a dependency graph by lifting nonprojective arcs is a nondeterministic operation in the general case.,[0],"to simplify implementation, we instead opted for the pseudo-projective approach (nivre and nilsson,2005), in which non projective links are lifted upwards in the tree to achieve projectivity, and special trace labels are used to enable recovery of the non projective links at parse time",[0],6,method,2,2.0,0.25,38.0,0.3333333333333333,9.0,0.28125,0,0.0,0.0,0.0,0.0,0.0,2 dependency graph transformations,abstract
P05-1013,D07-1013,[109.0],"we have presented a new method for non-projective dependency parsing, based on a combination of data-driven projective dependency parsing and graph transformation techniques.",[0],",wn in o (n) time, producing a projective dependency graph satisfying conditions 1? 4 in section 2.1, possibly after adding arcs (0, i ,lr) for every node i 6= 0 that is a root in the output graph (where lr is a special label for root modifiers) .nivre and nilsson (2005) showed how the restriction to projective dependency graphs could be lifted by using graph transformation techniques to pre process training data and post-process parser output, so-called pseudo-projective parsing. to learn transition scores, these systems use discriminative learning methods ,e.g., memory-based learning or support vector machines",[0],7,result,6,6.0,0.75,109.0,0.956140350877193,1.0,0.5,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
P05-1013,D07-1119,[79.0],"in the first part of the experiment, dependency graphs from the treebanks were projectivized using the algorithm described in section 2.",[0],"for handling non-projective relations, nivre and nilsson (2005) suggested applying a preprocessing step to a dependency parser, which consists in lifting non-projective arcs to their head repeatedly, until the tree becomes pseudo-projective",[0],8,method,4,4.0,0.5,79.0,0.6929824561403509,6.0,0.375,0,0.0,0.0,0.0,0.0,0.0,4 experiment 1: treebank transformation,abstract
P05-1013,N07-1050,[109.0],"we have presented a new method for non-projective dependency parsing, based on a combination of data-driven projective dependency parsing and graph transformation techniques.",[0],"whereas most of the early approaches were limited to strictly projective dependency structures, where the projection of a syntactic head must be continuous, attention has recently shifted to the analysis of non-projective structures, which are required for linguistically adequate representations, especially in languages with free or flexible word order. the most popular strategy for capturing non projective structures in data-driven dependency parsing is to apply some kind of post-processing to the output of a strictly projective dependency parser, as in pseudo-projective parsing (nivre and nilsson, 2005), corrective modeling (hall and nova? k, 2005), or approximate non-projective parsing (mcdonald and pereira, 2006)",[0],9,result,6,6.0,0.75,109.0,0.956140350877193,1.0,0.5,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
P05-1013,W09-1207,[109.0],"s sid=""109"" ssid=""1"">we have presented a new method for non-projective dependency parsing, based on a combination of data-driven projective dependency parsing and graph transformation techniques.",[0],"troduced in (nivre and nilsson, 2005) to handle the non-projective languages including czech, german and english",[0],10,result,6,6.0,0.75,109.0,0.956140350877193,1.0,0.5,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
P05-1013,E09-1034,[109.0],"s sid=""109"" ssid=""1"">we have presented a new method for non-projective dependency parsing, based on a combination of data-driven projective dependency parsing and graph transformation techniques.",[0],"non projective (nivre and nilsson, 2005), we char ac terise a sense in which the structures appearing in tree banks can be viewed as being only? slightly? ill-nested",[0],11,result,6,6.0,0.75,109.0,0.956140350877193,1.0,0.5,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
P05-1013,C08-1081,[86.0],"as expected, the most informative encoding, head+path, gives the highest accuracy with over 99% of all non-projective arcs being recovered correctly in both data sets.",[0],"pseudo-projective parsing for recovering non projective structures (nivre and nilsson, 2005)",[0],13,method,4,4.0,0.5,86.0,0.7543859649122807,13.0,0.8125,0,0.0,0.0,0.0,0.0,0.0,4 experiment 1: treebank transformation,abstract
P05-1013,C08-1081,[95.0],the second main result is that the pseudo-projective approach to parsing (using special arc labels to guide an inverse transformation) gives a further improvement of about one percentage point on attachment score.,[0],"although the parser only derives projective graphs, the fact that these graphs are labeled allows non-projective dependencies to be captured using the pseudo-projective approach of nivre and nilsson (2005) (section 3.4)",[0],14,method,5,5.0,0.625,95.0,0.8333333333333334,6.0,0.3157894736842105,0,0.0,0.0,0.0,0.0,0.0,5 experiment 2: memory-based parsing,abstract
P05-1013,C08-1081,[109.0],"we have presented a new method for non-projective dependency parsing, based on a combination of data-driven projective dependency parsing and graph transformation techniques.",[0],pseudo-projective parsing was proposed by nivreand nilsson (2005) as a way of dealing with non projective structures in a projective data-driven parser,[0],15,result,6,6.0,0.75,109.0,0.956140350877193,1.0,0.5,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
P05-1013,C08-1081,[51.0],"in the second scheme, head+path, we in addition modify the label of every arc along the lifting path from the syntactic to the linear head so that if the original label is p the new label is p↓.",[0],"weprojectivize training data by a minimal transformation, lifting non-projective arcs one step at a time, and extending the arc label of lifted arcs using the encoding scheme called head by nivre and nilsson (2005), which means that a lifted arc is assigned the label r? h, where r is the original label and h is the label of the original head in the non-projective dependency graph",[0],16,method,2,2.0,0.25,51.0,0.4473684210526316,22.0,0.6875,0,0.0,0.0,0.0,0.0,0.0,2 dependency graph transformations,abstract
P05-1013,D11-1006,[99.0],"this may seem surprising, given the experiments reported in section 4, but the explanation is probably that the non-projective dependencies that can be recovered at all are of the simple kind that only requires a single lift, where the encoding of path information is often redundant.",[0],"for tree banks with non-projective trees we use the pseudo-projective parsing technique to transform the tree bank into projective structures (nivre and nilsson, 2005)",[0],17,result,5,5.0,0.625,99.0,0.868421052631579,10.0,0.5263157894736842,0,0.0,0.0,0.0,0.0,0.0,5 experiment 2: memory-based parsing,abstract
P05-1013,P11-2121,[7.0],"from the point of view of computational implementation this can be problematic, since the inclusion of non-projective structures makes the parsing problem more complex and therefore compromises efficiency and in practice also accuracy and robustness.",[0],"since the number of non-projective dependencies is much smaller than the number of projective dependencies (nivre and nilsson, 2005), it is not efficient to perform non-projective parsing for all cases",[0],18,method,1,1.0,0.125,7.0,0.06140350877192982,3.0,0.12,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P05-1013,D07-1111,[2.0],"we show how a datadriven deterministic dependency parser, in itself restricted to projective structures, can be combined with graph transformation techniques to produce non-projective structures.",[0],"the resulting algorithm is projective, and nonprojectivity is handled by pseudo-projective trans formations as described in (nivre and nilsson, 2005)",[0],20,aim,0,0.0,0.0,2.0,0.017543859649122806,2.0,0.4,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
P05-1013,W05-1505,[20],"in this paper, we show how non-projective dependency parsing can be achieved by combining a datadriven projective parser with special graph transformation techniques.",[0],"recent work by nivre and nilsson introduces a technique where the projectivization transformation is encoded in the non-terminals of constituents during parsing (nivre and nilsson, 2005)",[0],1,method,1,1.0,0.125,20.0,0.17543859649122806,16.0,0.64,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P05-1013,P08-1006,[9],"this is true of the widely used link grammar parser for english (sleator and temperley, 1993), which uses a dependency grammar of sorts, the probabilistic dependency parser of eisner (1996), and more recently proposed deterministic dependency parsers (yamada and matsumoto, 2003; nivre et al., 2004).",[0],"1http: //sourceforge.net/projects/mstparser figure 1: conll-x dependency tree figure 2: penn treebank-style phrase structure tree ksdep sagae and tsujii (2007)? s dependencyparser,2 based on a probabilistic shift-reduce algorithm extended by the pseudo-projective parsing technique (nivre and nilsson, 2005)",[0],2,method,1,1.0,0.125,9.0,0.07894736842105263,5.0,0.2,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P05-1013,W10-1401,[104],the overall parsing accuracy obtained with the pseudo-projective approach is still lower than for the best projective parsers.,[0],"bengoetxea and gojenola (2010) discuss non-projective dependencies in basque and show that the pseudo-projective transformation of (nivre and nilsson, 2005) improves accuracy for dependency parsing of basque",[0],3,method,5,5.0,0.625,104.0,0.9122807017543859,15.0,0.7894736842105263,0,0.0,0.0,0.0,0.0,0.0,5 experiment 2: memory-based parsing,abstract
P05-1013,P12-3029,[104],the overall parsing accuracy obtained with the pseudo-projective approach is still lower than for the best projective parsers.,[0],"for tree banks with non-projective trees weuse the pseudo-projective parsing technique to trans form the tree bank into projective structures (nivre and nilsson, 2005)",[0],4,method,5,5.0,0.625,104.0,0.9122807017543859,15.0,0.7894736842105263,0,0.0,0.0,0.0,0.0,0.0,5 experiment 2: memory-based parsing,abstract
P05-1013,W10-1403,[109],"we have presented a new method for non-projective dependency parsing, based on a combination of data-driven projective dependency parsing and graph transformation techniques.",[0],"it uses graph transformation to handle non-projective trees (nivre and nilsson, 2005)",[0],5,method,6,6.0,0.75,109.0,0.956140350877193,1.0,0.5,0,0.0,0.0,0.0,0.0,0.0,6 conclusion,abstract
P05-1013,D08-1008,[95],the second main result is that the pseudo-projective approach to parsing (using special arc labels to guide an inverse transformation) gives a further improvement of about one percentage point on attachment score.,[0],"to simplify implementation, we instead opted for the pseudo-projective approach (nivre and nilsson,2005), in which non projective links are lifted upwards in the tree to achieve projectivity, and special trace labels are used to enable recovery of the non projective links at parse time",[0],6,method,5,5.0,0.625,95.0,0.8333333333333334,6.0,0.3157894736842105,0,0.0,0.0,0.0,0.0,0.0,5 experiment 2: memory-based parsing,abstract
P05-1013,D07-1013,[20],"in this paper, we show how non-projective dependency parsing can be achieved by combining a datadriven projective parser with special graph transformation techniques.",[0],",wn in o (n) time, producing a projective dependency graph satisfying conditions 1? 4 in section 2.1, possibly after adding arcs (0, i ,lr) for every node i 6= 0 that is a root in the output graph (where lr is a special label for root modifiers) .nivre and nilsson (2005) showed how the restriction to projective dependency graphs could be lifted by using graph transformation techniques to pre process training data and post-process parser output, so-called pseudo-projective parsing. to learn transition scores, these systems use discriminative learning methods ,e.g., memory-based learning or support vector machines",[0],7,method,1,1.0,0.125,20.0,0.17543859649122806,16.0,0.64,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P05-1013,D07-1119,[36],"as observed by kahane et al. (1998), any (nonprojective) dependency graph can be transformed into a projective one by a lifting operation, which replaces each non-projective arc wj wk by a projective arc wi —* wk such that wi —*∗ wj holds in the original graph.",[0],"for handling non-projective relations, nivre and nilsson (2005) suggested applying a preprocessing step to a dependency parser, which consists in lifting non-projective arcs to their head repeatedly, until the tree becomes pseudo-projective",[0],8,method,2,2.0,0.25,36.0,0.3157894736842105,7.0,0.21875,0,0.0,0.0,0.0,0.0,0.0,2 dependency graph transformations,abstract
P05-1013,N07-1050,[62],"in the experiments below, we employ a data-driven deterministic dependency parser producing labeled projective dependency graphs,3 previously tested on swedish (nivre et al., 2004) and english (nivre and scholz, 2004).",[0],"whereas most of the early approaches were limited to strictly projective dependency structures, where the projection of a syntactic head must be continuous, attention has recently shifted to the analysis of non-projective structures, which are required for linguistically adequate representations, especially in languages with free or flexible word order. the most popular strategy for capturing non projective structures in data-driven dependency parsing is to apply some kind of post-processing to the output of a strictly projective dependency parser, as in pseudo-projective parsing (nivre and nilsson, 2005), corrective modeling (hall and nova? k, 2005), or approximate non-projective parsing (mcdonald and pereira, 2006)",[0],9,method,3,3.0,0.375,62.0,0.543859649122807,1.0,0.08333333333333333,0,0.0,0.0,0.0,0.0,0.0,3 memory-based dependency parsing,abstract
P05-1013,W09-1207,[104],the overall parsing accuracy obtained with the pseudo-projective approach is still lower than for the best projective parsers.,[0],"troduced in (nivre and nilsson, 2005) to handle the non-projective languages including czech, german and english",[0],10,method,5,5.0,0.625,104.0,0.9122807017543859,15.0,0.7894736842105263,0,0.0,0.0,0.0,0.0,0.0,5 experiment 2: memory-based parsing,abstract
P05-1013,E09-1034,[23],"by applying an inverse transformation to the output of the parser, arcs with non-standard labels can be lowered to their proper place in the dependency graph, giving rise 1the dependency graph has been modified to make the final period a dependent of the main verb instead of being a dependent of a special root node for the sentence. to non-projective structures.",[0],"non projective (nivre and nilsson, 2005), we char ac terise a sense in which the structures appearing in tree banks can be viewed as being only? slightly? ill-nested",[0],11,method,1,1.0,0.125,23.0,0.20175438596491227,19.0,0.76,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P05-1013,W09-1218,[104],the overall parsing accuracy obtained with the pseudo-projective approach is still lower than for the best projective parsers.,[0],"in order to avoid losing the benefits of higher-order parsing, we considered applying pseudo-projective transformation (nivre and nilsson, 2005)",[0],12,method,5,5.0,0.625,104.0,0.9122807017543859,15.0,0.7894736842105263,0,0.0,0.0,0.0,0.0,0.0,5 experiment 2: memory-based parsing,abstract
P05-1013,C08-1081,[95],the second main result is that the pseudo-projective approach to parsing (using special arc labels to guide an inverse transformation) gives a further improvement of about one percentage point on attachment score.,[0],"pseudo-projective parsing for recovering non projective structures (nivre and nilsson, 2005)",[0],13,method,5,5.0,0.625,95.0,0.8333333333333334,6.0,0.3157894736842105,0,0.0,0.0,0.0,0.0,0.0,5 experiment 2: memory-based parsing,abstract
P05-1013,C08-1081,[96],"with respect to exact match, the improvement is even more noticeable, which shows quite clearly that even if non-projective dependencies are rare on the token level, they are nevertheless important for getting the global syntactic structure correct.",[0],"although the parser only derives projective graphs, the fact that these graphs are labeled allows non-projective dependencies to be captured using the pseudo-projective approach of nivre and nilsson (2005) (section 3.4)",[0],14,method,5,5.0,0.625,96.0,0.8421052631578947,7.0,0.3684210526315789,0,0.0,0.0,0.0,0.0,0.0,5 experiment 2: memory-based parsing,abstract
P05-1013,C08-1081,[95],the second main result is that the pseudo-projective approach to parsing (using special arc labels to guide an inverse transformation) gives a further improvement of about one percentage point on attachment score.,[0],pseudo-projective parsing was proposed by nivreand nilsson (2005) as a way of dealing with non projective structures in a projective data-driven parser,[0],15,method,5,5.0,0.625,95.0,0.8333333333333334,6.0,0.3157894736842105,0,0.0,0.0,0.0,0.0,0.0,5 experiment 2: memory-based parsing,abstract
P05-1013,C08-1081,[40],"even this may be nondeterministic, in case the graph contains several non-projective arcs whose lifts interact, but we use the following algorithm to construct a minimal projective transformation d0 = (w, a0) of a (nonprojective) dependency graph d = (w, a): the function smallest-nonp-arc returns the non-projective arc with the shortest distance from head to dependent (breaking ties from left to right).",[0],"weprojectivize training data by a minimal transformation, lifting non-projective arcs one step at a time, and extending the arc label of lifted arcs using the encoding scheme called head by nivre and nilsson (2005), which means that a lifted arc is assigned the label r? h, where r is the original label and h is the label of the original head in the non-projective dependency graph",[0],16,method,2,2.0,0.25,40.0,0.3508771929824561,11.0,0.34375,0,0.0,0.0,0.0,0.0,0.0,2 dependency graph transformations,abstract
P05-1013,D11-1006,[7],"from the point of view of computational implementation this can be problematic, since the inclusion of non-projective structures makes the parsing problem more complex and therefore compromises efficiency and in practice also accuracy and robustness.",[0],"for tree banks with non-projective trees we use the pseudo-projective parsing technique to transform the tree bank into projective structures (nivre and nilsson, 2005)",[0],17,method,1,1.0,0.125,7.0,0.06140350877192982,3.0,0.12,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P05-1013,P11-2121,[14],"while the proportion of sentences containing non-projective dependencies is often 15–25%, the total proportion of non-projective arcs is normally only 1–2%.",[0],"since the number of non-projective dependencies is much smaller than the number of projective dependencies (nivre and nilsson, 2005), it is not efficient to perform non-projective parsing for all cases",[0],18,method,1,1.0,0.125,14.0,0.12280701754385964,10.0,0.4,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P05-1013,E06-1010,[49],"the baseline simply retains the original labels for all arcs, regardless of whether they have been lifted or not, and the number of distinct labels is therefore simply the number n of distinct dependency types.2 in the first encoding scheme, called head, we use a new label d↑h for each lifted arc, where d is the dependency relation between the syntactic head and the dependent in the non-projective representation, and h is the dependency relation that the syntactic head has to its own head in the underlying structure.",[0],"itshould be noted that the proportion of lost dependencies is about twice as high as the proportion of dependencies that are non-projective in them selves (nivre and nilsson, 2005)",[0],19,method,2,2.0,0.25,49.0,0.4298245614035088,20.0,0.625,0,0.0,0.0,0.0,0.0,0.0,2 dependency graph transformations,abstract
P05-1013,D07-1111,[104],the overall parsing accuracy obtained with the pseudo-projective approach is still lower than for the best projective parsers.,[0],"the resulting algorithm is projective, and nonprojectivity is handled by pseudo-projective trans formations as described in (nivre and nilsson, 2005)",[0],20,method,5,5.0,0.625,104.0,0.9122807017543859,15.0,0.7894736842105263,0,0.0,0.0,0.0,0.0,0.0,5 experiment 2: memory-based parsing,abstract
P08-1028,D08-1094,[51],"our work proposes a framework for vector composition which allows the derivation of different types of models and licenses two fundamental composition operations, multiplication and addition (and their combination).",[0],"mitchell and lapata (2008) propose a framework to represent the meaning of the combination p+ a as a function f operating on four components: c= f (p, a, r, k) (3) r is the relation holding between p and a, and kadditional knowledge",[0],1,method,2,2.0,0.2857142857142857,51.0,0.2512315270935961,24.0,0.96,0,0.0,0.0,0.0,0.0,0.0,2 related work,abstract
P08-1028,P10-1097,"[189, 190]","in this paper we presented a general framework for vector-based semantic composition.
we formulated composition as a function of two vectors and introduced several models based on addition and multiplication.",[0],"mitchell and lapata (2008), henceforth m& amp; l, propose a general framework in which meaning representations for complex expressions are computed compositionally by combining the vector representations of the individual words of the complex expression",[0],6,method,6_6,6.0,0.8571428571428571,189.5,0.9334975369458128,1.5,0.10714285714285714,0,0.0,0.0,0.0,0.0,0.0,"6 discussion, 6 discussion",abstract
P08-1028,P10-1097,"[185, 186]","the multiplicative model yields a better fit with the experimental data, ρ = 0.17.
the combined model is best overall with ρ = 0.19.
however, the difference between the two models is not statistically significant.",[0],"interestingly, mitchell and lapata (2008) came to the same result in a different setting",[0],7,result,5_5,5.0,0.7142857142857143,185.5,0.9137931034482759,19.5,0.8863636363636364,0,0.0,0.0,0.0,0.0,0.0,"5 results, 5 results",abstract
P08-1028,D11-1094,[51],"our work proposes a framework for vector composition which allows the derivation of different types of models and licenses two fundamental composition operations, multiplication and addition (and their combination).",[0],"and mitchell and lapata (2008) propose a model for vector composition, focusing on the different functions that might be used to combine the constituent vectors",[0],8,method,2,2.0,0.2857142857142857,51.0,0.2512315270935961,24.0,0.96,0,0.0,0.0,0.0,0.0,0.0,2 related work,abstract
P08-1028,W11-0131,"[189, 190]","in this paper we presented a general framework for vector-based semantic composition.
we formulated composition as a function of two vectors and introduced several models based on addition and multiplication.",[0],"mitchell and lapata (2008) provide a general framework for semantic vector composition: p= f (u, v, r, k) (1) 295 where u and v are the vectors to be composed, r is syntactic context, k is a semantic knowledge base, and p is a resulting composed vector (or tensor)",[0],9,method,6_6,6.0,0.8571428571428571,189.5,0.9334975369458128,1.5,0.10714285714285714,0,0.0,0.0,0.0,0.0,0.0,"6 discussion, 6 discussion",abstract
P08-1028,W11-0131,[48],the idea is to add not only the vectors representing the predicate and its argument but also the neighbors associated with both of them.,[0],"as mitchell and lapata (2008) did, let us temporarily suspend discussion on what semantics populate our vectors for now",[0],10,method,2,2.0,0.2857142857142857,48.0,0.23645320197044334,21.0,0.84,0,0.0,0.0,0.0,0.0,0.0,2 related work,abstract
P08-1028,P13-2083,"[53, 57]","we formulate semantic composition as a function of two vectors, u and v. we assume that individual words are represented by vectors acquired from a corpus following any of the parametrisations that have been suggested in the literature.1 we briefly note here that a word’s vector typically represents its co-occurrence with neighboring words.let p denote the composition of two vectors u and v, representing a pair of constituents which stand in some syntactic relation r. let k stand for any additional knowledge or information which is needed to construct the semantics of their composition.",[0],"mitchell and lapata (2008) propose a framework to define the composition c= f (a, b, r, k) where r is the relation between a and b, and k is the additional knowledge used to define composition",[0],11,method,3_3,3.0,0.42857142857142855,55.0,0.270935960591133,3.0,0.08571428571428572,0,0.0,0.0,0.0,0.0,0.0,"3 composition models, 3 composition models",abstract
P08-1028,P13-2083,"[68, 69, 70]","although the composition model in (5) is commonly used in the literature, from a linguistic perspective, the model in (6) is more appealing.
simply adding the vectors u and v lumps their contents together rather than allowing the content of one vector to pick out the relevant content of the other.
instead, it could be argued that the contribution of the ith component of u should be scaled according to its relevance to v, and vice versa.",[0],"as our final set of baselines, we extend two simple techniques proposed by (mitchell and lapata, 2008) that use element-wise addition and multiplication operators to perform composition",[0],12,method,3_3_3,3.0,0.42857142857142855,69.0,0.3399014778325123,17.0,0.4857142857142857,0,0.0,0.0,0.0,0.0,0.0,"3 composition models, 3 composition models, 3 composition models",abstract
P08-1028,P10-1021,"[189, 190]","in this paper we presented a general framework for vector-based semantic composition.
we formulated composition as a function of two vectors and introduced several models based on addition and multiplication.",[0],"althoughthis model has been shown to successfully simulate single and multiple-word priming (mcdonald and brew 2004), it failed to predict processing costs in the embra eye-tracking corpus (mcdonald and shillcock 2003) .in this work we model semantic constraint using the representational framework put forward in mitchell and lapata (2008)",[0],13,method,6_6,6.0,0.8571428571428571,189.5,0.9334975369458128,1.5,0.10714285714285714,0,0.0,0.0,0.0,0.0,0.0,"6 discussion, 6 discussion",abstract
P08-1028,P10-1021,"[189, 190]","in this paper we presented a general framework for vector-based semantic composition.
we formulated composition as a function of two vectors and introduced several models based on addition and multiplication.",[0],"assuming that h is a linear function of the cartesian product of u and v allows to specify additive models which are by far the most common method of vector combination in the literature: hi =ui+ vi (3) alternatively, we can assume that h is a linear function of the tensor product of u and v, and thus derive models based on multiplication: hi =ui? vi (4) mitchell and lapata (2008) show that several additive and multiplicative models can be formulated under this framework, including the well known tensor products (smolensky 1990) and circular convolution (plate 1995)",[0],14,method,6_6,6.0,0.8571428571428571,189.5,0.9334975369458128,1.5,0.10714285714285714,0,0.0,0.0,0.0,0.0,0.0,"6 discussion, 6 discussion",abstract
P08-1028,W11-0115,"[24, 25]","in this paper we examine models of semantic composition that are empirically grounded and can represent similarity relations.
we present a general framework for vector-based composition which allows us to consider different classes of models.",[0],"mitchell and lapata (2008) introduce a whole family of models of compositionality based on vector addition and point wise-multiplication (and a weighted combination of both), evaluated on a sentence similarity task inspired by kintsch (2001)",[0],15,method,1_1,1.0,0.14285714285714285,24.5,0.1206896551724138,20.5,0.8913043478260869,0,0.0,0.0,0.0,0.0,0.0,"1 introduction, 1 introduction",abstract
P08-1028,W11-0115,[64],"now, if we assume that p lies in the same space as u and v, avoiding the issues of dimensionality associated with tensor products, and that f is a linear function, for simplicity, of the cartesian product of u and v, then we generate a class of additive models: where a and b are matrices which determine the contributions made by u and v to the product p. in contrast, if we assume that f is a linear function of the tensor product of u and v, then we obtain multiplicative models: where c is a tensor of rank 3, which projects the tensor product of u and v onto the space of p. further constraints can be introduced to reduce the free parameters in these models.",[0],"the approach proposed by guevara (2010) is really only an extension of the full additive model of mitchell and lapata (2008), the only difference being that adopting a supervised learning methodology ensures that the weight parameters in the function are estimated optimally by linear regression",[0],16,method,3,3.0,0.42857142857142855,64.0,0.31527093596059114,12.0,0.34285714285714286,0,0.0,0.0,0.0,0.0,0.0,3 composition models,abstract
P08-1028,W11-0115,"[176, 177]","the multiplicative and combined models yield means closer to the human ratings.
the difference between high and low similarity values estimated by these models are statistically significant (p < 0.01 using the wilcoxon rank sum test).",[0],"for example, mitchell and lapata (2008) use their models to approximate the human ratings in their sentence similarity dataset",[0],17,method,5_5,5.0,0.7142857142857143,176.5,0.8694581280788177,10.5,0.4772727272727273,0,0.0,0.0,0.0,0.0,0.0,"5 results, 5 results",abstract
P08-1028,W11-1310,[191],"despite the popularity of additive models, our experimental results showed the superiority of models utilizing multiplicative combinations, at least for the sentence similarity task attempted here.",[0],mitchell and lapata (2008) observed that a simple multiplication function modelled compositionality better than addition,[0],19,method,6,6.0,0.8571428571428571,191.0,0.9408866995073891,3.0,0.21428571428571427,0,0.0,0.0,0.0,0.0,0.0,6 discussion,abstract
P08-1028,W11-1310,[24],in this paper we examine models of semantic composition that are empirically grounded and can represent similarity relations.,[0],"we use the compositionality functions, simple addition and simple multiplication to build compositional vectors vwr1+wr2 and vwr1 ?wr2. these are as described in (mitchell and lapata, 2008)",[0],20,method,1,1.0,0.14285714285714285,24.0,0.11822660098522167,20.0,0.8695652173913043,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P08-1028,D08-1094,[21.0],central in these models is the notion of compositionality — the meaning of complex expressions is determined by the meanings of their constituent expressions and the rules used to combine them.,[0],"mitchell and lapata (2008) propose a framework to represent the meaning of the combination p+ a as a function f operating on four components: c= f (p, a, r, k) (3) r is the relation holding between p and a, and kadditional knowledge",[0],1,method,1,1.0,0.14285714285714285,21.0,0.10344827586206896,17.0,0.7391304347826086,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P08-1028,D08-1094,[27.0],our results show that the multiplicative models are superior and correlate significantly with behavioral data.,[0],"in both experiments, we compare the svs model against the state-of-the art model by mitchell and lapata 2008 (henceforth m& amp; l; cf",[0],2,result,1,1.0,0.14285714285714285,27.0,0.1330049261083744,23.0,1.0,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P08-1028,P14-1060,[189.0],in this paper we presented a general framework for vector-based semantic composition.,[0],"while works such asthe sdsm model suffer from the problem of sparsity in composing structures beyond bi grams and trigrams, methods such as mitchell and lapata (2008) and (socher et al, 2012) and grefenstetteand sadrzadeh (2011) are restricted by significant model biases in representing semantic com position by generic algebraic operations",[0],4,aim,6,6.0,0.8571428571428571,189.0,0.9310344827586207,1.0,0.07142857142857142,0,0.0,0.0,0.0,0.0,0.0,6 discussion,abstract
P08-1028,P10-1097,[53.0],"we formulate semantic composition as a function of two vectors, u and v. we assume that individual words are represented by vectors acquired from a corpus following any of the parametrisations that have been suggested in the literature.1 we briefly note here that a word’s vector typically represents its co-occurrence with neighboring words.",[0],"mitchell and lapata (2008), henceforth m& amp; l, propose a general framework in which meaning representations for complex expressions are computed compositionally by combining the vector representations of the individual words of the complex expression",[0],6,method,3,3.0,0.42857142857142855,53.0,0.26108374384236455,1.0,0.02857142857142857,0,0.0,0.0,0.0,0.0,0.0,3 composition models,abstract
P08-1028,D11-1094,[76.0],"the models considered so far assume that components do not ‘interfere’ with each other, i.e., that it is also possible to re-introduce the dependence on k into the model of vector composition.",[0],"and mitchell and lapata (2008) propose a model for vector composition, focusing on the different functions that might be used to combine the constituent vectors",[0],8,method,3,3.0,0.42857142857142855,76.0,0.37438423645320196,24.0,0.6857142857142857,0,0.0,0.0,0.0,0.0,0.0,3 composition models,abstract
P08-1028,W11-0131,[57.0],"let p denote the composition of two vectors u and v, representing a pair of constituents which stand in some syntactic relation r. let k stand for any additional knowledge or information which is needed to construct the semantics of their composition.",[0],"mitchell and lapata (2008) provide a general framework for semantic vector composition: p= f (u, v, r, k) (1) 295 where u and v are the vectors to be composed, r is syntactic context, k is a semantic knowledge base, and p is a resulting composed vector (or tensor)",[0],9,method,3,3.0,0.42857142857142855,57.0,0.28078817733990147,5.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,3 composition models,abstract
P08-1028,P13-2083,[57.0],"let p denote the composition of two vectors u and v, representing a pair of constituents which stand in some syntactic relation r. let k stand for any additional knowledge or information which is needed to construct the semantics of their composition.",[0],"mitchell and lapata (2008) propose a framework to define the composition c= f (a, b, r, k) where r is the relation between a and b, and k is the additional knowledge used to define composition",[0],11,method,3,3.0,0.42857142857142855,57.0,0.28078817733990147,5.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,3 composition models,abstract
P08-1028,P13-2083,[190.0],we formulated composition as a function of two vectors and introduced several models based on addition and multiplication.,[0],"as our final set of baselines, we extend two simple techniques proposed by (mitchell and lapata, 2008) that use element-wise addition and multiplication operators to perform composition",[0],12,result,6,6.0,0.8571428571428571,190.0,0.9359605911330049,2.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,6 discussion,abstract
P08-1028,P10-1021,[60.0],to derive specific models from this general framework requires the identification of appropriate constraints to narrow the space of functions being considered.,[0],"althoughthis model has been shown to successfully simulate single and multiple-word priming (mcdonald and brew 2004), it failed to predict processing costs in the embra eye-tracking corpus (mcdonald and shillcock 2003) .in this work we model semantic constraint using the representational framework put forward in mitchell and lapata (2008)",[0],13,method,3,3.0,0.42857142857142855,60.0,0.2955665024630542,8.0,0.22857142857142856,0,0.0,0.0,0.0,0.0,0.0,3 composition models,abstract
P08-1028,P10-1021,[190.0],we formulated composition as a function of two vectors and introduced several models based on addition and multiplication.,[0],"assuming that h is a linear function of the cartesian product of u and v allows to specify additive models which are by far the most common method of vector combination in the literature: hi =ui+ vi (3) alternatively, we can assume that h is a linear function of the tensor product of u and v, and thus derive models based on multiplication: hi =ui? vi (4) mitchell and lapata (2008) show that several additive and multiplicative models can be formulated under this framework, including the well known tensor products (smolensky 1990) and circular convolution (plate 1995)",[0],14,result,6,6.0,0.8571428571428571,190.0,0.9359605911330049,2.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,6 discussion,abstract
P08-1028,W11-0115,[190.0],we formulated composition as a function of two vectors and introduced several models based on addition and multiplication.,[0],"mitchell and lapata (2008) introduce a whole family of models of compositionality based on vector addition and point wise-multiplication (and a weighted combination of both), evaluated on a sentence similarity task inspired by kintsch (2001)",[0],15,result,6,6.0,0.8571428571428571,190.0,0.9359605911330049,2.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,6 discussion,abstract
P08-1028,W11-0115,[73.0],"relaxing the assumption of symmetry in the case of the simple additive model produces a model which weighs the contribution of the two components differently: this allows additive models to become more syntax aware, since semantically important constituents can participate more actively in the composition.",[0],"the approach proposed by guevara (2010) is really only an extension of the full additive model of mitchell and lapata (2008), the only difference being that adopting a supervised learning methodology ensures that the weight parameters in the function are estimated optimally by linear regression",[0],16,result,3,3.0,0.42857142857142855,73.0,0.35960591133004927,21.0,0.6,0,0.0,0.0,0.0,0.0,0.0,3 composition models,abstract
P08-1028,W11-0115,[99.0],"in order to establish an independent measure of sentence similarity, we assembled a set of experimental materials and elicited similarity ratings from human subjects.",[0],"for example, mitchell and lapata (2008) use their models to approximate the human ratings in their sentence similarity dataset",[0],17,method,4,4.0,0.5714285714285714,99.0,0.4876847290640394,12.0,0.1518987341772152,0,0.0,0.0,0.0,0.0,0.0,4 evaluation set-up,abstract
P08-1028,W11-1310,[189.0],in this paper we presented a general framework for vector-based semantic composition.,[0],we use other wsm settings following mitchell and lapata (2008),[0],18,aim,6,6.0,0.8571428571428571,189.0,0.9310344827586207,1.0,0.07142857142857142,0,0.0,0.0,0.0,0.0,0.0,6 discussion,abstract
P08-1028,W11-1310,[191.0],"despite the popularity of additive models, our experimental results showed the superiority of models utilizing multiplicative combinations, at least for the sentence similarity task attempted here.",[0],mitchell and lapata (2008) observed that a simple multiplication function modelled compositionality better than addition,[0],19,result,6,6.0,0.8571428571428571,191.0,0.9408866995073891,3.0,0.21428571428571427,0,0.0,0.0,0.0,0.0,0.0,6 discussion,abstract
P08-1028,W11-1310,[190.0],we formulated composition as a function of two vectors and introduced several models based on addition and multiplication.,[0],"we use the compositionality functions, simple addition and simple multiplication to build compositional vectors vwr1+wr2 and vwr1 ?wr2. these are as described in (mitchell and lapata, 2008)",[0],20,result,6,6.0,0.8571428571428571,190.0,0.9359605911330049,2.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,6 discussion,abstract
P08-1028,D08-1094,[65],"so, if we assume that only the ith components of u and v contribute to the ith component of p, that these components are not dependent on i, and that the function is symmetric with regard to the interchange of u and v, we obtain a simpler instantiation of an additive model: analogously, under the same assumptions, we obtain the following simpler multiplicative model: only the ith components of u and v contribute to the ith component of p. another class of models can be derived by relaxing this constraint.",[0],"mitchell and lapata (2008) propose a framework to represent the meaning of the combination p+ a as a function f operating on four components: c= f (p, a, r, k) (3) r is the relation holding between p and a, and kadditional knowledge",[0],1,method,3,3.0,0.42857142857142855,65.0,0.32019704433497537,13.0,0.37142857142857144,0,0.0,0.0,0.0,0.0,0.0,3 composition models,abstract
P08-1028,D08-1094,[75],"an extreme form of this differential in the contribution of constituents is where one of the vectors, say u, contributes nothing at all to the combination: admittedly the model in (8) is impoverished and rather simplistic, however it can serve as a simple baseline against which to compare more sophisticated models.",[0],"in both experiments, we compare the svs model against the state-of-the art model by mitchell and lapata 2008 (henceforth m& amp; l; cf",[0],2,method,3,3.0,0.42857142857142855,75.0,0.3694581280788177,23.0,0.6571428571428571,0,0.0,0.0,0.0,0.0,0.0,3 composition models,abstract
P08-1028,P14-1060,[42],this poses problems for modeling linguistic data which is typically represented by vectors with non-random structure.,[0],"while works such asthe sdsm model suffer from the problem of sparsity in composing structures beyond bi grams and trigrams, methods such as mitchell and lapata (2008) and (socher et al, 2012) and grefenstetteand sadrzadeh (2011) are restricted by significant model biases in representing semantic com position by generic algebraic operations",[0],4,method,2,2.0,0.2857142857142857,42.0,0.20689655172413793,15.0,0.6,0,0.0,0.0,0.0,0.0,0.0,2 related work,abstract
P08-1028,P10-1097,[21],central in these models is the notion of compositionality — the meaning of complex expressions is determined by the meanings of their constituent expressions and the rules used to combine them.,[0],"mitchell and lapata (2008), henceforth m& amp; l, propose a general framework in which meaning representations for complex expressions are computed compositionally by combining the vector representations of the individual words of the complex expression",[0],6,method,1,1.0,0.14285714285714285,21.0,0.10344827586206896,17.0,0.7391304347826086,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P08-1028,P10-1097,[195],"the resulting vector is sparser but expresses more succinctly the meaning of the predicate-argument structure, and thus allows semantic similarity to be modelled more accurately.",[0],"interestingly, mitchell and lapata (2008) came to the same result in a different setting",[0],7,method,6,6.0,0.8571428571428571,195.0,0.9605911330049262,7.0,0.5,0,0.0,0.0,0.0,0.0,0.0,6 discussion,abstract
P08-1028,D11-1094,[25],we present a general framework for vector-based composition which allows us to consider different classes of models.,[0],"and mitchell and lapata (2008) propose a model for vector composition, focusing on the different functions that might be used to combine the constituent vectors",[0],8,method,1,1.0,0.14285714285714285,25.0,0.12315270935960591,21.0,0.9130434782608695,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P08-1028,W11-0131,[25],we present a general framework for vector-based composition which allows us to consider different classes of models.,[0],"mitchell and lapata (2008) provide a general framework for semantic vector composition: p= f (u, v, r, k) (1) 295 where u and v are the vectors to be composed, r is syntactic context, k is a semantic knowledge base, and p is a resulting composed vector (or tensor)",[0],9,method,1,1.0,0.14285714285714285,25.0,0.12315270935960591,21.0,0.9130434782608695,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P08-1028,W11-0131,[57],"let p denote the composition of two vectors u and v, representing a pair of constituents which stand in some syntactic relation r. let k stand for any additional knowledge or information which is needed to construct the semantics of their composition.",[0],"as mitchell and lapata (2008) did, let us temporarily suspend discussion on what semantics populate our vectors for now",[0],10,method,3,3.0,0.42857142857142855,57.0,0.28078817733990147,5.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,3 composition models,abstract
P08-1028,P13-2083,[51],"our work proposes a framework for vector composition which allows the derivation of different types of models and licenses two fundamental composition operations, multiplication and addition (and their combination).",[0],"mitchell and lapata (2008) propose a framework to define the composition c= f (a, b, r, k) where r is the relation between a and b, and k is the additional knowledge used to define composition",[0],11,method,2,2.0,0.2857142857142857,51.0,0.2512315270935961,24.0,0.96,0,0.0,0.0,0.0,0.0,0.0,2 related work,abstract
P08-1028,P13-2083,[190],we formulated composition as a function of two vectors and introduced several models based on addition and multiplication.,[0],"as our final set of baselines, we extend two simple techniques proposed by (mitchell and lapata, 2008) that use element-wise addition and multiplication operators to perform composition",[0],12,method,6,6.0,0.8571428571428571,190.0,0.9359605911330049,2.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,6 discussion,abstract
P08-1028,P10-1021,[29],"while neural networks can readily represent single distinct objects, in the case of multiple objects there are fundamental difficulties in keeping track of which features are bound to which objects.",[0],"althoughthis model has been shown to successfully simulate single and multiple-word priming (mcdonald and brew 2004), it failed to predict processing costs in the embra eye-tracking corpus (mcdonald and shillcock 2003) .in this work we model semantic constraint using the representational framework put forward in mitchell and lapata (2008)",[0],13,method,2,2.0,0.2857142857142857,29.0,0.14285714285714285,2.0,0.08,0,0.0,0.0,0.0,0.0,0.0,2 related work,abstract
P08-1028,P10-1021,[38],the projection is defined in terms of circular convolution a mathematical function that compresses the tensor product of two vectors.,[0],"assuming that h is a linear function of the cartesian product of u and v allows to specify additive models which are by far the most common method of vector combination in the literature: hi =ui+ vi (3) alternatively, we can assume that h is a linear function of the tensor product of u and v, and thus derive models based on multiplication: hi =ui? vi (4) mitchell and lapata (2008) show that several additive and multiplicative models can be formulated under this framework, including the well known tensor products (smolensky 1990) and circular convolution (plate 1995)",[0],14,method,2,2.0,0.2857142857142857,38.0,0.18719211822660098,11.0,0.44,0,0.0,0.0,0.0,0.0,0.0,2 related work,abstract
P08-1028,W11-0115,[51],"our work proposes a framework for vector composition which allows the derivation of different types of models and licenses two fundamental composition operations, multiplication and addition (and their combination).",[0],"mitchell and lapata (2008) introduce a whole family of models of compositionality based on vector addition and point wise-multiplication (and a weighted combination of both), evaluated on a sentence similarity task inspired by kintsch (2001)",[0],15,method,2,2.0,0.2857142857142857,51.0,0.2512315270935961,24.0,0.96,0,0.0,0.0,0.0,0.0,0.0,2 related work,abstract
P08-1028,W11-0115,[64],"now, if we assume that p lies in the same space as u and v, avoiding the issues of dimensionality associated with tensor products, and that f is a linear function, for simplicity, of the cartesian product of u and v, then we generate a class of additive models: where a and b are matrices which determine the contributions made by u and v to the product p. in contrast, if we assume that f is a linear function of the tensor product of u and v, then we obtain multiplicative models: where c is a tensor of rank 3, which projects the tensor product of u and v onto the space of p. further constraints can be introduced to reduce the free parameters in these models.",[0],"the approach proposed by guevara (2010) is really only an extension of the full additive model of mitchell and lapata (2008), the only difference being that adopting a supervised learning methodology ensures that the weight parameters in the function are estimated optimally by linear regression",[0],16,method,3,3.0,0.42857142857142855,64.0,0.31527093596059114,12.0,0.34285714285714286,0,0.0,0.0,0.0,0.0,0.0,3 composition models,abstract
P08-1028,W11-0115,[163],we expect better models to yield a pattern of similarity scores like those observed in the human ratings (see figure 2).,[0],"for example, mitchell and lapata (2008) use their models to approximate the human ratings in their sentence similarity dataset",[0],17,method,4,4.0,0.5714285714285714,163.0,0.8029556650246306,76.0,0.9620253164556962,0,0.0,0.0,0.0,0.0,0.0,4 evaluation set-up,abstract
P08-1028,W11-1310,[185],"the multiplicative model yields a better fit with the experimental data, ρ = 0.17.",[0],mitchell and lapata (2008) observed that a simple multiplication function modelled compositionality better than addition,[0],19,method,5,5.0,0.7142857142857143,185.0,0.9113300492610837,19.0,0.8636363636363636,0,0.0,0.0,0.0,0.0,0.0,5 results,abstract
P08-1028,W11-1310,[190],we formulated composition as a function of two vectors and introduced several models based on addition and multiplication.,[0],"we use the compositionality functions, simple addition and simple multiplication to build compositional vectors vwr1+wr2 and vwr1 ?wr2. these are as described in (mitchell and lapata, 2008)",[0],20,method,6,6.0,0.8571428571428571,190.0,0.9359605911330049,2.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,6 discussion,abstract
P08-1043,C10-1045,[94],our use of an unweighted lattice reflects our belief that all the segmentations of the given input sentence are a-priori equally likely; the only reason to prefer one segmentation over the another is due to the overall syntactic context which is modeled via the pcfg derivations.,[0],"finally, we note that simple weighting gives nearly a 2% f1 improvement, whereas goldberg and tsarfaty (2008) found that unweighted lattices were more effective for hebrew",[0],1,method,5,5.0,0.5555555555555556,94.0,0.47474747474747475,26.0,0.48148148148148145,0,0.0,0.0,0.0,0.0,0.0,5 a generative pcfg model,abstract
P08-1043,P11-1141,[4],"using a treebank grammar, a data-driven lexicon, and a linguistically motivated unknown-tokens handling technique our model outperforms previous pipelined, integrated or factorized systems for hebrew morphological and syntactic processing, yielding an error reduction of 12% over the best published results so far.",[0],goldberg and tsarfaty (2008) showed that a single model for morphological segmentation and syntactic parsing of hebrew yielded an error reduction of 12% over the best pipelined models,[0],2,method,0,0.0,0.0,4.0,0.020202020202020204,4.0,0.8,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
P08-1043,P10-1074,[19],here we push the single-framework conjecture across the board and present a single model that performs morphological segmentation and syntactic disambiguation in a fully generative framework.,[0],"zhang and clark (2008) built a perceptron-based joint segmenter and part-of-speech (pos) tagger for chinese, and toutanova and cherry (2009) learned a joint model of lemmatization and pos tagging which outperformed a pipelined model. adler and elhadad (2006) presented an hmmbased approach for unsupervised joint morphological segmentation and tagging of hebrew, and goldberg and tsarfaty (2008) developed a joint model of segmentation, tagging and parsing of he brew, based on lattice parsing",[0],3,method,1,1.0,0.1111111111111111,19.0,0.09595959595959595,15.0,0.8823529411764706,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P08-1043,P11-1089,[19],here we push the single-framework conjecture across the board and present a single model that performs morphological segmentation and syntactic disambiguation in a fully generative framework.,[0],goldberg and tsarfaty (2008) pro pose a generative joint model,[0],4,method,1,1.0,0.1111111111111111,19.0,0.09595959595959595,15.0,0.8823529411764706,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P08-1043,W10-1404,[4],"using a treebank grammar, a data-driven lexicon, and a linguistically motivated unknown-tokens handling technique our model outperforms previous pipelined, integrated or factorized systems for hebrew morphological and syntactic processing, yielding an error reduction of 12% over the best published results so far.",[0],goldberg and tsarfaty (2008) concluded that an integrated model of morphological disambiguation and syntactic parsing in hebrew treebank parsing improves the results of a pipelined approach,[0],5,method,0,0.0,0.0,4.0,0.020202020202020204,4.0,0.8,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
P08-1043,P11-2124,[19],here we push the single-framework conjecture across the board and present a single model that performs morphological segmentation and syntactic disambiguation in a fully generative framework.,[0],goldberg and tsarfaty (2008) demonstrated the effectiveness of lattice parsing for jointly performing segmentation and parsing of hebrewtext,[0],6,method,1,1.0,0.1111111111111111,19.0,0.09595959595959595,15.0,0.8823529411764706,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P08-1043,P11-2124,"[69, 70]","we represent all morphological analyses of a given utterance using a lattice structure.
each lattice arc corresponds to a segment and its corresponding pos tag, and a path through the lattice corresponds to a specific morphological segmentation of the utterance.",[0],"following (goldberg and tsarfaty, 2008) we deal with the ambiguous affixation patterns in hebrew by encoding the input sentence as a segmentation lattice",[0],7,method,5_5,5.0,0.5555555555555556,69.5,0.351010101010101,1.5,0.027777777777777776,0,0.0,0.0,0.0,0.0,0.0,"5 a generative pcfg model, 5 a generative pcfg model",abstract
P08-1043,P12-2002,[85],"the input the set of analyses for a token is thus represented as a lattice in which every arc corresponds to a specific lexeme l, as shown in figure 1.",[0],2the complete set of analyses for this word is provided in goldberg and tsarfaty (2008),[0],8,method,5,5.0,0.5555555555555556,85.0,0.4292929292929293,17.0,0.3148148148148148,0,0.0,0.0,0.0,0.0,0.0,5 a generative pcfg model,abstract
P08-1043,D12-1046,[19],here we push the single-framework conjecture across the board and present a single model that performs morphological segmentation and syntactic disambiguation in a fully generative framework.,[0],"a study that is closely related toours is (goldberg and tsarfaty, 2008), where a single generative model was proposed for joint morphological segmentation and syntactic parsing for hebrew",[0],9,method,1,1.0,0.1111111111111111,19.0,0.09595959595959595,15.0,0.8823529411764706,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P08-1043,D12-1133,[19],here we push the single-framework conjecture across the board and present a single model that performs morphological segmentation and syntactic disambiguation in a fully generative framework.,[0],"models that in addition incorporate morphological analysis and segmentation have been explored by tsarfaty (2006), cohen and smith (2007), and goldberg and tsarfaty (2008) with special reference to hebrew parsing",[0],10,method,1,1.0,0.1111111111111111,19.0,0.09595959595959595,15.0,0.8823529411764706,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P08-1043,E09-1038,[19],here we push the single-framework conjecture across the board and present a single model that performs morphological segmentation and syntactic disambiguation in a fully generative framework.,[0],"4), and in a more realistic one in which parsing and segmentation are handled jointly by the parser (goldberg and tsarfaty, 2008) (sec",[0],11,method,1,1.0,0.1111111111111111,19.0,0.09595959595959595,15.0,0.8823529411764706,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P08-1043,E09-1038,[21],"morphological segmentation decisions in our model are delegated to a lexeme-based pcfg and we show that using a simple treebank grammar, a data-driven lexicon, and a linguistically motivated unknown-tokens handling our model outperforms (tsarfaty, 2006) and (cohen and smith, 2007) on the joint task and achieves state-of-the-art results on a par with current respective standalone models.2",[0],"it is the same grammar as described in (goldberg and tsarfaty, 2008)",[0],12,method,1,1.0,0.1111111111111111,21.0,0.10606060606060606,17.0,1.0,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P08-1043,E09-1038,[94],our use of an unweighted lattice reflects our belief that all the segmentations of the given input sentence are a-priori equally likely; the only reason to prefer one segmentation over the another is due to the overall syntactic context which is modeled via the pcfg derivations.,[0],"several studies followed this line, (cohen and smith, 2007) the most recent of which is goldberg and tsarfaty (2008), who presented a model based on unweighted lattice parsing for performing the joint task",[0],14,method,5,5.0,0.5555555555555556,94.0,0.47474747474747475,26.0,0.48148148148148145,0,0.0,0.0,0.0,0.0,0.0,5 a generative pcfg model,abstract
P08-1043,E09-1038,"[133, 134]","morphological analyzer ideally, we would use an of-the-shelf morphological analyzer for mapping each input token to its possible analyses.
such resources exist for hebrew (itai et al., 2006), but unfortunately use a tagging scheme which is incompatible with the one of the hebrew treebank.s for this reason, we use a data-driven morphological analyzer derived from the training 	similar to (cohen and smith, 2007).",[0],goldberg and tsarfaty (2008) use a data-driven morphological analyzer derived from the tree bank,[0],15,method,6_6,6.0,0.6666666666666666,133.5,0.6742424242424242,11.5,0.2875,0,0.0,0.0,0.0,0.0,0.0,"6 experimental setup, 6 experimental setup",abstract
P08-1043,E09-1038,[85],"the input the set of analyses for a token is thus represented as a lattice in which every arc corresponds to a specific lexeme l, as shown in figure 1.",[0],the model of goldberg and tsarfaty (2008) uses a morphological analyzer to constructs a lattice for each input token,[0],16,method,5,5.0,0.5555555555555556,85.0,0.4292929292929293,17.0,0.3148148148148148,0,0.0,0.0,0.0,0.0,0.0,5 a generative pcfg model,abstract
P08-1043,E09-1038,[155],evaluation we use 8 different measures to evaluate the performance of our system on the joint disambiguation task.,[0],"instead, we use the evaluation measure of (tsarfaty, 2006), also used in (goldberg and tsarfaty, 2008), which is an adaptation of parse val to use characters instead of space-delimited tokens as its basic units",[0],17,method,6,6.0,0.6666666666666666,155.0,0.7828282828282829,33.0,0.825,0,0.0,0.0,0.0,0.0,0.0,6 experimental setup,abstract
P08-1043,C10-1045,[94.0],our use of an unweighted lattice reflects our belief that all the segmentations of the given input sentence are a-priori equally likely; the only reason to prefer one segmentation over the another is due to the overall syntactic context which is modeled via the pcfg derivations.,[0],"finally, we note that simple weighting gives nearly a 2% f1 improvement, whereas goldberg and tsarfaty (2008) found that unweighted lattices were more effective for hebrew",[0],1,aim,5,5.0,0.5555555555555556,94.0,0.47474747474747475,26.0,0.48148148148148145,0,0.0,0.0,0.0,0.0,0.0,5 a generative pcfg model,abstract
P08-1043,P11-1141,[4.0],"using a treebank grammar, a data-driven lexicon, and a linguistically motivated unknown-tokens handling technique our model outperforms previous pipelined, integrated or factorized systems for hebrew morphological and syntactic processing, yielding an error reduction of 12% over the best published results so far.",[0],goldberg and tsarfaty (2008) showed that a single model for morphological segmentation and syntactic parsing of hebrew yielded an error reduction of 12% over the best pipelined models,[0],2,result,0,0.0,0.0,4.0,0.020202020202020204,4.0,0.8,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
P08-1043,P10-1074,[94.0],our use of an unweighted lattice reflects our belief that all the segmentations of the given input sentence are a-priori equally likely; the only reason to prefer one segmentation over the another is due to the overall syntactic context which is modeled via the pcfg derivations.,[0],"zhang and clark (2008) built a perceptron-based joint segmenter and part-of-speech (pos) tagger for chinese, and toutanova and cherry (2009) learned a joint model of lemmatization and pos tagging which outperformed a pipelined model. adler and elhadad (2006) presented an hmmbased approach for unsupervised joint morphological segmentation and tagging of hebrew, and goldberg and tsarfaty (2008) developed a joint model of segmentation, tagging and parsing of he brew, based on lattice parsing",[0],3,method,5,5.0,0.5555555555555556,94.0,0.47474747474747475,26.0,0.48148148148148145,0,0.0,0.0,0.0,0.0,0.0,5 a generative pcfg model,abstract
P08-1043,P11-1089,[19.0],here we push the single-framework conjecture across the board and present a single model that performs morphological segmentation and syntactic disambiguation in a fully generative framework.,[0],goldberg and tsarfaty (2008) pro pose a generative joint model,[0],4,method,1,1.0,0.1111111111111111,19.0,0.09595959595959595,15.0,0.8823529411764706,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P08-1043,W10-1404,[19.0],here we push the single-framework conjecture across the board and present a single model that performs morphological segmentation and syntactic disambiguation in a fully generative framework.,[0],goldberg and tsarfaty (2008) concluded that an integrated model of morphological disambiguation and syntactic parsing in hebrew treebank parsing improves the results of a pipelined approach,[0],5,method,1,1.0,0.1111111111111111,19.0,0.09595959595959595,15.0,0.8823529411764706,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P08-1043,P11-2124,[4.0],"using a treebank grammar, a data-driven lexicon, and a linguistically motivated unknown-tokens handling technique our model outperforms previous pipelined, integrated or factorized systems for hebrew morphological and syntactic processing, yielding an error reduction of 12% over the best published results so far.",[0],goldberg and tsarfaty (2008) demonstrated the effectiveness of lattice parsing for jointly performing segmentation and parsing of hebrewtext,[0],6,result,0,0.0,0.0,4.0,0.020202020202020204,4.0,0.8,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
P08-1043,P11-2124,[105.0],"3an english sentence with ambiguous pos assignment can be trivially represented as a lattice similar to our own, where every pair of consecutive nodes correspond to a word, and every possible pos assignment for this word is a connecting arc.",[0],"following (goldberg and tsarfaty, 2008) we deal with the ambiguous affixation patterns in hebrew by encoding the input sentence as a segmentation lattice",[0],7,method,5,5.0,0.5555555555555556,105.0,0.5303030303030303,37.0,0.6851851851851852,0,0.0,0.0,0.0,0.0,0.0,5 a generative pcfg model,abstract
P08-1043,D12-1046,[19.0],here we push the single-framework conjecture across the board and present a single model that performs morphological segmentation and syntactic disambiguation in a fully generative framework.,[0],"a study that is closely related toours is (goldberg and tsarfaty, 2008), where a single generative model was proposed for joint morphological segmentation and syntactic parsing for hebrew",[0],9,method,1,1.0,0.1111111111111111,19.0,0.09595959595959595,15.0,0.8823529411764706,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P08-1043,D12-1133,[19.0],here we push the single-framework conjecture across the board and present a single model that performs morphological segmentation and syntactic disambiguation in a fully generative framework.,[0],"models that in addition incorporate morphological analysis and segmentation have been explored by tsarfaty (2006), cohen and smith (2007), and goldberg and tsarfaty (2008) with special reference to hebrew parsing",[0],10,method,1,1.0,0.1111111111111111,19.0,0.09595959595959595,15.0,0.8823529411764706,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P08-1043,E09-1038,[163.0],"the accuracy results for segmentation, tagging and parsing using our different models and our standard data split are summarized in table 1.",[0],"4), and in a more realistic one in which parsing and segmentation are handled jointly by the parser (goldberg and tsarfaty, 2008) (sec",[0],11,result,7,7.0,0.7777777777777778,163.0,0.8232323232323232,1.0,0.041666666666666664,0,0.0,0.0,0.0,0.0,0.0,7 results and analysis,abstract
P08-1043,E09-1038,[100.0],"this means that the rules in our grammar are of two kinds: (a) syntactic rules relating nonterminals to a sequence of non-terminals and/or pos tags, and (b) lexical rules relating pos tags to lattice arcs (lexemes).",[0],"it is the same grammar as described in (goldberg and tsarfaty, 2008)",[0],12,method,5,5.0,0.5555555555555556,100.0,0.5050505050505051,32.0,0.5925925925925926,0,0.0,0.0,0.0,0.0,0.0,5 a generative pcfg model,abstract
P08-1043,E09-1038,[94.0],our use of an unweighted lattice reflects our belief that all the segmentations of the given input sentence are a-priori equally likely; the only reason to prefer one segmentation over the another is due to the overall syntactic context which is modeled via the pcfg derivations.,[0],"several studies followed this line, (cohen and smith, 2007) the most recent of which is goldberg and tsarfaty (2008), who presented a model based on unweighted lattice parsing for performing the joint task",[0],14,result,5,5.0,0.5555555555555556,94.0,0.47474747474747475,26.0,0.48148148148148145,0,0.0,0.0,0.0,0.0,0.0,5 a generative pcfg model,abstract
P08-1043,E09-1038,[188.0],the overall performance of our joint framework demonstrates that a probability distribution obtained over mere syntactic contexts using a treebank grammar and a data-driven lexicon outperforms upper bounds proposed by previous joint disambiguation systems and achieves segmentation and parsing results on a par with state-of-the-art standalone applications results.,[0],goldberg and tsarfaty (2008) use a data-driven morphological analyzer derived from the tree bank,[0],15,result,8,8.0,0.8888888888888888,188.0,0.9494949494949495,2.0,0.18181818181818182,0,0.0,0.0,0.0,0.0,0.0,8 discussion and conclusion,abstract
P08-1043,E09-1038,[86.0],a morphological analyzer m : w—* l is a function mapping sentences in hebrew (w e w) to their corresponding lattices (m(w) = l e l).,[0],the model of goldberg and tsarfaty (2008) uses a morphological analyzer to constructs a lattice for each input token,[0],16,result,5,5.0,0.5555555555555556,86.0,0.43434343434343436,18.0,0.3333333333333333,0,0.0,0.0,0.0,0.0,0.0,5 a generative pcfg model,abstract
P08-1043,E09-1038,[97.0],"thus our proposed model is a proper model assigning probability mass to all (7r, l) pairs, where 7r is a parse tree and l is the one and only lattice that a sequence of characters (and spaces) w over our alpha-beth gives rise to.",[0],"instead, we use the evaluation measure of (tsarfaty, 2006), also used in (goldberg and tsarfaty, 2008), which is an adaptation of parse val to use characters instead of space-delimited tokens as its basic units",[0],17,method,5,5.0,0.5555555555555556,97.0,0.4898989898989899,29.0,0.5370370370370371,0,0.0,0.0,0.0,0.0,0.0,5 a generative pcfg model,abstract
P08-1043,C10-1045,[156],"to evaluate the performance on the segmentation task, we report seg, the standard harmonic means for segmentation precision and recall f1 (as defined in bar-haim et al. (2005); tsarfaty (2006)) as well as the segmentation accuracy segtok measure indicating the percentage of input tokens assigned the correct exact segmentation (as reported by cohen and smith (2007)).",[0],"finally, we note that simple weighting gives nearly a 2% f1 improvement, whereas goldberg and tsarfaty (2008) found that unweighted lattices were more effective for hebrew",[0],1,method,6,6.0,0.6666666666666666,156.0,0.7878787878787878,34.0,0.85,0,0.0,0.0,0.0,0.0,0.0,6 experimental setup,abstract
P08-1043,P11-1141,[4],"using a treebank grammar, a data-driven lexicon, and a linguistically motivated unknown-tokens handling technique our model outperforms previous pipelined, integrated or factorized systems for hebrew morphological and syntactic processing, yielding an error reduction of 12% over the best published results so far.",[0],goldberg and tsarfaty (2008) showed that a single model for morphological segmentation and syntactic parsing of hebrew yielded an error reduction of 12% over the best pipelined models,[0],2,method,0,0.0,0.0,4.0,0.020202020202020204,4.0,0.8,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
P08-1043,P10-1074,[70],"each lattice arc corresponds to a segment and its corresponding pos tag, and a path through the lattice corresponds to a specific morphological segmentation of the utterance.",[0],"zhang and clark (2008) built a perceptron-based joint segmenter and part-of-speech (pos) tagger for chinese, and toutanova and cherry (2009) learned a joint model of lemmatization and pos tagging which outperformed a pipelined model. adler and elhadad (2006) presented an hmmbased approach for unsupervised joint morphological segmentation and tagging of hebrew, and goldberg and tsarfaty (2008) developed a joint model of segmentation, tagging and parsing of he brew, based on lattice parsing",[0],3,method,5,5.0,0.5555555555555556,70.0,0.35353535353535354,2.0,0.037037037037037035,0,0.0,0.0,0.0,0.0,0.0,5 a generative pcfg model,abstract
P08-1043,P11-1089,[3],here we propose a single joint model for performing both morphological segmentation and syntactic disambiguation which bypasses the associated circularity.,[0],goldberg and tsarfaty (2008) pro pose a generative joint model,[0],4,method,0,0.0,0.0,3.0,0.015151515151515152,3.0,0.6,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
P08-1043,W10-1404,[51],"tsarfaty (2006) used a morphological analyzer (segal, 2000), a pos tagger (bar-haim et al., 2005), and a general purpose parser (schmid, 2000) in an integrated framework in which morphological and syntactic components interact to share information, leading to improved performance on the joint task.",[0],goldberg and tsarfaty (2008) concluded that an integrated model of morphological disambiguation and syntactic parsing in hebrew treebank parsing improves the results of a pipelined approach,[0],5,method,3,3.0,0.3333333333333333,51.0,0.25757575757575757,9.0,0.8181818181818182,0,0.0,0.0,0.0,0.0,0.0,3 previous work on hebrew processing,abstract
P08-1043,P11-2124,[107],"firstly, hebrew unknown tokens are doubly unknown: each unknown token may correspond to several segmentation possibilities, and each segment in such sequences may be able to admit multiple pos tags.",[0],goldberg and tsarfaty (2008) demonstrated the effectiveness of lattice parsing for jointly performing segmentation and parsing of hebrewtext,[0],6,method,5,5.0,0.5555555555555556,107.0,0.5404040404040404,39.0,0.7222222222222222,0,0.0,0.0,0.0,0.0,0.0,5 a generative pcfg model,abstract
P08-1043,P11-2124,[14],"the input for the segmentation task is however highly ambiguous for semitic languages, and surface forms (tokens) may admit multiple possible analyses as in (barhaim et al., 2007; adler and elhadad, 2006).",[0],"following (goldberg and tsarfaty, 2008) we deal with the ambiguous affixation patterns in hebrew by encoding the input sentence as a segmentation lattice",[0],7,method,1,1.0,0.1111111111111111,14.0,0.0707070707070707,10.0,0.5882352941176471,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P08-1043,P12-2002,[33],"the current work treats both segmental and super-segmental phenomena, yet we note that there may be more adequate ways to treat supersegmental phenomena assuming word-based morphology as we explore in (tsarfaty and goldberg, 2008).",[0],2the complete set of analyses for this word is provided in goldberg and tsarfaty (2008),[0],8,method,2,2.0,0.2222222222222222,33.0,0.16666666666666666,12.0,0.5714285714285714,0,0.0,0.0,0.0,0.0,0.0,2 modern hebrew structure,abstract
P08-1043,D12-1046,[53],"both (tsarfaty, 2006; cohen and smith, 2007) have shown that a single integrated framework outperforms a completely streamlined implementation, yet neither has shown a single generative model which handles both tasks.",[0],"a study that is closely related toours is (goldberg and tsarfaty, 2008), where a single generative model was proposed for joint morphological segmentation and syntactic parsing for hebrew",[0],9,method,3,3.0,0.3333333333333333,53.0,0.2676767676767677,11.0,1.0,0,0.0,0.0,0.0,0.0,0.0,3 previous work on hebrew processing,abstract
P08-1043,D12-1133,[48],tsarfaty (2006) was the first to demonstrate that fully automatic hebrew parsing is feasible using the newly available 5000 sentences treebank.,[0],"models that in addition incorporate morphological analysis and segmentation have been explored by tsarfaty (2006), cohen and smith (2007), and goldberg and tsarfaty (2008) with special reference to hebrew parsing",[0],10,method,3,3.0,0.3333333333333333,48.0,0.24242424242424243,6.0,0.5454545454545454,0,0.0,0.0,0.0,0.0,0.0,3 previous work on hebrew processing,abstract
P08-1043,E09-1038,[141],"this analyzer setting is similar to that of (cohen and smith, 2007), and models using it are denoted nohsp, parser and grammar we used bitpar (schmid, 2004), an efficient general purpose parser,10 together with various treebank grammars to parse the input sentences and propose compatible morphological segmentation and syntactic analysis.",[0],"4), and in a more realistic one in which parsing and segmentation are handled jointly by the parser (goldberg and tsarfaty, 2008) (sec",[0],11,method,6,6.0,0.6666666666666666,141.0,0.7121212121212122,19.0,0.475,0,0.0,0.0,0.0,0.0,0.0,6 experimental setup,abstract
P08-1043,E09-1038,[188],the overall performance of our joint framework demonstrates that a probability distribution obtained over mere syntactic contexts using a treebank grammar and a data-driven lexicon outperforms upper bounds proposed by previous joint disambiguation systems and achieves segmentation and parsing results on a par with state-of-the-art standalone applications results.,[0],"it is the same grammar as described in (goldberg and tsarfaty, 2008)",[0],12,method,8,8.0,0.8888888888888888,188.0,0.9494949494949495,2.0,0.18181818181818182,0,0.0,0.0,0.0,0.0,0.0,8 discussion and conclusion,abstract
P08-1043,E09-1038,[94],our use of an unweighted lattice reflects our belief that all the segmentations of the given input sentence are a-priori equally likely; the only reason to prefer one segmentation over the another is due to the overall syntactic context which is modeled via the pcfg derivations.,[0],"several studies followed this line, (cohen and smith, 2007) the most recent of which is goldberg and tsarfaty (2008), who presented a model based on unweighted lattice parsing for performing the joint task",[0],13,method,5,5.0,0.5555555555555556,94.0,0.47474747474747475,26.0,0.48148148148148145,0,0.0,0.0,0.0,0.0,0.0,5 a generative pcfg model,abstract
P08-1043,E09-1038,[134],"such resources exist for hebrew (itai et al., 2006), but unfortunately use a tagging scheme which is incompatible with the one of the hebrew treebank.s for this reason, we use a data-driven morphological analyzer derived from the training data similar to (cohen and smith, 2007).",[0],goldberg and tsarfaty (2008) use a data-driven morphological analyzer derived from the tree bank,[0],14,method,6,6.0,0.6666666666666666,134.0,0.6767676767676768,12.0,0.3,0,0.0,0.0,0.0,0.0,0.0,6 experimental setup,abstract
P08-1043,E09-1038,[156],"to evaluate the performance on the segmentation task, we report seg, the standard harmonic means for segmentation precision and recall f1 (as defined in bar-haim et al. (2005); tsarfaty (2006)) as well as the segmentation accuracy segtok measure indicating the percentage of input tokens assigned the correct exact segmentation (as reported by cohen and smith (2007)).",[0],the model of goldberg and tsarfaty (2008) uses a morphological analyzer to constructs a lattice for each input token,[0],15,method,6,6.0,0.6666666666666666,156.0,0.7878787878787878,34.0,0.85,0,0.0,0.0,0.0,0.0,0.0,6 experimental setup,abstract
P08-1043,E09-1038,[5],"current state-of-the-art broad-coverage parsers assume a direct correspondence between the lexical items ingrained in the proposed syntactic analyses (the yields of syntactic parse-trees) and the spacedelimited tokens (henceforth, ‘tokens’) that constitute the unanalyzed surface forms (utterances).",[0],"instead, we use the evaluation measure of (tsarfaty, 2006), also used in (goldberg and tsarfaty, 2008), which is an adaptation of parse val to use characters instead of space-delimited tokens as its basic units",[0],16,method,1,1.0,0.1111111111111111,5.0,0.025252525252525252,1.0,0.058823529411764705,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P08-1102,C08-1049,[130],we proposed a cascaded linear model for chinese joint s&t.,[0],"following jiang et al (2008), we describe segmentation and joint s& amp; t as below: for a given chinese sentence appearing as a character sequence: c 1: n= c 1 c 2.",[0],1,method,6,6.0,0.75,130.0,0.9154929577464789,1.0,0.125,0,0.0,0.0,0.0,0.0,0.0,7 conclusions,abstract
P08-1102,C08-1049,[42],"as predications generated from such templates depend on the current character, we name these templates lexical-target.",[0],plates called lexical-target in the column below areintroduced by jiang et al (2008),[0],3,method,2,2.0,0.25,42.0,0.29577464788732394,14.0,0.6666666666666666,0,0.0,0.0,0.0,0.0,0.0,3 the perceptron,abstract
P08-1102,P12-1110,[25],"according to ng and low (2004), the segmentation task can be transformed to a tagging problem by assigning each character a boundary tag of the following four types: we can extract segmentation result by splitting the labelled result into subsequences of pattern s or bm*e which denote single-character word and multicharacter word respectively.",[0],"for ctb-5, we refer to the split by duan et al (2007) as ctb-5d, and to the split by jiang et al (2008) as ctb-5j",[0],4,method,1,1.0,0.125,25.0,0.176056338028169,21.0,0.875,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P08-1102,D12-1126,[130],we proposed a cascaded linear model for chinese joint s&t.,[0],jiang et al (2008) proposes a cascaded linear model for joint chinese word segmentation and pos tagging,[0],5,method,6,6.0,0.75,130.0,0.9154929577464789,1.0,0.125,0,0.0,0.0,0.0,0.0,0.0,7 conclusions,abstract
P08-1102,C10-1135,[34],the feature templates we adopted are selected from those of ng and low (2004).,[0],"we use the feature templates the same as jiang et al, (2008) to extract features form e model",[0],6,method,2,2.0,0.25,34.0,0.23943661971830985,6.0,0.2857142857142857,0,0.0,0.0,0.0,0.0,0.0,3 the perceptron,abstract
P08-1102,P12-1025,[12],"besides the usual character-based features, additional features dependent on pos’s or words can also be employed to improve the performance.",[0],"approach, where basic processing units are characters which compose words (jiangetal., 2008a)",[0],8,method,1,1.0,0.125,12.0,0.08450704225352113,8.0,0.3333333333333333,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P08-1102,C10-2096,[130],we proposed a cascaded linear model for chinese joint s&t.,[0],"6.1.1 baseline forest-based system we first segment the chinese sentences into the1-best segmentations using a state-of-the-art system (jiang et al, 2008a), since it is not necessary for a conventional parser to take as input the pos tagging results",[0],10,method,6,6.0,0.75,130.0,0.9154929577464789,1.0,0.125,0,0.0,0.0,0.0,0.0,0.0,7 conclusions,abstract
P08-1102,C10-2096,[130],we proposed a cascaded linear model for chinese joint s&t.,[0],"6.1.2 lattice-forest systemwe first segment and pos tag the chinese sentences into word lattices using the same system (jiang et al, 2008a), and prune each lattice into a reasonable size using the marginal probability-based pruning algorithm",[0],11,method,6,6.0,0.75,130.0,0.9154929577464789,1.0,0.125,0,0.0,0.0,0.0,0.0,0.0,7 conclusions,abstract
P08-1102,C10-1132,[121],"among other features, the 4-gram pos lm plays the most important role, removing this feature causes f-measure decrement of 0.33 points on segmentation and 0.71 points on joint s&t.",[0],"however, when we repeat the work of (jiang et al, 2008), which reports to achieve the state-of-art performance in the data-sets that we adopt, it has been found that some features (e.g., c0) are unnoticeably trained several times in their model (which are implicitly generated from different feature templates used in the paper)",[0],12,method,5,5.0,0.625,121.0,0.852112676056338,32.0,0.8,0,0.0,0.0,0.0,0.0,0.0,6 experiments,abstract
P08-1102,C10-1132,[37],c represents a chinese character while the subscript of c indicates its position in the sentence relative to the current character (it has the subscript 0).,[0],"unicode/cp936 1.1m/55k 104k/13k 0.035 table 3: corpus statistics for the second sighan bakeoff appears twice, which is generated from two different templates cn (with n=0, generates c0) and [c0cn] (used in (jiang et al, 2008), with n=0, generates [c0c0])",[0],13,method,2,2.0,0.25,37.0,0.2605633802816901,9.0,0.42857142857142855,0,0.0,0.0,0.0,0.0,0.0,3 the perceptron,abstract
P08-1102,C10-1132,[73],"for instance, if the word w appears n times in training corpus and is labelled as pos t for n times, the probability pr(t|w) can be estimated by the formula below: the probability pr(w|t) could be estimated through the same approach.",[0],"as all the features adopted in (jiang et al, 2008) possess binary values, if a binary feature is repeated n times, then it should behave like a real-valued feature with its value to be? n?, at least in principle",[0],14,method,3,3.0,0.375,73.0,0.5140845070422535,24.0,0.9230769230769231,0,0.0,0.0,0.0,0.0,0.0,4 cascaded linear model,abstract
P08-1102,C10-1132,[46],"following collins, we use a function gen(x) generating all candidate results of an input x , a representation 4) mapping each training example (x, y) ∈ x × y to a feature vector 4)(x, y) ∈ rd, and a parameter vector α� ∈ rd corresponding to the feature vector. d means the dimension of the vector space, it equals to the amount of features in the model.",[0],"inspired by (jiang et al, 2008), we set the real d although table 5 has shown that the proposed all the value of c0 to be 2.0, the value of c-1c0anc0c1 to be 3.0, and the values of all other features to be 1.0 for the character-based discriminative-plus model",[0],15,method,2,2.0,0.25,46.0,0.323943661971831,18.0,0.8571428571428571,0,0.0,0.0,0.0,0.0,0.0,3 the perceptron,abstract
P08-1102,C10-1132,[12],"besides the usual character-based features, additional features dependent on pos’s or words can also be employed to improve the performance.",[0],"last, (jiang et al, 2008) 5 adds repeated features implicitly based on (ng and low, 2004)",[0],17,method,1,1.0,0.125,12.0,0.08450704225352113,8.0,0.3333333333333333,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P08-1102,D12-1046,[130],we proposed a cascaded linear model for chinese joint s&t.,[0],"previous joint models mainly focus on word segmentation and pos tagging task, such as the virtual nodes method (qian et al2010), cascaded linear model (jiang et al2008a) ,perceptron (zhang and clark, 2008), sub-word based stacked learning (sun, 2011), re ranking (jiang et al2008b)",[0],20,method,6,6.0,0.75,130.0,0.9154929577464789,1.0,0.125,0,0.0,0.0,0.0,0.0,0.0,7 conclusions,abstract
P08-1102,C08-1049,[32],"we trained a character-based perceptron for chinese joint s&t, and found that the perceptron itself could achieve considerably high accuracy on segmentation and joint s&t.",[0],"following jiang et al (2008), we describe segmentation and joint s& amp; t as below: for a given chinese sentence appearing as a character sequence: c 1: n= c 1 c 2.",[0],1,method,2,2.0,0.25,32.0,0.22535211267605634,4.0,0.19047619047619047,0,0.0,0.0,0.0,0.0,0.0,3 the perceptron,abstract
P08-1102,C08-1049,[32],"we trained a character-based perceptron for chinese joint s&t, and found that the perceptron itself could achieve considerably high accuracy on segmentation and joint s&t.",[0],"as described in ng and low (2004 )andjiang et al (2008), we use s indicating a single character word, while b, m and e indicating the be gin, middle and end of a word respectively",[0],2,method,2,2.0,0.25,32.0,0.22535211267605634,4.0,0.19047619047619047,0,0.0,0.0,0.0,0.0,0.0,3 the perceptron,abstract
P08-1102,C08-1049,[38],templates immediately borrowed from ng and low (2004) are listed in the upper column named non-lexical-target.,[0],plates called lexical-target in the column below areintroduced by jiang et al (2008),[0],3,method,2,2.0,0.25,38.0,0.2676056338028169,10.0,0.47619047619047616,0,0.0,0.0,0.0,0.0,0.0,3 the perceptron,abstract
P08-1102,D12-1126,[92],the second was conducted on the penn chinese treebank 5.0 (ctb5.0) to test the performance of the cascaded model on segmentation and joint s&t.,[0],jiang et al (2008) proposes a cascaded linear model for joint chinese word segmentation and pos tagging,[0],5,method,5,5.0,0.625,92.0,0.647887323943662,3.0,0.075,0,0.0,0.0,0.0,0.0,0.0,6 experiments,abstract
P08-1102,C10-1135,[36],all feature templates and their instances are shown in table 1.,[0],"we use the feature templates the same as jiang et al, (2008) to extract features form e model",[0],6,method,2,2.0,0.25,36.0,0.2535211267605634,8.0,0.38095238095238093,0,0.0,0.0,0.0,0.0,0.0,3 the perceptron,abstract
P08-1102,P12-1025,[32],"we trained a character-based perceptron for chinese joint s&t, and found that the perceptron itself could achieve considerably high accuracy on segmentation and joint s&t.",[0],"approach, where basic processing units are characters which compose words (jiangetal., 2008a)",[0],8,method,2,2.0,0.25,32.0,0.22535211267605634,4.0,0.19047619047619047,0,0.0,0.0,0.0,0.0,0.0,3 the perceptron,abstract
P08-1102,C10-2096,[92],the second was conducted on the penn chinese treebank 5.0 (ctb5.0) to test the performance of the cascaded model on segmentation and joint s&t.,[0],"6.1.1 baseline forest-based system we first segment the chinese sentences into the1-best segmentations using a state-of-the-art system (jiang et al, 2008a), since it is not necessary for a conventional parser to take as input the pos tagging results",[0],10,method,5,5.0,0.625,92.0,0.647887323943662,3.0,0.075,0,0.0,0.0,0.0,0.0,0.0,6 experiments,abstract
P08-1102,C10-2096,[92],the second was conducted on the penn chinese treebank 5.0 (ctb5.0) to test the performance of the cascaded model on segmentation and joint s&t.,[0],"6.1.2 lattice-forest systemwe first segment and pos tag the chinese sentences into word lattices using the same system (jiang et al, 2008a), and prune each lattice into a reasonable size using the marginal probability-based pruning algorithm",[0],11,method,5,5.0,0.625,92.0,0.647887323943662,3.0,0.075,0,0.0,0.0,0.0,0.0,0.0,6 experiments,abstract
P08-1102,C10-1132,[97],figure 3 shows their learning curves depicting the f-measure on the development set after 1 to 10 training iterations.,[0],"however, when we repeat the work of (jiang et al, 2008), which reports to achieve the state-of-art performance in the data-sets that we adopt, it has been found that some features (e.g., c0) are unnoticeably trained several times in their model (which are implicitly generated from different feature templates used in the paper)",[0],12,result,5,5.0,0.625,97.0,0.6830985915492958,8.0,0.2,0,0.0,0.0,0.0,0.0,0.0,6 experiments,abstract
P08-1102,C10-1132,[91],"the first was conducted to test the performance of the perceptron on segmentation on the corpus from sighan bakeoff 2, including the academia sinica corpus (as), the hong kong city university corpus (cityu), the peking university corpus (pku) and the microsoft research corpus (msr).",[0],"unicode/cp936 1.1m/55k 104k/13k 0.035 table 3: corpus statistics for the second sighan bakeoff appears twice, which is generated from two different templates cn (with n=0, generates c0) and [c0cn] (used in (jiang et al, 2008), with n=0, generates [c0c0])",[0],13,aim,5,5.0,0.625,91.0,0.6408450704225352,2.0,0.05,0,0.0,0.0,0.0,0.0,0.0,6 experiments,abstract
P08-1102,C10-1132,[16],"shown in figure 1, the cascaded model has a two-layer architecture, with a characterbased perceptron as the core combined with other real-valued features such as language models.",[0],"as all the features adopted in (jiang et al, 2008) possess binary values, if a binary feature is repeated n times, then it should behave like a real-valued feature with its value to be? n?, at least in principle",[0],14,method,1,1.0,0.125,16.0,0.11267605633802817,12.0,0.5,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P08-1102,C10-1132,[34],the feature templates we adopted are selected from those of ng and low (2004).,[0],"last, (jiang et al, 2008) 5 adds repeated features implicitly based on (ng and low, 2004)",[0],17,method,2,2.0,0.25,34.0,0.23943661971830985,6.0,0.2857142857142857,0,0.0,0.0,0.0,0.0,0.0,3 the perceptron,abstract
P08-1102,D12-1046,[92],the second was conducted on the penn chinese treebank 5.0 (ctb5.0) to test the performance of the cascaded model on segmentation and joint s&t.,[0],"previous joint models mainly focus on word segmentation and pos tagging task, such as the virtual nodes method (qian et al2010), cascaded linear model (jiang et al2008a) ,perceptron (zhang and clark, 2008), sub-word based stacked learning (sun, 2011), re ranking (jiang et al2008b)",[0],20,method,5,5.0,0.625,92.0,0.647887323943662,3.0,0.075,0,0.0,0.0,0.0,0.0,0.0,6 experiments,abstract
P08-1102,C08-1049,[21],experiments show that our cascaded model can utilize different knowledge sources effectively and obtain accuracy improvements on both segmentation and joint s&t.,[0],"following jiang et al (2008), we describe segmentation and joint s& amp; t as below: for a given chinese sentence appearing as a character sequence: c 1: n= c 1 c 2.",[0],1,method,1,1.0,0.125,21.0,0.14788732394366197,17.0,0.7083333333333334,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P08-1102,C08-1049,[28],"a subsequence of boundary-pos labelling result indicates a word with pos t only if the boundary tag sequence composed of its boundary part conforms to s or bm*e style, and all pos tags in its pos part equal to t. for example, a tag sequence b nn m nn e nn represents a threecharacter word with pos tag nn.",[0],"as described in ng and low (2004 )andjiang et al (2008), we use s indicating a single character word, while b, m and e indicating the be gin, middle and end of a word respectively",[0],2,method,1,1.0,0.125,28.0,0.19718309859154928,24.0,1.0,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P08-1102,C08-1049,[43],note that the templates of ng and low (2004) have already contained some lexical-target ones.,[0],plates called lexical-target in the column below areintroduced by jiang et al (2008),[0],3,method,2,2.0,0.25,43.0,0.3028169014084507,15.0,0.7142857142857143,0,0.0,0.0,0.0,0.0,0.0,3 the perceptron,abstract
P08-1102,P12-1110,[92],the second was conducted on the penn chinese treebank 5.0 (ctb5.0) to test the performance of the cascaded model on segmentation and joint s&t.,[0],"for ctb-5, we refer to the split by duan et al (2007) as ctb-5d, and to the split by jiang et al (2008) as ctb-5j",[0],4,method,5,5.0,0.625,92.0,0.647887323943662,3.0,0.075,0,0.0,0.0,0.0,0.0,0.0,6 experiments,abstract
P08-1102,D12-1126,[9],"to segment and tag a character sequence, there are two strategies to choose: performing pos tagging following segmentation; or joint segmentation and pos tagging (joint s&t).",[0],jiang et al (2008) proposes a cascaded linear model for joint chinese word segmentation and pos tagging,[0],5,method,1,1.0,0.125,9.0,0.06338028169014084,5.0,0.20833333333333334,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P08-1102,C10-1135,"[33, 34]","in following subsections, we describe the feature templates and the perceptron training algorithm.
the feature templates we adopted are selected from those of ng and low (2004).",[0],"we use the feature templates the same as jiang et al, (2008) to extract features form e model",[0],6,method,2_2,2.0,0.25,33.5,0.23591549295774647,5.5,0.26190476190476186,0,0.0,0.0,0.0,0.0,0.0,"3 the perceptron, 3 the perceptron",abstract
P08-1102,P12-1025,[12],"besides the usual character-based features, additional features dependent on pos’s or words can also be employed to improve the performance.",[0],"approach, where basic processing units are characters which compose words (jiangetal., 2008a)",[0],8,method,1,1.0,0.125,12.0,0.08450704225352113,8.0,0.3333333333333333,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P08-1102,C10-2096,[64],"in our experiments we trained a 3-gram word language model measuring the fluency of the segmentation result, a 4-gram pos language model functioning as the product of statetransition probabilities in hmm, and a word-pos co-occurrence model describing how much probably a word sequence coexists with a pos sequence.",[0],"6.1.1 baseline forest-based system we first segment the chinese sentences into the1-best segmentations using a state-of-the-art system (jiang et al, 2008a), since it is not necessary for a conventional parser to take as input the pos tagging results",[0],10,method,3,3.0,0.375,64.0,0.4507042253521127,15.0,0.5769230769230769,0,0.0,0.0,0.0,0.0,0.0,4 cascaded linear model,abstract
P08-1102,C10-2096,[79],"by maintaining a stack of size n at each position i of the sequence, we can preserve the top n best candidate labelled results of subsequence c1:i during decoding.",[0],"6.1.2 lattice-forest systemwe first segment and pos tag the chinese sentences into word lattices using the same system (jiang et al, 2008a), and prune each lattice into a reasonable size using the marginal probability-based pruning algorithm",[0],11,method,4,4.0,0.5,79.0,0.5563380281690141,4.0,0.2857142857142857,0,0.0,0.0,0.0,0.0,0.0,5 decoder,abstract
P08-1102,C10-1132,[96],"in order to test the performance of the lexical-target templates and meanwhile determine the best iterations over the training corpus, we randomly chosen 2, 000 shorter sentences (less than 50 words) as the development set and the rest as the training set (84, 294 sentences), then trained a perceptron model named non-lex using only nonlexical-target features and another named lex using both the two kinds of features.",[0],"however, when we repeat the work of (jiang et al, 2008), which reports to achieve the state-of-art performance in the data-sets that we adopt, it has been found that some features (e.g., c0) are unnoticeably trained several times in their model (which are implicitly generated from different feature templates used in the paper)",[0],12,method,5,5.0,0.625,96.0,0.676056338028169,7.0,0.175,0,0.0,0.0,0.0,0.0,0.0,6 experiments,abstract
P08-1102,C10-1132,[91],"the first was conducted to test the performance of the perceptron on segmentation on the corpus from sighan bakeoff 2, including the academia sinica corpus (as), the hong kong city university corpus (cityu), the peking university corpus (pku) and the microsoft research corpus (msr).",[0],"unicode/cp936 1.1m/55k 104k/13k 0.035 table 3: corpus statistics for the second sighan bakeoff appears twice, which is generated from two different templates cn (with n=0, generates c0) and [c0cn] (used in (jiang et al, 2008), with n=0, generates [c0c0])",[0],13,method,5,5.0,0.625,91.0,0.6408450704225352,2.0,0.05,0,0.0,0.0,0.0,0.0,0.0,6 experiments,abstract
P08-1102,C10-1132,[16],"shown in figure 1, the cascaded model has a two-layer architecture, with a characterbased perceptron as the core combined with other real-valued features such as language models.",[0],"as all the features adopted in (jiang et al, 2008) possess binary values, if a binary feature is repeated n times, then it should behave like a real-valued feature with its value to be? n?, at least in principle",[0],14,method,1,1.0,0.125,16.0,0.11267605633802817,12.0,0.5,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P08-1102,C10-1132,[35],"to compare with others conveniently, we excluded the ones forbidden by the close test regulation of sighan, for example, pu(c0), indicating whether character c0 is a punctuation.",[0],"inspired by (jiang et al, 2008), we set the real d although table 5 has shown that the proposed all the value of c0 to be 2.0, the value of c-1c0anc0c1 to be 3.0, and the values of all other features to be 1.0 for the character-based discriminative-plus model",[0],15,method,2,2.0,0.25,35.0,0.24647887323943662,7.0,0.3333333333333333,0,0.0,0.0,0.0,0.0,0.0,3 the perceptron,abstract
P08-1102,D12-1046,[91],we propose a cascaded linear model for joint chinese word segmentation and partof-speech tagging.,[0],"previous joint models mainly focus on word segmentation and pos tagging task, such as the virtual nodes method (qian et al2010), cascaded linear model (jiang et al2008a) ,perceptron (zhang and clark, 2008), sub-word based stacked learning (sun, 2011), re ranking (jiang et al2008b)",[0],17,method,5,5.0,0.625,91.0,0.6408450704225352,2.0,0.05,0,0.0,0.0,0.0,0.0,0.0,6 experiments,abstract
P11-1060,D11-1039,[11],"figure 1 shows our probabilistic model: with respect to a world w (database of facts), producing an answer y.",[0],"clarkeet al (2010) and liang et al (2011) describe approaches for learning semantic parsers from questions paired with database answers, while goldwasser et al (2011) presents work on unsupervised learning",[0],1,method,1,1.0,0.25,11.0,0.06285714285714286,7.0,0.35,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1060,P13-1092,[2],"in this paper, we learn to map questions to answers via latent logical forms, which are induced automatically from question-answer pairs.",[0],"in particular, clarke et al (2010) and liang et al (2011) proposed methods to learn from question answer pairs alone, which represents a significant advance",[0],2,method,0,0.0,0.0,2.0,0.011428571428571429,2.0,0.4,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
P11-1060,P13-1092,[9],"as in clarke et al. (2010), we obviate the need for annotated logical forms by considering the endto-end problem of mapping questions to answers.",[0],"to handle syntax-semantics mismatch, gusp introduces a novel dependency-based meaning representation 1clarke et al (2010) and liang et al (2011) used the annotated logical forms to compute answers for their experiments",[0],3,method,1,1.0,0.25,9.0,0.05142857142857143,5.0,0.25,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1060,P13-1092,[21],"the main technical contribution of this work is a new semantic representation, dependency-based compositional semantics (dcs), which is both simple and expressive (section 2).",[0],"more recently, liang et al (2011 )proposeddcs for dependency-based compositional semantics, which represents a semantic parse as a tree with nodes representing database elements and operations, and edges representing relational joins",[0],4,method,1,1.0,0.25,21.0,0.12,17.0,0.85,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1060,P13-1092,[21],"the main technical contribution of this work is a new semantic representation, dependency-based compositional semantics (dcs), which is both simple and expressive (section 2).",[0],"gusp represents meaning by a semantic tree, which is similar to dcs (liang et al, 2011)",[0],5,method,1,1.0,0.25,21.0,0.12,17.0,0.85,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1060,D12-1069,[112],"our learning algorithm alternates between (i) using the current parameters θ to generate the k-best set ˜zl,θ(x) for each training example x, and (ii) optimizing the parameters to put probability mass on the correct trees in these sets; sets containing no correct answers are skipped.",[0],"one line of work eliminates the need for an annotated logical form, instead using only the correct answer for a database query (liangetal2011) or even a binary correct/incorrect signal (clarke et al2010)",[0],8,method,2,2.0,0.5,112.0,0.64,88.0,0.967032967032967,0,0.0,0.0,0.0,0.0,0.0,2 semantic representation,abstract
P11-1060,N12-1049,[11],"although a dcs tree is a logical form, note that it looks like a syntactic dependency tree with predicates in place of words.",[0],"for example, liang et al (2011) constructs a latent parse similar in structure to a dependency grammar, but representing a logical form",[0],9,method,1,1.0,0.25,11.0,0.06285714285714286,7.0,0.35,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1060,P12-1045,[21],"the main technical contribution of this work is a new semantic representation, dependency-based compositional semantics (dcs), which is both simple and expressive (section 2).",[0],clarke et al (2010) and liang et al (2011) trained systems on question and answer pairs by automatically finding semantic interpretations of the questions that would generate the correct answers,[0],10,method,1,1.0,0.25,21.0,0.12,17.0,0.85,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1060,P14-1008,[21],"the main technical contribution of this work is a new semantic representation, dependency-based compositional semantics (dcs), which is both simple and expressive (section 2).",[0],"dependency-based compositional semantics (dcs) provides an intuitive way to model semantics of questions, by using simple dependency-like trees (liang et al, 2011)",[0],11,method,1,1.0,0.25,21.0,0.12,17.0,0.85,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1060,P14-1008,[10],"however, we still model the logical form (now as a latent variable) to capture the complexities of language.",[0],"dcs trees has been proposed to represent natural language semantics with a structure similar to dependency trees (liang et al, 2011) (figure 1)",[0],12,method,1,1.0,0.25,10.0,0.05714285714285714,6.0,0.3,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1060,P14-1008,[36],it is this transparency between syntax and semantics provided by dcs which leads to a simple and streamlined compositional semantics suitable for program induction.,[0],"are explained in? 2.5. 5http: //nlp.stanford.edu/software/corenlp.shtml 6 in (liang et al, 2011) dcs trees are learned from qapairs and database entries",[0],13,method,2,2.0,0.5,36.0,0.2057142857142857,12.0,0.13186813186813187,0,0.0,0.0,0.0,0.0,0.0,2 semantic representation,abstract
P11-1060,P14-1008,[42],the denotation jzkw (z evaluated on w) is the set of consistent values of the root node (see figure 2 for an example).,[0],"as in the sentence? tropi cal storm debby is blamed for death?, which is a tropical storm, is debby, etc. technically, each germ in a dcs tree indicates a variable when the dcs tree is translated to a fol formula, and the abstract denotation of the germ corresponds to the set of consistent values (liang et al, 2011) of that variable",[0],14,method,2,2.0,0.5,42.0,0.24,18.0,0.1978021978021978,0,0.0,0.0,0.0,0.0,0.0,2 semantic representation,abstract
P11-1060,D11-1140,[106],"learning given a training dataset d containing (x, y) pairs, we define the regularized marginal log-likelihood objective o(θ) = e(x,y)ed log pθ(jzkw = y |x, z ∈ zl(x)) − λkθk22, which sums over all dcs trees z that evaluate to the target answer y.",[0],clarke et al (2010) and liang et al (2011) replace semantic annotations in the training set with target answers which are more easily available,[0],15,method,2,2.0,0.5,106.0,0.6057142857142858,82.0,0.9010989010989011,0,0.0,0.0,0.0,0.0,0.0,2 semantic representation,abstract
P11-1060,D11-1140,[45],"the logical forms in dcs are called dcs trees, where nodes are labeled with predicates, and edges are labeled with relations.",[0],"and collins, 2005, 2007),? -wasp (wong and mooney, 2007), ubl (kwiatkowski et al, 2010) systems and dcs (liang et al, 2011)",[0],16,method,2,2.0,0.5,45.0,0.2571428571428571,21.0,0.23076923076923078,0,0.0,0.0,0.0,0.0,0.0,2 semantic representation,abstract
P11-1060,P13-1007,[88],"generalized quantification (d.ri = q) generalized quantifiers are predicates on two sets, a restrictor a and a nuclear scope b.",[0],"in general, every plural nppotentially introduces an implicit universal, ranging 1for example, liang et al (2011) in their state-of-the-art statistical semantic parser within the domain of natural language queries to databases, explicitly devise quantifier scoping in the semantic model",[0],17,method,2,2.0,0.5,88.0,0.5028571428571429,64.0,0.7032967032967034,0,0.0,0.0,0.0,0.0,0.0,2 semantic representation,abstract
P11-1060,P12-1051,[171],"this yields a more system is based on a new semantic representation, factorized and flexible representation that is easier dcs, which offers a simple and expressive alterto search through and parametrize using features. native to lambda calculus.",[0],"in fact, for any cfg g, it 1see liang et al (2011) for work in representing lambda calculus expressions with trees",[0],19,method,3,3.0,0.75,171.0,0.9771428571428571,56.0,0.9491525423728814,0,0.0,0.0,0.0,0.0,0.0,4 experiments,abstract
P11-1060,D11-1039,[112.0],"our learning algorithm alternates between (i) using the current parameters θ to generate the k-best set ˜zl,θ(x) for each training example x, and (ii) optimizing the parameters to put probability mass on the correct trees in these sets; sets containing no correct answers are skipped.",[0],"clarkeet al (2010) and liang et al (2011) describe approaches for learning semantic parsers from questions paired with database answers, while goldwasser et al (2011) presents work on unsupervised learning",[0],1,method,2,2.0,0.5,112.0,0.64,88.0,0.967032967032967,0,0.0,0.0,0.0,0.0,0.0,2 semantic representation,abstract
P11-1060,P13-1092,[112.0],"our learning algorithm alternates between (i) using the current parameters θ to generate the k-best set ˜zl,θ(x) for each training example x, and (ii) optimizing the parameters to put probability mass on the correct trees in these sets; sets containing no correct answers are skipped.",[0],"in particular, clarke et al (2010) and liang et al (2011) proposed methods to learn from question answer pairs alone, which represents a significant advance",[0],2,method,2,2.0,0.5,112.0,0.64,88.0,0.967032967032967,0,0.0,0.0,0.0,0.0,0.0,2 semantic representation,abstract
P11-1060,P13-1092,[25.0],"we first present a basic version (section 2.1) of dependency-based compositional semantics (dcs), which captures the core idea of using trees to represent formal semantics.",[0],"more recently, liang et al (2011 )proposeddcs for dependency-based compositional semantics, which represents a semantic parse as a tree with nodes representing database elements and operations, and edges representing relational joins",[0],4,aim,2,2.0,0.5,25.0,0.14285714285714285,1.0,0.01098901098901099,0,0.0,0.0,0.0,0.0,0.0,2 semantic representation,abstract
P11-1060,P13-1092,[21.0],"the main technical contribution of this work is a new semantic representation, dependency-based compositional semantics (dcs), which is both simple and expressive (section 2).",[0],"gusp represents meaning by a semantic tree, which is similar to dcs (liang et al, 2011)",[0],5,aim,1,1.0,0.25,21.0,0.12,17.0,0.85,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1060,W12-2802,[25.0],"we first present a basic version (section 2.1) of dependency-based compositional semantics (dcs), which captures the core idea of using trees to represent formal semantics.",[0],"matuszek et al [2010], liang et al [2011] and chen and mooney [2011] describe models that learn compositional semantics, but word meanings are symbolic structures rather than patterns of features in the external world",[0],7,aim,2,2.0,0.5,25.0,0.14285714285714285,1.0,0.01098901098901099,0,0.0,0.0,0.0,0.0,0.0,2 semantic representation,abstract
P11-1060,D12-1069,[148.0],"this bootstrapping behavior occurs naturally: the “easy” examples are processed first, where easy is defined by the ability of the current model to generate the correct answer using any tree. with scope variation.",[0],"one line of work eliminates the need for an annotated logical form, instead using only the correct answer for a database query (liangetal2011) or even a binary correct/incorrect signal (clarke et al2010)",[0],9,method,3,3.0,0.75,148.0,0.8457142857142858,33.0,0.559322033898305,0,0.0,0.0,0.0,0.0,0.0,4 experiments,abstract
P11-1060,N12-1049,[13.0],"we want to induce latent logical forms z (and parameters 0) given only question-answer pairs (x, y), which is much cheaper to obtain than (x, z) pairs.",[0],"for example, liang et al (2011) constructs a latent parse similar in structure to a dependency grammar, but representing a logical form",[0],10,result,1,1.0,0.25,13.0,0.07428571428571429,9.0,0.45,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1060,P12-1045,[112.0],"our learning algorithm alternates between (i) using the current parameters θ to generate the k-best set ˜zl,θ(x) for each training example x, and (ii) optimizing the parameters to put probability mass on the correct trees in these sets; sets containing no correct answers are skipped.",[0],clarke et al (2010) and liang et al (2011) trained systems on question and answer pairs by automatically finding semantic interpretations of the questions that would generate the correct answers,[0],11,result,2,2.0,0.5,112.0,0.64,88.0,0.967032967032967,0,0.0,0.0,0.0,0.0,0.0,2 semantic representation,abstract
P11-1060,P14-1008,[21.0],"the main technical contribution of this work is a new semantic representation, dependency-based compositional semantics (dcs), which is both simple and expressive (section 2).",[0],"dependency-based compositional semantics (dcs) provides an intuitive way to model semantics of questions, by using simple dependency-like trees (liang et al, 2011)",[0],12,aim,1,1.0,0.25,21.0,0.12,17.0,0.85,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1060,P14-1008,[47.0],"this algorithm is linear in the number of nodes times the size of the denotations.1 now the dual importance of trees in dcs is clear: we have seen that trees parallel syntactic dependency structure, which will facilitate parsing.",[0],"dcs trees has been proposed to represent natural language semantics with a structure similar to dependency trees (liang et al, 2011) (figure 1)",[0],13,method,2,2.0,0.5,47.0,0.26857142857142857,23.0,0.25274725274725274,0,0.0,0.0,0.0,0.0,0.0,2 semantic representation,abstract
P11-1060,P14-1008,[112.0],"our learning algorithm alternates between (i) using the current parameters θ to generate the k-best set ˜zl,θ(x) for each training example x, and (ii) optimizing the parameters to put probability mass on the correct trees in these sets; sets containing no correct answers are skipped.",[0],"are explained in? 2.5. 5http: //nlp.stanford.edu/software/corenlp.shtml 6 in (liang et al, 2011) dcs trees are learned from qapairs and database entries",[0],14,method,2,2.0,0.5,112.0,0.64,88.0,0.967032967032967,0,0.0,0.0,0.0,0.0,0.0,2 semantic representation,abstract
P11-1060,P14-1008,[44.0],"s sid=""44"" ssid=""20"">the recurrence is as follows: at each node, we compute the set of tuples v consistent with the predicate at that node (v ∈ w(p)), and s(x)}, where a set of pairs s is treated as a set-valued function s(x) = {y : (x, y) ∈ s} with domain s1 = {x : (x, y) ∈ s}.",[0],"as in the sentence? tropi cal storm debby is blamed for death?, which is a tropical storm, is debby, etc. technically, each germ in a dcs tree indicates a variable when the dcs tree is translated to a fol formula, and the abstract denotation of the germ corresponds to the set of consistent values (liang et al, 2011) of that variable",[0],15,method,2,2.0,0.5,44.0,0.25142857142857145,20.0,0.21978021978021978,0,0.0,0.0,0.0,0.0,0.0,2 semantic representation,abstract
P11-1060,D11-1140,[106.0],"learning given a training dataset d containing (x, y) pairs, we define the regularized marginal log-likelihood objective o(θ) = e(x,y)ed log pθ(jzkw = y |x, z ∈ zl(x)) − λkθk22, which sums over all dcs trees z that evaluate to the target answer y.",[0],clarke et al (2010) and liang et al (2011) replace semantic annotations in the training set with target answers which are more easily available,[0],16,aim,2,2.0,0.5,106.0,0.6057142857142858,82.0,0.9010989010989011,0,0.0,0.0,0.0,0.0,0.0,2 semantic representation,abstract
P11-1060,D11-1140,[21.0],"the main technical contribution of this work is a new semantic representation, dependency-based compositional semantics (dcs), which is both simple and expressive (section 2).",[0],"and collins, 2005, 2007),? -wasp (wong and mooney, 2007), ubl (kwiatkowski et al, 2010) systems and dcs (liang et al, 2011)",[0],17,aim,1,1.0,0.25,21.0,0.12,17.0,0.85,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1060,P13-1007,[172.0],"free from the burden it also allows us to easily add new lexical triggers of annotating logical forms, we hope to use our without becoming mired in the semantic formalism. techniques in developing even more accurate and quantifiers and superlatives significantly compli- broader-coverage language understanding systems. cate scoping in lambda calculus, and often type rais- acknowledgments we thank luke zettlemoyer ing needs to be employed.",[0],"in general, every plural nppotentially introduces an implicit universal, ranging 1for example, liang et al (2011) in their state-of-the-art statistical semantic parser within the domain of natural language queries to databases, explicitly devise quantifier scoping in the semantic model",[0],18,result,3,3.0,0.75,172.0,0.9828571428571429,57.0,0.9661016949152542,0,0.0,0.0,0.0,0.0,0.0,4 experiments,abstract
P11-1060,D11-1022,[21.0],"the main technical contribution of this work is a new semantic representation, dependency-based compositional semantics (dcs), which is both simple and expressive (section 2).",[0],"dd-admm may be useful in other frameworks involving logical constraints, such as the models for compositional semantics presented by liang et al (2011)",[0],19,aim,1,1.0,0.25,21.0,0.12,17.0,0.85,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1060,P12-1051,[171.0],"this yields a more system is based on a new semantic representation, factorized and flexible representation that is easier dcs, which offers a simple and expressive alterto search through and parametrize using features. native to lambda calculus.",[0],"in fact, for any cfg g, it 1see liang et al (2011) for work in representing lambda calculus expressions with trees",[0],20,method,3,3.0,0.75,171.0,0.9771428571428571,56.0,0.9491525423728814,0,0.0,0.0,0.0,0.0,0.0,4 experiments,abstract
P11-1060,D11-1039,[8],"on the other hand, existing unsupervised semantic parsers (poon and domingos, 2009) do not handle deeper linguistic phenomena such as quantification, negation, and superlatives.",[0],"clarkeet al (2010) and liang et al (2011) describe approaches for learning semantic parsers from questions paired with database answers, while goldwasser et al (2011) presents work on unsupervised learning",[0],1,method,1,1.0,0.25,8.0,0.045714285714285714,4.0,0.2,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1060,P13-1092,[132],"results we first compare our system with clarke et al. (2010) (henceforth, semresp), which also learns a semantic parser from question-answer pairs.",[0],"in particular, clarke et al (2010) and liang et al (2011) proposed methods to learn from question answer pairs alone, which represents a significant advance",[0],2,method,3,3.0,0.75,132.0,0.7542857142857143,17.0,0.288135593220339,0,0.0,0.0,0.0,0.0,0.0,4 experiments,abstract
P11-1060,P13-1092,[25],"we first present a basic version (section 2.1) of dependency-based compositional semantics (dcs), which captures the core idea of using trees to represent formal semantics.",[0],"to handle syntax-semantics mismatch, gusp introduces a novel dependency-based meaning representation 1clarke et al (2010) and liang et al (2011) used the annotated logical forms to compute answers for their experiments",[0],3,method,2,2.0,0.5,25.0,0.14285714285714285,1.0,0.01098901098901099,0,0.0,0.0,0.0,0.0,0.0,2 semantic representation,abstract
P11-1060,P13-1092,[45],"the logical forms in dcs are called dcs trees, where nodes are labeled with predicates, and edges are labeled with relations.",[0],"more recently, liang et al (2011 )proposeddcs for dependency-based compositional semantics, which represents a semantic parse as a tree with nodes representing database elements and operations, and edges representing relational joins",[0],4,method,2,2.0,0.5,45.0,0.2571428571428571,21.0,0.23076923076923078,0,0.0,0.0,0.0,0.0,0.0,2 semantic representation,abstract
P11-1060,P13-1092,[51],"it is impossible to represent the semantics of this phrase with just a csp, so we introduce a new aggregate relation, notated e. consider a tree he:ci, whose root is connected to a child c via e. if the denotation of c is a set of values s, the parent’s denotation is then a singleton set containing s. formally: figure 3(a) shows the dcs tree for our running example.",[0],"gusp represents meaning by a semantic tree, which is similar to dcs (liang et al, 2011)",[0],5,method,2,2.0,0.5,51.0,0.2914285714285714,27.0,0.2967032967032967,0,0.0,0.0,0.0,0.0,0.0,2 semantic representation,abstract
P11-1060,W12-2802,[166],"our employed (zettlemoyer and collins, 2007) or words work pushes the grounded language agenda towards are given multiple lexical entries (kwiatkowski et deeper representations of language—think grounded al., 2010). compositional semantics.",[0],"matuszek et al [2010], liang et al [2011] and chen and mooney [2011] describe models that learn compositional semantics, but word meanings are symbolic structures rather than patterns of features in the external world",[0],7,method,3,3.0,0.75,166.0,0.9485714285714286,51.0,0.864406779661017,0,0.0,0.0,0.0,0.0,0.0,4 experiments,abstract
P11-1060,P13-2009,[8],"on the other hand, existing unsupervised semantic parsers (poon and domingos, 2009) do not handle deeper linguistic phenomena such as quantification, negation, and superlatives.",[0],"it is well-studied in nlp, and a wide variety of methods have been proposed to tackle it ,e.g. rule-based (popescu et al, 2003), super vised (zelle, 1995), unsupervised (goldwasser et al., 2011), and response-based (liang et al, 2011)",[0],8,method,1,1.0,0.25,8.0,0.045714285714285714,4.0,0.2,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1060,D12-1069,[11],"figure 1 shows our probabilistic model: with respect to a world w (database of facts), producing an answer y.",[0],"one line of work eliminates the need for an annotated logical form, instead using only the correct answer for a database query (liangetal2011) or even a binary correct/incorrect signal (clarke et al2010)",[0],9,method,1,1.0,0.25,11.0,0.06285714285714286,7.0,0.35,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1060,N12-1049,[115],"after training, given a new utterance x, our system outputs the most likely y, summing out the latent logical form z: argmaxy pθ(t)(y |x, z ∈ ˜zl,θ(t)).",[0],"for example, liang et al (2011) constructs a latent parse similar in structure to a dependency grammar, but representing a logical form",[0],10,method,2,2.0,0.5,115.0,0.6571428571428571,91.0,1.0,0,0.0,0.0,0.0,0.0,0.0,2 semantic representation,abstract
P11-1060,P12-1045,[132],"results we first compare our system with clarke et al. (2010) (henceforth, semresp), which also learns a semantic parser from question-answer pairs.",[0],clarke et al (2010) and liang et al (2011) trained systems on question and answer pairs by automatically finding semantic interpretations of the questions that would generate the correct answers,[0],11,method,3,3.0,0.75,132.0,0.7542857142857143,17.0,0.288135593220339,0,0.0,0.0,0.0,0.0,0.0,4 experiments,abstract
P11-1060,P14-1008,[25],"we first present a basic version (section 2.1) of dependency-based compositional semantics (dcs), which captures the core idea of using trees to represent formal semantics.",[0],"dependency-based compositional semantics (dcs) provides an intuitive way to model semantics of questions, by using simple dependency-like trees (liang et al, 2011)",[0],12,method,2,2.0,0.5,25.0,0.14285714285714285,1.0,0.01098901098901099,0,0.0,0.0,0.0,0.0,0.0,2 semantic representation,abstract
P11-1060,P14-1008,[94],"we now turn to the task of mapping natural language for the example in figure 4(b), the de- utterances to dcs trees.",[0],"dcs trees has been proposed to represent natural language semantics with a structure similar to dependency trees (liang et al, 2011) (figure 1)",[0],13,method,2,2.0,0.5,94.0,0.5371428571428571,70.0,0.7692307692307693,0,0.0,0.0,0.0,0.0,0.0,2 semantic representation,abstract
P11-1060,P14-1008,[132],"results we first compare our system with clarke et al. (2010) (henceforth, semresp), which also learns a semantic parser from question-answer pairs.",[0],"are explained in? 2.5. 5http: //nlp.stanford.edu/software/corenlp.shtml 6 in (liang et al, 2011) dcs trees are learned from qapairs and database entries",[0],14,method,3,3.0,0.75,132.0,0.7542857142857143,17.0,0.288135593220339,0,0.0,0.0,0.0,0.0,0.0,4 experiments,abstract
P11-1060,P14-1008,[157],"eisenciations due to data sparsity, and having an insuffi- stein et al. (2009) induces conjunctive formulae and ciently large k. uses them as features in another learning problem.",[0],"as in the sentence? tropi cal storm debby is blamed for death?, which is a tropical storm, is debby, etc. technically, each germ in a dcs tree indicates a variable when the dcs tree is translated to a fol formula, and the abstract denotation of the germ corresponds to the set of consistent values (liang et al, 2011) of that variable",[0],15,method,3,3.0,0.75,157.0,0.8971428571428571,42.0,0.711864406779661,0,0.0,0.0,0.0,0.0,0.0,4 experiments,abstract
P11-1060,D11-1140,[106],"learning given a training dataset d containing (x, y) pairs, we define the regularized marginal log-likelihood objective o(θ) = e(x,y)ed log pθ(jzkw = y |x, z ∈ zl(x)) − λkθk22, which sums over all dcs trees z that evaluate to the target answer y.",[0],clarke et al (2010) and liang et al (2011) replace semantic annotations in the training set with target answers which are more easily available,[0],16,method,2,2.0,0.5,106.0,0.6057142857142858,82.0,0.9010989010989011,0,0.0,0.0,0.0,0.0,0.0,2 semantic representation,abstract
P11-1060,D11-1140,[167],"in dcs, we start with lexical triggers, which are 6 conclusion more basic than ccg lexical entries.",[0],"and collins, 2005, 2007),? -wasp (wong and mooney, 2007), ubl (kwiatkowski et al, 2010) systems and dcs (liang et al, 2011)",[0],17,method,3,3.0,0.75,167.0,0.9542857142857143,52.0,0.8813559322033898,0,0.0,0.0,0.0,0.0,0.0,4 experiments,abstract
P11-1060,P13-1007,[138],"next, we compared our systems (dcs and dcs+) with the state-of-the-art semantic parsers on the full dataset for both geo and jobs (see table 3).",[0],"in general, every plural nppotentially introduces an implicit universal, ranging 1for example, liang et al (2011) in their state-of-the-art statistical semantic parser within the domain of natural language queries to databases, explicitly devise quantifier scoping in the semantic model",[0],18,method,3,3.0,0.75,138.0,0.7885714285714286,23.0,0.3898305084745763,0,0.0,0.0,0.0,0.0,0.0,4 experiments,abstract
P11-1060,D11-1022,[40],"the csp has two types of constraints: (i) x ∈ w(p) for each node x labeled with predicate p ∈ p; and (ii) xj = yj0 (the j-th component of x must equal the j'-th component of y) for each edge (x, y) labeled with j0j ∈ r. a solution to the csp is an assignment of nodes to values that satisfies all the constraints.",[0],"dd-admm may be useful in other frameworks involving logical constraints, such as the models for compositional semantics presented by liang et al (2011)",[0],19,method,2,2.0,0.5,40.0,0.22857142857142856,16.0,0.17582417582417584,0,0.0,0.0,0.0,0.0,0.0,2 semantic representation,abstract
P11-1060,P12-1051,[171],"this yields a more system is based on a new semantic representation, factorized and flexible representation that is easier dcs, which offers a simple and expressive alterto search through and parametrize using features. native to lambda calculus.",[0],"in fact, for any cfg g, it 1see liang et al (2011) for work in representing lambda calculus expressions with trees",[0],20,method,3,3.0,0.75,171.0,0.9771428571428571,56.0,0.9491525423728814,0,0.0,0.0,0.0,0.0,0.0,4 experiments,abstract
P11-1061,P11-1144,[40],we extend subramanya et al.’s intuitions to our bilingual setup.,[0],subramanya et al? s model was extended by das and petrov (2011) to induce part-of-speech dictionaries for unsupervised learning of taggers,[0],1,method,3,3.0,0.3333333333333333,40.0,0.24242424242424243,6.0,0.17142857142857143,0,0.0,0.0,0.0,0.0,0.0,3 graph construction,abstract
P11-1061,P14-1126,[10],"to bridge this gap, we consider a practically motivated scenario, in which we want to leverage existing resources from a resource-rich language (like english) when building tools for resource-poor foreign languages.1 we assume that absolutely no labeled training data is available for the foreign language of interest, but that we have access to parallel data with a resource-rich language.",[0],"fortunately, some recently proposed pos taggers, such as the postagger of das and petrov (2011), rely only on labeled training data for english and the same kind of parallel text in our approach",[0],3,method,1,1.0,0.1111111111111111,10.0,0.06060606060606061,6.0,0.3157894736842105,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1061,N12-1086,[15],"first, we use a novel graph-based framework for projecting syntactic information across language boundaries.",[0],"applications have ranged from domain adaptation of part-of-speech (pos) taggers (subramanya et al, 2010), unsupervised learning ofpos taggers by using bilingual graph-based projections (das and petrov, 2011), and shallow semantic parsing for unknown predicates (das and smith,2011)",[0],4,method,1,1.0,0.1111111111111111,15.0,0.09090909090909091,11.0,0.5789473684210527,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1061,N12-1086,[25],central to our approach (see algorithm 1) is a bilingual similarity graph built from a sentence-aligned parallel corpus.,[0],"following das and petrov (2011) and subramanya et al (2010), a similarity score between two trigram types was computed by measuring the cosine similarity between their empirical sentential context statistics",[0],5,method,2,2.0,0.2222222222222222,25.0,0.15151515151515152,2.0,0.18181818181818182,0,0.0,0.0,0.0,0.0,0.0,2 approach overview,abstract
P11-1061,N12-1086,[29],"to establish a soft correspondence between the two languages, we use a second similarity function, which leverages standard unsupervised word alignment statistics (§3.3).3 since we have no labeled foreign data, our goal is to project syntactic information from the english side to the foreign side.",[0],"sparsity is desirable in settings where labeled development data for tuning thresholds that select the most probable labels for a given type is unavailable (e.g., das and petrov, 2011)",[0],6,method,2,2.0,0.2222222222222222,29.0,0.17575757575757575,6.0,0.5454545454545454,0,0.0,0.0,0.0,0.0,0.0,2 approach overview,abstract
P11-1061,N12-1052,[18],"to make the projection practical, we rely on the twelve universal part-of-speech tags of petrov et al. (2011).",[0],"specifically, by replacing fine-grained language specific part-of-speech tags with universal part-of-speech tags, generated with the method described by das and petrov (2011), a universal parser is achieved that can be applied to any language for which universal part-of-speech tags are available. below, we extend this approach to universal parsing by adding cross-lingual word cluster features",[0],7,method,1,1.0,0.1111111111111111,18.0,0.10909090909090909,14.0,0.7368421052631579,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1061,N12-1052,[18],"to make the projection practical, we rely on the twelve universal part-of-speech tags of petrov et al. (2011).",[0],"we study the impact of using cross-lingual cluster features by comparing the strong delexicalized baseline model of mcdonald et al (2011), which only has features derived from universal part-of-speech tags, projected from english with the method of das and petrov (2011), to the same model when adding features derived from cross-lingual clusters",[0],8,method,1,1.0,0.1111111111111111,18.0,0.10909090909090909,14.0,0.7368421052631579,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1061,N12-1090,[158],we have shown the efficacy of graph-based label propagation for projecting part-of-speech information across languages.,[0],"mt-based projection has been applied to various nlp tasks, such as part of-speech tagging (e.g., das and petrov (2011)), mention detection (e.g., zitouni and florian (2008)), and sentiment analysis (e.g., mihalcea et al (2007)) .there have been two initial attempts to apply projection to create co reference-annotated data for aresource-poor language, both of which involve projecting hand-annotated co reference data from english to romanian via a parallel corpus",[0],9,method,7,7.0,0.7777777777777778,158.0,0.9575757575757575,1.0,0.25,0,0.0,0.0,0.0,0.0,0.0,7 conclusion,abstract
P11-1061,W11-2205,[21],"these universal pos categories not only facilitate the transfer of pos information from one language to another, but also relieve us from using controversial evaluation metrics,2 by establishing a direct correspondence between the induced hidden states in the foreign language and the observed english labels.",[0],"for example, the multilingual pos induction approach of das and petrov (2011) assumes no supervision for the language whose pos tags are being 35 induced, but it assumes access to a labeled dataset of a different language. we begin by surveying recent work on unsupervised pos tagging, focusing on the issue of evaluation (section 2)",[0],10,method,1,1.0,0.1111111111111111,21.0,0.12727272727272726,17.0,0.8947368421052632,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1061,P13-1155,[158],we have shown the efficacy of graph-based label propagation for projecting part-of-speech information across languages.,[0],"(das and petrov, 2011) used graph-based label propagation for cross-lingual knowledge transfers to induce pos tags between two languages",[0],11,method,7,7.0,0.7777777777777778,158.0,0.9575757575757575,1.0,0.25,0,0.0,0.0,0.0,0.0,0.0,7 conclusion,abstract
P11-1061,D12-1127,[21],"these universal pos categories not only facilitate the transfer of pos information from one language to another, but also relieve us from using controversial evaluation metrics,2 by establishing a direct correspondence between the induced hidden states in the foreign language and the observed english labels.",[0],recent work by das and petrov (2011 )buildsa dictionary for a particular language by transfer ring annotated data from a resource-rich language through the use of word alignments in parallel text,[0],12,method,1,1.0,0.1111111111111111,21.0,0.12727272727272726,17.0,0.8947368421052632,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1061,D12-1127,[10],"to bridge this gap, we consider a practically motivated scenario, in which we want to leverage existing resources from a resource-rich language (like english) when building tools for resource-poor foreign languages.1 we assume that absolutely no labeled training data is available for the foreign language of interest, but that we have access to parallel data with a resource-rich language.",[0],"theseapproaches build a dictionary by transferring labeled data from a resource rich language (english) to a re source poor language (das and petrov, 2011)",[0],13,method,1,1.0,0.1111111111111111,10.0,0.06060606060606061,6.0,0.3157894736842105,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1061,P12-3012,[24],"the focus of this work is on building pos taggers for foreign languages, assuming that we have an english pos tagger and some parallel text between the two languages.",[0],"in recent years research in natural language processing (nlp) has been steadily moving towards multilingual processing: the availability of ever growing amounts of text in different languages ,infact, has been a major driving force behind research on multilingual approaches, from morphosyntactic (das and petrov, 2011) and syntactico semantic (peirsman and pado?, 2010) phenomena to high-end tasks like textual entailment (mehdad et al., 2011) and sentiment analysis (lu et al, 2011)",[0],14,method,2,2.0,0.2222222222222222,24.0,0.14545454545454545,1.0,0.09090909090909091,0,0.0,0.0,0.0,0.0,0.0,2 approach overview,abstract
P11-1061,D11-1006,[17],"second, we treat the projected labels as features in an unsupervised model (§5), rather than using them directly for supervised training.",[0],"furthermore, we evaluate with both gold-standard part-of-speech tags, as well as predicted part-of speech tags from the projected part-of-speech tagger of das and petrov (2011) .2 this tagger relies only onlabeled training data for english, and achieves accuracies around 85% on the languages that we con sider",[0],15,method,1,1.0,0.1111111111111111,17.0,0.10303030303030303,13.0,0.6842105263157895,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1061,D11-1006,[111],"we use the universal pos tagset of petrov et al. (2011) in our experiments.10 this set c consists of the following 12 coarse-grained tags: noun (nouns), verb (verbs), adj (adjectives), adv (adverbs), pron (pronouns), det (determiners), adp (prepositions or postpositions), num (numerals), conj (conjunctions), prt (particles), punc (punctuation marks) and x (a catch-all for other categories such as abbreviations or foreign words).",[0],"in the first, we assumed that the test set for each target language had gold part-of-speech tags, and in the second we used predicted part-of-speech tags from the projection tagger of das and petrov (2011), which also uses english as the source language",[0],16,method,5,5.0,0.5555555555555556,111.0,0.6727272727272727,11.0,0.2972972972972973,0,0.0,0.0,0.0,0.0,0.0,6 experiments and results,abstract
P11-1061,P13-2112,[10],"to bridge this gap, we consider a practically motivated scenario, in which we want to leverage existing resources from a resource-rich language (like english) when building tools for resource-poor foreign languages.1 we assume that absolutely no labeled training data is available for the foreign language of interest, but that we have access to parallel data with a resource-rich language.",[0],"this parallel data can be exploited to bridge languages, and in particular, transfer information from a highly-resourced language to a lesser-resourced language, to build unsupervised pos taggers. in this paper, we propose an unsupervised approach to pos tagging in a similar vein to the work of das and petrov (2011)",[0],17,method,1,1.0,0.1111111111111111,10.0,0.06060606060606061,6.0,0.3157894736842105,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1061,P13-2112,[29],"to establish a soft correspondence between the two languages, we use a second similarity function, which leverages standard unsupervised word alignment statistics (§3.3).3 since we have no labeled foreign data, our goal is to project syntactic information from the english side to the foreign side.",[0],das and petrov (2011) achieved the current state-of-the-art for unsupervised tagging by exploiting high confidence alignments to copy tags from the source language to the target language,[0],18,method,2,2.0,0.2222222222222222,29.0,0.17575757575757575,6.0,0.5454545454545454,0,0.0,0.0,0.0,0.0,0.0,2 approach overview,abstract
P11-1061,P13-2112,[161],"our results outperform strong unsupervised baselines as well as approaches that rely on direct projections, and bridge the gap between purely supervised and unsupervised pos tagging models.",[0],"we have proposed a method for unsupervised postagging that performs on par with the current state of-the-art (das and petrov, 2011), but is subs tan tially less-sophisticated (specifically not requiring convex optimization or a feature-based hmm)",[0],19,method,7,7.0,0.7777777777777778,161.0,0.9757575757575757,4.0,1.0,0,0.0,0.0,0.0,0.0,0.0,7 conclusion,abstract
P11-1061,P11-1144,[144],"for comparison, the completely unsupervised feature-hmm baseline accuracy on the universal pos tags for english is 79.4%, and goes up to 88.7% with a treebank dictionary.",[0],subramanya et al? s model was extended by das and petrov (2011) to induce part-of-speech dictionaries for unsupervised learning of taggers,[0],1,result,6,6.0,0.6666666666666666,144.0,0.8727272727272727,7.0,0.35,0,0.0,0.0,0.0,0.0,0.0,6.5 results,abstract
P11-1061,P14-1126,[44],"because all english vertices are going to be labeled, we do not need to disambiguate them by embedding them in trigrams.",[0],"fortunately, some recently proposed pos taggers, such as the postagger of das and petrov (2011), rely only on labeled training data for english and the same kind of parallel text in our approach",[0],3,method,3,3.0,0.3333333333333333,44.0,0.26666666666666666,10.0,0.2857142857142857,0,0.0,0.0,0.0,0.0,0.0,3 graph construction,abstract
P11-1061,N12-1086,[16],"to this end, we construct a bilingual graph over word types to establish a connection between the two languages (§3), and then use graph label propagation to project syntactic information from english to the foreign language (§4).",[0],"applications have ranged from domain adaptation of part-of-speech (pos) taggers (subramanya et al, 2010), unsupervised learning ofpos taggers by using bilingual graph-based projections (das and petrov, 2011), and shallow semantic parsing for unknown predicates (das and smith,2011)",[0],4,method,1,1.0,0.1111111111111111,16.0,0.09696969696969697,12.0,0.631578947368421,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1061,N12-1086,[44],"because all english vertices are going to be labeled, we do not need to disambiguate them by embedding them in trigrams.",[0],"following das and petrov (2011) and subramanya et al (2010), a similarity score between two trigram types was computed by measuring the cosine similarity between their empirical sentential context statistics",[0],5,method,3,3.0,0.3333333333333333,44.0,0.26666666666666666,10.0,0.2857142857142857,0,0.0,0.0,0.0,0.0,0.0,3 graph construction,abstract
P11-1061,N12-1086,[110],we hope that this will allow practitioners to apply our approach directly to languages for which no resources are available.,[0],"sparsity is desirable in settings where labeled development data for tuning thresholds that select the most probable labels for a given type is unavailable (e.g., das and petrov, 2011)",[0],6,aim,5,5.0,0.5555555555555556,110.0,0.6666666666666666,10.0,0.2702702702702703,0,0.0,0.0,0.0,0.0,0.0,6 experiments and results,abstract
P11-1061,N12-1052,[115],the taggers were trained on datasets labeled with the universal tags.,[0],"specifically, by replacing fine-grained language specific part-of-speech tags with universal part-of-speech tags, generated with the method described by das and petrov (2011), a universal parser is achieved that can be applied to any language for which universal part-of-speech tags are available. below, we extend this approach to universal parsing by adding cross-lingual word cluster features",[0],7,method,5,5.0,0.5555555555555556,115.0,0.696969696969697,15.0,0.40540540540540543,0,0.0,0.0,0.0,0.0,0.0,6 experiments and results,abstract
P11-1061,N12-1052,[115],the taggers were trained on datasets labeled with the universal tags.,[0],"we study the impact of using cross-lingual cluster features by comparing the strong delexicalized baseline model of mcdonald et al (2011), which only has features derived from universal part-of-speech tags, projected from english with the method of das and petrov (2011), to the same model when adding features derived from cross-lingual clusters",[0],8,method,5,5.0,0.5555555555555556,115.0,0.696969696969697,15.0,0.40540540540540543,0,0.0,0.0,0.0,0.0,0.0,6 experiments and results,abstract
P11-1061,N12-1090,[158],we have shown the efficacy of graph-based label propagation for projecting part-of-speech information across languages.,[0],"mt-based projection has been applied to various nlp tasks, such as part of-speech tagging (e.g., das and petrov (2011)), mention detection (e.g., zitouni and florian (2008)), and sentiment analysis (e.g., mihalcea et al (2007)) .there have been two initial attempts to apply projection to create co reference-annotated data for aresource-poor language, both of which involve projecting hand-annotated co reference data from english to romanian via a parallel corpus",[0],9,result,7,7.0,0.7777777777777778,158.0,0.9575757575757575,1.0,0.25,0,0.0,0.0,0.0,0.0,0.0,7 conclusion,abstract
P11-1061,W11-2205,[23],"our final average pos tagging accuracy of 83.4% compares very favorably to the average accuracy of berg-kirkpatrick et al.’s monolingual unsupervised state-of-the-art model (73.0%), and considerably bridges the gap to fully supervised pos tagging performance (96.6%).",[0],"for example, the multilingual pos induction approach of das and petrov (2011) assumes no supervision for the language whose pos tags are being 35 induced, but it assumes access to a labeled dataset of a different language. we begin by surveying recent work on unsupervised pos tagging, focusing on the issue of evaluation (section 2)",[0],10,result,1,1.0,0.1111111111111111,23.0,0.1393939393939394,19.0,1.0,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1061,P13-1155,[24],"the focus of this work is on building pos taggers for foreign languages, assuming that we have an english pos tagger and some parallel text between the two languages.",[0],"(das and petrov, 2011) used graph-based label propagation for cross-lingual knowledge transfers to induce pos tags between two languages",[0],11,aim,2,2.0,0.2222222222222222,24.0,0.14545454545454545,1.0,0.09090909090909091,0,0.0,0.0,0.0,0.0,0.0,2 approach overview,abstract
P11-1061,D12-1127,[10],"to bridge this gap, we consider a practically motivated scenario, in which we want to leverage existing resources from a resource-rich language (like english) when building tools for resource-poor foreign languages.1 we assume that absolutely no labeled training data is available for the foreign language of interest, but that we have access to parallel data with a resource-rich language.",[0],recent work by das and petrov (2011 )buildsa dictionary for a particular language by transfer ring annotated data from a resource-rich language through the use of word alignments in parallel text,[0],12,method,1,1.0,0.1111111111111111,10.0,0.06060606060606061,6.0,0.3157894736842105,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1061,D12-1127,[],"to bridge this gap, we consider a practically motivated scenario, in which we want to leverage existing resources from a resource-rich language (like english) when building tools for resource-poor foreign languages.1 we assume that absolutely no labeled training data is available for the foreign language of interest, but that we have access to parallel data with a resource-rich language.",[0],"theseapproaches build a dictionary by transferring labeled data from a resource rich language (english) to a re source poor language (das and petrov, 2011)",[0],13,method,,,0.0,0.0,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,0.0,,abstract
P11-1061,P12-3012,[16],"to this end, we construct a bilingual graph over word types to establish a connection between the two languages (§3), and then use graph label propagation to project syntactic information from english to the foreign language (§4).",[0],"in recent years research in natural language processing (nlp) has been steadily moving towards multilingual processing: the availability of ever growing amounts of text in different languages ,infact, has been a major driving force behind research on multilingual approaches, from morphosyntactic (das and petrov, 2011) and syntactico semantic (peirsman and pado?, 2010) phenomena to high-end tasks like textual entailment (mehdad et al., 2011) and sentiment analysis (lu et al, 2011)",[0],14,method,1,1.0,0.1111111111111111,16.0,0.09696969696969697,12.0,0.631578947368421,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1061,D11-1006,[23],"our final average pos tagging accuracy of 83.4% compares very favorably to the average accuracy of berg-kirkpatrick et al.’s monolingual unsupervised state-of-the-art model (73.0%), and considerably bridges the gap to fully supervised pos tagging performance (96.6%).",[0],"furthermore, we evaluate with both gold-standard part-of-speech tags, as well as predicted part-of speech tags from the projected part-of-speech tagger of das and petrov (2011) .2 this tagger relies only onlabeled training data for english, and achieves accuracies around 85% on the languages that we con sider",[0],15,result,1,1.0,0.1111111111111111,23.0,0.1393939393939394,19.0,1.0,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1061,D11-1006,[158],we have shown the efficacy of graph-based label propagation for projecting part-of-speech information across languages.,[0],"in the first, we assumed that the test set for each target language had gold part-of-speech tags, and in the second we used predicted part-of-speech tags from the projection tagger of das and petrov (2011), which also uses english as the source language",[0],16,method,7,7.0,0.7777777777777778,158.0,0.9575757575757575,1.0,0.25,0,0.0,0.0,0.0,0.0,0.0,7 conclusion,abstract
P11-1061,P13-2112,[10],"to bridge this gap, we consider a practically motivated scenario, in which we want to leverage existing resources from a resource-rich language (like english) when building tools for resource-poor foreign languages.1 we assume that absolutely no labeled training data is available for the foreign language of interest, but that we have access to parallel data with a resource-rich language.",[0],"this parallel data can be exploited to bridge languages, and in particular, transfer information from a highly-resourced language to a lesser-resourced language, to build unsupervised pos taggers. in this paper, we propose an unsupervised approach to pos tagging in a similar vein to the work of das and petrov (2011)",[0],17,method,1,1.0,0.1111111111111111,10.0,0.06060606060606061,6.0,0.3157894736842105,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1061,P13-2112,[56],"to define a similarity function between the english and the foreign vertices, we rely on high-confidence word alignments.",[0],das and petrov (2011) achieved the current state-of-the-art for unsupervised tagging by exploiting high confidence alignments to copy tags from the source language to the target language,[0],18,method,3,3.0,0.3333333333333333,56.0,0.3393939393939394,22.0,0.6285714285714286,0,0.0,0.0,0.0,0.0,0.0,3 graph construction,abstract
P11-1061,P13-2112,[161],"our results outperform strong unsupervised baselines as well as approaches that rely on direct projections, and bridge the gap between purely supervised and unsupervised pos tagging models.",[0],"we have proposed a method for unsupervised postagging that performs on par with the current state of-the-art (das and petrov, 2011), but is subs tan tially less-sophisticated (specifically not requiring convex optimization or a feature-based hmm)",[0],20,result,7,7.0,0.7777777777777778,161.0,0.9757575757575757,4.0,1.0,0,0.0,0.0,0.0,0.0,0.0,7 conclusion,abstract
P11-1061,P11-1144,[9],"unfortunately, the best completely unsupervised english pos tagger (that does not make use of a tagging dictionary) reaches only 76.1% accuracy (christodoulopoulos et al., 2010), making its practical usability questionable at best.",[0],subramanya et al? s model was extended by das and petrov (2011) to induce part-of-speech dictionaries for unsupervised learning of taggers,[0],1,method,1,1.0,0.1111111111111111,9.0,0.05454545454545454,5.0,0.2631578947368421,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1061,P11-1144,[47],our monolingual similarity function (for connecting pairs of foreign trigram types) is the same as the one used by subramanya et al. (2010).,[0],"to this end, we use a variant of the quadratic cost criterion of bengio et al (2006), also used by subramanya et al (2010) and das and petrov (2011) .7 let v denote the set of all vertices in the graph, vl? v be the set of known targets and f denote theset of all frames",[0],2,method,3,3.0,0.3333333333333333,47.0,0.28484848484848485,13.0,0.37142857142857144,0,0.0,0.0,0.0,0.0,0.0,3 graph construction,abstract
P11-1061,P14-1126,[10],"to bridge this gap, we consider a practically motivated scenario, in which we want to leverage existing resources from a resource-rich language (like english) when building tools for resource-poor foreign languages.1 we assume that absolutely no labeled training data is available for the foreign language of interest, but that we have access to parallel data with a resource-rich language.",[0],das and petrov (2011) achieved the current state-of-the-art for unsupervised tagging by exploiting high confidence alignments to copy tags from the source language to the target language,[0],3,method,1,1.0,0.1111111111111111,10.0,0.06060606060606061,6.0,0.3157894736842105,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1061,N12-1086,[70],"given the bilingual graph described in the previous section, we can use label propagation to project the english pos labels to the foreign language.",[0],"applications have ranged from domain adaptation of part-of-speech (pos) taggers (subramanya et al, 2010), unsupervised learning ofpos taggers by using bilingual graph-based projections (das and petrov, 2011), and shallow semantic parsing for unknown predicates (das and smith,2011)",[0],4,method,4,4.0,0.4444444444444444,70.0,0.42424242424242425,1.0,0.03225806451612903,0,0.0,0.0,0.0,0.0,0.0,4 pos projection,abstract
P11-1061,N12-1086,[52],this is similar to stacking the different feature instantiations into long (sparse) vectors and computing the cosine similarity between them.,[0],"following das and petrov (2011) and subramanya et al (2010), a similarity score between two trigram types was computed by measuring the cosine similarity between their empirical sentential context statistics",[0],5,method,3,3.0,0.3333333333333333,52.0,0.3151515151515151,18.0,0.5142857142857142,0,0.0,0.0,0.0,0.0,0.0,3 graph construction,abstract
P11-1061,N12-1086,[83],we then extract a set of possible tags tx(y) by eliminating labels whose probability is below a threshold value τ: we describe how we choose τ in §6.4.,[0],"sparsity is desirable in settings where labeled development data for tuning thresholds that select the most probable labels for a given type is unavailable (e.g., das and petrov, 2011)",[0],6,method,4,4.0,0.4444444444444444,83.0,0.503030303030303,14.0,0.45161290322580644,0,0.0,0.0,0.0,0.0,0.0,4 pos projection,abstract
P11-1061,N12-1052,[113],"for each language under consideration, petrov et al. (2011) provide a mapping a from the fine-grained language specific pos tags in the foreign treebank to the universal pos tags.",[0],"specifically, by replacing fine-grained language specific part-of-speech tags with universal part-of-speech tags, generated with the method described by das and petrov (2011), a universal parser is achieved that can be applied to any language for which universal part-of-speech tags are available. below, we extend this approach to universal parsing by adding cross-lingual word cluster features",[0],7,method,5,5.0,0.5555555555555556,113.0,0.6848484848484848,13.0,0.35135135135135137,0,0.0,0.0,0.0,0.0,0.0,6 experiments and results,abstract
P11-1061,N12-1052,[3],"we use graph-based label propagation for cross-lingual knowledge transfer and use the projected labels as features in an unsupervised model (berg- kirkpatrick et al., 2010).",[0],"we study the impact of using cross-lingual cluster features by comparing the strong delexicalized baseline model of mcdonald et al (2011), which only has features derived from universal part-of-speech tags, projected from english with the method of das and petrov (2011), to the same model when adding features derived from cross-lingual clusters",[0],8,method,0,0.0,0.0,3.0,0.01818181818181818,3.0,0.6,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
P11-1061,N12-1090,[18],"to make the projection practical, we rely on the twelve universal part-of-speech tags of petrov et al. (2011).",[0],"mt-based projection has been applied to various nlp tasks, such as part of-speech tagging (e.g., das and petrov (2011)), mention detection (e.g., zitouni and florian (2008)), and sentiment analysis (e.g., mihalcea et al (2007)) .there have been two initial attempts to apply projection to create co reference-annotated data for aresource-poor language, both of which involve projecting hand-annotated co reference data from english to romanian via a parallel corpus",[0],9,method,1,1.0,0.1111111111111111,18.0,0.10909090909090909,14.0,0.7368421052631579,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1061,W11-2205,[13],"(2009) study related but different multilingual grammar and tagger induction tasks, where it is assumed that no labeled data at all is available.",[0],"for example, the multilingual pos induction approach of das and petrov (2011) assumes no supervision for the language whose pos tags are being 35 induced, but it assumes access to a labeled dataset of a different language. we begin by surveying recent work on unsupervised pos tagging, focusing on the issue of evaluation (section 2)",[0],10,method,1,1.0,0.1111111111111111,13.0,0.07878787878787878,9.0,0.47368421052631576,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1061,P13-1155,[3],"we use graph-based label propagation for cross-lingual knowledge transfer and use the projected labels as features in an unsupervised model (berg- kirkpatrick et al., 2010).",[0],"(das and petrov, 2011) used graph-based label propagation for cross-lingual knowledge transfers to induce pos tags between two languages",[0],11,method,0,0.0,0.0,3.0,0.01818181818181818,3.0,0.6,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
P11-1061,D12-1127,[120],we were intentionally lenient with our baselines: bilingual information by projecting pos tags directly across alignments in the parallel data.,[0],recent work by das and petrov (2011 )buildsa dictionary for a particular language by transfer ring annotated data from a resource-rich language through the use of word alignments in parallel text,[0],12,method,5,5.0,0.5555555555555556,120.0,0.7272727272727273,20.0,0.5405405405405406,0,0.0,0.0,0.0,0.0,0.0,6 experiments and results,abstract
P11-1061,D12-1127,[2],"our method does not assume any knowledge about the target language (in particular no tagging dictionary is assumed), making it applicable to a wide array of resource-poor languages.",[0],"theseapproaches build a dictionary by transferring labeled data from a resource rich language (english) to a re source poor language (das and petrov, 2011)",[0],13,method,0,0.0,0.0,2.0,0.012121212121212121,2.0,0.4,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
P11-1061,P12-3012,[19],"syntactic universals are a well studied concept in linguistics (carnie, 2002; newmeyer, 2005), and were recently used in similar form by naseem et al. (2010) for multilingual grammar induction.",[0],"in recent years research in natural language processing (nlp) has been steadily moving towards multilingual processing: the availability of ever growing amounts of text in different languages ,infact, has been a major driving force behind research on multilingual approaches, from morphosyntactic (das and petrov, 2011) and syntactico semantic (peirsman and pado?, 2010) phenomena to high-end tasks like textual entailment (mehdad et al., 2011) and sentiment analysis (lu et al, 2011)",[0],14,method,1,1.0,0.1111111111111111,19.0,0.11515151515151516,15.0,0.7894736842105263,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1061,D11-1006,[153],"figure 2 shows an excerpt of a sentence from the italian test set and the tags assigned by four different models, as well as the gold tags.",[0],"furthermore, we evaluate with both gold-standard part-of-speech tags, as well as predicted part-of speech tags from the projected part-of-speech tagger of das and petrov (2011) .2 this tagger relies only onlabeled training data for english, and achieves accuracies around 85% on the languages that we con sider",[0],15,method,6,6.0,0.6666666666666666,153.0,0.9272727272727272,16.0,0.8,0,0.0,0.0,0.0,0.0,0.0,6.5 results,abstract
P11-1061,D11-1006,[18],"to make the projection practical, we rely on the twelve universal part-of-speech tags of petrov et al. (2011).",[0],"in the first, we assumed that the test set for each target language had gold part-of-speech tags, and in the second we used predicted part-of-speech tags from the projection tagger of das and petrov (2011), which also uses english as the source language",[0],16,method,1,1.0,0.1111111111111111,18.0,0.10909090909090909,14.0,0.7368421052631579,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1061,P13-2112,[161],"our results outperform strong unsupervised baselines as well as approaches that rely on direct projections, and bridge the gap between purely supervised and unsupervised pos tagging models.",[0],"this parallel data can be exploited to bridge languages, and in particular, transfer information from a highly-resourced language to a lesser-resourced language, to build unsupervised pos taggers. in this paper, we propose an unsupervised approach to pos tagging in a similar vein to the work of das and petrov (2011)",[0],17,method,7,7.0,0.7777777777777778,161.0,0.9757575757575757,4.0,1.0,0,0.0,0.0,0.0,0.0,0.0,7 conclusion,abstract
P11-1061,P13-2112,[23],"our final average pos tagging accuracy of 83.4% compares very favorably to the average accuracy of berg-kirkpatrick et al.’s monolingual unsupervised state-of-the-art model (73.0%), and considerably bridges the gap to fully supervised pos tagging performance (96.6%).",[0],das and petrov (2011) achieved the current state-of-the-art for unsupervised tagging by exploiting high confidence alignments to copy tags from the source language to the target language,[0],18,method,1,1.0,0.1111111111111111,23.0,0.1393939393939394,19.0,1.0,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P11-1061,P13-2112,[23],"our final average pos tagging accuracy of 83.4% compares very favorably to the average accuracy of berg-kirkpatrick et al.’s monolingual unsupervised state-of-the-art model (73.0%), and considerably bridges the gap to fully supervised pos tagging performance (96.6%).",[0],"we have proposed a method for unsupervised postagging that performs on par with the current state of-the-art (das and petrov, 2011), but is subs tan tially less-sophisticated (specifically not requiring convex optimization or a feature-based hmm)",[0],20,method,1,1.0,0.1111111111111111,23.0,0.1393939393939394,19.0,1.0,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P87-1015,P01-1018,[118],"in the remainder of the paper, we outline how a class of linear context-free rewriting systems (lcfrs's) may be defined and sketch how semilinearity and polynomial recognition of these systems follows.",[0],"the approach that vijay-shanker et al (1987) and weir (1988) take, elaborated on by becker et al (1992), is to identify a very general class of formalisms, which they call linear context free rewriting systems (cfrss), and define for this class a large space of structural descriptions which serves as a common ground in which the strong generative capacities of these formalisms can be compared",[0],1,aim,4,4.0,0.6666666666666666,118.0,0.5064377682403434,3.0,0.0379746835443038,0,0.0,0.0,0.0,0.0,0.0,4 linear context-free rewriting systems,abstract
P87-1015,E09-1055,[118],"in the remainder of the paper, we outline how a class of linear context-free rewriting systems (lcfrs's) may be defined and sketch how semilinearity and polynomial recognition of these systems follows.",[0],"here we use the standard definition of lcfrs (vijay-shanker et al, 1987) and only fix our notation; for a more thorough discussion of this formal ism, we refer to the literature. let g be an lcfrs",[0],2,aim,4,4.0,0.6666666666666666,118.0,0.5064377682403434,3.0,0.0379746835443038,0,0.0,0.0,0.0,0.0,0.0,4 linear context-free rewriting systems,abstract
P87-1015,W07-2214,[149],"we can obtain a letter equivalent cfl defined by a cfg in which the for each rule as above, we have the production a —* a1 anup where tk (up) = cp.",[0],"there are many (structural) mildly context sensitive grammar formalisms ,e.g .mcfg ,lcfrs, mg, and they have been shown to be equivalent (vijay-shanker et al., 1987)",[0],3,method,4,4.0,0.6666666666666666,149.0,0.6394849785407726,34.0,0.43037974683544306,0,0.0,0.0,0.0,0.0,0.0,4 linear context-free rewriting systems,abstract
P87-1015,P09-1111,[118],"in the remainder of the paper, we outline how a class of linear context-free rewriting systems (lcfrs's) may be defined and sketch how semilinearity and polynomial recognition of these systems follows.",[0],"following this line, (vijay-shanker et al, 1987) have introduced a formalism called linear context-free rewriting systems (lcfrss) that has received much attention in later years by the community",[0],5,aim,4,4.0,0.6666666666666666,118.0,0.5064377682403434,3.0,0.0379746835443038,0,0.0,0.0,0.0,0.0,0.0,4 linear context-free rewriting systems,abstract
P87-1015,P09-1111,[118],"in the remainder of the paper, we outline how a class of linear context-free rewriting systems (lcfrs's) may be defined and sketch how semilinearity and polynomial recognition of these systems follows.",[0],"we briefly summarize here the terminology and notation that we adopt for lcfrs; for detailed definitions, see (vijay-shanker et al, 1987)",[0],6,aim,4,4.0,0.6666666666666666,118.0,0.5064377682403434,3.0,0.0379746835443038,0,0.0,0.0,0.0,0.0,0.0,4 linear context-free rewriting systems,abstract
P87-1015,P07-1021,[2],"in considering the relationship between formalisms, we show that it is useful to abstract away from the details of the formalism, and examine the nature of their derivation process as reflected by properties their trees. find that several of the formalisms considered can be seen as being closely related since they have derivation tree sets with the same structure as those produced by context-free grammars on the basis of this observation, we describe a class of formalisms which we call linear context- free rewriting systems, and show they are recognizable in polynomial time and generate only semilinear languages.",[0],"we write regd.k/ to refer to the class of regular dependency languages with a gap-degree bounded by k. linear context-free rewriting systems gap-restricted dependency languages are closely related to linear context-free rewriting systems (lcfrs) (vijay-shanker et al, 1987), a class of formal systems that generalizes several mildly context-sensitive grammar formalisms",[0],7,aim,0,0.0,0.0,2.0,0.008583690987124463,2.0,0.6666666666666666,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
P87-1015,N09-1061,[118],"in the remainder of the paper, we outline how a class of linear context-free rewriting systems (lcfrs's) may be defined and sketch how semilinearity and polynomial recognition of these systems follows.",[0],"this observation is in line with empirical studies in the context of dependency parsing, where the need for formalisms with higher fan-out has been observed even in standard, single language texts (kuhlmann and nivre, 2006) .in this paper, we present an algorithm that computes optimal decompositions of rules in the formalism of linear context-free rewriting systems (lcfrs) (vijay-shanker et al, 1987)",[0],8,aim,4,4.0,0.6666666666666666,118.0,0.5064377682403434,3.0,0.0379746835443038,0,0.0,0.0,0.0,0.0,0.0,4 linear context-free rewriting systems,abstract
P87-1015,N09-1061,[222],"however, in order to capture the properties of various grammatical systems under consideration, our notation is more restrictive that ilfp, which was designed as a general logical notation to characterize the complete class of languages that are recognizable in polynomial time.",[0],"we briefly summarize the terminology and notation that we adopt for lcfrs; for detailed definitions, see vijay-shanker et al (1987)",[0],9,method,5,5.0,0.8333333333333334,222.0,0.9527896995708155,28.0,0.7368421052631579,0,0.0,0.0,0.0,0.0,0.0,5 discussion,abstract
P87-1015,W10-1407,[119],"in defining lcfrs's, we hope to generalize the definition of cfg's to formalisms manipulating any structure, e.g. strings, trees, or graphs.",[0],"lcfrs (vijay-shanker et al, 1987) are anatural extension of cfg in which a single nonterminal node can dominate more than one continuous span of terminals",[0],10,aim,4,4.0,0.6666666666666666,119.0,0.5107296137339056,4.0,0.05063291139240506,0,0.0,0.0,0.0,0.0,0.0,4 linear context-free rewriting systems,abstract
P87-1015,W10-1407,[],"in the remainder of the paper, we outline how a class of linear context-free rewriting systems (lcfrs's) may be defined and sketch how semilinearity and polynomial recognition of these systems follows.",[0],"a lcfrs (vijay-shanker et al, 1987) is a tuple g= (n, t, v, p, s )wherea) n is a finite set of non-terminals with a function dim: n? n that determines the fan-out of each a? n; b) t and v are disjoint finite sets of terminals and variables; c) s? n is the start symbol with dim (s)= 1; d) p is a finite set of rewriting rules a (? 1,..",[0],11,aim,,,0.0,0.0,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,0.0,,abstract
P87-1015,E09-1053,[207],"we outlined the definition of a family of constrained grammatical formalisms, called linear context-free rewriting systems.",[0],"in particular, we cast new light on the relationship between ccg and other mildly context-sensitive formalisms such as tree-adjoining grammar (tag; joshi and schabes (1997)) and linear context-free rewrite systems (lcfrs; vijay-shanker et al (1987))",[0],12,result,5,5.0,0.8333333333333334,207.0,0.8884120171673819,13.0,0.34210526315789475,0,0.0,0.0,0.0,0.0,0.0,5 discussion,abstract
P87-1015,E09-1053,[207],"we outlined the definition of a family of constrained grammatical formalisms, called linear context-free rewriting systems.",[0],"2 by this result, ccg falls in line with context-free grammars, tag, and lcfrs, whose sets of deriva tional structures are all regular (vijay-shanker et al., 1987)",[0],13,result,5,5.0,0.8333333333333334,207.0,0.8884120171673819,13.0,0.34210526315789475,0,0.0,0.0,0.0,0.0,0.0,5 discussion,abstract
P87-1015,E09-1053,[19],it can be easily shown from thatcher's result that the path set of every local set is a regular set.,[0],"it is important to note that while ccg derivations themselves can be seen as trees as well, they do not always form regular tree languages (vijay-shanker et al, 1987)",[0],14,method,2,2.0,0.3333333333333333,19.0,0.0815450643776824,4.0,0.05063291139240506,0,0.0,0.0,0.0,0.0,0.0,2 tree sets of various formalisms,abstract
P87-1015,N10-1035,[119],"in defining lcfrs's, we hope to generalize the definition of cfg's to formalisms manipulating any structure, e.g. strings, trees, or graphs.",[0],"on this line of investigation, mildly context-sensitive grammar formalisms have been introduced (joshi,1985), including, among several others, the tree ad joining grammars (tags) of joshi et al (1975) .linear context-free rewriting system (lcfrs), introduced by vijay-shanker et al (1987), is a mildly context-sensitive formalism that allows the derivation of tuples of strings ,i.e., discontinuous phrases",[0],15,aim,4,4.0,0.6666666666666666,119.0,0.5107296137339056,4.0,0.05063291139240506,0,0.0,0.0,0.0,0.0,0.0,4 linear context-free rewriting systems,abstract
P87-1015,P12-1053,[118],"in the remainder of the paper, we outline how a class of linear context-free rewriting systems (lcfrs's) may be defined and sketch how semilinearity and polynomial recognition of these systems follows.",[0],"cftg are weakly equivalent to the simple macro grammars of fischer (1968), which are a notational variant of the well-nested linear context-free rewriting systems (lcfrs) of vijay-shanker et al (1987) and the well-nested multiple context-free grammars (mcfg) of seki et al (1991) .3 thus, cftg are mildly context-sensitive since their generated string languages are semi-linear and can be parsed in polynomial time (go ?mez-rodr? ?guez et al, 2010)",[0],16,aim,4,4.0,0.6666666666666666,118.0,0.5064377682403434,3.0,0.0379746835443038,0,0.0,0.0,0.0,0.0,0.0,4 linear context-free rewriting systems,abstract
P87-1015,P01-1018,[205],independence of paths at this level reflects context freeness of rewriting and suggests why they can be recognized efficiently.,[0],"the approach that vijay-shanker et al (1987) and weir (1988) take, elaborated on by becker et al (1992), is to identify a very general class of formalisms, which they call linear context free rewriting systems (cfrss), and define for this class a large space of structural descriptions which serves as a common ground in which the strong generative capacities of these formalisms can be compared",[0],1,method,5,5.0,0.8333333333333334,205.0,0.8798283261802575,11.0,0.2894736842105263,0,0.0,0.0,0.0,0.0,0.0,5 discussion,abstract
P87-1015,E09-1055,[229],"in addition, the restricted version of cg's (discussed in section 6) generates tree sets with independent paths and we hope that it can be included in a more general definition of lcfrs's containing formalisms whose tree sets have path sets that are themselves lcfrl's (as in the case of the restricted indexed grammars, and the hierarchy defined by weir).",[0],"here we use the standard definition of lcfrs (vijay-shanker et al, 1987) and only fix our notation; for a more thorough discussion of this formal ism, we refer to the literature. let g be an lcfrs",[0],2,method,5,5.0,0.8333333333333334,229.0,0.9828326180257511,35.0,0.9210526315789473,0,0.0,0.0,0.0,0.0,0.0,5 discussion,abstract
P87-1015,W07-2214,[146],"since every cfl is known to be semilinear (parikh, 1966), in order to show semilinearity of some language, we need only show the existence of a letter equivalent cfl our definition of lcfrs's insists that the composition operations are linear and nonerasing.",[0],"there are many (structural) mildly context sensitive grammar formalisms ,e.g .mcfg ,lcfrs, mg, and they have been shown to be equivalent (vijay-shanker et al., 1987)",[0],3,method,4,4.0,0.6666666666666666,146.0,0.6266094420600858,31.0,0.3924050632911392,0,0.0,0.0,0.0,0.0,0.0,4 linear context-free rewriting systems,abstract
P87-1015,P09-2003,[201],"it is interesting to note, however, that the ability to produce a bounded number of dependent paths (where two dependent paths can share an unbounded amount of information) does not require machinery as powerful as that used in lfg, fug and ig's.",[0],"they are in particular more powerful than linear context-free rewriting systems (lcfrs) (vijay-shanker et al, 1987)",[0],4,method,5,5.0,0.8333333333333334,201.0,0.8626609442060086,7.0,0.18421052631578946,0,0.0,0.0,0.0,0.0,0.0,5 discussion,abstract
P87-1015,P09-1111,[151],we now turn our attention to the recognition of string languages generated by these formalisms (lcfrl's).,[0],"following this line, (vijay-shanker et al, 1987) have introduced a formalism called linear context-free rewriting systems (lcfrss) that has received much attention in later years by the community",[0],5,method,4,4.0,0.6666666666666666,151.0,0.648068669527897,36.0,0.45569620253164556,0,0.0,0.0,0.0,0.0,0.0,4 linear context-free rewriting systems,abstract
P87-1015,P09-1111,[222],"however, in order to capture the properties of various grammatical systems under consideration, our notation is more restrictive that ilfp, which was designed as a general logical notation to characterize the complete class of languages that are recognizable in polynomial time.",[0],"we briefly summarize here the terminology and notation that we adopt for lcfrs; for detailed definitions, see (vijay-shanker et al, 1987)",[0],6,method,5,5.0,0.8333333333333334,222.0,0.9527896995708155,28.0,0.7368421052631579,0,0.0,0.0,0.0,0.0,0.0,5 discussion,abstract
P87-1015,P07-1021,"[22, 23]","gazdar (1985) argues this is the appropriate analysis of unbounded dependencies in the hypothetical scandinavian language norwedish.
he also argues that paired english complementizers may also require structural descriptions whose path sets have nested dependencies.",[0],"we write regd.k/ to refer to the class of regular dependency languages with a gap-degree bounded by k. linear context-free rewriting systems gap-restricted dependency languages are closely related to linear context-free rewriting systems (lcfrs) (vijay-shanker et al, 1987), a class of formal systems that generalizes several mildly context-sensitive grammar formalisms",[0],7,method,2_2,2.0,0.3333333333333333,22.5,0.09656652360515021,7.5,0.0949367088607595,0,0.0,0.0,0.0,0.0,0.0,"2 tree sets of various formalisms, 2 tree sets of various formalisms",abstract
P87-1015,N09-1061,[156],giving a recognition algorithm for lcfrl's involves describing the substrings of the input that are spanned by the structures derived by the lcfrs's and how the composition operation combines these substrings.,[0],"this observation is in line with empirical studies in the context of dependency parsing, where the need for formalisms with higher fan-out has been observed even in standard, single language texts (kuhlmann and nivre, 2006) .in this paper, we present an algorithm that computes optimal decompositions of rules in the formalism of linear context-free rewriting systems (lcfrs) (vijay-shanker et al, 1987)",[0],8,method,4,4.0,0.6666666666666666,156.0,0.6695278969957081,41.0,0.5189873417721519,0,0.0,0.0,0.0,0.0,0.0,4 linear context-free rewriting systems,abstract
P87-1015,N09-1061,[221],"members of lcfrs whose operations have this property can be translated into the ilfp notation (rounds, 1985).",[0],"we briefly summarize the terminology and notation that we adopt for lcfrs; for detailed definitions, see vijay-shanker et al (1987)",[0],9,method,5,5.0,0.8333333333333334,221.0,0.9484978540772532,27.0,0.7105263157894737,0,0.0,0.0,0.0,0.0,0.0,5 discussion,abstract
P87-1015,W10-1407,[54],an ig can be viewed as a cfg in which each nonterminal is associated with a stack.,[0],"lcfrs (vijay-shanker et al, 1987) are anatural extension of cfg in which a single nonterminal node can dominate more than one continuous span of terminals",[0],10,method,2,2.0,0.3333333333333333,54.0,0.2317596566523605,39.0,0.4936708860759494,0,0.0,0.0,0.0,0.0,0.0,2 tree sets of various formalisms,abstract
P87-1015,W10-1407,[128],"as in the case of the derivation trees of cfg's, nodes are labeled by a member of some finite set of symbols (perhaps only implicit in the grammar as in tag's) used to denote derived structures.",[0],"a lcfrs (vijay-shanker et al, 1987) is a tuple g= (n, t, v, p, s )wherea) n is a finite set of non-terminals with a function dim: n? n that determines the fan-out of each a? n; b) t and v are disjoint finite sets of terminals and variables; c) s? n is the start symbol with dim (s)= 1; d) p is a finite set of rewriting rules a (? 1,..",[0],11,method,4,4.0,0.6666666666666666,128.0,0.5493562231759657,13.0,0.16455696202531644,0,0.0,0.0,0.0,0.0,0.0,4 linear context-free rewriting systems,abstract
P87-1015,E09-1053,[217],"in considering the recognition of these languages, we were forced to be more specific regarding the relationship between the structures derived by these formalisms and the substrings they span.",[0],"in particular, we cast new light on the relationship between ccg and other mildly context-sensitive formalisms such as tree-adjoining grammar (tag; joshi and schabes (1997)) and linear context-free rewrite systems (lcfrs; vijay-shanker et al (1987))",[0],12,method,5,5.0,0.8333333333333334,217.0,0.9313304721030042,23.0,0.6052631578947368,0,0.0,0.0,0.0,0.0,0.0,5 discussion,abstract
P87-1015,E09-1053,[16],"from thatcher's (1973) work, it is obvious that the complexity of the set of paths from root to frontier of trees in a local set (the tree set of a cfg) is regular'.",[0],"2 by this result, ccg falls in line with context-free grammars, tag, and lcfrs, whose sets of deriva tional structures are all regular (vijay-shanker et al., 1987)",[0],13,method,2,2.0,0.3333333333333333,16.0,0.06866952789699571,1.0,0.012658227848101266,0,0.0,0.0,0.0,0.0,0.0,2 tree sets of various formalisms,abstract
P87-1015,E09-1053,[16],"from thatcher's (1973) work, it is obvious that the complexity of the set of paths from root to frontier of trees in a local set (the tree set of a cfg) is regular'.",[0],"it is important to note that while ccg derivations themselves can be seen as trees as well, they do not always form regular tree languages (vijay-shanker et al, 1987)",[0],14,method,2,2.0,0.3333333333333333,16.0,0.06866952789699571,1.0,0.012658227848101266,0,0.0,0.0,0.0,0.0,0.0,2 tree sets of various formalisms,abstract
P87-1015,N10-1035,[214],lcfrs's share several properties possessed by the class of mildly context-sensitive formalisms discussed by joshi (1983/85).,[0],"on this line of investigation, mildly context-sensitive grammar formalisms have been introduced (joshi,1985), including, among several others, the tree ad joining grammars (tags) of joshi et al (1975) .linear context-free rewriting system (lcfrs), introduced by vijay-shanker et al (1987), is a mildly context-sensitive formalism that allows the derivation of tuples of strings ,i.e., discontinuous phrases",[0],15,method,5,5.0,0.8333333333333334,214.0,0.9184549356223176,20.0,0.5263157894736842,0,0.0,0.0,0.0,0.0,0.0,5 discussion,abstract
P87-1015,P12-1053,[35],"tag's can be used to give the structural descriptions discussed by gazdar (1985) for the unbounded nested dependencies in norwedish, for cross serial dependencies in dutch subordinate clauses, and for the nestings of paired english complementizers.",[0],"cftg are weakly equivalent to the simple macro grammars of fischer (1968), which are a notational variant of the well-nested linear context-free rewriting systems (lcfrs) of vijay-shanker et al (1987) and the well-nested multiple context-free grammars (mcfg) of seki et al (1991) .3 thus, cftg are mildly context-sensitive since their generated string languages are semi-linear and can be parsed in polynomial time (go ?mez-rodr? ?guez et al, 2010)",[0],16,method,2,2.0,0.3333333333333333,35.0,0.15021459227467812,20.0,0.25316455696202533,0,0.0,0.0,0.0,0.0,0.0,2 tree sets of various formalisms,abstract
P87-1015,P01-1018,[165],"this class of formalisms have the properties that their derivation trees are local sets, and manipulate objects, using a finite number of composition operations that use a finite number of symbols.",[0],"the approach that vijay-shanker et al (1987) and weir (1988) take, elaborated on by becker et al (1992), is to identify a very general class of formalisms, which they call linear context free rewriting systems (cfrss), and define for this class a large space of structural descriptions which serves as a common ground in which the strong generative capacities of these formalisms can be compared",[0],1,method,4,4.0,0.6666666666666666,165.0,0.7081545064377682,50.0,0.6329113924050633,0,0.0,0.0,0.0,0.0,0.0,4 linear context-free rewriting systems,abstract
P87-1015,E09-1055,[119],"in defining lcfrs's, we hope to generalize the definition of cfg's to formalisms manipulating any structure, e.g. strings, trees, or graphs.",[0],"here we use the standard definition of lcfrs (vijay-shanker et al, 1987) and only fix our notation; for a more thorough discussion of this formal ism, we refer to the literature. let g be an lcfrs",[0],2,method,4,4.0,0.6666666666666666,119.0,0.5107296137339056,4.0,0.05063291139240506,0,0.0,0.0,0.0,0.0,0.0,4 linear context-free rewriting systems,abstract
P87-1015,W07-2214,[3],much of the study of grammatical systems in computational linguistics has been focused on the weak generative capacity of grammatical formalism.,[0],"there are many (structural) mildly context sensitive grammar formalisms ,e.g .mcfg ,lcfrs, mg, and they have been shown to be equivalent (vijay-shanker et al., 1987)",[0],3,method,1,1.0,0.16666666666666666,3.0,0.012875536480686695,1.0,0.07692307692307693,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P87-1015,P09-2003,[118],"in the remainder of the paper, we outline how a class of linear context-free rewriting systems (lcfrs's) may be defined and sketch how semilinearity and polynomial recognition of these systems follows.",[0],"they are in particular more powerful than linear context-free rewriting systems (lcfrs) (vijay-shanker et al, 1987)",[0],4,method,4,4.0,0.6666666666666666,118.0,0.5064377682403434,3.0,0.0379746835443038,0,0.0,0.0,0.0,0.0,0.0,4 linear context-free rewriting systems,abstract
P87-1015,P09-1111,[118],"in the remainder of the paper, we outline how a class of linear context-free rewriting systems (lcfrs's) may be defined and sketch how semilinearity and polynomial recognition of these systems follows.",[0],"following this line, (vijay-shanker et al, 1987) have introduced a formalism called linear context-free rewriting systems (lcfrss) that has received much attention in later years by the community",[0],5,method,4,4.0,0.6666666666666666,118.0,0.5064377682403434,3.0,0.0379746835443038,0,0.0,0.0,0.0,0.0,0.0,4 linear context-free rewriting systems,abstract
P87-1015,P09-1111,[133],"to show that the derivation trees of any grammar in lcfrs is a local set, we can rewrite the annotated derivation trees such that every node is labelled by a pair to include the composition operations.",[0],"we briefly summarize here the terminology and notation that we adopt for lcfrs; for detailed definitions, see (vijay-shanker et al, 1987)",[0],6,method,4,4.0,0.6666666666666666,133.0,0.5708154506437768,18.0,0.22784810126582278,0,0.0,0.0,0.0,0.0,0.0,4 linear context-free rewriting systems,abstract
P87-1015,P07-1021,[138],we can show that languages generated by lcfrs's are semilinear as long as the composition operation does not remove any terminal symbols from its arguments.,[0],"we write regd.k/ to refer to the class of regular dependency languages with a gap-degree bounded by k. linear context-free rewriting systems gap-restricted dependency languages are closely related to linear context-free rewriting systems (lcfrs) (vijay-shanker et al, 1987), a class of formal systems that generalizes several mildly context-sensitive grammar formalisms",[0],7,method,4,4.0,0.6666666666666666,138.0,0.592274678111588,23.0,0.2911392405063291,0,0.0,0.0,0.0,0.0,0.0,4 linear context-free rewriting systems,abstract
P87-1015,N09-1061,[156],giving a recognition algorithm for lcfrl's involves describing the substrings of the input that are spanned by the structures derived by the lcfrs's and how the composition operation combines these substrings.,[0],"this observation is in line with empirical studies in the context of dependency parsing, where the need for formalisms with higher fan-out has been observed even in standard, single language texts (kuhlmann and nivre, 2006) .in this paper, we present an algorithm that computes optimal decompositions of rules in the formalism of linear context-free rewriting systems (lcfrs) (vijay-shanker et al, 1987)",[0],8,method,4,4.0,0.6666666666666666,156.0,0.6695278969957081,41.0,0.5189873417721519,0,0.0,0.0,0.0,0.0,0.0,4 linear context-free rewriting systems,abstract
P87-1015,N09-1061,[118],"in the remainder of the paper, we outline how a class of linear context-free rewriting systems (lcfrs's) may be defined and sketch how semilinearity and polynomial recognition of these systems follows.",[0],"we briefly summarize the terminology and notation that we adopt for lcfrs; for detailed definitions, see vijay-shanker et al (1987)",[0],9,method,4,4.0,0.6666666666666666,118.0,0.5064377682403434,3.0,0.0379746835443038,0,0.0,0.0,0.0,0.0,0.0,4 linear context-free rewriting systems,abstract
P87-1015,W10-1407,[119],"in defining lcfrs's, we hope to generalize the definition of cfg's to formalisms manipulating any structure, e.g. strings, trees, or graphs.",[0],"lcfrs (vijay-shanker et al, 1987) are anatural extension of cfg in which a single nonterminal node can dominate more than one continuous span of terminals",[0],10,method,4,4.0,0.6666666666666666,119.0,0.5107296137339056,4.0,0.05063291139240506,0,0.0,0.0,0.0,0.0,0.0,4 linear context-free rewriting systems,abstract
P87-1015,W10-1407,[133],"to show that the derivation trees of any grammar in lcfrs is a local set, we can rewrite the annotated derivation trees such that every node is labelled by a pair to include the composition operations.",[0],"a lcfrs (vijay-shanker et al, 1987) is a tuple g= (n, t, v, p, s )wherea) n is a finite set of non-terminals with a function dim: n? n that determines the fan-out of each a? n; b) t and v are disjoint finite sets of terminals and variables; c) s? n is the start symbol with dim (s)= 1; d) p is a finite set of rewriting rules a (? 1,..",[0],11,method,4,4.0,0.6666666666666666,133.0,0.5708154506437768,18.0,0.22784810126582278,0,0.0,0.0,0.0,0.0,0.0,4 linear context-free rewriting systems,abstract
P87-1015,E09-1053,[164],"although embedding this version of lcfrs's in the framework of ilfp developed by rounds (1985) is straightforward, our motivation was to capture properties shared by a family of grammatical systems and generalize them defining a class of related formalisms.",[0],"in particular, we cast new light on the relationship between ccg and other mildly context-sensitive formalisms such as tree-adjoining grammar (tag; joshi and schabes (1997)) and linear context-free rewrite systems (lcfrs; vijay-shanker et al (1987))",[0],12,method,4,4.0,0.6666666666666666,164.0,0.703862660944206,49.0,0.620253164556962,0,0.0,0.0,0.0,0.0,0.0,4 linear context-free rewriting systems,abstract
P87-1015,E09-1053,[204],"the similarities become apparent when they are studied at the level of derivation structures: derivation nee sets of cfg's, hg's, tag's, and mctag's are all local sets.",[0],"2 by this result, ccg falls in line with context-free grammars, tag, and lcfrs, whose sets of deriva tional structures are all regular (vijay-shanker et al., 1987)",[0],13,method,5,5.0,0.8333333333333334,204.0,0.8755364806866953,10.0,0.2631578947368421,0,0.0,0.0,0.0,0.0,0.0,5 discussion,abstract
P87-1015,E09-1053,[9],"we examine both the complexity of the paths of trees in the tree sets, and the kinds of dependencies that the formalisms can impose between paths.",[0],"it is important to note that while ccg derivations themselves can be seen as trees as well, they do not always form regular tree languages (vijay-shanker et al, 1987)",[0],14,method,1,1.0,0.16666666666666666,9.0,0.03862660944206009,7.0,0.5384615384615384,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
P87-1015,N10-1035,[28],a tag consists of a finite set of elementary trees that are either initial trees or auxiliary trees.,[0],"on this line of investigation, mildly context-sensitive grammar formalisms have been introduced (joshi,1985), including, among several others, the tree ad joining grammars (tags) of joshi et al (1975) .linear context-free rewriting system (lcfrs), introduced by vijay-shanker et al (1987), is a mildly context-sensitive formalism that allows the derivation of tuples of strings ,i.e., discontinuous phrases",[0],15,method,2,2.0,0.3333333333333333,28.0,0.12017167381974249,13.0,0.16455696202531644,0,0.0,0.0,0.0,0.0,0.0,2 tree sets of various formalisms,abstract
P87-1015,P12-1053,[138],we can show that languages generated by lcfrs's are semilinear as long as the composition operation does not remove any terminal symbols from its arguments.,[0],"cftg are weakly equivalent to the simple macro grammars of fischer (1968), which are a notational variant of the well-nested linear context-free rewriting systems (lcfrs) of vijay-shanker et al (1987) and the well-nested multiple context-free grammars (mcfg) of seki et al (1991) .3 thus, cftg are mildly context-sensitive since their generated string languages are semi-linear and can be parsed in polynomial time (go ?mez-rodr? ?guez et al, 2010)",[0],16,method,4,4.0,0.6666666666666666,138.0,0.592274678111588,23.0,0.2911392405063291,0,0.0,0.0,0.0,0.0,0.0,4 linear context-free rewriting systems,abstract
W06-2932,W06-2920,[86],unlabeled accuracy for all verbs increases from 71% to 73% and for all conjunctions from 71% to 74%.,[0],"introduce through post-processing ,e.g. through reattachment rules (bick, 2006) or if the change increases overall parse tree probability (mcdonald et al, 2006)",[0],2,result,6,6.0,0.75,86.0,0.7747747747747747,8.0,0.32,0,0.0,0.0,0.0,0.0,0.0,6 detailed analysis,abstract
W06-2932,W06-2920,[79],"although overall unlabeled accuracy is 86%, most verbs and some conjunctions attach to their head words with much lower accuracy: 69% for main verbs, 75% for the verb ser, and 65% for coordinating conjunctions.",[0],table 5 shows the official results for submitted parser outputs.31 the two participant groups with the highest total score are mcdonald et al (2006) and nivre et al (2006),[0],3,result,6,6.0,0.75,79.0,0.7117117117117117,1.0,0.04,0,0.0,0.0,0.0,0.0,0.0,6 detailed analysis,abstract
W06-2932,W06-2920,[79],"although overall unlabeled accuracy is 86%, most verbs and some conjunctions attach to their head words with much lower accuracy: 69% for main verbs, 75% for the verb ser, and 65% for coordinating conjunctions.",[0],"even though mcdonald et al (2006) and nivre et al (2006) obtained very similar overall scores, a more detailed look at their performance shows clear differences",[0],4,result,6,6.0,0.75,79.0,0.7117117117117117,1.0,0.04,0,0.0,0.0,0.0,0.0,0.0,6 detailed analysis,abstract
W06-2932,W08-1007,[79],"although overall unlabeled accuracy is 86%, most verbs and some conjunctions attach to their head words with much lower accuracy: 69% for main verbs, 75% for the verb ser, and 65% for coordinating conjunctions.",[0],"the high est score on parsing german in the conll-x shared task was obtained by the system of mcdonald et al (2006) with a las of 87.34 based on the tiger tree bank, but we want to stress that these results are not comparable due to different data sets (anda different policy regarding the inclusion of punctuation) .the constituency versions were evaluated according to the labeled recall (lr), labeled precision (lp) and labeled f-score (lf)",[0],5,result,6,6.0,0.75,79.0,0.7117117117117117,1.0,0.04,0,0.0,0.0,0.0,0.0,0.0,6 detailed analysis,abstract
W06-2932,W09-1210,[22],"an exact projective and an approximate non-projective parsing algorithm are presented, since it is shown that nonprojective dependency parsing becomes np-hard when features are extended beyond a single edge.",[0],mcdonald et al (2006) use an additional algorithm,[0],6,method,2,2.0,0.25,22.0,0.1981981981981982,4.0,0.3076923076923077,0,0.0,0.0,0.0,0.0,0.0,2 stage 1: unlabeled parsing,abstract
W06-2932,W12-3407,[54],"based on performance from a held-out section of the training data, we used non-projective parsing algorithms for czech, danish, dutch, german, japanese, portuguese and slovene, and projective parsing algorithms for arabic, bulgarian, chinese, spanish, swedish and turkish.",[0],"regarding the data-driven parsers, we have made use of maltparser (nivre et al, 2007b) and mst parser (mcdonald et al, 2006), two state of the art dependency parsers representing two dominant approaches in data-driven dependency parsing, and that have been successfully applied to typologically different languages and tree banks (mcdonald and nivre, 2007)",[0],7,method,4,4.0,0.5,54.0,0.4864864864864865,2.0,0.2,0,0.0,0.0,0.0,0.0,0.0,4 results,abstract
W06-2932,I08-1012,[12],in this paper we describe a two-stage discriminative parsing approach consisting of an unlabeled parser and a subsequent edge labeler.,[0],"in fact, our approach can also be applied to other parsers, such as (yamada and matsumoto, 2003)? s parser, (mcdonald et al., 2006)? s parser, and so on",[0],8,method,1,1.0,0.125,12.0,0.10810810810810811,8.0,0.5714285714285714,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W06-2932,N07-1050,[22],"an exact projective and an approximate non-projective parsing algorithm are presented, since it is shown that nonprojective dependency parsing becomes np-hard when features are extended beyond a single edge.",[0],"we have shown that, for languages with a7mcdonald et al (2006) use post-processing for non projective dependencies and for labeling",[0],11,method,2,2.0,0.25,22.0,0.1981981981981982,4.0,0.3076923076923077,0,0.0,0.0,0.0,0.0,0.0,2 stage 1: unlabeled parsing,abstract
W06-2932,D07-1122,[41],"to model this we treat the labeling of the edges (i, j1), ... , (i, jm) as a sequence labeling problem, we use a first-order markov factorization of the score s(l(i,jm), l(i,jm�1), i, y, x) in which each factor is the score of labeling the adjacent edges (i, jm) and (i, jm−1) in the tree y.",[0],"as described in (mcdonald et al, 2006), we treat the labeling of dependencies as a sequence labeling problem",[0],12,method,3,3.0,0.375,41.0,0.36936936936936937,10.0,0.47619047619047616,0,0.0,0.0,0.0,0.0,0.0,3 stage 2: label classification,abstract
W06-2932,D07-1015,[24],"its power lies in the ability to define a rich set of features over parsing decisions, as well as surface level features relative to these decisions.",[0],5it should be noted that mcdonald et al (2006) use a richer feature set that is incomparable to our features,[0],14,method,2,2.0,0.25,24.0,0.21621621621621623,6.0,0.46153846153846156,0,0.0,0.0,0.0,0.0,0.0,2 stage 1: unlabeled parsing,abstract
W06-2932,D10-1004,[79],"although overall unlabeled accuracy is 86%, most verbs and some conjunctions attach to their head words with much lower accuracy: 69% for main verbs, 75% for the verb ser, and 65% for coordinating conjunctions.",[0],"entries marked with? are the highest reported in the literature, to the best of our knowledge, beating (sometimes slightly) mcdonald et al (2006), martins et al (2008), martins et al (2009), and, in the case of english proj., also the third-order parser of koo and collins (2010), which achieves 93.04% on that dataset (their experiments in czech are not comparable, since the datasets are different)",[0],18,result,6,6.0,0.75,79.0,0.7117117117117117,1.0,0.04,0,0.0,0.0,0.0,0.0,0.0,6 detailed analysis,abstract
W06-2932,P08-1108,[12],in this paper we describe a two-stage discriminative parsing approach consisting of an unlabeled parser and a subsequent edge labeler.,[0],"the specific graph-based model studied in this work is that presented by mcdonald et al (2006), which factors scores over pairs of arcs (instead of just single arcs) and uses near exhaustive search for unlabeled parsing coupled with a separate classifier to label each arc. we call this system mstparser, or simply mst for short, which is also the name of the freely available implementation.2 2.3 transition-based models",[0],19,method,1,1.0,0.125,12.0,0.10810810810810811,8.0,0.5714285714285714,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W06-2932,P08-1108,[43],"for score functions, we use simple dot products between high dimensional feature representations and a weight vector assuming we have an appropriate feature representation, we can find the highest scoring label sequence with viterbi’s algorithm.",[0],"more precisely, dependency arcs (or pairs of arcs) are first represented by a high dimensional feature vector f (i, j, l)? rk, where f is typically a bi nary feature vector over properties of the arc as well as the surrounding input (mcdonald et al, 2005a; mcdonald et al, 2006)",[0],20,method,3,3.0,0.375,43.0,0.38738738738738737,12.0,0.5714285714285714,0,0.0,0.0,0.0,0.0,0.0,3 stage 2: label classification,abstract
W06-2932,W06-2920,[5],often in language processing we require a deep syntactic representation of a sentence in order to assist further processing.,[0],"introduce through post-processing ,e.g. through reattachment rules (bick, 2006) or if the change increases overall parse tree probability (mcdonald et al, 2006)",[0],2,method,1,1.0,0.125,5.0,0.04504504504504504,1.0,0.07142857142857142,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W06-2932,W06-2920,[36],"however, in a two stage system we can incorporate features over the entire output of the unlabeled parser since that structure is fixed as input.",[0],table 5 shows the official results for submitted parser outputs.31 the two participant groups with the highest total score are mcdonald et al (2006) and nivre et al (2006),[0],3,method,3,3.0,0.375,36.0,0.32432432432432434,5.0,0.23809523809523808,0,0.0,0.0,0.0,0.0,0.0,3 stage 2: label classification,abstract
W06-2932,W06-2920,[61],"in fact, for every language our models perform significantly higher than the average performance for all the systems reported in buchholz et al. (2006).",[0],"even though mcdonald et al (2006) and nivre et al (2006) obtained very similar overall scores, a more detailed look at their performance shows clear differences",[0],4,method,4,4.0,0.5,61.0,0.5495495495495496,9.0,0.9,0,0.0,0.0,0.0,0.0,0.0,4 results,abstract
W06-2932,W08-1007,[76],"for instance, sequential labeling improves the labeling of 2this difference was much larger for experiments in which gold standard unlabeled dependencies are used. objects from 81.7%/75.6% to 84.2%/81.3% (labeled precision/recall) and the labeling of subjects from 86.8%/88.2% to 90.5%/90.4% for swedish.",[0],"the high est score on parsing german in the conll-x shared task was obtained by the system of mcdonald et al (2006) with a las of 87.34 based on the tiger tree bank, but we want to stress that these results are not comparable due to different data sets (anda different policy regarding the inclusion of punctuation) .the constituency versions were evaluated according to the labeled recall (lr), labeled precision (lp) and labeled f-score (lf)",[0],5,method,5,5.0,0.625,76.0,0.6846846846846847,14.0,0.875,0,0.0,0.0,0.0,0.0,0.0,5 general error analysis,abstract
W06-2932,W09-1210,[45],"furthermore, it made the system homogeneous in terms of learning algorithms since that is what is used to train our unlabeled parser (mcdonald and pereira, 2006).",[0],mcdonald et al (2006) use an additional algorithm,[0],6,method,3,3.0,0.375,45.0,0.40540540540540543,14.0,0.6666666666666666,0,0.0,0.0,0.0,0.0,0.0,3 stage 2: label classification,abstract
W06-2932,W12-3407,[106],"first, we plan on examining the performance difference between two-staged dependency parsing (as presented here) and joint parsing plus labeling.",[0],"regarding the data-driven parsers, we have made use of maltparser (nivre et al, 2007b) and mst parser (mcdonald et al, 2006), two state of the art dependency parsers representing two dominant approaches in data-driven dependency parsing, and that have been successfully applied to typologically different languages and tree banks (mcdonald and nivre, 2007)",[0],7,method,7,7.0,0.875,106.0,0.954954954954955,3.0,0.42857142857142855,0,0.0,0.0,0.0,0.0,0.0,7 conclusions,abstract
W06-2932,I08-1012,[12],in this paper we describe a two-stage discriminative parsing approach consisting of an unlabeled parser and a subsequent edge labeler.,[0],"in fact, our approach can also be applied to other parsers, such as (yamada and matsumoto, 2003)? s parser, (mcdonald et al., 2006)? s parser, and so on",[0],8,method,1,1.0,0.125,12.0,0.10810810810810811,8.0,0.5714285714285714,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W06-2932,N07-1050,[104],"we have presented results showing that the spanning tree dependency parsing framework of mcdonald et al. (mcdonald et al., 2005b; mcdonald and pereira, 2006) generalizes well to languages other than english.",[0],"but whereas the spanning tree parser of mcdonald et al (2006) and the pseudo-projective parser of nivre et al (2006) achieve this performance only with special preorpost-processing,7 the approach presented here derives a labeled non-projective graph in a single incremental process and hence at least has the advantage of simplicity",[0],9,method,7,7.0,0.875,104.0,0.9369369369369369,1.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,7 conclusions,abstract
W06-2932,N07-1050,[58],"these results show that the discriminative spanning tree parsing framework (mcdonald et al., 2005b; mcdonald and pereira, 2006) is easily adapted across all these languages.",[0],"moreover, it has better time complexity than the approximate second-order spanning tree parsing of mcdonald et al (2006), which has exponential complexity in the worst case (although this does not appear to be a problem in practice)",[0],10,method,4,4.0,0.5,58.0,0.5225225225225225,6.0,0.6,0,0.0,0.0,0.0,0.0,0.0,4 results,abstract
W06-2932,N07-1050,[64],"n/p: allow non-projective/force projective, s/a: sequential labeling/atomic labeling, m/b: include morphology features/no morphology features. assignment of edge labels instead of individual assignment, and a rich feature set that incorporates morphological properties when available.",[0],"we have shown that, for languages with a7mcdonald et al (2006) use post-processing for non projective dependencies and for labeling",[0],11,method,5,5.0,0.625,64.0,0.5765765765765766,2.0,0.125,0,0.0,0.0,0.0,0.0,0.0,5 general error analysis,abstract
W06-2932,D07-1122,[41],"to model this we treat the labeling of the edges (i, j1), ... , (i, jm) as a sequence labeling problem, we use a first-order markov factorization of the score s(l(i,jm), l(i,jm�1), i, y, x) in which each factor is the score of labeling the adjacent edges (i, jm) and (i, jm−1) in the tree y.",[0],"as described in (mcdonald et al, 2006), we treat the labeling of dependencies as a sequence labeling problem",[0],12,method,3,3.0,0.375,41.0,0.36936936936936937,10.0,0.47619047619047616,0,0.0,0.0,0.0,0.0,0.0,3 stage 2: label classification,abstract
W06-2932,W11-0314,[21],"that work extends the maximum spanning tree dependency parsing framework (mcdonald et al., 2005a; mcdonald et al., 2005b) to incorporate features over multiple edges in the dependency graph.",[0],"ulisse was tested against the output of two really different data? driven parsers: the first? order maximum spanning tree (mst) parser (mcdonald et al., 2006) and the desr parser (attardi, 2006) using support vector machine as learning algorithm",[0],13,method,2,2.0,0.25,21.0,0.1891891891891892,3.0,0.23076923076923078,0,0.0,0.0,0.0,0.0,0.0,2 stage 1: unlabeled parsing,abstract
W06-2932,D07-1015,[64],"n/p: allow non-projective/force projective, s/a: sequential labeling/atomic labeling, m/b: include morphology features/no morphology features. assignment of edge labels instead of individual assignment, and a rich feature set that incorporates morphological properties when available.",[0],5it should be noted that mcdonald et al (2006) use a richer feature set that is incomparable to our features,[0],14,method,5,5.0,0.625,64.0,0.5765765765765766,2.0,0.125,0,0.0,0.0,0.0,0.0,0.0,5 general error analysis,abstract
W06-2932,D10-1069,[104],"we have presented results showing that the spanning tree dependency parsing framework of mcdonald et al. (mcdonald et al., 2005b; mcdonald and pereira, 2006) generalizes well to languages other than english.",[0],"the dependency parsers that we compare are the deterministic shift-reduce maltparser (nivre et al, 2007) and the second-order minimum spanning tree algorithm based mstparser (mcdonald et al, 2006)",[0],16,method,7,7.0,0.875,104.0,0.9369369369369369,1.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,7 conclusions,abstract
W06-2932,D10-1004,[33],ideally one would like to make all parsing and labeling decisions jointly so that the shared knowledge of both decisions will help resolve any ambiguities.,[0],"entries marked with? are the highest reported in the literature, to the best of our knowledge, beating (sometimes slightly) mcdonald et al (2006), martins et al (2008), martins et al (2009), and, in the case of english proj., also the third-order parser of koo and collins (2010), which achieves 93.04% on that dataset (their experiments in czech are not comparable, since the datasets are different)",[0],18,method,3,3.0,0.375,33.0,0.2972972972972973,2.0,0.09523809523809523,0,0.0,0.0,0.0,0.0,0.0,3 stage 2: label classification,abstract
W06-2932,P08-1108,[41],"to model this we treat the labeling of the edges (i, j1), ... , (i, jm) as a sequence labeling problem, we use a first-order markov factorization of the score s(l(i,jm), l(i,jm�1), i, y, x) in which each factor is the score of labeling the adjacent edges (i, jm) and (i, jm−1) in the tree y.",[0],"the specific graph-based model studied in this work is that presented by mcdonald et al (2006), which factors scores over pairs of arcs (instead of just single arcs) and uses near exhaustive search for unlabeled parsing coupled with a separate classifier to label each arc. we call this system mstparser, or simply mst for short, which is also the name of the freely available implementation.2 2.3 transition-based models",[0],19,method,3,3.0,0.375,41.0,0.36936936936936937,10.0,0.47619047619047616,0,0.0,0.0,0.0,0.0,0.0,3 stage 2: label classification,abstract
W06-2932,P08-1108,[43],"for score functions, we use simple dot products between high dimensional feature representations and a weight vector assuming we have an appropriate feature representation, we can find the highest scoring label sequence with viterbi’s algorithm.",[0],"more precisely, dependency arcs (or pairs of arcs) are first represented by a high dimensional feature vector f (i, j, l)? rk, where f is typically a bi nary feature vector over properties of the arc as well as the surrounding input (mcdonald et al, 2005a; mcdonald et al, 2006)",[0],20,method,3,3.0,0.375,43.0,0.38738738738738737,12.0,0.5714285714285714,0,0.0,0.0,0.0,0.0,0.0,3 stage 2: label classification,abstract
W06-2932,W06-2920,[19],the first stage of our system creates an unlabeled parse y for an input sentence x.,[0],"introduce through post-processing ,e.g. through reattachment rules (bick, 2006) or if the change increases overall parse tree probability (mcdonald et al, 2006)",[0],2,method,2,2.0,0.25,19.0,0.17117117117117117,1.0,0.07692307692307693,0,0.0,0.0,0.0,0.0,0.0,2 stage 1: unlabeled parsing,abstract
W06-2932,W06-2920,[36],"however, in a two stage system we can incorporate features over the entire output of the unlabeled parser since that structure is fixed as input.",[0],table 5 shows the official results for submitted parser outputs.31 the two participant groups with the highest total score are mcdonald et al (2006) and nivre et al (2006),[0],3,method,3,3.0,0.375,36.0,0.32432432432432434,5.0,0.23809523809523808,0,0.0,0.0,0.0,0.0,0.0,3 stage 2: label classification,abstract
W06-2932,W06-2920,[57],"performance is measured through unlabeled accuracy, which is the percentage of words that modify the correct head in the dependency graph, and labeled accuracy, which is the percentage of words that modify the correct head and label the dependency edge correctly in the graph.",[0],"even though mcdonald et al (2006) and nivre et al (2006) obtained very similar overall scores, a more detailed look at their performance shows clear differences",[0],4,method,4,4.0,0.5,57.0,0.5135135135135135,5.0,0.5,0,0.0,0.0,0.0,0.0,0.0,4 results,abstract
W06-2932,W08-1007,[76],"for instance, sequential labeling improves the labeling of 2this difference was much larger for experiments in which gold standard unlabeled dependencies are used. objects from 81.7%/75.6% to 84.2%/81.3% (labeled precision/recall) and the labeling of subjects from 86.8%/88.2% to 90.5%/90.4% for swedish.",[0],"the high est score on parsing german in the conll-x shared task was obtained by the system of mcdonald et al (2006) with a las of 87.34 based on the tiger tree bank, but we want to stress that these results are not comparable due to different data sets (anda different policy regarding the inclusion of punctuation) .the constituency versions were evaluated according to the labeled recall (lr), labeled precision (lp) and labeled f-score (lf)",[0],5,method,5,5.0,0.625,76.0,0.6846846846846847,14.0,0.875,0,0.0,0.0,0.0,0.0,0.0,5 general error analysis,abstract
W06-2932,W09-1210,[54],"based on performance from a held-out section of the training data, we used non-projective parsing algorithms for czech, danish, dutch, german, japanese, portuguese and slovene, and projective parsing algorithms for arabic, bulgarian, chinese, spanish, swedish and turkish.",[0],mcdonald et al (2006) use an additional algorithm,[0],6,method,4,4.0,0.5,54.0,0.4864864864864865,2.0,0.2,0,0.0,0.0,0.0,0.0,0.0,4 results,abstract
W06-2932,W12-3407,[104],"we have presented results showing that the spanning tree dependency parsing framework of mcdonald et al. (mcdonald et al., 2005b; mcdonald and pereira, 2006) generalizes well to languages other than english.",[0],"regarding the data-driven parsers, we have made use of maltparser (nivre et al, 2007b) and mst parser (mcdonald et al, 2006), two state of the art dependency parsers representing two dominant approaches in data-driven dependency parsing, and that have been successfully applied to typologically different languages and tree banks (mcdonald and nivre, 2007)",[0],7,method,7,7.0,0.875,104.0,0.9369369369369369,1.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,7 conclusions,abstract
W06-2932,I08-1012,[12],in this paper we describe a two-stage discriminative parsing approach consisting of an unlabeled parser and a subsequent edge labeler.,[0],"in fact, our approach can also be applied to other parsers, such as (yamada and matsumoto, 2003)? s parser, (mcdonald et al., 2006)? s parser, and so on",[0],8,method,1,1.0,0.125,12.0,0.10810810810810811,8.0,0.5714285714285714,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W06-2932,N07-1050,[57],"performance is measured through unlabeled accuracy, which is the percentage of words that modify the correct head in the dependency graph, and labeled accuracy, which is the percentage of words that modify the correct head and label the dependency edge correctly in the graph.",[0],"but whereas the spanning tree parser of mcdonald et al (2006) and the pseudo-projective parser of nivre et al (2006) achieve this performance only with special preorpost-processing,7 the approach presented here derives a labeled non-projective graph in a single incremental process and hence at least has the advantage of simplicity",[0],9,method,4,4.0,0.5,57.0,0.5135135135135135,5.0,0.5,0,0.0,0.0,0.0,0.0,0.0,4 results,abstract
W06-2932,N07-1050,[58],"these results show that the discriminative spanning tree parsing framework (mcdonald et al., 2005b; mcdonald and pereira, 2006) is easily adapted across all these languages.",[0],"moreover, it has better time complexity than the approximate second-order spanning tree parsing of mcdonald et al (2006), which has exponential complexity in the worst case (although this does not appear to be a problem in practice)",[0],10,method,4,4.0,0.5,58.0,0.5225225225225225,6.0,0.6,0,0.0,0.0,0.0,0.0,0.0,4 results,abstract
W06-2932,N07-1050,[22],"an exact projective and an approximate non-projective parsing algorithm are presented, since it is shown that nonprojective dependency parsing becomes np-hard when features are extended beyond a single edge.",[0],"we have shown that, for languages with a7mcdonald et al (2006) use post-processing for non projective dependencies and for labeling",[0],11,method,2,2.0,0.25,22.0,0.1981981981981982,4.0,0.3076923076923077,0,0.0,0.0,0.0,0.0,0.0,2 stage 1: unlabeled parsing,abstract
W06-2932,D07-1122,[41],"to model this we treat the labeling of the edges (i, j1), ... , (i, jm) as a sequence labeling problem, we use a first-order markov factorization of the score s(l(i,jm), l(i,jm�1), i, y, x) in which each factor is the score of labeling the adjacent edges (i, jm) and (i, jm−1) in the tree y.",[0],"as described in (mcdonald et al, 2006), we treat the labeling of dependencies as a sequence labeling problem",[0],12,method,3,3.0,0.375,41.0,0.36936936936936937,10.0,0.47619047619047616,0,0.0,0.0,0.0,0.0,0.0,3 stage 2: label classification,abstract
W06-2932,W11-0314,[21],"that work extends the maximum spanning tree dependency parsing framework (mcdonald et al., 2005a; mcdonald et al., 2005b) to incorporate features over multiple edges in the dependency graph.",[0],"ulisse was tested against the output of two really different data? driven parsers: the first? order maximum spanning tree (mst) parser (mcdonald et al., 2006) and the desr parser (attardi, 2006) using support vector machine as learning algorithm",[0],13,method,2,2.0,0.25,21.0,0.1891891891891892,3.0,0.23076923076923078,0,0.0,0.0,0.0,0.0,0.0,2 stage 1: unlabeled parsing,abstract
W06-2932,D07-1015,[64],"n/p: allow non-projective/force projective, s/a: sequential labeling/atomic labeling, m/b: include morphology features/no morphology features. assignment of edge labels instead of individual assignment, and a rich feature set that incorporates morphological properties when available.",[0],5it should be noted that mcdonald et al (2006) use a richer feature set that is incomparable to our features,[0],14,method,5,5.0,0.625,64.0,0.5765765765765766,2.0,0.125,0,0.0,0.0,0.0,0.0,0.0,5 general error analysis,abstract
W06-2932,D10-1069,[21],"that work extends the maximum spanning tree dependency parsing framework (mcdonald et al., 2005a; mcdonald et al., 2005b) to incorporate features over multiple edges in the dependency graph.",[0],"the dependency parsers that we compare are the deterministic shift-reduce maltparser (nivre et al, 2007) and the second-order minimum spanning tree algorithm based mstparser (mcdonald et al, 2006)",[0],16,method,2,2.0,0.25,21.0,0.1891891891891892,3.0,0.23076923076923078,0,0.0,0.0,0.0,0.0,0.0,2 stage 1: unlabeled parsing,abstract
W06-2932,P08-1108,[57],"performance is measured through unlabeled accuracy, which is the percentage of words that modify the correct head in the dependency graph, and labeled accuracy, which is the percentage of words that modify the correct head and label the edge correctly in the graph.",[0],"the specific graph-based model studied in this work is that presented by mcdonald et al (2006), which factors scores over pairs of arcs (instead of just single arcs) and uses near exhaustive search for unlabeled parsing coupled with a separate classifier to label each arc. we call this system mstparser, or simply mst for short, which is also the name of the freely available implementation.2 2.3 transition-based models",[0],19,method,4,4.0,0.5,57.0,0.5135135135135135,5.0,0.5,0,0.0,0.0,0.0,0.0,0.0,4 results,abstract
W06-2932,P08-1108,[43],"for score functions, we use simple dot products between high dimensional feature representations and a weight vector assuming we have an appropriate feature representation, we can find the highest scoring label sequence with viterbi’s algorithm.",[0],"more precisely, dependency arcs (or pairs of arcs) are first represented by a high dimensional feature vector f (i, j, l)? rk, where f is typically a bi nary feature vector over properties of the arc as well as the surrounding input (mcdonald et al, 2005a; mcdonald et al, 2006)",[0],20,method,3,3.0,0.375,43.0,0.38738738738738737,12.0,0.5714285714285714,0,0.0,0.0,0.0,0.0,0.0,3 stage 2: label classification,abstract
W06-3114,W06-3120,[170],we carried out an extensive manual and automatic evaluation of machine translation performance on european language pairs.,[0],"the official results were slightly better because a lowercase evaluation was used, see (koehn and monz, 2006)",[0],1,method,7,7.0,0.7777777777777778,170.0,0.9497206703910615,1.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,5 conclusions,abstract
W06-3114,D07-1092,[8],the evaluation framework for the shared task is similar to the one used in last year’s shared task.,[0],"we are further focusing on the shared task of the workshop on statistical machine translation, which took place last year (koehn and monz, 2006) and consisted in translating spanish, german, and french texts from and to english",[0],2,method,2,2.0,0.2222222222222222,8.0,0.0446927374301676,1.0,0.037037037037037035,0,0.0,0.0,0.0,0.0,0.0,1 evaluation framework,abstract
W06-3114,C08-1074,[9],training and testing is based on the europarl corpus.,[0],"for our training and test data we used the english-french subset of the europarl corpus provided for the shared task (koehn and monz, 2006) at the statistical machine translation workshop held in conjunction with the 2006 hlt-naacl conference",[0],3,method,2,2.0,0.2222222222222222,9.0,0.05027932960893855,2.0,0.07407407407407407,0,0.0,0.0,0.0,0.0,0.0,1 evaluation framework,abstract
W06-3114,W07-0718,[36],"the bleu metric, as all currently proposed automatic metrics, is occasionally suspected to be biased towards statistical systems, especially the phrase-based systems currently in use.",[0],"the results of last year? s workshop further suggested that bleu systematically underestimated the quality of rule-based machine translation systems (koehn and monz, 2006)",[0],4,method,3,3.0,0.3333333333333333,36.0,0.2011173184357542,2.0,0.07407407407407407,0,0.0,0.0,0.0,0.0,0.0,2 automatic evaluation,abstract
W06-3114,P07-1083,[9],training and testing is based on the europarl corpus.,[0],"for the bi text-based annotation, we use publicly available word alignments from the europarl corpus, automatically generated by giza++ for frenchenglish (fr), spanish-english (es) and germanenglish (de) (koehn and monz, 2006)",[0],5,method,2,2.0,0.2222222222222222,9.0,0.05027932960893855,2.0,0.07407407407407407,0,0.0,0.0,0.0,0.0,0.0,1 evaluation framework,abstract
W06-3114,W07-0738,[36],"the bleu metric, as all currently proposed automatic metrics, is occasionally suspected to be biased towards statistical systems, especially the phrase-based systems currently in use.",[0],"evaluation results recently reported by callison-burch et al (2006) and koehn and monz (2006), revealed that, in certain cases, the bleu metric may not be a reliable mtquality indicator",[0],6,method,3,3.0,0.3333333333333333,36.0,0.2011173184357542,2.0,0.07407407407407407,0,0.0,0.0,0.0,0.0,0.0,2 automatic evaluation,abstract
W06-3114,W07-0738,[140],we confirm the finding by callison-burch et al. (2006) that the rule-based system of systran is not adequately appreciated by bleu.,[0],"for instance, callison-burch et al (2006) and koehn and monz (2006) reported and analyzed several cases of strong disagreement between system rankings provided by human assessors and those produced by the bleu metric (papineni et al, 2001)",[0],7,method,6,6.0,0.6666666666666666,140.0,0.7821229050279329,33.0,0.532258064516129,0,0.0,0.0,0.0,0.0,0.0,4 results and analysis,abstract
W06-3114,W07-0738,[140],we confirm the finding by callison-burch et al. (2006) that the rule-based system of systran is not adequately appreciated by bleu.,[0],wepresenta comparative study on the behavior of several metric representatives from each linguistic level in the context of some of the cases reported by koehn and monz (2006) and callison-burch et al (2006) (see section 3),[0],8,method,6,6.0,0.6666666666666666,140.0,0.7821229050279329,33.0,0.532258064516129,0,0.0,0.0,0.0,0.0,0.0,4 results and analysis,abstract
W06-3114,W07-0738,[140],we confirm the finding by callison-burch et al. (2006) that the rule-based system of systran is not adequately appreciated by bleu.,[0],weanalyze some of the cases reported by koehn and monz (2006) and callison-burch et al (2006),[0],9,method,6,6.0,0.6666666666666666,140.0,0.7821229050279329,33.0,0.532258064516129,0,0.0,0.0,0.0,0.0,0.0,4 results and analysis,abstract
W06-3114,D07-1030,[102],"confidence interval: to estimate confidence intervals for the average mean scores for the systems, we use standard significance testing.",[0],"we use the same method described in (koehn and monz, 2006) to perform the significance test",[0],10,method,5,5.0,0.5555555555555556,102.0,0.5698324022346368,18.0,0.782608695652174,0,0.0,0.0,0.0,0.0,0.0,adequacy fluency 5 all meaning flawless english 4 most meaning good english 3 much meaning non-native english 2 little meaning disfluent english 1 none incomprehensible,abstract
W06-3114,D07-1030,[84],"the human judges were presented with the following definition of adequacy and fluency, but no additional instructions:",[0],"we also manually evaluated the rbmt systems and smt systems in terms of both adequacy and fluency as defined in (koehn and monz, 2006)",[0],11,method,4,4.0,0.4444444444444444,84.0,0.4692737430167598,23.0,1.0,0,0.0,0.0,0.0,0.0,0.0,3 manual evaluation,abstract
W06-3114,W08-0406,[11],"to lower the barrier of entrance to the competition, we provided a complete baseline mt system, along with data resources.",[0],"the baseline is the psmt system used for the 2006 naacl smt workshop (koehn and monz, 2006) with phrase length 3 and a trigram language model (stolcke, 2002)",[0],12,method,2,2.0,0.2222222222222222,11.0,0.061452513966480445,4.0,0.14814814814814814,0,0.0,0.0,0.0,0.0,0.0,1 evaluation framework,abstract
W06-3114,W11-1002,[140],we confirm the finding by callison-burch et al. (2006) that the rule-based system of systran is not adequately appreciated by bleu.,[0],"callison-burch et al (2006 )andkoehn and monz (2006), for example, study situations where bleu strongly disagrees with human judgment of translation quality",[0],13,method,6,6.0,0.6666666666666666,140.0,0.7821229050279329,33.0,0.532258064516129,0,0.0,0.0,0.0,0.0,0.0,4 results and analysis,abstract
W06-3114,D07-1091,[126],"the test set included 2000 sentences from the europarl corpus, but also 1064 sentences out-ofdomain test data.",[0],"the english? german systems were trained on the full 751,088 sentence europarl corpus and evaluated on the wmt 2006 test set (koehn and monz, 2006)",[0],14,method,6,6.0,0.6666666666666666,126.0,0.7039106145251397,19.0,0.3064516129032258,0,0.0,0.0,0.0,0.0,0.0,4 results and analysis,abstract
W06-3114,D07-1091,[15],"out-of-domain test data is from the project syndicate web site, a compendium of political commentary.",[0],"we report results on the development test set, which is also the out-of-domain test set of the wmt06 workshop shared task (koehn and monz, 2006)",[0],15,method,2,2.0,0.2222222222222222,15.0,0.08379888268156424,8.0,0.2962962962962963,0,0.0,0.0,0.0,0.0,0.0,1 evaluation framework,abstract
W06-3114,P07-1108,[8],the evaluation framework for the shared task is similar to the one used in last year’s shared task.,[0],"a shared task to evaluate machine translation performance was organized as part of the naacl/hlt 2006 workshop on statistical ma chine translation (koehn and monz, 2006)",[0],16,method,2,2.0,0.2222222222222222,8.0,0.0446927374301676,1.0,0.037037037037037035,0,0.0,0.0,0.0,0.0,0.0,1 evaluation framework,abstract
W06-3114,E12-3010,[90],"another way to view the judgements is that they are less quality judgements of machine translation systems per se, but rankings of machine translation systems.",[0],"for the same reason, human evaluation metrics based on adequacy and fluency were not suitable either (koehn and monz, 2006)",[0],18,method,5,5.0,0.5555555555555556,90.0,0.5027932960893855,6.0,0.2608695652173913,0,0.0,0.0,0.0,0.0,0.0,adequacy fluency 5 all meaning flawless english 4 most meaning good english 3 much meaning non-native english 2 little meaning disfluent english 1 none incomprehensible,abstract
W06-3114,W09-0402,"[5, 6]","• we evaluated translation from english, in addition to into english.
english was again paired with german, french, and spanish.",[0],"the correlations on the document level were computed on the english, french, spanish and german texts generated by various translation systems in the framework of the first (koehn and monz, 2006), second (callison-burch et al, 2007) and third shared translation task (callison-burchet al, 2008)",[0],19,method,1_1,1.0,0.1111111111111111,5.5,0.030726256983240222,3.5,0.7,0,0.0,0.0,0.0,0.0,0.0,", ",abstract
W06-3114,W06-3120,[47.0],"because of this, we retokenized and lowercased submitted output with our own tokenizer, which was also used to prepare the training and test data.",[0],"the official results were slightly better because a lowercase evaluation was used, see (koehn and monz, 2006)",[0],1,method,3,3.0,0.3333333333333333,47.0,0.26256983240223464,13.0,0.48148148148148145,0,0.0,0.0,0.0,0.0,0.0,2 automatic evaluation,abstract
W06-3114,D07-1092,[8.0],the evaluation framework for the shared task is similar to the one used in last year’s shared task.,[0],"we are further focusing on the shared task of the workshop on statistical machine translation, which took place last year (koehn and monz, 2006) and consisted in translating spanish, german, and french texts from and to english",[0],2,method,2,2.0,0.2222222222222222,8.0,0.0446927374301676,1.0,0.037037037037037035,0,0.0,0.0,0.0,0.0,0.0,1 evaluation framework,abstract
W06-3114,C08-1074,[18.0],"in addition to the europarl test set, we also collected 29 editorials from the project syndicate website2, which are published in all the four languages of the shared task.",[0],"for our training and test data we used the english-french subset of the europarl corpus provided for the shared task (koehn and monz, 2006) at the statistical machine translation workshop held in conjunction with the 2006 hlt-naacl conference",[0],3,method,2,2.0,0.2222222222222222,18.0,0.1005586592178771,11.0,0.4074074074074074,0,0.0,0.0,0.0,0.0,0.0,1 evaluation framework,abstract
W06-3114,P07-1083,[18.0],"in addition to the europarl test set, we also collected 29 editorials from the project syndicate website2, which are published in all the four languages of the shared task.",[0],"for the bi text-based annotation, we use publicly available word alignments from the europarl corpus, automatically generated by giza++ for frenchenglish (fr), spanish-english (es) and germanenglish (de) (koehn and monz, 2006)",[0],5,method,2,2.0,0.2222222222222222,18.0,0.1005586592178771,11.0,0.4074074074074074,0,0.0,0.0,0.0,0.0,0.0,1 evaluation framework,abstract
W06-3114,W07-0738,[144.0],"our suspicion is that bleu is very sensitive to jargon, to selecting exactly the right words, and not synonyms that human judges may appreciate as equally good.",[0],"evaluation results recently reported by callison-burch et al (2006) and koehn and monz (2006), revealed that, in certain cases, the bleu metric may not be a reliable mtquality indicator",[0],6,result,6,6.0,0.6666666666666666,144.0,0.8044692737430168,37.0,0.5967741935483871,0,0.0,0.0,0.0,0.0,0.0,4 results and analysis,abstract
W06-3114,W07-0738,[145.0],"this is can not be the only explanation, since the discrepancy still holds, for instance, for out-of-domain french-english, where systran receives among the best adequacy and fluency scores, but a worse bleu score than all but one statistical system.",[0],"for instance, callison-burch et al (2006) and koehn and monz (2006) reported and analyzed several cases of strong disagreement between system rankings provided by human assessors and those produced by the bleu metric (papineni et al, 2001)",[0],7,result,6,6.0,0.6666666666666666,145.0,0.8100558659217877,38.0,0.6129032258064516,0,0.0,0.0,0.0,0.0,0.0,4 results and analysis,abstract
W06-3114,W07-0738,[103.0],"given a set of n sentences, we can compute the sample mean x� and sample variance s2 of the individual sentence judgements xi: the extend of the confidence interval [x−d, x+df can be computed by d = 1.96 ·�n (6) pairwise comparison: as for the automatic evaluation metric, we want to be able to rank different systems against each other, for which we need assessments of statistical significance on the differences between a pair of systems.",[0],wepresenta comparative study on the behavior of several metric representatives from each linguistic level in the context of some of the cases reported by koehn and monz (2006) and callison-burch et al (2006) (see section 3),[0],8,method,5,5.0,0.5555555555555556,103.0,0.5754189944134078,19.0,0.8260869565217391,0,0.0,0.0,0.0,0.0,0.0,adequacy fluency 5 all meaning flawless english 4 most meaning good english 3 much meaning non-native english 2 little meaning disfluent english 1 none incomprehensible,abstract
W06-3114,D07-1030,[50.0],"following this method, we repeatedly — say, 1000 times — sample sets of sentences from the output of each system, measure their bleu score, and use these 1000 bleu scores as basis for estimating a confidence interval.",[0],"we use the same method described in (koehn and monz, 2006) to perform the significance test",[0],11,method,3,3.0,0.3333333333333333,50.0,0.27932960893854747,16.0,0.5925925925925926,0,0.0,0.0,0.0,0.0,0.0,2 automatic evaluation,abstract
W06-3114,D07-1030,[68.0],"we asked participants to each judge 200–300 sentences in terms of fluency and adequacy, the most commonly used manual evaluation metrics.",[0],"we also manually evaluated the rbmt systems and smt systems in terms of both adequacy and fluency as defined in (koehn and monz, 2006)",[0],12,method,4,4.0,0.4444444444444444,68.0,0.37988826815642457,7.0,0.30434782608695654,0,0.0,0.0,0.0,0.0,0.0,3 manual evaluation,abstract
W06-3114,W08-0406,[170.0],we carried out an extensive manual and automatic evaluation of machine translation performance on european language pairs.,[0],"the baseline is the psmt system used for the 2006 naacl smt workshop (koehn and monz, 2006) with phrase length 3 and a trigram language model (stolcke, 2002)",[0],13,method,7,7.0,0.7777777777777778,170.0,0.9497206703910615,1.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,5 conclusions,abstract
W06-3114,D07-1091,[18.0],"in addition to the europarl test set, we also collected 29 editorials from the project syndicate website2, which are published in all the four languages of the shared task.",[0],"the english? german systems were trained on the full 751,088 sentence europarl corpus and evaluated on the wmt 2006 test set (koehn and monz, 2006)",[0],15,method,2,2.0,0.2222222222222222,18.0,0.1005586592178771,11.0,0.4074074074074074,0,0.0,0.0,0.0,0.0,0.0,1 evaluation framework,abstract
W06-3114,D07-1091,[170.0],we carried out an extensive manual and automatic evaluation of machine translation performance on european language pairs.,[0],"we report results on the development test set, which is also the out-of-domain test set of the wmt06 workshop shared task (koehn and monz, 2006)",[0],16,method,7,7.0,0.7777777777777778,170.0,0.9497206703910615,1.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,5 conclusions,abstract
W06-3114,P07-1108,[170.0],we carried out an extensive manual and automatic evaluation of machine translation performance on european language pairs.,[0],"a shared task to evaluate machine translation performance was organized as part of the naacl/hlt 2006 workshop on statistical ma chine translation (koehn and monz, 2006)",[0],17,method,7,7.0,0.7777777777777778,170.0,0.9497206703910615,1.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,5 conclusions,abstract
W06-3114,E12-3010,[92.0],"the way judgements are collected, human judges tend to use the scores to rank systems against each other.",[0],"for the same reason, human evaluation metrics based on adequacy and fluency were not suitable either (koehn and monz, 2006)",[0],19,result,5,5.0,0.5555555555555556,92.0,0.5139664804469274,8.0,0.34782608695652173,0,0.0,0.0,0.0,0.0,0.0,adequacy fluency 5 all meaning flawless english 4 most meaning good english 3 much meaning non-native english 2 little meaning disfluent english 1 none incomprehensible,abstract
W06-3114,W09-0402,[145.0],"this is can not be the only explanation, since the discrepancy still holds, for instance, for out-of-domain french-english, where systran receives among the best adequacy and fluency scores, but a worse bleu score than all but one statistical system.",[0],"the correlations on the document level were computed on the english, french, spanish and german texts generated by various translation systems in the framework of the first (koehn and monz, 2006), second (callison-burch et al, 2007) and third shared translation task (callison-burchet al, 2008)",[0],20,method,6,6.0,0.6666666666666666,145.0,0.8100558659217877,38.0,0.6129032258064516,0,0.0,0.0,0.0,0.0,0.0,4 results and analysis,abstract
W06-3114,W06-3120,[108],the results of the manual and automatic evaluation of the participating system translations is detailed in the figures at the end of this paper.,[0],"the official results were slightly better because a lowercase evaluation was used, see (koehn and monz, 2006)",[0],1,method,6,6.0,0.6666666666666666,108.0,0.6033519553072626,1.0,0.016129032258064516,0,0.0,0.0,0.0,0.0,0.0,4 results and analysis,abstract
W06-3114,D07-1092,[34],"for more on the participating systems, please refer to the respective system description in the proceedings of the workshop.",[0],"we are further focusing on the shared task of the workshop on statistical machine translation, which took place last year (koehn and monz, 2006) and consisted in translating spanish, german, and french texts from and to english",[0],2,method,2,2.0,0.2222222222222222,34.0,0.18994413407821228,27.0,1.0,0,0.0,0.0,0.0,0.0,0.0,1 evaluation framework,abstract
W06-3114,C08-1074,[18],"in addition to the europarl test set, we also collected 29 editorials from the project syndicate website2, which are published in all the four languages of the shared task.",[0],"for our training and test data we used the english-french subset of the europarl corpus provided for the shared task (koehn and monz, 2006) at the statistical machine translation workshop held in conjunction with the 2006 hlt-naacl conference",[0],3,method,2,2.0,0.2222222222222222,18.0,0.1005586592178771,11.0,0.4074074074074074,0,0.0,0.0,0.0,0.0,0.0,1 evaluation framework,abstract
W06-3114,W07-0718,[151],"the statistical systems seem to still lag behind the commercial rule-based competition when translating into morphological rich languages, as demonstrated by the results for english-german and english-french.",[0],"the results of last year? s workshop further suggested that bleu systematically underestimated the quality of rule-based machine translation systems (koehn and monz, 2006)",[0],4,method,6,6.0,0.6666666666666666,151.0,0.8435754189944135,44.0,0.7096774193548387,0,0.0,0.0,0.0,0.0,0.0,4 results and analysis,abstract
W06-3114,P07-1083,[16],"the test data was again drawn from a segment of the europarl corpus from the fourth quarter of 2000, which is excluded from the training data.",[0],"for the bi text-based annotation, we use publicly available word alignments from the europarl corpus, automatically generated by giza++ for frenchenglish (fr), spanish-english (es) and germanenglish (de) (koehn and monz, 2006)",[0],5,method,2,2.0,0.2222222222222222,16.0,0.0893854748603352,9.0,0.3333333333333333,0,0.0,0.0,0.0,0.0,0.0,1 evaluation framework,abstract
W06-3114,W07-0738,[172],"due to many similarly performing systems, we are not able to draw strong conclusions on the question of correlation of manual and automatic evaluation metrics.",[0],"evaluation results recently reported by callison-burch et al (2006) and koehn and monz (2006), revealed that, in certain cases, the bleu metric may not be a reliable mtquality indicator",[0],6,method,7,7.0,0.7777777777777778,172.0,0.9608938547486033,3.0,0.42857142857142855,0,0.0,0.0,0.0,0.0,0.0,5 conclusions,abstract
W06-3114,W07-0738,[36],"the bleu metric, as all currently proposed automatic metrics, is occasionally suspected to be biased towards statistical systems, especially the phrase-based systems currently in use.",[0],"for instance, callison-burch et al (2006) and koehn and monz (2006) reported and analyzed several cases of strong disagreement between system rankings provided by human assessors and those produced by the bleu metric (papineni et al, 2001)",[0],7,method,3,3.0,0.3333333333333333,36.0,0.2011173184357542,2.0,0.07407407407407407,0,0.0,0.0,0.0,0.0,0.0,2 automatic evaluation,abstract
W06-3114,W07-0738,[103],"given a set of n sentences, we can compute the sample mean x� and sample variance s2 of the individual sentence judgements xi: the extend of the confidence interval [x−d, x+df can be computed by d = 1.96 ·�n (6) pairwise comparison: as for the automatic evaluation metric, we want to be able to rank different systems against each other, for which we need assessments of statistical significance on the differences between a pair of systems.",[0],wepresenta comparative study on the behavior of several metric representatives from each linguistic level in the context of some of the cases reported by koehn and monz (2006) and callison-burch et al (2006) (see section 3),[0],8,method,5,5.0,0.5555555555555556,103.0,0.5754189944134078,19.0,0.8260869565217391,0,0.0,0.0,0.0,0.0,0.0,adequacy fluency 5 all meaning flawless english 4 most meaning good english 3 much meaning non-native english 2 little meaning disfluent english 1 none incomprehensible,abstract
W06-3114,W07-0738,[167],one annotator suggested that this was the case for as much as 10% of our test sentences.,[0],weanalyze some of the cases reported by koehn and monz (2006) and callison-burch et al (2006),[0],9,method,6,6.0,0.6666666666666666,167.0,0.9329608938547486,60.0,0.967741935483871,0,0.0,0.0,0.0,0.0,0.0,4 results and analysis,abstract
W06-3114,D07-1030,[102],"confidence interval: to estimate confidence intervals for the average mean scores for the systems, we use standard significance testing.",[0],"we use the same method described in (koehn and monz, 2006) to perform the significance test",[0],11,method,5,5.0,0.5555555555555556,102.0,0.5698324022346368,18.0,0.782608695652174,0,0.0,0.0,0.0,0.0,0.0,adequacy fluency 5 all meaning flawless english 4 most meaning good english 3 much meaning non-native english 2 little meaning disfluent english 1 none incomprehensible,abstract
W06-3114,D07-1030,[123],"for the manual scoring, we can distinguish only half of the systems, both in terms of fluency and adequacy.",[0],"we also manually evaluated the rbmt systems and smt systems in terms of both adequacy and fluency as defined in (koehn and monz, 2006)",[0],12,method,6,6.0,0.6666666666666666,123.0,0.6871508379888268,16.0,0.25806451612903225,0,0.0,0.0,0.0,0.0,0.0,4 results and analysis,abstract
W06-3114,W08-0406,[34],"for more on the participating systems, please refer to the respective system description in the proceedings of the workshop.",[0],"the baseline is the psmt system used for the 2006 naacl smt workshop (koehn and monz, 2006) with phrase length 3 and a trigram language model (stolcke, 2002)",[0],13,method,2,2.0,0.2222222222222222,34.0,0.18994413407821228,27.0,1.0,0,0.0,0.0,0.0,0.0,0.0,1 evaluation framework,abstract
W06-3114,W11-1002,[62],"while automatic measures are an invaluable tool for the day-to-day development of machine translation systems, they are only a imperfect substitute for human assessment of translation quality, or as the acronym bleu puts it, a bilingual evaluation understudy.",[0],"callison-burch et al (2006 )andkoehn and monz (2006), for example, study situations where bleu strongly disagrees with human judgment of translation quality",[0],14,method,4,4.0,0.4444444444444444,62.0,0.3463687150837989,1.0,0.043478260869565216,0,0.0,0.0,0.0,0.0,0.0,3 manual evaluation,abstract
W06-3114,D07-1091,[126],"the test set included 2000 sentences from the europarl corpus, but also 1064 sentences out-ofdomain test data.",[0],"the english? german systems were trained on the full 751,088 sentence europarl corpus and evaluated on the wmt 2006 test set (koehn and monz, 2006)",[0],15,method,6,6.0,0.6666666666666666,126.0,0.7039106145251397,19.0,0.3064516129032258,0,0.0,0.0,0.0,0.0,0.0,4 results and analysis,abstract
W06-3114,D07-1091,[173],the bias of automatic methods in favor of statistical systems seems to be less pronounced on out-of-domain test data.,[0],"we report results on the development test set, which is also the out-of-domain test set of the wmt06 workshop shared task (koehn and monz, 2006)",[0],16,method,7,7.0,0.7777777777777778,173.0,0.9664804469273743,4.0,0.5714285714285714,0,0.0,0.0,0.0,0.0,0.0,5 conclusions,abstract
W06-3114,P07-1108,[170],we carried out an extensive manual and automatic evaluation of machine translation performance on european language pairs.,[0],"a shared task to evaluate machine translation performance was organized as part of the naacl/hlt 2006 workshop on statistical ma chine translation (koehn and monz, 2006)",[0],17,method,7,7.0,0.7777777777777778,170.0,0.9497206703910615,1.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,5 conclusions,abstract
W06-3114,E12-3010,[84],"the human judges were presented with the following definition of adequacy and fluency, but no additional instructions:",[0],"for the same reason, human evaluation metrics based on adequacy and fluency were not suitable either (koehn and monz, 2006)",[0],19,method,4,4.0,0.4444444444444444,84.0,0.4692737430167598,23.0,1.0,0,0.0,0.0,0.0,0.0,0.0,3 manual evaluation,abstract
W06-3114,W09-0402,[8],the evaluation framework for the shared task is similar to the one used in last year’s shared task.,[0],"the correlations on the document level were computed on the english, french, spanish and german texts generated by various translation systems in the framework of the first (koehn and monz, 2006), second (callison-burch et al, 2007) and third shared translation task (callison-burchet al, 2008)",[0],20,method,2,2.0,0.2222222222222222,8.0,0.0446927374301676,1.0,0.037037037037037035,0,0.0,0.0,0.0,0.0,0.0,1 evaluation framework,abstract
W11-2123,W11-2138,[7],"this paper presents methods to query n-gram language models, minimizing time and space costs.",[0],"we used common tools for phrase-based translation? moses (koehn et al, 2007) decoder and tools, srilm (stolcke, 2002) and kenlm (heafield, 2011) for language modelling and giza++ (och and ney, 2000) for word alignments",[0],1,method,1,1.0,0.1111111111111111,7.0,0.024305555555555556,2.0,0.11764705882352941,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W11-2123,P14-2022,[45],the probing data structure is a rather straightforward application of these hash tables to store ngram language models.,[0],"the language model was com piled into kenlm probing format (heafield, 2011) and placed in ram while text phrase tables were forced into the disk cache before each run",[0],2,method,2,2.0,0.2222222222222222,45.0,0.15625,23.0,0.3108108108108108,0,0.0,0.0,0.0,0.0,0.0,2 data structures,abstract
W11-2123,W12-3145,[136],we offer a state function s(wn1) = wn� where substring wn� is guaranteed to extend (to the right) in the same way that wn1 does for purposes of language modeling.,[0],"thus given afragment tf consisting of a sequence of target to kens, we compute lm scores for (i) < s& gt ;tf, (ii )tf and (iii )tf < /s& gt; and use the best score (only) for pruning.2 while this increases the number oflm queries, we exploit the language model state in formation in kenlm (heafield, 2011) to optimize the queries by saving the scores for the unchanged states",[0],3,method,4,4.0,0.4444444444444444,136.0,0.4722222222222222,8.0,0.1509433962264151,0,0.0,0.0,0.0,0.0,0.0,4 optimizations,abstract
W11-2123,W12-3131,[1],"we present kenlm, a library that implements two data structures for efficient language model queries, reducing both time and costs.",[0],"our translation system uses cdec (dyer et al,2010), an implementation of the hierarchical phrase based translation model (chiang, 2007) that uses the kenlm library (heafield, 2011) for language model inference",[0],4,method,0,0.0,0.0,1.0,0.003472222222222222,1.0,0.16666666666666666,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
W11-2123,W12-3154,[7],"this paper presents methods to query n-gram language models, minimizing time and space costs.",[0],"the three data sets in use in this paper are summarised in table 1.the translation systems consisted of phrase tables and lexicalised reordering tables estimated using the standard moses (koehn et al, 2007) training pipeline, and 5-gram kneser-ney smoothed language models estimated using the srilm toolkit (stolcke, 2002), with kenlm (heafield, 2011) used at runtime",[0],5,method,1,1.0,0.1111111111111111,7.0,0.024305555555555556,2.0,0.11764705882352941,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W11-2123,P12-2058,[8],queries take the form p(wn|wn−1 1 ) where wn1 is an n-gram.,[0],"the features used are basic lexical features, word penalty and a 3-gram language model (heafield, 2011)",[0],6,method,1,1.0,0.1111111111111111,8.0,0.027777777777777776,3.0,0.17647058823529413,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W11-2123,W11-2139,[1],"we present kenlm, a library that implements two data structures for efficient language model queries, reducing both time and costs.",[0],inference was carried out using the language modeling library described by heafield (2011),[0],7,method,0,0.0,0.0,1.0,0.003472222222222222,1.0,0.16666666666666666,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
W11-2123,P13-2003,[205],"we evaluate the time and memory consumption of each data structure by computing perplexity on 4 billion tokens from the english gigaword corpus (parker et al., 2009).",[0],"we used the mada atb segmentation for arabic (roth et al, 2008) and true casing for english, phrases of maximal length 7, kneserney smoothing, and lexicalized reordering (koehn et al, 2005), and a 5-gram language model, trained on gigawordv.5 using kenlm (heafield, 2011)",[0],8,method,5,5.0,0.5555555555555556,205.0,0.7118055555555556,24.0,0.3116883116883117,,,,,,,5 benchmarks,
W11-2123,W12-3134,[274],we have described two data structures for language modeling that achieve substantial reductions in time and memory cost.,[0],the approach we take is similar to work on efficiently storing large phrase tables by zens and ney (2007) and language mod els by heafield (2011) and pauls and klein (2011)? both language model implementations are now integrated with joshua,[0],9,method,7,7.0,0.7777777777777778,274.0,0.9513888888888888,1.0,0.16666666666666666,0,0.0,0.0,0.0,0.0,0.0,7 conclusion,abstract
W11-2123,W12-3134,[204],"for randlm, we used the settings in the documentation: 8 bits per value and false positive probability 1 256.",[0],our quantization approach follows federico and bertoldi (2006) and heafield (2011) in partitioning the value histogram into 256 equal-sized buckets,[0],10,method,5,5.0,0.5555555555555556,204.0,0.7083333333333334,23.0,0.2987012987012987,0,0.0,0.0,0.0,0.0,0.0,5 benchmarks,abstract
W11-2123,W12-3134,[274],we have described two data structures for language modeling that achieve substantial reductions in time and memory cost.,[0],"with the help of the respective original authors, the language model implementations by heafield (2011) and pauls and klein (2011) have been integrated with joshua, dropping support for the slower and more difficult to compile srilm toolkit (stolcke, 2002)",[0],11,method,7,7.0,0.7777777777777778,274.0,0.9513888888888888,1.0,0.16666666666666666,0,0.0,0.0,0.0,0.0,0.0,7 conclusion,abstract
W11-2123,W12-3160,[1],"we present kenlm, a library that implements two data structures for efficient language model queries, reducing both time and costs.",[0],"this was used to create a kenlm (heafield, 2011)",[0],12,method,0,0.0,0.0,1.0,0.003472222222222222,1.0,0.16666666666666666,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
W11-2123,W12-3706,[1],"we present kenlm, a library that implements two data structures for efficient language model queries, reducing both time and costs.",[0],"in the opinum system we query the m p, m n mod els with the kenlm (heafield, 2011) open-source library because it answers the queries very quickly and has a short loading time, which is suitable fora web application",[0],13,method,0,0.0,0.0,1.0,0.003472222222222222,1.0,0.16666666666666666,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
W11-2123,W11-2147,[1],"we present kenlm, a library that implements two data structures for efficient language model queries, reducing both time and costs.",[0],"our base line is a factored phrase based smt system that uses the moses toolkit (koehn et al, 2007) for translation model training and decoding, giza++ (ochand ney, 2003) for word alignment, srilm (stolcke, 2002) an kenlm (heafield, 2011) for language modelling and minimum error rate training (och, 2003) to tune model feature weights",[0],14,method,0,0.0,0.0,1.0,0.003472222222222222,1.0,0.16666666666666666,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
W11-2123,E12-1083,[1],"we present kenlm, a library that implements two data structures for efficient language model queries, reducing both time and costs.",[0],"for language modeling, we computed 5-gram models using irstlm7 (federico et al., 2008) and queried the model with kenlm (heafield, 2011)",[0],15,method,0,0.0,0.0,1.0,0.003472222222222222,1.0,0.16666666666666666,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
W11-2123,P12-1002,[229],then we ran binary search to determine the least amount of memory with which it would run.,[0],"furthermore, the extraction of grammars for training is done in a leave-one-out fashion (zollmann and sima ?an,2005) where rules are extracted for a parallel sentence pair only if the same rules are found in other sentences of the corpus as well.3-gram (news-commentary) and 5-gram (europarl) language models are trained on the data described in table 1, using the srilm toolkit (stolcke, 2002) and binarized for efficient querying using kenlm (heafield, 2011)",[0],16,method,5,5.0,0.5555555555555556,229.0,0.7951388888888888,48.0,0.6233766233766234,0,0.0,0.0,0.0,0.0,0.0,5 benchmarks,abstract
W11-2123,D12-1108,[1],"we present kenlm, a library that implements two data structures for efficient language model queries, reducing both time and costs.",[0],"n-gram language model scores implemented with the kenlm toolkit (heafield, 2011), 3",[0],17,method,0,0.0,0.0,1.0,0.003472222222222222,1.0,0.16666666666666666,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
W11-2123,P12-2006,[93],"the cost of storing these averages, in bits, is because there are comparatively few unigrams, we elected to store them byte-aligned and unquantized, making every query faster.",[0],"research efforts to increase search efficiency for phrase-based mt (koehn et al, 2003) have explored several directions, ranging from generalizing the stack decoding algorithm (ortiz et al, 2006) to additional early pruning techniques (delaney et al, 2006), (moore and quirk, 2007) and more efficient language model (lm) querying (heafield, 2011)",[0],18,method,2,2.0,0.2222222222222222,93.0,0.3229166666666667,71.0,0.9594594594594594,0,0.0,0.0,0.0,0.0,0.0,2 data structures,abstract
W11-2123,P13-2073,[1],"we present kenlm, a library that implements two data structures for efficient language model queries, reducing both time and costs.",[0],"for english language modeling, we use english giga word corpus with 5-gram lm using the kenlm toolkit (heafield, 2011)",[0],19,method,0,0.0,0.0,1.0,0.003472222222222222,1.0,0.16666666666666666,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
W11-2123,P13-1109,[199],"for the perplexity and translation tasks, we used srilm to build a 5-gram english language model on 834 million tokens from europarl v6 (koehn, 2005) and the 2011 workshop on machine translation news crawl corpus with duplicate lines removed.",[0],"for the language model, we used the kenlm toolkit (heafield, 2011) to create a 5-gram language model on the target side of the europarl corpus (v7) with approximately 54m tokens with kneserney smoothing",[0],20,method,5,5.0,0.5555555555555556,199.0,0.6909722222222222,18.0,0.23376623376623376,0,0.0,0.0,0.0,0.0,0.0,5 benchmarks,abstract
W11-2123,W11-2138,[1],"we present kenlm, a library that implements two data structures for efficient language model queries, reducing both time and costs.",[0],"we used common tools for phrase-based translation? moses (koehn et al, 2007) decoder and tools, srilm (stolcke, 2002) and kenlm (heafield, 2011) for language modelling and giza++ (och and ney, 2000) for word alignments",[0],1,aim,0,0.0,0.0,1.0,0.003472222222222222,1.0,0.16666666666666666,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
W11-2123,P14-2022,[1],"we present kenlm, a library that implements two data structures for efficient language model queries, reducing both time and costs.",[0],"the language model was com piled into kenlm probing format (heafield, 2011) and placed in ram while text phrase tables were forced into the disk cache before each run",[0],2,aim,0,0.0,0.0,1.0,0.003472222222222222,1.0,0.16666666666666666,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
W11-2123,W12-3145,[7],"this paper presents methods to query n-gram language models, minimizing time and space costs.",[0],"thus given afragment tf consisting of a sequence of target to kens, we compute lm scores for (i) < s& gt ;tf, (ii )tf and (iii )tf < /s& gt; and use the best score (only) for pruning.2 while this increases the number oflm queries, we exploit the language model state in formation in kenlm (heafield, 2011) to optimize the queries by saving the scores for the unchanged states",[0],3,aim,1,1.0,0.1111111111111111,7.0,0.024305555555555556,2.0,0.11764705882352941,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W11-2123,W12-3131,[1],"we present kenlm, a library that implements two data structures for efficient language model queries, reducing both time and costs.",[0],"our translation system uses cdec (dyer et al,2010), an implementation of the hierarchical phrase based translation model (chiang, 2007) that uses the kenlm library (heafield, 2011) for language model inference",[0],4,aim,0,0.0,0.0,1.0,0.003472222222222222,1.0,0.16666666666666666,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
W11-2123,W12-3154,[1],"we present kenlm, a library that implements two data structures for efficient language model queries, reducing both time and costs.",[0],"the three data sets in use in this paper are summarised in table 1.the translation systems consisted of phrase tables and lexicalised reordering tables estimated using the standard moses (koehn et al, 2007) training pipeline, and 5-gram kneser-ney smoothed language models estimated using the srilm toolkit (stolcke, 2002), with kenlm (heafield, 2011) used at runtime",[0],5,aim,0,0.0,0.0,1.0,0.003472222222222222,1.0,0.16666666666666666,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
W11-2123,P12-2058,[52],our implementation permits jumping to any n-gram of any length with a single lookup; this appears to be unique among language model implementations.,[0],"the features used are basic lexical features, word penalty and a 3-gram language model (heafield, 2011)",[0],6,method,2,2.0,0.2222222222222222,52.0,0.18055555555555555,30.0,0.40540540540540543,0,0.0,0.0,0.0,0.0,0.0,2 data structures,abstract
W11-2123,W11-2139,[1],"we present kenlm, a library that implements two data structures for efficient language model queries, reducing both time and costs.",[0],inference was carried out using the language modeling library described by heafield (2011),[0],7,aim,0,0.0,0.0,1.0,0.003472222222222222,1.0,0.16666666666666666,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
W11-2123,P13-2003,[1],"we present kenlm, a library that implements two data structures for efficient language model queries, reducing both time and costs.",[0],"we used the mada atb segmentation for arabic (roth et al, 2008) and true casing for english, phrases of maximal length 7, kneserney smoothing, and lexicalized reordering (koehn et al, 2005), and a 5-gram language model, trained on gigawordv.5 using kenlm (heafield, 2011)",[0],8,aim,0,0.0,0.0,1.0,0.003472222222222222,1.0,0.16666666666666666,,,,,,,abstract,
W11-2123,W12-3134,[7],"this paper presents methods to query n-gram language models, minimizing time and space costs.",[0],the approach we take is similar to work on efficiently storing large phrase tables by zens and ney (2007) and language mod els by heafield (2011) and pauls and klein (2011)? both language model implementations are now integrated with joshua,[0],9,aim,1,1.0,0.1111111111111111,7.0,0.024305555555555556,2.0,0.11764705882352941,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W11-2123,W12-3134,[177],"however, trie partitions storage by n-gram length, so walking the trie reads n disjoint pages.",[0],our quantization approach follows federico and bertoldi (2006) and heafield (2011) in partitioning the value histogram into 256 equal-sized buckets,[0],10,method,4,4.0,0.4444444444444444,177.0,0.6145833333333334,49.0,0.9245283018867925,0,0.0,0.0,0.0,0.0,0.0,4 optimizations,abstract
W11-2123,W12-3134,[7],"this paper presents methods to query n-gram language models, minimizing time and space costs.",[0],"with the help of the respective original authors, the language model implementations by heafield (2011) and pauls and klein (2011) have been integrated with joshua, dropping support for the slower and more difficult to compile srilm toolkit (stolcke, 2002)",[0],11,aim,1,1.0,0.1111111111111111,7.0,0.024305555555555556,2.0,0.11764705882352941,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W11-2123,W12-3160,[1],"we present kenlm, a library that implements two data structures for efficient language model queries, reducing both time and costs.",[0],"this was used to create a kenlm (heafield, 2011)",[0],12,aim,0,0.0,0.0,1.0,0.003472222222222222,1.0,0.16666666666666666,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
W11-2123,W12-3706,[200],"the model was built with open vocabulary, modified kneser-ney smoothing, and default pruning settings that remove singletons of order 3 and higher.",[0],"in the opinum system we query the m p, m n mod els with the kenlm (heafield, 2011) open-source library because it answers the queries very quickly and has a short loading time, which is suitable fora web application",[0],13,method,5,5.0,0.5555555555555556,200.0,0.6944444444444444,19.0,0.24675324675324675,0,0.0,0.0,0.0,0.0,0.0,5 benchmarks,abstract
W11-2123,W11-2147,[7],"this paper presents methods to query n-gram language models, minimizing time and space costs.",[0],"our base line is a factored phrase based smt system that uses the moses toolkit (koehn et al, 2007) for translation model training and decoding, giza++ (ochand ney, 2003) for word alignment, srilm (stolcke, 2002) an kenlm (heafield, 2011) for language modelling and minimum error rate training (och, 2003) to tune model feature weights",[0],14,aim,1,1.0,0.1111111111111111,7.0,0.024305555555555556,2.0,0.11764705882352941,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W11-2123,E12-1083,[200],"the model was built with open vocabulary, modified kneser-ney smoothing, and default pruning settings that remove singletons of order 3 and higher.",[0],"for language modeling, we computed 5-gram models using irstlm7 (federico et al., 2008) and queried the model with kenlm (heafield, 2011)",[0],15,method,5,5.0,0.5555555555555556,200.0,0.6944444444444444,19.0,0.24675324675324675,0,0.0,0.0,0.0,0.0,0.0,5 benchmarks,abstract
W11-2123,P12-1002,[200],"the model was built with open vocabulary, modified kneser-ney smoothing, and default pruning settings that remove singletons of order 3 and higher.",[0],"furthermore, the extraction of grammars for training is done in a leave-one-out fashion (zollmann and sima ?an,2005) where rules are extracted for a parallel sentence pair only if the same rules are found in other sentences of the corpus as well.3-gram (news-commentary) and 5-gram (europarl) language models are trained on the data described in table 1, using the srilm toolkit (stolcke, 2002) and binarized for efficient querying using kenlm (heafield, 2011)",[0],16,method,5,5.0,0.5555555555555556,200.0,0.6944444444444444,19.0,0.24675324675324675,0,0.0,0.0,0.0,0.0,0.0,5 benchmarks,abstract
W11-2123,D12-1108,[7],"this paper presents methods to query n-gram language models, minimizing time and space costs.",[0],"n-gram language model scores implemented with the kenlm toolkit (heafield, 2011), 3",[0],17,aim,1,1.0,0.1111111111111111,7.0,0.024305555555555556,2.0,0.11764705882352941,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W11-2123,P12-2006,[278],"we attain these results using several optimizations: hashing, custom lookup tables, bit-level packing, and state for left-to-right query patterns.",[0],"research efforts to increase search efficiency for phrase-based mt (koehn et al, 2003) have explored several directions, ranging from generalizing the stack decoding algorithm (ortiz et al, 2006) to additional early pruning techniques (delaney et al, 2006), (moore and quirk, 2007) and more efficient language model (lm) querying (heafield, 2011)",[0],18,method,7,7.0,0.7777777777777778,278.0,0.9652777777777778,5.0,0.8333333333333334,0,0.0,0.0,0.0,0.0,0.0,7 conclusion,abstract
W11-2123,P13-2073,[7],"this paper presents methods to query n-gram language models, minimizing time and space costs.",[0],"for english language modeling, we use english giga word corpus with 5-gram lm using the kenlm toolkit (heafield, 2011)",[0],19,aim,1,1.0,0.1111111111111111,7.0,0.024305555555555556,2.0,0.11764705882352941,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W11-2123,P13-1109,[7],"this paper presents methods to query n-gram language models, minimizing time and space costs.",[0],"for the language model, we used the kenlm toolkit (heafield, 2011) to create a 5-gram language model on the target side of the europarl corpus (v7) with approximately 54m tokens with kneserney smoothing",[0],20,aim,1,1.0,0.1111111111111111,7.0,0.024305555555555556,2.0,0.11764705882352941,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W11-2123,W11-2138,[12],"throughout this paper we compare with several packages: srilm 1.5.12 (stolcke, 2002) is a popular toolkit based on tries used in several decoders.",[0],"we used common tools for phrase-based translation? moses (koehn et al, 2007) decoder and tools, srilm (stolcke, 2002) and kenlm (heafield, 2011) for language modelling and giza++ (och and ney, 2000) for word alignments",[0],1,method,1,1.0,0.1111111111111111,12.0,0.041666666666666664,7.0,0.4117647058823529,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W11-2123,P14-2022,[7],"this paper presents methods to query n-gram language models, minimizing time and space costs.",[0],"the language model was com piled into kenlm probing format (heafield, 2011) and placed in ram while text phrase tables were forced into the disk cache before each run",[0],2,method,1,1.0,0.1111111111111111,7.0,0.024305555555555556,2.0,0.11764705882352941,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W11-2123,W12-3145,[131],dynamic programming efficiently scores many hypotheses by exploiting the fact that an n-gram language model conditions on at most n − 1 preceding words.,[0],"thus given afragment tf consisting of a sequence of target to kens, we compute lm scores for (i) < s& gt ;tf, (ii )tf and (iii )tf < /s& gt; and use the best score (only) for pruning.2 while this increases the number oflm queries, we exploit the language model state in formation in kenlm (heafield, 2011) to optimize the queries by saving the scores for the unchanged states",[0],3,method,4,4.0,0.4444444444444444,131.0,0.4548611111111111,3.0,0.05660377358490566,0,0.0,0.0,0.0,0.0,0.0,4 optimizations,abstract
W11-2123,W12-3131,[21],"performance improvements transfer to the moses (koehn et al., 2007), cdec (dyer et al., 2010), and joshua (li et al., 2009) translation systems where our code has been integrated.",[0],"our translation system uses cdec (dyer et al,2010), an implementation of the hierarchical phrase based translation model (chiang, 2007) that uses the kenlm library (heafield, 2011) for language model inference",[0],4,method,1,1.0,0.1111111111111111,21.0,0.07291666666666667,16.0,0.9411764705882353,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W11-2123,W12-3154,[21],"performance improvements transfer to the moses (koehn et al., 2007), cdec (dyer et al., 2010), and joshua (li et al., 2009) translation systems where our code has been integrated.",[0],"the three data sets in use in this paper are summarised in table 1.the translation systems consisted of phrase tables and lexicalised reordering tables estimated using the standard moses (koehn et al, 2007) training pipeline, and 5-gram kneser-ney smoothed language models estimated using the srilm toolkit (stolcke, 2002), with kenlm (heafield, 2011) used at runtime",[0],5,method,1,1.0,0.1111111111111111,21.0,0.07291666666666667,16.0,0.9411764705882353,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W11-2123,P12-2058,[108],"compared with srilm, irstlm adds several features: lower memory consumption, a binary file format with memory mapping, caching to increase speed, and quantization.",[0],"the features used are basic lexical features, word penalty and a 3-gram language model (heafield, 2011)",[0],6,method,3,3.0,0.3333333333333333,108.0,0.375,12.0,0.375,0,0.0,0.0,0.0,0.0,0.0,3 related work,abstract
W11-2123,W11-2139,[129],"in addition to the optimizations specific to each datastructure described in section 2, we implement several general optimizations for language modeling.",[0],inference was carried out using the language modeling library described by heafield (2011),[0],7,method,4,4.0,0.4444444444444444,129.0,0.4479166666666667,1.0,0.018867924528301886,0,0.0,0.0,0.0,0.0,0.0,4 optimizations,abstract
W11-2123,P13-2003,[199],"for the perplexity and translation tasks, we used srilm to build a 5-gram english language model on 834 million tokens from europarl v6 (koehn, 2005) and the 2011 workshop on machine translation news crawl corpus with duplicate lines removed.",[0],"we used the mada atb segmentation for arabic (roth et al, 2008) and true casing for english, phrases of maximal length 7, kneserney smoothing, and lexicalized reordering (koehn et al, 2005), and a 5-gram language model, trained on gigawordv.5 using kenlm (heafield, 2011)",[0],8,method,5,5.0,0.5555555555555556,199.0,0.6909722222222222,18.0,0.23376623376623376,,,,,,,5 benchmarks,
W11-2123,W12-3134,[52],our implementation permits jumping to any n-gram of any length with a single lookup; this appears to be unique among language model implementations.,[0],the approach we take is similar to work on efficiently storing large phrase tables by zens and ney (2007) and language mod els by heafield (2011) and pauls and klein (2011)? both language model implementations are now integrated with joshua,[0],9,method,2,2.0,0.2222222222222222,52.0,0.18055555555555555,30.0,0.40540540540540543,0,0.0,0.0,0.0,0.0,0.0,2 data structures,abstract
W11-2123,W12-3134,[263],quantization can be improved by jointly encoding probability and backoff.,[0],our quantization approach follows federico and bertoldi (2006) and heafield (2011) in partitioning the value histogram into 256 equal-sized buckets,[0],10,method,6,6.0,0.6666666666666666,263.0,0.9131944444444444,5.0,0.3333333333333333,0,0.0,0.0,0.0,0.0,0.0,6 future work,abstract
W11-2123,W12-3134,[52],our implementation permits jumping to any n-gram of any length with a single lookup; this appears to be unique among language model implementations.,[0],"with the help of the respective original authors, the language model implementations by heafield (2011) and pauls and klein (2011) have been integrated with joshua, dropping support for the slower and more difficult to compile srilm toolkit (stolcke, 2002)",[0],11,method,2,2.0,0.2222222222222222,52.0,0.18055555555555555,30.0,0.40540540540540543,0,0.0,0.0,0.0,0.0,0.0,2 data structures,abstract
W11-2123,W12-3160,[1],"we present kenlm, a library that implements two data structures for efficient language model queries, reducing both time and costs.",[0],"this was used to create a kenlm (heafield, 2011)",[0],12,method,0,0.0,0.0,1.0,0.003472222222222222,1.0,0.16666666666666666,0,0.0,0.0,0.0,0.0,0.0,abstract,abstract
W11-2123,W12-3706,[145],if the context wnf will never extend to the right (i.e. wnf v is not present in the model for all words v) then no subsequent query will match the full context.,[0],"in the opinum system we query the m p, m n mod els with the kenlm (heafield, 2011) open-source library because it answers the queries very quickly and has a short loading time, which is suitable fora web application",[0],13,method,4,4.0,0.4444444444444444,145.0,0.5034722222222222,17.0,0.32075471698113206,0,0.0,0.0,0.0,0.0,0.0,4 optimizations,abstract
W11-2123,W11-2147,[182],"this section measures performance on shared tasks in order of increasing complexity: sparse lookups, evaluating perplexity of a large file, and translation with moses.",[0],"our base line is a factored phrase based smt system that uses the moses toolkit (koehn et al, 2007) for translation model training and decoding, giza++ (ochand ney, 2003) for word alignment, srilm (stolcke, 2002) an kenlm (heafield, 2011) for language modelling and minimum error rate training (och, 2003) to tune model feature weights",[0],14,method,5,5.0,0.5555555555555556,182.0,0.6319444444444444,1.0,0.012987012987012988,0,0.0,0.0,0.0,0.0,0.0,5 benchmarks,abstract
W11-2123,E12-1083,[274],we have described two data structures for language modeling that achieve substantial reductions in time and memory cost.,[0],"for language modeling, we computed 5-gram models using irstlm7 (federico et al., 2008) and queried the model with kenlm (heafield, 2011)",[0],15,method,7,7.0,0.7777777777777778,274.0,0.9513888888888888,1.0,0.16666666666666666,0,0.0,0.0,0.0,0.0,0.0,7 conclusion,abstract
W11-2123,P12-1002,[12],"throughout this paper we compare with several packages: srilm 1.5.12 (stolcke, 2002) is a popular toolkit based on tries used in several decoders.",[0],"furthermore, the extraction of grammars for training is done in a leave-one-out fashion (zollmann and sima ?an,2005) where rules are extracted for a parallel sentence pair only if the same rules are found in other sentences of the corpus as well.3-gram (news-commentary) and 5-gram (europarl) language models are trained on the data described in table 1, using the srilm toolkit (stolcke, 2002) and binarized for efficient querying using kenlm (heafield, 2011)",[0],16,method,1,1.0,0.1111111111111111,12.0,0.041666666666666664,7.0,0.4117647058823529,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W11-2123,D12-1108,[7],"this paper presents methods to query n-gram language models, minimizing time and space costs.",[0],"n-gram language model scores implemented with the kenlm toolkit (heafield, 2011), 3",[0],17,method,1,1.0,0.1111111111111111,7.0,0.024305555555555556,2.0,0.11764705882352941,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W11-2123,P12-2006,[140],"we have modified moses (koehn et al., 2007) to keep our state with hypotheses; to conserve memory, phrases do not keep state.",[0],"research efforts to increase search efficiency for phrase-based mt (koehn et al, 2003) have explored several directions, ranging from generalizing the stack decoding algorithm (ortiz et al, 2006) to additional early pruning techniques (delaney et al, 2006), (moore and quirk, 2007) and more efficient language model (lm) querying (heafield, 2011)",[0],18,method,4,4.0,0.4444444444444444,140.0,0.4861111111111111,12.0,0.22641509433962265,0,0.0,0.0,0.0,0.0,0.0,4 optimizations,abstract
W11-2123,P13-2073,[199],"for the perplexity and translation tasks, we used srilm to build a 5-gram english language model on 834 million tokens from europarl v6 (koehn, 2005) and the 2011 workshop on machine translation news crawl corpus with duplicate lines removed.",[0],"for english language modeling, we use english giga word corpus with 5-gram lm using the kenlm toolkit (heafield, 2011)",[0],19,method,5,5.0,0.5555555555555556,199.0,0.6909722222222222,18.0,0.23376623376623376,0,0.0,0.0,0.0,0.0,0.0,5 benchmarks,abstract
W11-2123,P13-1109,[199],"for the perplexity and translation tasks, we used srilm to build a 5-gram english language model on 834 million tokens from europarl v6 (koehn, 2005) and the 2011 workshop on machine translation news crawl corpus with duplicate lines removed.",[0],"for the language model, we used the kenlm toolkit (heafield, 2011) to create a 5-gram language model on the target side of the europarl corpus (v7) with approximately 54m tokens with kneserney smoothing",[0],20,method,5,5.0,0.5555555555555556,199.0,0.6909722222222222,18.0,0.23376623376623376,0,0.0,0.0,0.0,0.0,0.0,5 benchmarks,abstract
W99-0613,N01-1023,[9],this paper discusses the use of unlabeled examples for the problem of named entity classification.,[0],"co-training has been used before in applications like word-sense disambiguation (yarowsky, 1995), web-page classification (blum and mitchell, 1998) and named entity identification (collins and singer, 1999)",[0],1,method,1,1.0,0.125,9.0,0.03501945525291829,3.0,0.075,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W99-0613,N01-1023,[36],"roughly speaking, the new algorithm presented in this paper performs a similar search, but instead minimizes a bound on the number of (unlabeled) examples on which two classifiers disagree.",[0],"they also discuss an application of classifying web pages by using their method of mutually constrained models. (collins and singer, 1999) further extend the use of classifiers that have mutual constraints by adding terms toadaboost which force the classifiers to agree (called co boosting)",[0],2,method,1,1.0,0.125,36.0,0.14007782101167315,30.0,0.75,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W99-0613,W03-1509,[137],"the new algorithm, which we call coboost, uses labeled and unlabeled data and builds two classifiers in parallel.",[0],"recent methods for english ner focus on machine-learning algorithms such as dl-cotrain, coboost [collins and singer 1999], hmm [daniel m. bikel 1997], maximum entropy model [borthwick, et al 1999] and so on",[0],3,method,4,4.0,0.5,137.0,0.5330739299610895,4.0,0.045454545454545456,0,0.0,0.0,0.0,0.0,0.0,4 a boosting-based algorithm,abstract
W99-0613,C02-1154,[79],"2 we now introduce a new algorithm for learning from unlabeled examples, which we will call dlcotrain (dl stands for decision list, the term cotrain is taken from (blum and mitchell 98)).",[0],"dl-cotrain, (collins and singer, 1999), learns capitalized proper name nes from a syn tactically analyzed corpus",[0],4,method,3,3.0,0.375,79.0,0.30739299610894943,12.0,0.18181818181818182,0,0.0,0.0,0.0,0.0,0.0,3 unsupervised algorithms based on decision lists,abstract
W99-0613,C02-1154,[10],"the task is to learn a function from an input string (proper name) to its type, which we will assume to be one of the categories person, organization, or location.",[0],"(collins and singer, 1999) also makes use of competing categories (person, organization, and location), which cover 96% of all the instances itset out to classify",[0],5,method,1,1.0,0.125,10.0,0.038910505836575876,4.0,0.1,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W99-0613,W06-2204,[18],but we will show that the use of unlabeled data can drastically reduce the need for supervision.,[0],"in (collins and singer, 1999) collins and singer show that unlabeled data can be used to reduce the level of supervision required for named entity classification",[0],6,method,1,1.0,0.125,18.0,0.07003891050583658,12.0,0.3,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W99-0613,W03-1022,"[236, 237]","we chose one of four labels for each example: location, person, organization, or noise where the noise category was used for items that were outside the three categories.
the numbers falling into the location, person, organization categories were 186, 289 and 402 respectively.",[0],"collins and singer (1999) for example report that 88% of the named entities occurring in their data set belong to these three categories (collins and singer, 1999)",[0],8,method,6_6,6.0,0.75,236.5,0.9202334630350194,3.5,0.21875,0,0.0,0.0,0.0,0.0,0.0,"6 evaluation, 6 evaluation",abstract
W99-0613,E09-1018,"[9, 10]","this paper discusses the use of unlabeled examples for the problem of named entity classification.
the task is to learn a function from an input string (proper name) to its type, which we will assume to be one of the categories person, organization, or location.",[0],"while em has worked quite well for a few tasks, notably ma chine translations (starting with the ibm models 1-5 (brown et al, 1993), it has not had success inmost others, such as part-of-speech tagging (merialdo, 1991), named-entity recognition (collinsand singer, 1999) and context-free-grammar induction (numerous attempts, too many to mention)",[0],9,method,1_1,1.0,0.125,9.5,0.03696498054474708,3.5,0.0875,0,0.0,0.0,0.0,0.0,0.0,"1 introduction, 1 introduction",abstract
W99-0613,W07-1712,"[137, 39]","the new algorithm, which we call coboost, uses labeled and unlabeled data and builds two classifiers in parallel.this section describes adaboost, which is the basis for the coboost algorithm.",[0],"in addition, we would also like to explore the semi-supervised techniques such as co-training and self-training (collins and singer, 1999)",[0],11,method,4_1,2.5,0.3125,88.0,0.3424124513618677,18.5,0.4352272727272727,0,0.0,0.0,0.0,0.0,0.0,"4 a boosting-based algorithm, 1 introduction",abstract
W99-0613,W09-2208,"[26, 27]","we present two algorithms.
the first method builds on results from (yarowsky 95) and (blum and mitchell 98).",[0],"collins et al (collins and singer, 1999) proposed two algorithms for ner by modifying yarowsky ?smethod (yarowsky, 1995) and the framework suggested by (blum and mitchell, 1998)",[0],12,method,1_1,1.0,0.125,26.5,0.10311284046692606,20.5,0.5125,0,0.0,0.0,0.0,0.0,0.0,"1 introduction, 1 introduction",abstract
W99-0613,W06-2207,[18],but we will show that the use of unlabeled data can drastically reduce the need for supervision.,[0],"this approach was shown to perform well on real-world natural language problems (collins and singer, 1999)",[0],13,method,1,1.0,0.125,18.0,0.07003891050583658,12.0,0.3,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W99-0613,W06-2207,[85],"(if fewer than n rules have precision greater than pin, we 3note that taking tlie top n most frequent rules already makes the method robut to low count events, hence we do not use smoothing, allowing low-count high-precision features to be chosen on later iterations. keep only those rules which exceed the precision threshold.) pm,n was fixed at 0.95 in all experiments in this paper.",[0],"(6) similarly to (collins and singer, 1999) we used t= 0.95 for all experiments reported here",[0],15,method,3,3.0,0.375,85.0,0.33073929961089493,18.0,0.2727272727272727,0,0.0,0.0,0.0,0.0,0.0,3 unsupervised algorithms based on decision lists,abstract
W99-0613,P12-1065,"[8, 9]","recent results (e.g., (yarowsky 95; brill 95; blum and mitchell 98)) have suggested that unlabeled data can be used quite profitably in reducing the need for supervision.
this paper discusses the use of unlabeled examples for the problem of named entity classification.",[0],we use collins and singer (1999) for our exact specification of yarowsky.2 it uses dl rule scores ?fj?| ?fj |+ |? f |+ l (1) where is a smoothing constant,[0],16,method,1_1,1.0,0.125,8.5,0.033073929961089495,2.5,0.0625,0,0.0,0.0,0.0,0.0,0.0,"1 introduction, 1 introduction",abstract
W99-0613,N01-1023,[9.0],this paper discusses the use of unlabeled examples for the problem of named entity classification.,[0],"co-training has been used before in applications like word-sense disambiguation (yarowsky, 1995), web-page classification (blum and mitchell, 1998) and named entity identification (collins and singer, 1999)",[0],1,aim,1,1.0,0.125,9.0,0.03501945525291829,3.0,0.075,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W99-0613,N01-1023,[159.0],"to prevent this we &quot;smooth&quot; the confidence by adding a small value, e, to both w+ and w_, giving at = plugging the value of at from equ.",[0],"they also discuss an application of classifying web pages by using their method of mutually constrained models. (collins and singer, 1999) further extend the use of classifiers that have mutual constraints by adding terms toadaboost which force the classifiers to agree (called co boosting)",[0],2,method,4,4.0,0.5,159.0,0.6186770428015564,26.0,0.29545454545454547,0,0.0,0.0,0.0,0.0,0.0,4 a boosting-based algorithm,abstract
W99-0613,W03-1509,[137.0],"the new algorithm, which we call coboost, uses labeled and unlabeled data and builds two classifiers in parallel.",[0],"recent methods for english ner focus on machine-learning algorithms such as dl-cotrain, coboost [collins and singer 1999], hmm [daniel m. bikel 1997], maximum entropy model [borthwick, et al 1999] and so on",[0],4,method,4,4.0,0.5,137.0,0.5330739299610895,4.0,0.045454545454545456,0,0.0,0.0,0.0,0.0,0.0,4 a boosting-based algorithm,abstract
W99-0613,C02-1154,[91.0],"there are two differences between this method and the dl-cotrain algorithm: spelling and contextual features, alternating between labeling and learning with the two types of features.",[0],"dl-cotrain, (collins and singer, 1999), learns capitalized proper name nes from a syn tactically analyzed corpus",[0],5,method,3,3.0,0.375,91.0,0.3540856031128405,24.0,0.36363636363636365,0,0.0,0.0,0.0,0.0,0.0,3 unsupervised algorithms based on decision lists,abstract
W99-0613,C02-1154,[213.0],"thus at each iteration the algorithm is forced to pick features for the location, person and organization in turn for the classifier being trained.",[0],"(collins and singer, 1999) also makes use of competing categories (person, organization, and location), which cover 96% of all the instances itset out to classify",[0],6,method,4,4.0,0.5,213.0,0.8287937743190662,80.0,0.9090909090909091,0,0.0,0.0,0.0,0.0,0.0,4 a boosting-based algorithm,abstract
W99-0613,W06-2204,[250.0],unlabeled examples in the named-entity classification problem can reduce the need for supervision to a handful of seed rules.,[0],"in (collins and singer, 1999) collins and singer show that unlabeled data can be used to reduce the level of supervision required for named entity classification",[0],7,result,7,7.0,0.875,250.0,0.9727626459143969,1.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,7 conclusions,abstract
W99-0613,W03-1022,[213.0],"thus at each iteration the algorithm is forced to pick features for the location, person and organization in turn for the classifier being trained.",[0],"collins and singer (1999) for example report that 88% of the named entities occurring in their data set belong to these three categories (collins and singer, 1999)",[0],10,method,4,4.0,0.5,213.0,0.8287937743190662,80.0,0.9090909090909091,0,0.0,0.0,0.0,0.0,0.0,4 a boosting-based algorithm,abstract
W99-0613,E09-1018,[9.0],this paper discusses the use of unlabeled examples for the problem of named entity classification.,[0],"while em has worked quite well for a few tasks, notably ma chine translations (starting with the ibm models 1-5 (brown et al, 1993), it has not had success inmost others, such as part-of-speech tagging (merialdo, 1991), named-entity recognition (collinsand singer, 1999) and context-free-grammar induction (numerous attempts, too many to mention)",[0],11,aim,1,1.0,0.125,9.0,0.03501945525291829,3.0,0.075,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W99-0613,W10-3504,[36.0],"roughly speaking, the new algorithm presented in this paper performs a similar search, but instead minimizes a bound on the number of (unlabeled) examples on which two classifiers disagree.",[0],"this can be either a fixed number of added unlabelled examples (blum and mitchell, 1998), the performance drop on a control set of labelled instances, or a filter on the disagreement of h1 and h2 in classifying u (collins and singer, 1999)",[0],12,result,1,1.0,0.125,36.0,0.14007782101167315,30.0,0.75,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W99-0613,W09-2208,[29.0],"unfortunately, yarowsky's method is not well understood from a theoretical viewpoint: we would like to formalize the notion of redundancy in unlabeled data, and set up the learning task as optimization of some appropriate objective function.",[0],"collins et al (collins and singer, 1999) proposed two algorithms for ner by modifying yarowsky ?smethod (yarowsky, 1995) and the framework suggested by (blum and mitchell, 1998)",[0],15,method,1,1.0,0.125,29.0,0.11284046692607004,23.0,0.575,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W99-0613,W06-2207,[7.0],"many statistical or machine-learning approaches for natural language problems require a relatively large amount of supervision, in the form of labeled training examples.",[0],"this approach was shown to perform well on real-world natural language problems (collins and singer, 1999)",[0],16,aim,1,1.0,0.125,7.0,0.027237354085603113,1.0,0.025,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W99-0613,W06-2207,[85.0],"(if fewer than n rules have precision greater than pin, we 3note that taking tlie top n most frequent rules already makes the method robut to low count events, hence we do not use smoothing, allowing low-count high-precision features to be chosen on later iterations. keep only those rules which exceed the precision threshold.) pm,n was fixed at 0.95 in all experiments in this paper.",[0],"(6) similarly to (collins and singer, 1999) we used t= 0.95 for all experiments reported here",[0],18,method,3,3.0,0.375,85.0,0.33073929961089493,18.0,0.2727272727272727,0,0.0,0.0,0.0,0.0,0.0,3 unsupervised algorithms based on decision lists,abstract
W99-0613,P12-1065,[95.0],"(specifically, the limit n starts at 5 and increases by 5 at each iteration.)",[0],we use collins and singer (1999) for our exact specification of yarowsky.2 it uses dl rule scores ?fj?| ?fj |+ |? f |+ l (1) where is a smoothing constant,[0],19,method,3,3.0,0.375,95.0,0.36964980544747084,28.0,0.42424242424242425,0,0.0,0.0,0.0,0.0,0.0,3 unsupervised algorithms based on decision lists,abstract
W99-0613,P12-1065,[213.0],"thus at each iteration the algorithm is forced to pick features for the location, person and organization in turn for the classifier being trained.",[0],"3this is not clearly specified in collins and singer (1999), 3.2 yarowsky-cautious",[0],20,method,4,4.0,0.5,213.0,0.8287937743190662,80.0,0.9090909090909091,0,0.0,0.0,0.0,0.0,0.0,4 a boosting-based algorithm,abstract
W99-0613,N01-1023,[121],"they also describe an application of cotraining to classifying web pages (the to feature sets are the words on the page, and other pages pointing to the page).",[0],"co-training has been used before in applications like word-sense disambiguation (yarowsky, 1995), web-page classification (blum and mitchell, 1998) and named entity identification (collins and singer, 1999)",[0],1,method,3,3.0,0.375,121.0,0.4708171206225681,54.0,0.8181818181818182,0,0.0,0.0,0.0,0.0,0.0,3 unsupervised algorithms based on decision lists,abstract
W99-0613,N01-1023,[252],the method uses a &quot;soft&quot; measure of the agreement between two classifiers as an objective function; we described an algorithm which directly optimizes this function.,[0],"they also discuss an application of classifying web pages by using their method of mutually constrained models. (collins and singer, 1999) further extend the use of classifiers that have mutual constraints by adding terms toadaboost which force the classifiers to agree (called co boosting)",[0],2,method,7,7.0,0.875,252.0,0.980544747081712,3.0,0.42857142857142855,0,0.0,0.0,0.0,0.0,0.0,7 conclusions,abstract
W99-0613,W03-1509,[91],"there are two differences between this method and the dl-cotrain algorithm: spelling and contextual features, alternating between labeling and learning with the two types of features.",[0],"recent methods for english ner focus on machine-learning algorithms such as dl-cotrain, coboost [collins and singer 1999], hmm [daniel m. bikel 1997], maximum entropy model [borthwick, et al 1999] and so on",[0],4,method,3,3.0,0.375,91.0,0.3540856031128405,24.0,0.36363636363636365,0,0.0,0.0,0.0,0.0,0.0,3 unsupervised algorithms based on decision lists,abstract
W99-0613,C02-1154,[91],"there are two differences between this method and the dl-cotrain algorithm: spelling and contextual features, alternating between labeling and learning with the two types of features.",[0],"dl-cotrain, (collins and singer, 1999), learns capitalized proper name nes from a syn tactically analyzed corpus",[0],5,method,3,3.0,0.375,91.0,0.3540856031128405,24.0,0.36363636363636365,0,0.0,0.0,0.0,0.0,0.0,3 unsupervised algorithms based on decision lists,abstract
W99-0613,C02-1154,[213],"thus at each iteration the algorithm is forced to pick features for the location, person and organization in turn for the classifier being trained.",[0],"(collins and singer, 1999) also makes use of competing categories (person, organization, and location), which cover 96% of all the instances itset out to classify",[0],6,method,4,4.0,0.5,213.0,0.8287937743190662,80.0,0.9090909090909091,0,0.0,0.0,0.0,0.0,0.0,4 a boosting-based algorithm,abstract
W99-0613,W06-2204,[250],unlabeled examples in the named-entity classification problem can reduce the need for supervision to a handful of seed rules.,[0],"in (collins and singer, 1999) collins and singer show that unlabeled data can be used to reduce the level of supervision required for named entity classification",[0],7,method,7,7.0,0.875,250.0,0.9727626459143969,1.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,7 conclusions,abstract
W99-0613,W09-1116,[39],"(brin 98) ,describes a system for extracting (author, book-title) pairs from the world wide web using an approach that bootstraps from an initial seed set of examples.",[0],collins and singer (1999) and cucerzan and yarowsky (1999) apply bootstrapping to the related task of named-entity recognition,[0],8,method,1,1.0,0.125,39.0,0.1517509727626459,33.0,0.825,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W99-0613,W03-1022,[202],"the coboost algorithm just described is for the case where there are two labels: for the named entity task there are three labels, and in general it will be useful to generalize the coboost algorithm to the multiclass case.",[0],"collins and singer (1999) for example report that 88% of the named entities occurring in their data set belong to these three categories (collins and singer, 1999)",[0],10,method,4,4.0,0.5,202.0,0.7859922178988327,69.0,0.7840909090909091,0,0.0,0.0,0.0,0.0,0.0,4 a boosting-based algorithm,abstract
W99-0613,E09-1018,[61],"the following features were used: full-string=x the full string (e.g., for maury cooper, full- s tring=maury_cooper). contains(x) if the spelling contains more than one word, this feature applies for any words that the string contains (e.g., maury cooper contributes two such features, contains (maury) and contains (cooper) . allcapl this feature appears if the spelling is a single word which is all capitals (e.g., ibm would contribute this feature). allcap2 this feature appears if the spelling is a single word which is all capitals or full periods, and contains at least one period.",[0],"while em has worked quite well for a few tasks, notably ma chine translations (starting with the ibm models 1-5 (brown et al, 1993), it has not had success inmost others, such as part-of-speech tagging (merialdo, 1991), named-entity recognition (collinsand singer, 1999) and context-free-grammar induction (numerous attempts, too many to mention)",[0],11,method,2,2.0,0.25,61.0,0.23735408560311283,15.0,0.7142857142857143,0,0.0,0.0,0.0,0.0,0.0,2 the problem,abstract
W99-0613,W10-3504,[176],"(7) is at 0 when: 1) vi : sign(gi (xi)) = sign(g2 (xi)); 2) ig3(xi)l oo; and 3) sign(gi (xi)) = yi for i = 1, , m. in fact, zco provides a bound on the sum of the classification error of the labeled examples and the number of disagreements between the two classifiers on the unlabeled examples.",[0],"this can be either a fixed number of added unlabelled examples (blum and mitchell, 1998), the performance drop on a control set of labelled instances, or a filter on the disagreement of h1 and h2 in classifying u (collins and singer, 1999)",[0],12,method,4,4.0,0.5,176.0,0.6848249027237354,43.0,0.48863636363636365,0,0.0,0.0,0.0,0.0,0.0,4 a boosting-based algorithm,abstract
W99-0613,W07-1712,[108],"in the cotraining case, (blum and mitchell 98) argue that the task should be to induce functions ii and f2 such that so ii and 12 must (1) correctly classify the labeled examples, and (2) must agree with each other on the unlabeled examples.",[0],"in addition, we would also like to explore the semi-supervised techniques such as co-training and self-training (collins and singer, 1999)",[0],13,method,3,3.0,0.375,108.0,0.42023346303501946,41.0,0.6212121212121212,0,0.0,0.0,0.0,0.0,0.0,3 unsupervised algorithms based on decision lists,abstract
W99-0613,W09-2208,"[27, 28]","the first method builds on results from (yarowsky 95) and (blum and mitchell 98).
(yarowsky 95) describes an algorithm for word-sense disambiguation that exploits redundancy in contextual features, and gives impressive performance.",[0],"collins et al (collins and singer, 1999) proposed two algorithms for ner by modifying yarowsky ?smethod (yarowsky, 1995) and the framework suggested by (blum and mitchell, 1998)",[0],15,method,1_1,1.0,0.125,27.5,0.10700389105058365,21.5,0.5375000000000001,0,0.0,0.0,0.0,0.0,0.0,"1 introduction, 1 introduction",abstract
W99-0613,W06-2207,[7],"many statistical or machine-learning approaches for natural language problems require a relatively large amount of supervision, in the form of labeled training examples.",[0],"this approach was shown to perform well on real-world natural language problems (collins and singer, 1999)",[0],16,method,1,1.0,0.125,7.0,0.027237354085603113,1.0,0.025,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W99-0613,W06-2207,[172],"to see this, note thai the first two terms in the above equation correspond to the function that adaboost attempts to minimize in the standard supervised setting (equ.",[0],"(4 )prec (p, y)= count (p, y) count (p) (5) where prec (p, y) is the raw precision of pattern p in the set of documents labeled with category y. criterion 2: collins this criterion was used in a lightly-supervised ne recognizer (collins and singer, 1999)",[0],17,method,4,4.0,0.5,172.0,0.669260700389105,39.0,0.4431818181818182,0,0.0,0.0,0.0,0.0,0.0,4 a boosting-based algorithm,abstract
W99-0613,W06-2207,[85],"(if fewer than n rules have precision greater than pin, we 3note that taking tlie top n most frequent rules already makes the method robut to low count events, hence we do not use smoothing, allowing low-count high-precision features to be chosen on later iterations. keep only those rules which exceed the precision threshold.) pm,n was fixed at 0.95 in all experiments in this paper.",[0],"(6) similarly to (collins and singer, 1999) we used t= 0.95 for all experiments reported here",[0],18,method,3,3.0,0.375,85.0,0.33073929961089493,18.0,0.2727272727272727,0,0.0,0.0,0.0,0.0,0.0,3 unsupervised algorithms based on decision lists,abstract
W99-0613,P12-1065,[214],"this modification brings the method closer to the dl-cotrain algorithm described earlier, and is motivated by the intuition that all three labels should be kept healthily populated in the unlabeled examples, preventing one label from dominating — this deserves more theoretical investigation.",[0],"3this is not clearly specified in collins and singer (1999), 3.2 yarowsky-cautious",[0],20,method,4,4.0,0.5,214.0,0.8326848249027238,81.0,0.9204545454545454,0,0.0,0.0,0.0,0.0,0.0,4 a boosting-based algorithm,abstract
W99-0613,N01-1023,[9],this paper discusses the use of unlabeled examples for the problem of named entity classification.,[0],"co-training has been used before in applications like word-sense disambiguation (yarowsky, 1995), web-page classification (blum and mitchell, 1998) and named entity identification (collins and singer, 1999)",[0],1,method,1,1.0,0.125,9.0,0.03501945525291829,3.0,0.075,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W99-0613,N01-1023,[35],"adaboost finds a weighted combination of simple (weak) classifiers, where the weights are chosen to minimize a function that bounds the classification error on a set of training examples.",[0],"they also discuss an application of classifying web pages by using their method of mutually constrained models. (collins and singer, 1999) further extend the use of classifiers that have mutual constraints by adding terms toadaboost which force the classifiers to agree (called co boosting)",[0],2,method,1,1.0,0.125,35.0,0.13618677042801555,29.0,0.725,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W99-0613,W03-1509,[134],"this section describes an algorithm based on boosting algorithms, which were previously developed for supervised machine learning problems.",[0],"recent methods for english ner focus on machine-learning algorithms such as dl-cotrain, coboost [collins and singer 1999], hmm [daniel m. bikel 1997], maximum entropy model [borthwick, et al 1999] and so on",[0],4,method,4,4.0,0.5,134.0,0.5214007782101168,1.0,0.011363636363636364,0,0.0,0.0,0.0,0.0,0.0,4 a boosting-based algorithm,abstract
W99-0613,C02-1154,[236],"we chose one of four labels for each example: location, person, organization, or noise where the noise category was used for items that were outside the three categories.",[0],"(collins and singer, 1999) also makes use of competing categories (person, organization, and location), which cover 96% of all the instances itset out to classify",[0],6,method,6,6.0,0.75,236.0,0.9182879377431906,3.0,0.1875,0,0.0,0.0,0.0,0.0,0.0,6 evaluation,abstract
W99-0613,W06-2204,[8],"recent results (e.g., (yarowsky 95; brill 95; blum and mitchell 98)) have suggested that unlabeled data can be used quite profitably in reducing the need for supervision.",[0],"in (collins and singer, 1999) collins and singer show that unlabeled data can be used to reduce the level of supervision required for named entity classification",[0],7,method,1,1.0,0.125,8.0,0.0311284046692607,2.0,0.05,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W99-0613,W09-1116,[42],(riloff and shepherd 97) describe a bootstrapping approach for acquiring nouns in particular categories (such as &quot;vehicle&quot; or &quot;weapon&quot; categories).,[0],collins and singer (1999) and cucerzan and yarowsky (1999) apply bootstrapping to the related task of named-entity recognition,[0],8,method,1,1.0,0.125,42.0,0.16342412451361868,36.0,0.9,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W99-0613,W03-1022,[236],"we chose one of four labels for each example: location, person, organization, or noise where the noise category was used for items that were outside the three categories.",[0],"collins and singer (1999) for example report that 88% of the named entities occurring in their data set belong to these three categories (collins and singer, 1999)",[0],10,method,6,6.0,0.75,236.0,0.9182879377431906,3.0,0.1875,0,0.0,0.0,0.0,0.0,0.0,6 evaluation,abstract
W99-0613,E09-1018,[222],"the expectation maximization (em) algorithm (dempster, laird and rubin 77) is a common approach for unsupervised training; in this section we describe its application to the named entity problem.",[0],"while em has worked quite well for a few tasks, notably ma chine translations (starting with the ibm models 1-5 (brown et al, 1993), it has not had success inmost others, such as part-of-speech tagging (merialdo, 1991), named-entity recognition (collinsand singer, 1999) and context-free-grammar induction (numerous attempts, too many to mention)",[0],11,method,5,5.0,0.625,222.0,0.8638132295719845,1.0,0.08333333333333333,0,0.0,0.0,0.0,0.0,0.0,5 an em-based approach,abstract
W99-0613,W10-3504,[30],"(blum and mitchell 98) offer a promising formulation of redundancy, also prove some results about how the use of can help classification, and suggest an objective function when training with unlabeled examples.",[0],"this can be either a fixed number of added unlabelled examples (blum and mitchell, 1998), the performance drop on a control set of labelled instances, or a filter on the disagreement of h1 and h2 in classifying u (collins and singer, 1999)",[0],12,method,1,1.0,0.125,30.0,0.11673151750972763,24.0,0.6,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W99-0613,W09-2208,[26],we present two algorithms.,[0],"collins et al (collins and singer, 1999) proposed two algorithms for ner by modifying yarowsky ?smethod (yarowsky, 1995) and the framework suggested by (blum and mitchell, 1998)",[0],15,method,1,1.0,0.125,26.0,0.10116731517509728,20.0,0.5,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W99-0613,W06-2207,[7],"many statistical or machine-learning approaches for natural language problems require a relatively large amount of supervision, in the form of labeled training examples.",[0],"this approach was shown to perform well on real-world natural language problems (collins and singer, 1999)",[0],16,method,1,1.0,0.125,7.0,0.027237354085603113,1.0,0.025,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W99-0613,W06-2207,[32],the algorithm can be viewed as heuristically optimizing an objective function suggested by (blum and mitchell 98); empirically it is shown to be quite successful in optimizing this criterion.,[0],"(4 )prec (p, y)= count (p, y) count (p) (5) where prec (p, y) is the raw precision of pattern p in the set of documents labeled with category y. criterion 2: collins this criterion was used in a lightly-supervised ne recognizer (collins and singer, 1999)",[0],17,method,1,1.0,0.125,32.0,0.1245136186770428,26.0,0.65,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W99-0613,P12-1065,[47],"971,746 sentences of new york times text were parsed using the parser of (collins 96).1 word sequences that met the following criteria were then extracted as named entity examples: whose head is a singular noun (tagged nn).",[0],we use collins and singer (1999) for our exact specification of yarowsky.2 it uses dl rule scores ?fj?| ?fj |+ |? f |+ l (1) where is a smoothing constant,[0],19,method,2,2.0,0.25,47.0,0.1828793774319066,1.0,0.047619047619047616,0,0.0,0.0,0.0,0.0,0.0,2 the problem,abstract
W99-0613,P12-1065,[127],the dl-cotrain algorithm can be motivated as being a greedy method of satisfying the above 2 constraints.,[0],"3this is not clearly specified in collins and singer (1999), 3.2 yarowsky-cautious",[0],20,method,3,3.0,0.375,127.0,0.49416342412451364,60.0,0.9090909090909091,0,0.0,0.0,0.0,0.0,0.0,3 unsupervised algorithms based on decision lists,abstract
W99-0623,A00-2005,[85],we then show that the combining techniques presented above give better parsing accuracy than any of the individual parsers.,[0],1 introduct ion henderson and brill (1999) showed that independent human research efforts produce parsers that can be combined for an overall boost in accuracy,[0],1,aim,3,3.0,0.5,85.0,0.5704697986577181,14.0,0.208955223880597,0,0.0,0.0,0.0,0.0,0.0,3 experiments,abstract
W99-0623,A00-2005,[120],"the precision and recall of similarity switching and constituent voting are both significantly better than the best individual parser, and constituent voting is significantly better than parser switching in precision.4 constituent voting gives the highest accuracy for parsing the penn treebank reported to date.",[0],the collection of hypotheses ti =fi (stest) using the unweighted constituent voting scheme of henderson and brill (1999),[0],2,result,3,3.0,0.5,120.0,0.8053691275167785,49.0,0.7313432835820896,0,0.0,0.0,0.0,0.0,0.0,3 experiments,abstract
W99-0623,N10-1091,[25],in our particular case the majority requires the agreement of only two parsers because we have only three.,[0],"5 (henderson and brill, 1999) used a similar framework in the context of constituent parsing and only three base parsers",[0],4,method,2,2.0,0.3333333333333333,25.0,0.16778523489932887,11.0,0.19298245614035087,0,0.0,0.0,0.0,0.0,0.0,2 techniques for combining parsers,abstract
W99-0623,W05-1518,[120],"the precision and recall of similarity switching and constituent voting are both significantly better than the best individual parser, and constituent voting is significantly better than parser switching in precision.4 constituent voting gives the highest accuracy for parsing the penn treebank reported to date.",[0],"a successful application of voting and of a stacked classifier to constituent parsing followed in (henderson and brill, 1999)",[0],5,result,3,3.0,0.5,120.0,0.8053691275167785,49.0,0.7313432835820896,0,0.0,0.0,0.0,0.0,0.0,3 experiments,abstract
W99-0623,W05-1518,[38],under certain conditions the constituent voting and naïve bayes constituent combination techniques are guaranteed to produce sets of constituents with no crossing brackets.,[0],"this approach roughly corresponds to (henderson and brill, 1999)? s na ?ve bayes parse hybridization",[0],6,result,2,2.0,0.3333333333333333,38.0,0.2550335570469799,24.0,0.42105263157894735,0,0.0,0.0,0.0,0.0,0.0,2 techniques for combining parsers,abstract
W99-0623,W05-1518,[91],"features and context were initially introduced into the models, but they refused to offer any gains in performance.",[0],henderson and brill (1999) also reported that context did not help them to outperform simple voting,[0],7,method,3,3.0,0.5,91.0,0.610738255033557,20.0,0.29850746268656714,0,0.0,0.0,0.0,0.0,0.0,3 experiments,abstract
W99-0623,W05-1518,[120],"the precision and recall of similarity switching and constituent voting are both significantly better than the best individual parser, and constituent voting is significantly better than parser switching in precision.4 constituent voting gives the highest accuracy for parsing the penn treebank reported to date.",[0],"(henderson and brill, 1999) improved their best parser? s f-measure of 89.7 to 91.3, using their na ?ve bayes voting on the penn treebank constituent structures (16% error reduction)",[0],8,result,3,3.0,0.5,120.0,0.8053691275167785,49.0,0.7313432835820896,0,0.0,0.0,0.0,0.0,0.0,3 experiments,abstract
W99-0623,P01-1005,[120],"the precision and recall of similarity switching and constituent voting are both significantly better than the best individual parser, and constituent voting is significantly better than parser switching in precision.4 constituent voting gives the highest accuracy for parsing the penn treebank reported to date.",[0],"voting has proven to be an effective technique for improving classifier accuracy for many applications, including part-of-speech tagging (van halteren, et al 1998), parsing (henderson and brill, 1999), and word sense disambiguation (pederson, 2000)",[0],10,result,3,3.0,0.5,120.0,0.8053691275167785,49.0,0.7313432835820896,0,0.0,0.0,0.0,0.0,0.0,3 experiments,abstract
W99-0623,D09-1161,[139],we have presented two general approaches to studying parser combination: parser switching and parse hybridization.,[0],"regarding the system combination study, henderson and brill (1999) propose two parser combination schemes, one that selects an entire tree from one of the parsers, and one that builds a new tree by selecting constituents suggested by the initial trees",[0],11,result,4,4.0,0.6666666666666666,139.0,0.9328859060402684,1.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,4 conclusion,abstract
W99-0623,D09-1161,[25],in our particular case the majority requires the agreement of only two parsers because we have only three.,[0],"henderson and brill (1999) combine three parsers and obtained an f1 score of 90.6, which is better than the score of 88.6 obtained by the best individual parser as reported in their paper",[0],12,method,2,2.0,0.3333333333333333,25.0,0.16778523489932887,11.0,0.19298245614035087,0,0.0,0.0,0.0,0.0,0.0,2 techniques for combining parsers,abstract
W99-0623,D09-1161,[103],the counts represent portions of the approximately 44000 constituents hypothesized by the parsers in the development set.,[0],"besides the two model scores, we also adopt constituent count as an additional feature in spired by (henderson and brill 1999) and (sagae and lavie 2006)",[0],13,method,3,3.0,0.5,103.0,0.6912751677852349,32.0,0.47761194029850745,0,0.0,0.0,0.0,0.0,0.0,3 experiments,abstract
W99-0623,N06-2033,[139],we have presented two general approaches to studying parser combination: parser switching and parse hybridization.,[0],"henderson and brill (1999) proposed two parser combination schemes, one that picks an entire tree from one of the parsers, and one that, like ours, builds a new tree from constituents from the initial trees",[0],14,result,4,4.0,0.6666666666666666,139.0,0.9328859060402684,1.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,4 conclusion,abstract
W99-0623,N09-2064,[70],"in this case we are interested in finding' the maximum probability parse, ri, and mi is the set of relevant (binary) parsing decisions made by parser i. ri is a parse selected from among the outputs of the individual parsers.",[0],"(henderson and brill, 1999) perform parse selection by maximizing the expected precision of the selected parse with respect to the set of parses being combined",[0],15,aim,2,2.0,0.3333333333333333,70.0,0.4697986577181208,56.0,0.9824561403508771,0,0.0,0.0,0.0,0.0,0.0,2 techniques for combining parsers,abstract
W99-0623,N09-2064,[140],for each experiment we gave an nonparametric and a parametric technique for combining parsers.,[0],"(henderson and brill, 1999) and (sagae and lavie, 2006) propose methods for parse hybridization by recombining constituents",[0],16,method,4,4.0,0.6666666666666666,140.0,0.9395973154362416,2.0,0.2857142857142857,0,0.0,0.0,0.0,0.0,0.0,4 conclusion,abstract
W99-0623,N09-2064,[70],"in this case we are interested in finding' the maximum probability parse, ri, and mi is the set of relevant (binary) parsing decisions made by parser i. ri is a parse selected from among the outputs of the individual parsers.",[0],"output (figure 3) .second, the parse selection method of (henderson and brill, 1999) selects the parse with maximum expected precision; here, we present an efficient, linear-time algorithm for selecting the parse with maximum expected f-score within the mini mum bayes risk (mbr) framework. third, we extend these parser combination methods from 1-best outputs to n-best outputs",[0],17,aim,2,2.0,0.3333333333333333,70.0,0.4697986577181208,56.0,0.9824561403508771,0,0.0,0.0,0.0,0.0,0.0,2 techniques for combining parsers,abstract
W99-0623,P09-1065,[85],we then show that the combining techniques presented above give better parsing accuracy than any of the individual parsers.,[0],"system combination has benefited various nlp tasks in recent years, such as products-of-experts (e.g., (smith and eisner, 2005)) and ensemble based parsing (e.g., (henderson and brill, 1999))",[0],18,result,3,3.0,0.5,85.0,0.5704697986577181,14.0,0.208955223880597,0,0.0,0.0,0.0,0.0,0.0,3 experiments,abstract
W99-0623,C10-1151,[70],"in this case we are interested in finding' the maximum probability parse, ri, and mi is the set of relevant (binary) parsing decisions made by parser i. ri is a parse selected from among the outputs of the individual parsers.",[0],henderson and brill (1999) performs parse selection by maximizing the expected precision of selected parse with respect to the set of parses to be combined,[0],20,aim,2,2.0,0.3333333333333333,70.0,0.4697986577181208,56.0,0.9824561403508771,0,0.0,0.0,0.0,0.0,0.0,2 techniques for combining parsers,abstract
W99-0623,A00-2005,[144],combining multiple highly-accurate independent parsers yields promising results.,[0],1 introduct ion henderson and brill (1999) showed that independent human research efforts produce parsers that can be combined for an overall boost in accuracy,[0],1,method,4,4.0,0.6666666666666666,144.0,0.9664429530201343,6.0,0.8571428571428571,0,0.0,0.0,0.0,0.0,0.0,4 conclusion,abstract
W99-0623,A00-2005,[125],the constituent voting and naïve bayes techniques are equivalent because the parameters learned in the training set did not sufficiently discriminate between the three parsers.,[0],the collection of hypotheses ti =fi (stest) using the unweighted constituent voting scheme of henderson and brill (1999),[0],2,method,3,3.0,0.5,125.0,0.8389261744966443,54.0,0.8059701492537313,0,0.0,0.0,0.0,0.0,0.0,3 experiments,abstract
W99-0623,N10-1091,[125],the constituent voting and naïve bayes techniques are equivalent because the parameters learned in the training set did not sufficiently discriminate between the three parsers.,[0],"5 (henderson and brill, 1999) used a similar framework in the context of constituent parsing and only three base parsers",[0],4,method,3,3.0,0.5,125.0,0.8389261744966443,54.0,0.8059701492537313,0,0.0,0.0,0.0,0.0,0.0,3 experiments,abstract
W99-0623,W05-1518,[48],"• similarly, when the naïve bayes classifier is configured such that the constituents require estimated probabilities strictly larger than 0.5 to be accepted, there is not enough probability mass remaining on crossing brackets for them to be included in the hypothesis.",[0],"a successful application of voting and of a stacked classifier to constituent parsing followed in (henderson and brill, 1999)",[0],5,method,2,2.0,0.3333333333333333,48.0,0.3221476510067114,34.0,0.5964912280701754,0,0.0,0.0,0.0,0.0,0.0,2 techniques for combining parsers,abstract
W99-0623,W05-1518,[139],we have presented two general approaches to studying parser combination: parser switching and parse hybridization.,[0],"this approach roughly corresponds to (henderson and brill, 1999)? s na ?ve bayes parse hybridization",[0],6,method,4,4.0,0.6666666666666666,139.0,0.9328859060402684,1.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,4 conclusion,abstract
W99-0623,W05-1518,[134],"as seen by the drop in average individual parser performance baseline, the introduced parser does not perform very well.",[0],henderson and brill (1999) also reported that context did not help them to outperform simple voting,[0],7,method,3,3.0,0.5,134.0,0.8993288590604027,63.0,0.9402985074626866,0,0.0,0.0,0.0,0.0,0.0,3 experiments,abstract
W99-0623,W05-1518,[38],under certain conditions the constituent voting and naïve bayes constituent combination techniques are guaranteed to produce sets of constituents with no crossing brackets.,[0],"(henderson and brill, 1999) improved their best parser? s f-measure of 89.7 to 91.3, using their na ?ve bayes voting on the penn treebank constituent structures (16% error reduction)",[0],8,method,2,2.0,0.3333333333333333,38.0,0.2550335570469799,24.0,0.42105263157894735,0,0.0,0.0,0.0,0.0,0.0,2 techniques for combining parsers,abstract
W99-0623,P01-1005,[120],"the precision and recall of similarity switching and constituent voting are both significantly better than the best individual parser, and constituent voting is significantly better than parser switching in precision.4 constituent voting gives the highest accuracy for parsing the penn treebank reported to date.",[0],"voting has proven to be an effective technique for improving classifier accuracy for many applications, including part-of-speech tagging (van halteren, et al 1998), parsing (henderson and brill, 1999), and word sense disambiguation (pederson, 2000)",[0],10,method,3,3.0,0.5,120.0,0.8053691275167785,49.0,0.7313432835820896,0,0.0,0.0,0.0,0.0,0.0,3 experiments,abstract
W99-0623,D09-1161,[139],we have presented two general approaches to studying parser combination: parser switching and parse hybridization.,[0],"regarding the system combination study, henderson and brill (1999) propose two parser combination schemes, one that selects an entire tree from one of the parsers, and one that builds a new tree by selecting constituents suggested by the initial trees",[0],11,method,4,4.0,0.6666666666666666,139.0,0.9328859060402684,1.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,4 conclusion,abstract
W99-0623,D09-1161,[13],"these three parsers have given the best reported parsing results on the penn treebank wall street journal corpus (marcus et al., 1993).",[0],"henderson and brill (1999) combine three parsers and obtained an f1 score of 90.6, which is better than the score of 88.6 obtained by the best individual parser as reported in their paper",[0],12,method,1,1.0,0.16666666666666666,13.0,0.087248322147651,9.0,0.9,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W99-0623,D09-1161,[108],"from this we see that a finer-grained model for parser combination, at least for the features we have examined, will not give us any additional power.",[0],"besides the two model scores, we also adopt constituent count as an additional feature in spired by (henderson and brill 1999) and (sagae and lavie 2006)",[0],13,method,3,3.0,0.5,108.0,0.7248322147651006,37.0,0.5522388059701493,0,0.0,0.0,0.0,0.0,0.0,3 experiments,abstract
W99-0623,N06-2033,[139],we have presented two general approaches to studying parser combination: parser switching and parse hybridization.,[0],"henderson and brill (1999) proposed two parser combination schemes, one that picks an entire tree from one of the parsers, and one that, like ours, builds a new tree from constituents from the initial trees",[0],14,method,4,4.0,0.6666666666666666,139.0,0.9328859060402684,1.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,4 conclusion,abstract
W99-0623,N09-2064,[98],"adding the isolated constituents to our hypothesis parse could increase our expected recall, but in the cases we investigated it would invariably hurt our precision more than we would gain on recall.",[0],"(henderson and brill, 1999) perform parse selection by maximizing the expected precision of the selected parse with respect to the set of parses being combined",[0],15,method,3,3.0,0.5,98.0,0.6577181208053692,27.0,0.40298507462686567,0,0.0,0.0,0.0,0.0,0.0,3 experiments,abstract
W99-0623,N09-2064,[27],another technique for parse hybridization is to use a naïve bayes classifier to determine which constituents to include in the parse.,[0],"(henderson and brill, 1999) and (sagae and lavie, 2006) propose methods for parse hybridization by recombining constituents",[0],16,method,2,2.0,0.3333333333333333,27.0,0.18120805369127516,13.0,0.22807017543859648,0,0.0,0.0,0.0,0.0,0.0,2 techniques for combining parsers,abstract
W99-0623,N09-2064,"[80, 81, 82]","for our experiments we also report the mean of precision and recall, which we denote by (p + r)i2 and f-measure.
f-measure is the harmonic mean of precision and recall, 2pr/(p + r).
it is closer to the smaller value of precision and recall when there is a large skew in their values.",[0],"output (figure 3) .second, the parse selection method of (henderson and brill, 1999) selects the parse with maximum expected precision; here, we present an efficient, linear-time algorithm for selecting the parse with maximum expected f-score within the mini mum bayes risk (mbr) framework. third, we extend these parser combination methods from 1-best outputs to n-best outputs",[0],17,method,3_3_3,3.0,0.5,81.0,0.5436241610738255,10.0,0.14925373134328357,0,0.0,0.0,0.0,0.0,0.0,"3 experiments, 3 experiments, 3 experiments",abstract
W99-0623,P09-1065,[49],"in general, the lemma of the previous section does not ensure that all the productions in the combined parse are found in the grammars of the member parsers.",[0],"system combination has benefited various nlp tasks in recent years, such as products-of-experts (e.g., (smith and eisner, 2005)) and ensemble based parsing (e.g., (henderson and brill, 1999))",[0],18,method,2,2.0,0.3333333333333333,49.0,0.3288590604026846,35.0,0.6140350877192983,0,0.0,0.0,0.0,0.0,0.0,2 techniques for combining parsers,abstract
W99-0623,N03-1004,[11],"similar advances have been made in machine translation (frederking and nirenburg, 1994), speech recognition (fiscus, 1997) and named entity recognition (borthwick et al., 1998).",[0],"in nlp, such methods have been applied to tasks such as pos tagging (brill and wu, 1998), word sense disambiguation (pedersen, 2000), parsing (henderson and brill, 1999), and machine translation (frederking and nirenburg, 1994)",[0],19,method,1,1.0,0.16666666666666666,11.0,0.0738255033557047,7.0,0.7,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W99-0623,C10-1151,[98],"adding the isolated constituents to our hypothesis parse could increase our expected recall, but in the cases we investigated it would invariably hurt our precision more than we would gain on recall.",[0],henderson and brill (1999) performs parse selection by maximizing the expected precision of selected parse with respect to the set of parses to be combined,[0],20,method,3,3.0,0.5,98.0,0.6577181208053692,27.0,0.40298507462686567,0,0.0,0.0,0.0,0.0,0.0,3 experiments,abstract
W99-0623,A00-2005,[85],we then show that the combining techniques presented above give better parsing accuracy than any of the individual parsers.,[0],1 introduct ion henderson and brill (1999) showed that independent human research efforts produce parsers that can be combined for an overall boost in accuracy,[0],1,method,3,3.0,0.5,85.0,0.5704697986577181,14.0,0.208955223880597,0,0.0,0.0,0.0,0.0,0.0,3 experiments,abstract
W99-0623,A00-2005,[117],another way to interpret this is that less than 5% of the correct constituents are missing from the hypotheses generated by the union of the three parsers.,[0],the collection of hypotheses ti =fi (stest) using the unweighted constituent voting scheme of henderson and brill (1999),[0],2,method,3,3.0,0.5,117.0,0.785234899328859,46.0,0.6865671641791045,0,0.0,0.0,0.0,0.0,0.0,3 experiments,abstract
W99-0623,N10-1091,[72],"the three parsers were trained and tuned by their creators on various sections of the wsj portion of the penn treebank, leaving only sections 22 and 23 completely untouched during the development of any of the parsers.",[0],"5 (henderson and brill, 1999) used a similar framework in the context of constituent parsing and only three base parsers",[0],4,method,3,3.0,0.5,72.0,0.48322147651006714,1.0,0.014925373134328358,0,0.0,0.0,0.0,0.0,0.0,3 experiments,abstract
W99-0623,W05-1518,[120],"the precision and recall of similarity switching and constituent voting are both significantly better than the best individual parser, and constituent voting is significantly better than parser switching in precision.4 constituent voting gives the highest accuracy for parsing the penn treebank reported to date.",[0],"a successful application of voting and of a stacked classifier to constituent parsing followed in (henderson and brill, 1999)",[0],5,method,3,3.0,0.5,120.0,0.8053691275167785,49.0,0.7313432835820896,0,0.0,0.0,0.0,0.0,0.0,3 experiments,abstract
W99-0623,W05-1518,[139],we have presented two general approaches to studying parser combination: parser switching and parse hybridization.,[0],"this approach roughly corresponds to (henderson and brill, 1999)? s na ?ve bayes parse hybridization",[0],6,method,4,4.0,0.6666666666666666,139.0,0.9328859060402684,1.0,0.14285714285714285,0,0.0,0.0,0.0,0.0,0.0,4 conclusion,abstract
W99-0623,W05-1518,[84],the first shows how constituent features and context do not help in deciding which parser to trust.,[0],henderson and brill (1999) also reported that context did not help them to outperform simple voting,[0],7,method,3,3.0,0.5,84.0,0.5637583892617449,13.0,0.19402985074626866,0,0.0,0.0,0.0,0.0,0.0,3 experiments,abstract
W99-0623,W05-1518,[76],the standard measures for evaluating penn treebank parsing performance are precision and recall of the predicted constituents.,[0],"(henderson and brill, 1999) improved their best parser? s f-measure of 89.7 to 91.3, using their na ?ve bayes voting on the penn treebank constituent structures (16% error reduction)",[0],8,method,3,3.0,0.5,76.0,0.5100671140939598,5.0,0.07462686567164178,0,0.0,0.0,0.0,0.0,0.0,3 experiments,abstract
W99-0623,P01-1005,[38],under certain conditions the constituent voting and naïve bayes constituent combination techniques are guaranteed to produce sets of constituents with no crossing brackets.,[0],"voting has proven to be an effective technique for improving classifier accuracy for many applications, including part-of-speech tagging (van halteren, et al 1998), parsing (henderson and brill, 1999), and word sense disambiguation (pederson, 2000)",[0],10,method,2,2.0,0.3333333333333333,38.0,0.2550335570469799,24.0,0.42105263157894735,0,0.0,0.0,0.0,0.0,0.0,2 techniques for combining parsers,abstract
W99-0623,D09-1161,[25],in our particular case the majority requires the agreement of only two parsers because we have only three.,[0],"regarding the system combination study, henderson and brill (1999) propose two parser combination schemes, one that selects an entire tree from one of the parsers, and one that builds a new tree by selecting constituents suggested by the initial trees",[0],11,method,2,2.0,0.3333333333333333,25.0,0.16778523489932887,11.0,0.19298245614035087,0,0.0,0.0,0.0,0.0,0.0,2 techniques for combining parsers,abstract
W99-0623,D09-1161,[72],"the three parsers were trained and tuned by their creators on various sections of the wsj portion of the penn treebank, leaving only sections 22 and 23 completely untouched during the development of any of the parsers.",[0],"henderson and brill (1999) combine three parsers and obtained an f1 score of 90.6, which is better than the score of 88.6 obtained by the best individual parser as reported in their paper",[0],12,method,3,3.0,0.5,72.0,0.48322147651006714,1.0,0.014925373134328358,0,0.0,0.0,0.0,0.0,0.0,3 experiments,abstract
W99-0623,D09-1161,[87],it is possible one could produce better models by introducing features describing constituents and their contexts because one parser could be much better than the majority of the others in particular situations.,[0],"besides the two model scores, we also adopt constituent count as an additional feature in spired by (henderson and brill 1999) and (sagae and lavie 2006)",[0],13,method,3,3.0,0.5,87.0,0.5838926174496645,16.0,0.23880597014925373,0,0.0,0.0,0.0,0.0,0.0,3 experiments,abstract
W99-0623,N06-2033,[51],"one can trivially create situations in which strictly binary-branching trees are combined to create a tree with only the root node and the terminal nodes, a completely flat structure.",[0],"henderson and brill (1999) proposed two parser combination schemes, one that picks an entire tree from one of the parsers, and one that, like ours, builds a new tree from constituents from the initial trees",[0],14,method,2,2.0,0.3333333333333333,51.0,0.3422818791946309,37.0,0.6491228070175439,0,0.0,0.0,0.0,0.0,0.0,2 techniques for combining parsers,abstract
W99-0623,N09-2064,[79],precision is the portion of hypothesized constituents that are correct and recall is the portion of the treebank constituents that are hypothesized.,[0],"(henderson and brill, 1999) perform parse selection by maximizing the expected precision of the selected parse with respect to the set of parses being combined",[0],15,method,3,3.0,0.5,79.0,0.5302013422818792,8.0,0.11940298507462686,0,0.0,0.0,0.0,0.0,0.0,3 experiments,abstract
W99-0623,N09-2064,[27],another technique for parse hybridization is to use a naïve bayes classifier to determine which constituents to include in the parse.,[0],"(henderson and brill, 1999) and (sagae and lavie, 2006) propose methods for parse hybridization by recombining constituents",[0],16,method,2,2.0,0.3333333333333333,27.0,0.18120805369127516,13.0,0.22807017543859648,0,0.0,0.0,0.0,0.0,0.0,2 techniques for combining parsers,abstract
W99-0623,N09-2064,[77],"each parse is converted into a set of constituents represented as a tuples: (label, start, end).",[0],"output (figure 3) .second, the parse selection method of (henderson and brill, 1999) selects the parse with maximum expected precision; here, we present an efficient, linear-time algorithm for selecting the parse with maximum expected f-score within the mini mum bayes risk (mbr) framework. third, we extend these parser combination methods from 1-best outputs to n-best outputs",[0],17,method,3,3.0,0.5,77.0,0.5167785234899329,6.0,0.08955223880597014,0,0.0,0.0,0.0,0.0,0.0,3 experiments,abstract
W99-0623,N03-1004,[11],"similar advances have been made in machine translation (frederking and nirenburg, 1994), speech recognition (fiscus, 1997) and named entity recognition (borthwick et al., 1998).",[0],"in nlp, such methods have been applied to tasks such as pos tagging (brill and wu, 1998), word sense disambiguation (pedersen, 2000), parsing (henderson and brill, 1999), and machine translation (frederking and nirenburg, 1994)",[0],19,method,1,1.0,0.16666666666666666,11.0,0.0738255033557047,7.0,0.7,0,0.0,0.0,0.0,0.0,0.0,1 introduction,abstract
W99-0623,C10-1151,[116],the maximum precision row is the upper bound on accuracy if we could pick exactly the correct constituents from among the constituents suggested by the three parsers.,[0],henderson and brill (1999) performs parse selection by maximizing the expected precision of selected parse with respect to the set of parses to be combined,[0],20,method,3,3.0,0.5,116.0,0.7785234899328859,45.0,0.6716417910447762,0,0.0,0.0,0.0,0.0,0.0,3 experiments,abstract
