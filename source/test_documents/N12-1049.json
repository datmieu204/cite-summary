{
    "ID": "N12-1049",
    "sections": [
        {
            "text": "abstract",
            "number": 0,
            "sents": [
                {
                    "text": "Parsing Time: Learning to Interpret Time Expressions",
                    "sid": 0,
                    "ssid": null,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We present a probabilistic approach for learning to interpret temporal phrases given only a corpus of utterances and the times they reference.",
                    "sid": 1,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "While most approaches to the task have used regular expressions and similar linear pattern interpretation rules, the possibility of phrasal embedding and modification in time expressions motivates our use of a comof time This is used to construct a parse which evaluates to the time the phrase would represent, as a logical parse might evaluate to a concrete entity.",
                    "sid": 2,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In this way, we can employ a loosely supervised EM-style bootstrapping approach to learn these latent parses while capturing both syntactic uncertainty and pragmatic ambiguity in a probabilistic framework.",
                    "sid": 3,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We achieve an accuracy of 72% on an adapted TempEval-2 task \u2013 comparable to state of the art systems.",
                    "sid": 4,
                    "ssid": 4,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "1 introduction",
            "number": "1",
            "sents": [
                {
                    "text": "Temporal resolution is the task of mapping from a textual phrase describing a potentially complex time, date, or duration to a normalized (grounded) temporal representation.",
                    "sid": 5,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example, possibly complex phrases such as the week before last are often more useful in their grounded form \u2013 e.g., January 1 - January 7.",
                    "sid": 6,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The dominant approach to this problem in previous work has been to use rule-based methods, generally a combination of regular-expression matching followed by hand-written interpretation functions.",
                    "sid": 7,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In general, it is appealing to learn the interpretation of temporal expressions, rather than handbuilding systems.",
                    "sid": 8,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Moreover, complex hierarchical temporal expressions, such as the Tuesday before last or the third Wednesday of each month, and ambiguous expressions, such as last Friday, are difficult to handle using deterministic rules and would benefit from a recursive and probabilistic phrase structure representation.",
                    "sid": 9,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Therefore, we attempt to learn a temporal interpretation system where temporal phrases are parsed by a grammar, but this grammar and its semantic interpretation rules are latent, with only the input phrase and its grounded interpretation given to the learning system.",
                    "sid": 10,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Employing probabilistic techniques allows us to capture ambiguity in temporal phrases in two important respects.",
                    "sid": 11,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In part, it captures syntactic ambiguity \u2013 e.g., last Friday the 13th bracketing as either [last Friday] [the 13th], or last [Friday the 13th].",
                    "sid": 12,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This also includes examples of lexical ambiguity \u2013 e.g., two meanings of last in last week of November versus last week.",
                    "sid": 13,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In addition, temporal expressions often carry a pragmatic ambiguity.",
                    "sid": 14,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For instance, a speaker may refer to either the next or previous Friday when he utters Friday on a Sunday.",
                    "sid": 15,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Similarly, next week can refer to either the coming week or the week thereafter.",
                    "sid": 16,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Probabilistic systems furthermore allow propagation of uncertainty to higher-level components \u2013 for example recognizing that May could have a number of non-temporal meanings and allowing a system with a broader contextual scope to make the final judgment.",
                    "sid": 17,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We implement a CRF to detect temporal expressions, and show our model\u2019s ability to act as a component in such a system.",
                    "sid": 18,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We describe our temporal representation, followed by the learning algorithm; we conclude with experimental results showing our approach to be competitive with state of the art systems.",
                    "sid": 19,
                    "ssid": 15,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "2 related work",
            "number": "2",
            "sents": [
                {
                    "text": "Our approach draws inspiration from a large body of work on parsing expressions into a logical form.",
                    "sid": 20,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The latent parse parallels the formal semantics in previous work, e.g., Montague semantics.",
                    "sid": 21,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Like these representations, a parse \u2013 in conjunction with the reference time \u2013 defines a set of matching entities, in this case the grounded time.",
                    "sid": 22,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The matching times can be thought of as analogous to the entities in a logical model which satisfy a given expression.",
                    "sid": 23,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Supervised approaches to logical parsing prominently include Zelle and Mooney (1996), Zettlemoyer and Collins (2005), Kate et al. (2005), Zettlemoyer and Collins (2007), inter alia.",
                    "sid": 24,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example, Zettlemoyer and Collins (2007) learn a mapping from textual queries to a logical form.",
                    "sid": 25,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This logical form importantly contains all the predicates and entities used in their parse.",
                    "sid": 26,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We loosen the supervision required in these systems by allowing the parse to be entirely latent; the annotation of the grounded time neither defines, nor gives any direct cues about the elements of the parse, since many parses evaluate to the same grounding.",
                    "sid": 27,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "To demonstrate, the grounding for a week ago could be described by specifying a month and day, or as a week ago, or as last x \u2013 substituting today\u2019s day of the week for x.",
                    "sid": 28,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Each of these correspond to a completely different parse.",
                    "sid": 29,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Recent work by Clarke et al. (2010) and Liang et al.",
                    "sid": 30,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2011) similarly relax supervision to require only annotated answers rather than full logical forms.",
                    "sid": 31,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example, Liang et al. (2011) constructs a latent parse similar in structure to a dependency grammar, but representing a logical form.",
                    "sid": 32,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Our proposed lexical entries and grammar combination rules can be thought of as paralleling the lexical entries and predicates, and the implicit combination rules respectively in this framework.",
                    "sid": 33,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Rather than querying from a finite database, however, our system must compare temporal expression within an infinite timeline.",
                    "sid": 34,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Furthermore, our system is run using neither lexical cues nor intelligent initialization.",
                    "sid": 35,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Related work on interpreting temporal expressions has focused on constructing hand-crafted interpretation rules (Mani and Wilson, 2000; Saquete et al., 2003; Puscasu, 2004; Grover et al., 2010).",
                    "sid": 36,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Of these, HeidelTime (Str\u00a8otgen and Gertz, 2010) and SUTime (Chang and Manning, 2012) provide particularly strong competition.",
                    "sid": 37,
                    "ssid": 18,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Recent probabilistic approaches to temporal resolution include UzZaman and Allen (2010), who employ a parser to produce deep logical forms, in conjunction with a CRF classifier.",
                    "sid": 38,
                    "ssid": 19,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In a similar vein, Kolomiyets and Moens (2010) employ a maximum entropy classifier to detect the location and temporal type of expressions; the grounding is then done via deterministic rules.",
                    "sid": 39,
                    "ssid": 20,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "3 representation",
            "number": "3",
            "sents": [
                {
                    "text": "We define a compositional representation of time; a type system is described in Section 3.1 while the grammar is outlined in Section 3.2 and described in detail in Sections 3.3 and 3.4.",
                    "sid": 40,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We represent temporal expressions as either a Range, Sequence, or Duration.",
                    "sid": 41,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We describe these, the Function type, and the miscellaneous Number and Nil types below: Range [and Instant] A period between two dates (or times).",
                    "sid": 42,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This includes entities such as Today, 1987, or Now.",
                    "sid": 43,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We denote a range by the variable r. We maintain a consistent interval-based theory of time (Allen, 1981) and represent instants as intervals with zero span. relative to rs(0) \u2013 the element in the same containing unit as the reference time.",
                    "sid": 44,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We define the reference time t (Reichenbach, 1947) to be the instant relative to which times are evaluated.",
                    "sid": 45,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For the TempEval-2 corpus, we approximate this as the publication time of the article.",
                    "sid": 46,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "While this is conflating Reichenbach\u2019s reference time with speech time, it is a useful approximation.",
                    "sid": 47,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "To contrast with Ranges, a Sequence can represent a number of grounded times.",
                    "sid": 48,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Nonetheless, pragmatically, not all of these are given equal weight \u2013 an utterance of last Friday may mean either of the previous two Fridays, but is unlikely to ground to anything else.",
                    "sid": 49,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We represent this ambiguity by defining a distribution over the elements of the Sequence.",
                    "sid": 50,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "While this could be any distribution, we chose to approximate it as a Gaussian.",
                    "sid": 51,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In order to allow sharing parameters between any sequence, we define the domain in terms of the index of the sequence rather than of a constant unit of time (e.g., seconds).",
                    "sid": 52,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "To illustrate, the distribution over April would have a much larger variance than the distribution over Sunday, were the domains fixed.",
                    "sid": 53,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The probability of the ith element of a sequence thus depends on the beginning of the range rs(i), the reference time t, and the distance between elements of the sequence \u0394s.",
                    "sid": 54,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We summarize this in the equation below, with learned parameters p and Q: Figure 1 shows an example of such a distribution; importantly, note that moving the reference time between two elements dynamically changes the probability assigned to each.",
                    "sid": 55,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Duration A period of time.",
                    "sid": 56,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This includes entities like Week, Month, and 7 days.",
                    "sid": 57,
                    "ssid": 18,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We denote a duration with the variable d. We define a special case of the Duration type to represent approximate durations, identified by their canonical unit (week, month, etc).",
                    "sid": 58,
                    "ssid": 19,
                    "kind_of_tag": "s"
                },
                {
                    "text": "These are used to represent expressions such as a few years or some days.",
                    "sid": 59,
                    "ssid": 20,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Function A function of arity less than or equal to two representing some general modification to one of the above types.",
                    "sid": 60,
                    "ssid": 21,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This captures semantic entities such as those implied in last x, the third x [of y], or x days ago.",
                    "sid": 61,
                    "ssid": 22,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The particular functions and their application are enumerated in Table 2.",
                    "sid": 62,
                    "ssid": 23,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Other Types Two other types bear auxiliary roles in representing temporal expressions, though they are not directly temporal concepts.",
                    "sid": 63,
                    "ssid": 24,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In the grammar, these appear as preterminals only.",
                    "sid": 64,
                    "ssid": 25,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The first of these types is Number \u2013 denoting a number without any temporal meaning attached.",
                    "sid": 65,
                    "ssid": 26,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This comes into play representing expressions such as 2 weeks.",
                    "sid": 66,
                    "ssid": 27,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The other is the Nil type \u2013 denoting terms which are not directly contributing to the semantic meaning of the expression.",
                    "sid": 67,
                    "ssid": 28,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This is intended for words such as a or the, which serve as cues without bearing temporal content themselves.",
                    "sid": 68,
                    "ssid": 29,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The Nil type is lexicalized with the word it generates.",
                    "sid": 69,
                    "ssid": 30,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Omitted Phenomena The representation described is a simplification of the complexities of time.",
                    "sid": 70,
                    "ssid": 31,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Notably, a body of work has focused on reasoning about events or states relative to temporal expressions.",
                    "sid": 71,
                    "ssid": 32,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Moens and Steedman (1988) describes temporal expressions relating to changes of state; Condoravdi (2010) explores NPI licensing in temporal expressions.",
                    "sid": 72,
                    "ssid": 33,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Broader context is also not directly modeled, but rather left to systems in which the model would be embedded.",
                    "sid": 73,
                    "ssid": 34,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Furthermore, vague times (e.g., in the 90\u2019s) represent a notable chunk of temporal expressions uttered.",
                    "sid": 74,
                    "ssid": 35,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In contrast, NLP evaluations have generally not handled such vague time expressions.",
                    "sid": 75,
                    "ssid": 36,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Our approach builds on the assumption that natural language descriptions of time are compositional in nature.",
                    "sid": 76,
                    "ssid": 37,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Each word attached to a temporal phrase is usually compositionally modifying the meaning of the phrase.",
                    "sid": 77,
                    "ssid": 38,
                    "kind_of_tag": "s"
                },
                {
                    "text": "To demonstrate, we consider the expression the week before last week.",
                    "sid": 78,
                    "ssid": 39,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We can construct a meaning by applying the modifier last to week \u2013 creating the previous week; and then applying before to week and last week.",
                    "sid": 79,
                    "ssid": 40,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We construct a paradigm for parsing temporal phrases consisting of a standard PCFG over temporal types with each parse rule defining a function to apply to the child nodes, or the word being generated.",
                    "sid": 80,
                    "ssid": 41,
                    "kind_of_tag": "s"
                },
                {
                    "text": "At the root of the tree, we recursively apply the functions in the parse tree to obtain a final temporal value.",
                    "sid": 81,
                    "ssid": 42,
                    "kind_of_tag": "s"
                },
                {
                    "text": "One can view this formalism as a ruleto-rule translation (Bach, 1976; Allen, 1995, p. 263), or a constrained Synchronous PCFG (Yamada and Knight, 2001).",
                    "sid": 82,
                    "ssid": 43,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Our approach contrasts with common approaches, such as CCG grammars (Steedman, 2000; Bos et al., 2004; Kwiatkowski et al., 2011), giving us more flexibility in the composition rules.",
                    "sid": 83,
                    "ssid": 44,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Figure 2 shows an example of the grammar.",
                    "sid": 84,
                    "ssid": 45,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Formally, we define our temporal grammar G = (E, 5, V, W, R, 0).",
                    "sid": 85,
                    "ssid": 46,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The alphabet E and start symbol 5 retain their usual interpretations.",
                    "sid": 86,
                    "ssid": 47,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We define a set V to be the set of types, as described in Section 3.1 \u2013 these act as our nonterminals.",
                    "sid": 87,
                    "ssid": 48,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For each v E V we define an (infinite) set Wv corresponding to the possible instances of type v. Concretely, if v = Sequence, our set Wv E W could contain elements corresponding to Friday, last Friday, Nov. 27th, etc.",
                    "sid": 88,
                    "ssid": 49,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Each node in the tree defines a pair (v, w) such that w E Wv, with combination rules defined over v and function applications performed on w. A rule R E R is defined as a pair first term is our conventional PCFG rule over the types V. The second term defines the function to apply to the values returned recursively by the child nodes.",
                    "sid": 89,
                    "ssid": 50,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Note that this definition is trivially adapted for the case of unary rules.",
                    "sid": 90,
                    "ssid": 51,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The last term in our grammar formalism denotes the rule probabilities 0.",
                    "sid": 91,
                    "ssid": 52,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In line with the usual interpretation, this defines a probability of applying a particular rule r E R. Importantly, note that the distribution over possible groundings of a temporal expression are not included in the grammar formalism.",
                    "sid": 92,
                    "ssid": 53,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The learning of these probabilities is detailed in Section 4.",
                    "sid": 93,
                    "ssid": 54,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We define a set of preterminals, specifying their eventual type, as well as the temporal instance it produces when its function is evaluated on the word it generates (e.g., f(day) = Day).",
                    "sid": 94,
                    "ssid": 55,
                    "kind_of_tag": "s"
                },
                {
                    "text": "A distinction is made in our description between entities with content roles versus entities with a functional role.",
                    "sid": 95,
                    "ssid": 56,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The first \u2013 consisting of Ranges, Sequences, and Durations \u2013 are listed in Table 1.",
                    "sid": 96,
                    "ssid": 57,
                    "kind_of_tag": "s"
                },
                {
                    "text": "A total of 62 such preterminals are defined in the implemented system, corresponding to primitive entities often appearing in newswire, although this list is easily adaptable to mar, arranged by their types.",
                    "sid": 97,
                    "ssid": 58,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Note that the Sequence type contains more elements than enumerated here; however, only a few of each characteristic type are shown here for brevity. fit other domains.",
                    "sid": 98,
                    "ssid": 59,
                    "kind_of_tag": "s"
                },
                {
                    "text": "It should be noted that the expressions, represented in Typewriter, have no a priori association with words, denoted by italics; this correspondence must be learned.",
                    "sid": 99,
                    "ssid": 60,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Furthermore, entities which are subject to interpretation \u2013 for example Quarter or Season \u2013 are given a concrete interpretation.",
                    "sid": 100,
                    "ssid": 61,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The nth quarter is defined by evenly splitting a year into four; the seasons are defined in the same way but with winter beginning in December.",
                    "sid": 101,
                    "ssid": 62,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The functional entities are described in Table 2, and correspond to the Function type.",
                    "sid": 102,
                    "ssid": 63,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The majority of these mirror generic operations on intervals on a timeline, or manipulations of a sequence.",
                    "sid": 103,
                    "ssid": 64,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Notably, like intervals, times can be moved (3 weeks ago) or their size changed (the first two days of the month), or a new interval can be started from one of the endpoints (the last 2 days).",
                    "sid": 104,
                    "ssid": 65,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Additionally, a sequence can be modified by shifting its origin (last Friday), or taking the nth element of the sequence within some bound (fourth Sunday in November).",
                    "sid": 105,
                    "ssid": 66,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The lexical entry for the Nil type is tagged with the word it generates, producing entries such as Nil(a), Nil(November), etc.",
                    "sid": 106,
                    "ssid": 67,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The lexical entry for the Number type is parameterized by the order of magnitude and ordinality of the number; e.g., 27th becomes Number(101,ordinal).",
                    "sid": 107,
                    "ssid": 68,
                    "kind_of_tag": "s"
                },
                {
                    "text": "As mentioned earlier, our grammar defines both combination rules over types (in V) as well as a method for combining temporal instances (in W\u201e E W).",
                    "sid": 108,
                    "ssid": 69,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This method is either a function application of one of the functions in Table 2, a function which is implicit in the text (intersection and multiplication), November 27th.",
                    "sid": 109,
                    "ssid": 70,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The intersect function treats both arguments as intervals, and will return an interval (Range or Sequence) corresponding to the overlap between the two.1 change to the temporal expression, e.g., a week.",
                    "sid": 110,
                    "ssid": 71,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The lexicalization of the Nil type allows the algorithm to take hints from these supporting words.",
                    "sid": 111,
                    "ssid": 72,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We proceed to describe learning the parameters of this grammar.",
                    "sid": 112,
                    "ssid": 73,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "4 learning",
            "number": "4",
            "sents": [
                {
                    "text": "We present a system architecture, described in Figure 3.",
                    "sid": 113,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We detail the inference procedure in Section 4.1 and training in Section 4.2.",
                    "sid": 114,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "To provide a list of candidate expressions with their associated probabilities, we employ a k-best CKY parser.",
                    "sid": 115,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Specifically, we implement Algorithm 3 described in Huang and Chiang (2005), providing an 0(Gn3k log k) algorithm with respect to the grammar size G, phrase length n, and beam size k. We set the beam size to 2000.",
                    "sid": 116,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Revisiting the notion of pragmatic ambiguity, in a sense the most semantically complete output of the system would be a distribution \u2013 an utterance of Friday would give a distribution over Fridays rather than a best guess of its grounding.",
                    "sid": 117,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "However, it is often advantageous to ground to a concrete expression with a corresponding probability.",
                    "sid": 118,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The CKY k-best beam and the temporal distribution \u2013 capturing syntactic and pragmatic ambiguity \u2013 can be combined to provide a Viterbi decoding, as well as its associated probability.",
                    "sid": 119,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We define the probability of a syntactic parse y making use of rules R C_ R as P(y) = P(w1, ... wn; R) = l i,j,kER P(j, k  |i).",
                    "sid": 120,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "As described in Section 3.1, we define the probability of a grounding relative to reference time t and a particular syntactic interpretation Pt(i|y).",
                    "sid": 121,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The product of these two terms provides the probability of a grounded temporal interpretation; we can obtain a Viterbi decoding by maximizing this joint probability: This provides us with a framework for obtaining grounded times from a temporal phrase \u2013 in line with the annotations provided during training time.",
                    "sid": 122,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We present an EM-style bootstrapping approach to training the parameters of our grammar jointly with the parameters of our Gaussian temporal distribution.",
                    "sid": 123,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Our TimEM algorithm for learning the parameters for the grammar (0), jointly with the temporal distribution (\u00b5 and a) is given in Algorithm 1.",
                    "sid": 124,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The inputs to the algorithm are the initial parameters 0, \u00b5, and a, and a set of training instances D. Furthermore, the algorithm makes use of a Dirichlet prior a on the grammar parameters 0, as well as a Gaussian prior N on the mean of the temporal distribution \u00b5.",
                    "sid": 125,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The algorithm outputs the final parameters 0*, \u00b5* and a*.",
                    "sid": 126,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Each training instance is a tuple consisting of the words in the temporal phrase w, the annotated grounded time T*, and the reference time of the utterance t. The input phrase is tokenized according to Penn Treebank guidelines, except we additionally split on the characters \u2018-\u2019 and \u2018/,\u2019 which often delimit a boundary between temporal entities.",
                    "sid": 127,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Beyond this preprocessing, no language-specific information about the meanings of the words are introduced, including syntactic parses, POS tags, etc.",
                    "sid": 128,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The algorithm operates similarly to the EM algorithms used for grammar induction (Klein and Manning, 2004; Carroll and Charniak, 1992).",
                    "sid": 129,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "However, unlike grammar induction, we are allowed a certain amount of supervision by requiring that the predicted temporal expression match the annotation.",
                    "sid": 130,
                    "ssid": 18,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Our expected statistics are therefore more accurately our normalized expected counts of valid parses.",
                    "sid": 131,
                    "ssid": 19,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Note that in conventional grammar induction, the expected sufficient statistics can be gathered analytically from reading off the chart scores of a parse.",
                    "sid": 132,
                    "ssid": 20,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This does not work in our case for two reasons.",
                    "sid": 133,
                    "ssid": 21,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In part, we would like to incorporate the probability of the temporal grounding in our feedback probability.",
                    "sid": 134,
                    "ssid": 22,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Additionally, we are only using parses which are valid candidates \u2013 that is, the parses which ground to the correct time \u03c4* \u2013 which we cannot establish until the entire expression is parsed.",
                    "sid": 135,
                    "ssid": 23,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The expected statistics are thus computed non-analytically via a beam on both the possible parses (line 10) and the possible temporal groundings of a given interpretation (line 11).",
                    "sid": 136,
                    "ssid": 24,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The particular EM updates are the standard updates for multinomial and Gaussian distributions given fully observed data.",
                    "sid": 137,
                    "ssid": 25,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In the multinomial case, our (unnormalized) parameter updates, with Dirichlet prior \u03b1, are: In the Gaussian case, the parameter update for \u03c3 is the maximum likelihood update; while the update for \u00b5 incorporates a Bayesian prior N(\u00b50, \u03c30): As the parameters improve, the parser more efficiently prunes incorrect parses and the beam incorporates valid parses for longer and longer phrases.",
                    "sid": 138,
                    "ssid": 26,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For instance, in the first iteration the model must learn the meaning of both words in last Friday; once the parser learns the meaning of one of them \u2013 e.g., Friday appears elsewhere in the corpus \u2013 subsequent iterations focus on proposing candidate meanings for last.",
                    "sid": 139,
                    "ssid": 27,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In this way, a progressively larger percentage of the data is available to be learned from at each iteration.",
                    "sid": 140,
                    "ssid": 28,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "5 evaluation",
            "number": "5",
            "sents": [
                {
                    "text": "We evaluate our model against current state-of-the art systems for temporal resolution on the English portion of the TempEval-2 Task A dataset (Verhagen et al., 2010).",
                    "sid": 141,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The TempEval-2 dataset is relatively small, containing 162 documents and 1052 temporal phrases in the training set and an additional 20 documents and 156 phrases in the evaluation set.",
                    "sid": 142,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Each temporal phrase was annotated as a TIMEX32 tag around an adverbial or prepositional phrase In the TempEval-2 A Task, system performance is evaluated on detection and resolution of expressions.",
                    "sid": 143,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Since we perform only the second of these, we evaluate our system assuming gold detection.",
                    "sid": 144,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Similarly, the original TempEval-2 scoring scheme gave a precision and recall for detection, and an accuracy for only the temporal expressions attempted.",
                    "sid": 145,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Since our system is able to produce a guess for every expression, we produce a precisionrecall curve on which competing systems are plotted (see Figure 4).",
                    "sid": 146,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Note that the downward slope of the curve indicates that the probabilities returned by the system are indicative of its confidence \u2013 the probability of a parse correlates with the probability of that parse being correct.",
                    "sid": 147,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Additionally, and perhaps more accurately, we compare to previous system scores when constrained to make a prediction on every example; if no guess is made, the output is considered incorrect.",
                    "sid": 148,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This in general yields lower results, as the system is not allowed to abstain on expressions it does not recognize.",
                    "sid": 149,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Results are summarized in Table 3.",
                    "sid": 150,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We compare to three previous rule-based systems.",
                    "sid": 151,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "GUTime (Mani and Wilson, 2000) presents an older but widely used baseline.3 More recently, SUTime (Chang and Manning, 2012) provides a much stronger comparison.",
                    "sid": 152,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We also compare to HeidelTime (Str\u00a8otgen and Gertz, 2010), which represents the state-of-the-art system at the TempEval-2 task.",
                    "sid": 153,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "One of the advantages of our model is that it can provide candidate groundings for any expression.",
                    "sid": 154,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We explore this ability by building a detection model to find candidate temporal expressions, which we then ground.",
                    "sid": 155,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The detection model is implemented as a Conditional Random Field (Lafferty et al., 2001), with features over the morphology and context.",
                    "sid": 156,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Particularly, we define the following features: \u2022 The word and lemma within 2 of the current word.",
                    "sid": 157,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "\u2022 The word shape4 and part of speech of the current word.",
                    "sid": 158,
                    "ssid": 18,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We summarize our results in Table 4, noting that the performance indicates that the CRF and interpretation model find somewhat different phrases hard to detect and interpret respectively.",
                    "sid": 159,
                    "ssid": 19,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Many errors made in detection are attributable to the small size of the training corpus (63,000 tokens).",
                    "sid": 160,
                    "ssid": 20,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Our system performs well above the GUTime baseline and is competitive with both of the more recent systems.",
                    "sid": 161,
                    "ssid": 21,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In part, this is from more sophisticated modeling of syntactic ambiguity: e.g., the past few weeks has a clause the past \u2013 which, alone, should be parsed as PAST \u2013 yet the system correctly disprefers incorporating this interpretation and returns the approximate duration 1 week.",
                    "sid": 162,
                    "ssid": 22,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Furthermore, we often capture cases of pragmatic ambiguity \u2013 for example, empirically, August tends to refers to the previous August when mentioned in February.",
                    "sid": 163,
                    "ssid": 23,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Compared to rule-based systems, we attribute most errors the system makes to either data sparsity or missing lexical primitives.",
                    "sid": 164,
                    "ssid": 24,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example \u2013 illustrating sparsity \u2013 we have trouble recognizing Nov. as corresponding to November (e.g., Nov. 13), since the publication time of the articles happen to often be near November and we prefer tagging the word as Nil (analogous to the 13th).",
                    "sid": 165,
                    "ssid": 25,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Missing lexical primitives, in turn, include tags for 1990s, or half (in minute and a half); as well as missing functions, such as or (in weeks or months).",
                    "sid": 166,
                    "ssid": 26,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Remaining errors can be attributed to causes such as providing the wrong Viterbi grounding to the evaluation script (e.g., last rather than this Friday), differences in annotation (e.g., 24 hours is marked wrong against a day), or missing context (e.g., the publication time is not the true reference time), among others.",
                    "sid": 167,
                    "ssid": 27,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "6 conclusion",
            "number": "6",
            "sents": [
                {
                    "text": "We present a new approach to resolving temporal expressions, based on synchronous parsing of a fixed grammar with learned parameters and a compositional representation of time.",
                    "sid": 168,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The system allows for output which captures uncertainty both with respect to the syntactic structure of the phrase and the pragmatic ambiguity of temporal utterances.",
                    "sid": 169,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We also note that the approach is theoretically better adapted for phrases more complex than those found in TempEval-2.",
                    "sid": 170,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Furthermore, the system makes very few language-specific assumptions, and the algorithm could be adapted to domains beyond temporal resolution.",
                    "sid": 171,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We hope to improve detection and explore system performance on multilingual and complex datasets in future work.",
                    "sid": 172,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Acknowledgements The authors would like to thank Valentin Spitkovsky, David McClosky, and Angel Chang for valuable discussion and insights.",
                    "sid": 173,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We gratefully acknowledge the support of the Defense Advanced Research Projects Agency (DARPA) Machine Reading Program under Air Force Research Laboratory (AFRL) prime contract no.",
                    "sid": 174,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "FA8750-09-C-0181.",
                    "sid": 175,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the view of DARPA, AFRL, or the US government.",
                    "sid": 176,
                    "ssid": 9,
                    "kind_of_tag": "s"
                }
            ]
        }
    ]
}