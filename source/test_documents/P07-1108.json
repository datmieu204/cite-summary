{
    "ID": "P07-1108",
    "sections": [
        {
            "text": "abstract",
            "number": 0,
            "sents": [
                {
                    "text": "Pivot Language Approach for Phrase-Based Statistical Machine Translation",
                    "sid": 0,
                    "ssid": null,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This paper proposes a novel method for phrase-based statistical machine translation by using pivot language.",
                    "sid": 1,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "To conduct transbetween languages with a small bilingual corpus, we bring in a third which is named the lan- For and there exist bilingual corpora.",
                    "sid": 2,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Using only bilingual corpora, we can build a model for The advantage of this method lies in that we can perform between even if there is no bilingual corpus available for this language pair.",
                    "sid": 3,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Using BLEU as a metric, our pivot language method achieves an absolute improvement of 0.06 (22.13% relative) as compared with the model directly with 5,000 sentence pairs for French-Spanish translation.",
                    "sid": 4,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Moreover, with small bilingual corpus available, our method can further improve the translaquality by using the additional bilingual corpora.",
                    "sid": 5,
                    "ssid": 5,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "1 introduction",
            "number": "1",
            "sents": [
                {
                    "text": "For statistical machine translation (SMT), phrasebased methods (Koehn et al., 2003; Och and Ney, 2004) and syntax-based methods (Wu, 1997; Alshawi et al. 2000; Yamada and Knignt, 2001; Melamed, 2004; Chiang, 2005; Quick et al., 2005; Mellebeek et al., 2006) outperform word-based methods (Brown et al., 1993).",
                    "sid": 6,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "These methods need large bilingual corpora.",
                    "sid": 7,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "However, for some languages pairs, only a small bilingual corpus is available, which will degrade the performance of statistical translation systems.",
                    "sid": 8,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "To solve this problem, this paper proposes a novel method for phrase-based SMT by using a pivot language.",
                    "sid": 9,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "To perform translation between languages Lf and Le, we bring in a pivot language Lp, for which there exist large bilingual corpora for language pairs Lf-Lp and Lp-Le.",
                    "sid": 10,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "With the Lf-Lp and Lp-Le bilingual corpora, we can build a translation model for Lf-Le by using Lp as the pivot language.",
                    "sid": 11,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We name the translation model pivot model.",
                    "sid": 12,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The advantage of this method lies in that we can conduct translation between Lf and Le even if there is no bilingual corpus available for this language pair.",
                    "sid": 13,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Moreover, if a small corpus is available for Lf-Le, we build another translation model, which is named standard model.",
                    "sid": 14,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Then, we build an interpolated model by performing linear interpolation on the standard model and the pivot model.",
                    "sid": 15,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Thus, the interpolated model can employ both the small LfLe corpus and the large Lf-Lp and Lp-Le corpora.",
                    "sid": 16,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We perform experiments on the Europarl corpus (Koehn, 2005).",
                    "sid": 17,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Using BLEU (Papineni et al., 2002) as a metric, our method achieves an absolute improvement of 0.06 (22.13% relative) as compared with the standard model trained with 5,000 Lf-Le sentence pairs for French-Spanish translation.",
                    "sid": 18,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The translation quality is comparable with that of the model trained with a bilingual corpus of 30,000 LfLe sentence pairs.",
                    "sid": 19,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Moreover, translation quality is further boosted by using both the small Lf-Le bilingual corpus and the large Lf-Lp and Lp-Le corpora.",
                    "sid": 20,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Experimental results on Chinese-Japanese translation also indicate that our method achieves satisfactory results using English as the pivot language.",
                    "sid": 21,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The remainder of this paper is organized as follows.",
                    "sid": 22,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In section 2, we describe the related work.",
                    "sid": 23,
                    "ssid": 18,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Section 3 briefly introduces phrase-based SMT.",
                    "sid": 24,
                    "ssid": 19,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Section 4 and Section 5 describes our method for phrase-based SMT using pivot language.",
                    "sid": 25,
                    "ssid": 20,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We describe the experimental results in sections 6 and 7.",
                    "sid": 26,
                    "ssid": 21,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Lastly, we conclude in section 8.",
                    "sid": 27,
                    "ssid": 22,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "2 related work",
            "number": "2",
            "sents": [
                {
                    "text": "Our method is mainly related to two kinds of methods: those using pivot language and those using a small bilingual corpus or scarce resources.",
                    "sid": 28,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For the first kind, pivot languages are employed to translate queries in cross-language information retrieval (CLIR) (Gollins and Sanderson, 2001; Kishida and Kando, 2003).",
                    "sid": 29,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "These methods only used the available dictionaries to perform word by word translation.",
                    "sid": 30,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In addition, NTCIR 4 workshop organized a shared task for CLIR using pivot language.",
                    "sid": 31,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Machine translation systems are used to translate queries into pivot language sentences, and then into target sentences (Sakai et al., 2004).",
                    "sid": 32,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Callison-Burch et al. (2006) used pivot languages for paraphrase extraction to handle the unseen phrases for phrase-based SMT.",
                    "sid": 33,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Borin (2000) and Wang et al. (2006) used pivot languages to improve word alignment.",
                    "sid": 34,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Borin (2000) used multilingual corpora to increase alignment coverage.",
                    "sid": 35,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Wang et al. (2006) induced alignment models by using two additional bilingual corpora to improve word alignment quality.",
                    "sid": 36,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Pivot Language methods were also used for translation dictionary induction (Schafer and Yarowsky, 2002), word sense disambiguation (Diab and Resnik, 2002), and so on.",
                    "sid": 37,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For the second kind, Niessen and Ney (2004) used morpho-syntactic information for translation between language pairs with scarce resources.",
                    "sid": 38,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Vandeghinste et al. (2006) used translation dictionaries and shallow analysis tools for translation between the language pair with low resources.",
                    "sid": 39,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "A shared task on word alignment was organized as part of the ACL 2005 Workshop on Building and Using Parallel Texts (Martin et al., 2005).",
                    "sid": 40,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This task focused on languages with scarce resources.",
                    "sid": 41,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For the subtask of unlimited resources, some researchers (Aswani and Gaizauskas, 2005; Lopez and Resnik, 2005; Tufis et al., 2005) used language-dependent resources such as dictionary, thesaurus, and dependency parser to improve word alignment results.",
                    "sid": 42,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In this paper, we address the translation problem for language pairs with scarce resources by bringing in a pivot language, via which we can make use of large bilingual corpora.",
                    "sid": 43,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Our method does not need language-dependent resources or deep linguistic processing.",
                    "sid": 44,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Thus, the method is easy to be adapted to any language pair where a pivot language and corresponding large bilingual corpora are available.",
                    "sid": 45,
                    "ssid": 18,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "3 phrase-based smt",
            "number": "3",
            "sents": [
                {
                    "text": "According to the translation model presented in (Koehn et al., 2003), given a source sentence f , the best target translation ebest can be obtained according to the following model \u03bb is the strength of the lexical weight.",
                    "sid": 46,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Where i and d denote phrase translation probability and distortion probability, respectively.",
                    "sid": 47,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "4Phrase-Based SMT Via Pivot Language This section will introduce the method that performs phrase-based SMT for the language pair LfLe by using the two bilingual corpora of and With the two additional bilingual corpora, we train two translation models for and respectively.",
                    "sid": 48,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Based on these two models, we build a pivot translation model for with as a pivot language.",
                    "sid": 49,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "According to equation (2), the phrase translation probability and the lexical weight are language dependent.",
                    "sid": 50,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We will introduce them in sections 4.1 an d 4.2, respectively.",
                    "sid": 51,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Using the Lf-Lp and Lp-Le bilingual corpora, we train two phrase translation probabilities \u03c6(f i  |pi) and \u03c6(pi  |ei), where pi is the phrase in the pivot language Lp.",
                    "sid": 52,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Given the phrase translation probabilities \u03c6(f i  |pi) and \u03c6(pi  |ei) , we obtain the phrase translation probability The phrase translation probability \u03c6(f i  |pi , ei ) does not depend on the phase ei in the language Le, since it is estimated from the Lf-Lp bilingual corpus.",
                    "sid": 53,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Thus, equation (3) can be rewritten as Given a phrase pair (f , e) and a word alignment a between the source word positions i =1,..., n and the target word positions j =1,... , m , the lexical weight can be estimated according to the following method (Koehn et al., 2003). and a2 represent the word alignment inrespectively, then the alignment information a inside (f , e) can be obtained as shown in (6).",
                    "sid": 54,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "An example is shown in Figure 1. om the induced phrase pairs.",
                    "sid": 55,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We name this method phrase method.",
                    "sid": 56,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "If we use K to denote the number of the induced phrase pairs, we estimate the co-occurring frequency of the word pair (f , e) according to the following model.",
                    "sid": 57,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Where \u03c6k (f  |e) is the phrase translation probability for phrase pair k . \u03b4(x, y) =1 if x = y; otherwise, \u03b4(x, y) = 0 .",
                    "sid": 58,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Thus, lexical translation probability can be estimated as in (8).",
                    "sid": 59,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "&( } (6) With the induced alignment information, this paper proposes a method to estimate the probability directly fr ability w(f e) using the method described in (Wang et al., 2006), which is shown in (9).",
                    "sid": 60,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We named it word method in this paper. probabilities, and sim(f , e; p) is the crosslanguage word similari | | ty.",
                    "sid": 61,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In order to estimate the lexical weight, we first need to obtain the alignment information a between the two phrases f and e , andthen estimate the lexical translation probability w(f e) according to the alignment information.",
                    "sid": 62,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The alignment information of the phrase pair (f , e) can be induced fr | om the two phrase pairs (f , p) and (p, e) .",
                    "sid": 63,
                    "ssid": 18,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We also estimate the lexical translation probWhere w(f",
                    "sid": 64,
                    "ssid": 19,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "5 interpolated model",
            "number": "4",
            "sents": [
                {
                    "text": "If we have a small Lf-Le bilingual corpus, we can employ this corpus to estimate a translation model as described in section 3.",
                    "sid": 65,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "However, this model may perform poorly due to the sparseness of the data.",
                    "sid": 66,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In order to improve its performance, we can employ the additional and bilingual corpora.",
                    "sid": 67,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Moreover, we can use more than one pivot language to improve the translation performance if the corresponding bilingual corpora exist.",
                    "sid": 68,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Different pivot lan i j a nomena, and improve translation quality for the desired language pair Lf-Le in different ways.",
                    "sid": 69,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "If we include n pivot languages, n pivot models can be estimated using the method as described in section 4.",
                    "sid": 70,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In order to combine these n pivot models with the standard model trained with the Lf-Le corpus, we use the linear interpolation method.",
                    "sid": 71,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The phrase translation probability and the lexical weight are estimated as shown in (10) and (11), respectively.",
                    "sid": 72,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Where \u03c60 (f  |e) and p,,,0 (f  |e, a) denote the phrase translation probability and lexical weight trained with the Lf-Le bilingual corpus, respectively. \u03c6i (f  |e) and p ,,,i (f  |e, a) ( i =1,... , n ) are the phrase translation probability and lexical weight estimated by using the pivot languages. \u03b1i and \u03b2i are the interpolation coefficients.",
                    "sid": 73,
                    "ssid": 9,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "6 experiments on the europarl corpus",
            "number": "5",
            "sents": [
                {
                    "text": "A shared task to evaluate machine translation performance was organized as part of the NAACL/HLT 2006 Workshop on Statistical Machine Translation (Koehn and Monz, 2006).",
                    "sid": 74,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The shared task used the Europarl corpus (Koehn, 2005), in which four languages are involved: English, French, Spanish, and German.",
                    "sid": 75,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The shared task performed translation between English and the other three languages.",
                    "sid": 76,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In our work, we perform translation from French to the other three languages.",
                    "sid": 77,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We select French to Spanish and French to German translation that are not in the shared task because we want to use English as the pivot language.",
                    "sid": 78,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In general, for most of the languages, there exist bilingual corpora between these languages and English since English is an internationally used language.",
                    "sid": 79,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Table 1 shows the information about the bilingual training data.",
                    "sid": 80,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In the table, &quot;Fr&quot;, &quot;En&quot;, &quot;Es&quot;, and &quot;De&quot; denotes &quot;French&quot;, &quot;English&quot;, &quot;Spanish&quot;, and &quot;German&quot;, respectively.",
                    "sid": 81,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For the language pairs Lf-Le not including English, the bilingual corpus is extracted from Lf-English and English-Le since Europarl corpus is a multilingual corpus.",
                    "sid": 82,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For the language models, we use the same data provided in the shared task.",
                    "sid": 83,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We also use the same development set and test set provided by the shared task.",
                    "sid": 84,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The in-domain test set includes 2,000 sentences and the out-of-domain test set includes 1,064 sentences for each language.",
                    "sid": 85,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "To perform phrase-based SMT, we use Koehn's training scripts1 and the Pharaoh decoder (Koehn, 2004).",
                    "sid": 86,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We run the decoder with its default settings and then use Koehn's implementation of minimum error rate training (Och, 2003) to tune the feature weights on the development set.",
                    "sid": 87,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The translation quality was evaluated using a well-established automatic measure: BLEU score (Papineni et al., 2002).",
                    "sid": 88,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "And we also use the tool provided in the NAACL/HLT 2006 shared task on SMT to calculate the BLEU scores.",
                    "sid": 89,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "As described in section 4, we employ two methods to estimate the lexical weight in the translation model.",
                    "sid": 90,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In order to compare the two methods, we translate from French to Spanish, using English as the pivot language.",
                    "sid": 91,
                    "ssid": 18,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We use the French-English and English-Spanish corpora described in Table 1 as training data.",
                    "sid": 92,
                    "ssid": 19,
                    "kind_of_tag": "s"
                },
                {
                    "text": "During training, before estimating the Spanish to French phrase translation probability, we filter those French-English and EnglishSpanish phrase pairs whose translation probabilities are below a fixed threshold 0.001.2 The translation results are shown in Table 2.",
                    "sid": 93,
                    "ssid": 20,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The phrase method proposed in this paper performs better than the word method proposed in (Wang et al., 2006).",
                    "sid": 94,
                    "ssid": 21,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This is because our method uses phrase translation probability as a confidence weight to estimate the lexical translation probability.",
                    "sid": 95,
                    "ssid": 22,
                    "kind_of_tag": "s"
                },
                {
                    "text": "It strengthens the frequently aligned pairs and weakens the infrequently aligned pairs.",
                    "sid": 96,
                    "ssid": 23,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Thus, the following sections will use the phrase method to estimate the lexical weight.",
                    "sid": 97,
                    "ssid": 24,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This section describes the translation results by using only one pivot language.",
                    "sid": 98,
                    "ssid": 25,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For the language pair French and Spanish, we use English as the pivot language.",
                    "sid": 99,
                    "ssid": 26,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The entire French-English and English-Spanish corpora as described in section 4 are used to train a pivot model for French-Spanish.",
                    "sid": 100,
                    "ssid": 27,
                    "kind_of_tag": "s"
                },
                {
                    "text": "As described in section 5, if we have a small LfLe bilingual corpus and large Lf-Lp and Lp-Le bilingual corpora, we can obtain interpolated models.",
                    "sid": 101,
                    "ssid": 28,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In order to conduct the experiments, we randomly select 5K, 10K, 20K, 30K, 40K, 50K, and 100K sentence pairs from the French-Spanish corpus.",
                    "sid": 102,
                    "ssid": 29,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Using each of these corpora, we train a standard translation model.",
                    "sid": 103,
                    "ssid": 30,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For each standard model, we interpolate it with the pivot model to get an interpolated model.",
                    "sid": 104,
                    "ssid": 31,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The interpolation weights are tuned using the development set.",
                    "sid": 105,
                    "ssid": 32,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For all the interpolated models, we set \u03b10 = 0.9 , \u03b11 = 0.",
                    "sid": 106,
                    "ssid": 33,
                    "kind_of_tag": "s"
                },
                {
                    "text": "1 , ,Q0 = 0.9 , and ,Q1 = 0.",
                    "sid": 107,
                    "ssid": 34,
                    "kind_of_tag": "s"
                },
                {
                    "text": "1.",
                    "sid": 108,
                    "ssid": 35,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We test the three kinds of models on both the indomain and out-of-domain test sets.",
                    "sid": 109,
                    "ssid": 36,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The results are shown in Figures 2 and 3.",
                    "sid": 110,
                    "ssid": 37,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The pivot model achieves BLEU scores of 0.3212 and 0.2098 on the in-domain and out-ofdomain test set, respectively.",
                    "sid": 111,
                    "ssid": 38,
                    "kind_of_tag": "s"
                },
                {
                    "text": "It achieves an absolute improvement of 0.05 on both test sets (16.92% and 35.35% relative) over the standard model trained with 5,000 French-Spanish sentence pairs.",
                    "sid": 112,
                    "ssid": 39,
                    "kind_of_tag": "s"
                },
                {
                    "text": "And the performance of the pivot models are comparable with that of the standard models trained with 20,000 and 30,000 sentence pairs on the indomain and out-of-domain test set, respectively.",
                    "sid": 113,
                    "ssid": 40,
                    "kind_of_tag": "s"
                },
                {
                    "text": "When the French-Spanish training corpus is increased, the standard models quickly outperform the pivot model.",
                    "sid": 114,
                    "ssid": 41,
                    "kind_of_tag": "s"
                },
                {
                    "text": "When only a very small French-Spanish bilingual corpus is available, the interpolated method can greatly improve the translation quality.",
                    "sid": 115,
                    "ssid": 42,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example, when only 5,000 French-Spanish sentence pairs are available, the interpolated model outperforms the standard model by achieving a relative improvement of 17.55%, with the BLEU score improved from 0.2747 to 0.3229.",
                    "sid": 116,
                    "ssid": 43,
                    "kind_of_tag": "s"
                },
                {
                    "text": "With 50,000 French-Spanish sentence pairs available, the interpolated model significantly3 improves the translation quality by achieving an absolute improvement of 0.01 BLEU.",
                    "sid": 117,
                    "ssid": 44,
                    "kind_of_tag": "s"
                },
                {
                    "text": "When the FrenchSpanish training corpus increases to 100,000 sentence pairs, the interpolated model achieves almost the same result as the standard model.",
                    "sid": 118,
                    "ssid": 45,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This indicates that our pivot language method is suitable for the language pairs with small quantities of training data available.",
                    "sid": 119,
                    "ssid": 46,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Besides experiments on French-Spanish translation, we also conduct translation from French to English and French to German, using German and English as the pivot language, respectively.",
                    "sid": 120,
                    "ssid": 47,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The results on the in-domain test set4 are shown in Figures 4 and 5.",
                    "sid": 121,
                    "ssid": 48,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The tendency of the results is similar to that in Figure 2.",
                    "sid": 122,
                    "ssid": 49,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For French to Spanish translation, we also introduce German as a pivot language besides English.",
                    "sid": 123,
                    "ssid": 50,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Using these two pivot languages, we build two different pivot models, and then perform linear interpolation on them.",
                    "sid": 124,
                    "ssid": 51,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The interpolation weights for the English pivot model and the German pivot model are set to 0.6 and 0.4 respectively5.",
                    "sid": 125,
                    "ssid": 52,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The translation results on the in-domain test set are 0.3212, 0.3077, and 0.3355 for the pivot models using English, German, and both German and English as pivot languages, respectively.",
                    "sid": 126,
                    "ssid": 53,
                    "kind_of_tag": "s"
                },
                {
                    "text": "With the pivot model using both English and German as pivot languages, we interpolate it with the standard models trained with French-Spanish corpora of different sizes as described in the above section.",
                    "sid": 127,
                    "ssid": 54,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The comparison of the translation results among the interpolated models, standard models, and the pivot model are shown in Figure 6.",
                    "sid": 128,
                    "ssid": 55,
                    "kind_of_tag": "s"
                },
                {
                    "text": "It can be seen that the translation results can be further improved by using more than one pivot language.",
                    "sid": 129,
                    "ssid": 56,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The pivot model &quot;Pivot-En+De&quot; using two pivot languages achieves an absolute improvement of 0.06 (22.13% relative) as compared with the standard model trained with 5,000 sentence pairs.",
                    "sid": 130,
                    "ssid": 57,
                    "kind_of_tag": "s"
                },
                {
                    "text": "And it achieves comparable translation result as compared with the standard model trained with 30,000 French-Spanish sentence pairs.",
                    "sid": 131,
                    "ssid": 58,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The results in Figure 6 also indicate the interpolated models using two pivot languages achieve the best results of all.",
                    "sid": 132,
                    "ssid": 59,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Significance test shows that the interpolated models using two pivot languages significantly outperform those using one pivot language when less than 50,000 French-Spanish sentence pairs are available.",
                    "sid": 133,
                    "ssid": 60,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In all of the above results, the corpora used to train the pivot models are not changed.",
                    "sid": 134,
                    "ssid": 61,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In order to examine the effect of the size of the pivot corpora, we decrease the French-English and EnglishFrench corpora.",
                    "sid": 135,
                    "ssid": 62,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We randomly select 200,000 and 400,000 sentence pairs from both of them to train two pivot models, respectively.",
                    "sid": 136,
                    "ssid": 63,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The translation results on the in-domain test set are 0.2376, 0.2954, and 0.3212 for the pivot models trained with 200,000, 400,000, and the entire French-English and English-Spanish corpora, respectively.",
                    "sid": 137,
                    "ssid": 64,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The results of the interpolated models and the standard models are shown in Figure 7.",
                    "sid": 138,
                    "ssid": 65,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The results indicate that the larger the training corpora used to train the pivot model are, the better the translation quality is.",
                    "sid": 139,
                    "ssid": 66,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "7 experiments on chinese to japanese translation",
            "number": "6",
            "sents": [
                {
                    "text": "In section 6, translation results on the Europarl multilingual corpus indicate the effectiveness of our method.",
                    "sid": 140,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "To investigate the effectiveness of our method by using independently sourced parallel corpora, we conduct Chinese-Japanese translation using English as a pivot language in this section, where the training data are not limited to a specific domain.",
                    "sid": 141,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The data used for this experiment is the same as those used in (Wang et al., 2006).",
                    "sid": 142,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "There are 21,977, 329,350, and 160,535 sentence pairs for the language pairs Chinese-Japanese, Chinese-English, and English-Japanese, respectively.",
                    "sid": 143,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The development data and testing data include 500 and 1,000 Chinese sentences respectively, with one reference for each sentence.",
                    "sid": 144,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For Japanese language model training, we use about 100M bytes Japanese corpus.",
                    "sid": 145,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The translation result is shown in Figure 8.",
                    "sid": 146,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The pivot model only outperforms the standard model trained with 2,500 sentence pairs.",
                    "sid": 147,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This is because (1) the corpora used to train the pivot model are smaller as compared with the Europarl corpus; (2) the training data and the testing data are not limited to a specific domain; (3) The languages are not closely related.",
                    "sid": 148,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The interpolated models significantly outperform the other models.",
                    "sid": 149,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "When only 5,000 sentence pairs are available, the BLEU score increases relatively by 20.53%.",
                    "sid": 150,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "With the entire (21,977 pairs) Chinese-Japanese available, the interpolated model relatively increases the BLEU score by 5.62%, from 0.1708 to 0.1804.",
                    "sid": 151,
                    "ssid": 12,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "8 conclusion",
            "number": "7",
            "sents": [
                {
                    "text": "This paper proposed a novel method for phrasebased SMT on language pairs with a small bilingual corpus by bringing in pivot languages.",
                    "sid": 152,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "To perform translation between Lf and Le, we bring in a pivot language Lp, via which the large corpora of Lf-Lp and Lp-Le can be used to induce a translation model for Lf-Le.",
                    "sid": 153,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The advantage of this method is that it can perform translation between the language pair Lf-Le even if no bilingual corpus for this pair is available.",
                    "sid": 154,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Using BLEU as a metric, our method achieves an absolute improvement of 0.06 (22.13% relative) as compared with the model directly trained with 5,000 sentence pairs for FrenchSpanish translation.",
                    "sid": 155,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "And the translation quality is comparable with that of the model directly trained with 30,000 French-Spanish sentence pairs.",
                    "sid": 156,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The results also indicate that using more pivot languages leads to better translation quality.",
                    "sid": 157,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "With a small bilingual corpus available for Lf-Le, we built a translation model, and interpolated it with the pivot model trained with the large Lf-Lp and Lp-Le bilingual corpora.",
                    "sid": 158,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The results on both the Europarl corpus and Chinese-Japanese translation indicate that the interpolated models achieve the best results.",
                    "sid": 159,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Results also indicate that our pivot language approach is suitable for translation on language pairs with a small bilingual corpus.",
                    "sid": 160,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The less the Lf-Le bilingual corpus is, the bigger the improvement is.",
                    "sid": 161,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We also performed experiments using Lf-Lp and Lp-Le corpora of different sizes.",
                    "sid": 162,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The results indicate that using larger training corpora to train the pivot model leads to better translation quality.",
                    "sid": 163,
                    "ssid": 12,
                    "kind_of_tag": "s"
                }
            ]
        }
    ]
}