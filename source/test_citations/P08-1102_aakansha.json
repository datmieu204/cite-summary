{
    "ID": "P08-1102",
    "citations": [
        {
            "Number": 1,
            "refer_ID": "P08-1102",
            "refer_sids": [
                130
            ],
            "refer_text": "We proposed a cascaded linear model for Chinese Joint S&T.",
            "cite_ID": "C08-1049",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "Following Jiang et al (2008), we describe segmentation and Joint S& amp; T as below: For a given Chinese sentence appearing as a character sequence: C 1: n= C 1 C 2.",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 3,
            "refer_ID": "P08-1102",
            "refer_sids": [
                42
            ],
            "refer_text": "As predications generated from such templates depend on the current character, we name these templates lexical-target.",
            "cite_ID": "C08-1049",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "plates called lexical-target in the column below areintroduced by Jiang et al (2008)",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 4,
            "refer_ID": "P08-1102",
            "refer_sids": [
                25
            ],
            "refer_text": "According to Ng and Low (2004), the segmentation task can be transformed to a tagging problem by assigning each character a boundary tag of the following four types: We can extract segmentation result by splitting the labelled result into subsequences of pattern s or bm*e which denote single-character word and multicharacter word respectively.",
            "cite_ID": "P12-1110",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "For CTB-5, we refer to the split by Duan et al (2007) as CTB-5d, and to the split by Jiang et al (2008) as CTB-5j",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 5,
            "refer_ID": "P08-1102",
            "refer_sids": [
                130
            ],
            "refer_text": "We proposed a cascaded linear model for Chinese Joint S&T.",
            "cite_ID": "D12-1126",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "Jiang et al (2008) proposes a cascaded linear model for joint Chinese word segmentation and POS tagging",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 6,
            "refer_ID": "P08-1102",
            "refer_sids": [
                34
            ],
            "refer_text": "The feature templates we adopted are selected from those of Ng and Low (2004).",
            "cite_ID": "C10-1135",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "We use the feature templates the same as Jiang et al, (2008) to extract features form E model",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 8,
            "refer_ID": "P08-1102",
            "refer_sids": [
                12
            ],
            "refer_text": "Besides the usual character-based features, additional features dependent on POS\u2019s or words can also be employed to improve the performance.",
            "cite_ID": "P12-1025",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "approach, where basic processing units are characters which compose words (Jiangetal., 2008a)",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 10,
            "refer_ID": "P08-1102",
            "refer_sids": [
                130
            ],
            "refer_text": "We proposed a cascaded linear model for Chinese Joint S&T.",
            "cite_ID": "C10-2096",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "6.1.1 Baseline Forest-based System We first segment the Chinese sentences into the1-best segmentations using a state-of-the-art system (Jiang et al, 2008a), since it is not necessary for a conventional parser to take as input the POS tagging results",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 11,
            "refer_ID": "P08-1102",
            "refer_sids": [
                130
            ],
            "refer_text": "We proposed a cascaded linear model for Chinese Joint S&T.",
            "cite_ID": "C10-2096",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "6.1.2 Lattice-forest SystemWe first segment and POS tag the Chinese sentences into word lattices using the same system (Jiang et al, 2008a), and prune each lattice into a reasonable size using the marginal probability-based pruning algorithm",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 12,
            "refer_ID": "P08-1102",
            "refer_sids": [
                121
            ],
            "refer_text": "Among other features, the 4-gram POS LM plays the most important role, removing this feature causes F-measure decrement of 0.33 points on segmentation and 0.71 points on Joint S&T.",
            "cite_ID": "C10-1132",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "However, when we repeat the work of (Jiang et al, 2008), which reports to achieve the state-of-art performance in the data-sets that we adopt, it has been found that some features (e.g., C0) are unnoticeably trained several times in their model (which are implicitly generated from different feature templates used in the paper)",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 13,
            "refer_ID": "P08-1102",
            "refer_sids": [
                37
            ],
            "refer_text": "C represents a Chinese character while the subscript of C indicates its position in the sentence relative to the current character (it has the subscript 0).",
            "cite_ID": "C10-1132",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "Unicode/CP936 1.1M/55K 104K/13K 0.035 Table 3: Corpus statistics for the second SIGHAN Bakeoff appears twice, which is generated from two different templates Cn (with n=0, generates C0) and [C0Cn] (used in (Jiang et al, 2008), with n=0, generates [C0C0])",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 14,
            "refer_ID": "P08-1102",
            "refer_sids": [
                73
            ],
            "refer_text": "For instance, if the word w appears N times in training corpus and is labelled as POS t for n times, the probability Pr(t|w) can be estimated by the formula below: The probability Pr(w|t) could be estimated through the same approach.",
            "cite_ID": "C10-1132",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "As all the features adopted in (Jiang et al, 2008) possess binary values, if a binary feature is repeated n times, then it should behave like a real-valued feature with its value to be? n?, at least in principle",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 15,
            "refer_ID": "P08-1102",
            "refer_sids": [
                46
            ],
            "refer_text": "Following Collins, we use a function GEN(x) generating all candidate results of an input x , a representation 4) mapping each training example (x, y) \u2208 X \u00d7 Y to a feature vector 4)(x, y) \u2208 Rd, and a parameter vector \u03b1\ufffd \u2208 Rd corresponding to the feature vector. d means the dimension of the vector space, it equals to the amount of features in the model.",
            "cite_ID": "C10-1132",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "Inspired by (Jiang et al, 2008), we set the real d Although Table 5 has shown that the proposed all the value of C0 to be 2.0, the value of C-1C0anC0C1 to be 3.0, and the values of all other features to be 1.0 for the character-based discriminative-plus model",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 17,
            "refer_ID": "P08-1102",
            "refer_sids": [
                12
            ],
            "refer_text": "Besides the usual character-based features, additional features dependent on POS\u2019s or words can also be employed to improve the performance.",
            "cite_ID": "C10-1132",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "Last, (Jiang et al, 2008) 5 adds repeated features implicitly based on (Ng and Low, 2004)",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 20,
            "refer_ID": "P08-1102",
            "refer_sids": [
                130
            ],
            "refer_text": "We proposed a cascaded linear model for Chinese Joint S&T.",
            "cite_ID": "D12-1046",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "Previous joint models mainly focus on word segmentation and POS tagging task, such as the virtual nodes method (Qian et al2010), cascaded linear model (Jiang et al2008a) ,perceptron (Zhang and Clark, 2008), sub-word based stacked learning (Sun, 2011), re ranking (Jiang et al2008b)",
            "label": [
                "Method_Citation"
            ]
        }
    ]
}