{
    "ID": "P08-1102",
    "citations": [
        {
            "Number": 1,
            "refer_ID": "P08-1102",
            "refer_sids": [
                21
            ],
            "refer_text": "Experiments show that our cascaded model can utilize different knowledge sources effectively and obtain accuracy improvements on both segmentation and Joint S&T.",
            "cite_ID": "C08-1049",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "Following Jiang et al (2008), we describe segmentation and Joint S& amp; T as below: For a given Chinese sentence appearing as a character sequence: C 1: n= C 1 C 2.",
            "label": [
                "Method citation"
            ]
        },
        {
            "Number": 2,
            "refer_ID": "P08-1102",
            "refer_sids": [
                28
            ],
            "refer_text": "A subsequence of boundary-POS labelling result indicates a word with POS t only if the boundary tag sequence composed of its boundary part conforms to s or bm*e style, and all POS tags in its POS part equal to t. For example, a tag sequence b NN m NN e NN represents a threecharacter word with POS tag NN.",
            "cite_ID": "C08-1049",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "As described in Ng and Low (2004 )andJiang et al (2008), we use s indicating a single character word, while b, m and e indicating the be gin, middle and end of a word respectively",
            "label": [
                "Method citation"
            ]
        },
        {
            "Number": 3,
            "refer_ID": "P08-1102",
            "refer_sids": [
                43
            ],
            "refer_text": "Note that the templates of Ng and Low (2004) have already contained some lexical-target ones.",
            "cite_ID": "C08-1049",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "plates called lexical-target in the column below areintroduced by Jiang et al (2008)",
            "label": [
                "Method citation"
            ]
        },
        {
            "Number": 4,
            "refer_ID": "P08-1102",
            "refer_sids": [
                92
            ],
            "refer_text": "The second was conducted on the Penn Chinese Treebank 5.0 (CTB5.0) to test the performance of the cascaded model on segmentation and Joint S&T.",
            "cite_ID": "P12-1110",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "For CTB-5, we refer to the split by Duan et al (2007) as CTB-5d, and to the split by Jiang et al (2008) as CTB-5j",
            "label": [
                "Method citation"
            ]
        },
        {
            "Number": 5,
            "refer_ID": "P08-1102",
            "refer_sids": [
                9
            ],
            "refer_text": "To segment and tag a character sequence, there are two strategies to choose: performing POS tagging following segmentation; or joint segmentation and POS tagging (Joint S&T).",
            "cite_ID": "D12-1126",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "Jiang et al (2008) proposes a cascaded linear model for joint Chinese word segmentation and POS tagging",
            "label": [
                "Method citation"
            ]
        },
        {
            "Number": 6,
            "refer_ID": "P08-1102",
            "refer_sids": [
                33,
                34
            ],
            "refer_text": "In following subsections, we describe the feature templates and the perceptron training algorithm.\nThe feature templates we adopted are selected from those of Ng and Low (2004).",
            "cite_ID": "C10-1135",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "We use the feature templates the same as Jiang et al, (2008) to extract features form E model",
            "label": [
                "Method citation"
            ]
        },
        {
            "Number": 8,
            "refer_ID": "P08-1102",
            "refer_sids": [
                12
            ],
            "refer_text": "Besides the usual character-based features, additional features dependent on POS\u2019s or words can also be employed to improve the performance.",
            "cite_ID": "P12-1025",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "approach, where basic processing units are characters which compose words (Jiangetal., 2008a)",
            "label": [
                "Method citation"
            ]
        },
        {
            "Number": 10,
            "refer_ID": "P08-1102",
            "refer_sids": [
                64
            ],
            "refer_text": "In our experiments we trained a 3-gram word language model measuring the fluency of the segmentation result, a 4-gram POS language model functioning as the product of statetransition probabilities in HMM, and a word-POS co-occurrence model describing how much probably a word sequence coexists with a POS sequence.",
            "cite_ID": "C10-2096",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "6.1.1 Baseline Forest-based System We first segment the Chinese sentences into the1-best segmentations using a state-of-the-art system (Jiang et al, 2008a), since it is not necessary for a conventional parser to take as input the POS tagging results",
            "label": [
                "Method citation"
            ]
        },
        {
            "Number": 11,
            "refer_ID": "P08-1102",
            "refer_sids": [
                79
            ],
            "refer_text": "By maintaining a stack of size N at each position i of the sequence, we can preserve the top N best candidate labelled results of subsequence C1:i during decoding.",
            "cite_ID": "C10-2096",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "6.1.2 Lattice-forest SystemWe first segment and POS tag the Chinese sentences into word lattices using the same system (Jiang et al, 2008a), and prune each lattice into a reasonable size using the marginal probability-based pruning algorithm",
            "label": [
                "Method citation"
            ]
        },
        {
            "Number": 12,
            "refer_ID": "P08-1102",
            "refer_sids": [
                96
            ],
            "refer_text": "In order to test the performance of the lexical-target templates and meanwhile determine the best iterations over the training corpus, we randomly chosen 2, 000 shorter sentences (less than 50 words) as the development set and the rest as the training set (84, 294 sentences), then trained a perceptron model named NON-LEX using only nonlexical-target features and another named LEX using both the two kinds of features.",
            "cite_ID": "C10-1132",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "However, when we repeat the work of (Jiang et al, 2008), which reports to achieve the state-of-art performance in the data-sets that we adopt, it has been found that some features (e.g., C0) are unnoticeably trained several times in their model (which are implicitly generated from different feature templates used in the paper)",
            "label": [
                "Method citation"
            ]
        },
        {
            "Number": 13,
            "refer_ID": "P08-1102",
            "refer_sids": [
                91
            ],
            "refer_text": "The first was conducted to test the performance of the perceptron on segmentation on the corpus from SIGHAN Bakeoff 2, including the Academia Sinica Corpus (AS), the Hong Kong City University Corpus (CityU), the Peking University Corpus (PKU) and the Microsoft Research Corpus (MSR).",
            "cite_ID": "C10-1132",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "Unicode/CP936 1.1M/55K 104K/13K 0.035 Table 3: Corpus statistics for the second SIGHAN Bakeoff appears twice, which is generated from two different templates Cn (with n=0, generates C0) and [C0Cn] (used in (Jiang et al, 2008), with n=0, generates [C0C0])",
            "label": [
                "Method citation"
            ]
        },
        {
            "Number": 14,
            "refer_ID": "P08-1102",
            "refer_sids": [
                16
            ],
            "refer_text": "Shown in Figure 1, the cascaded model has a two-layer architecture, with a characterbased perceptron as the core combined with other real-valued features such as language models.",
            "cite_ID": "C10-1132",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "As all the features adopted in (Jiang et al, 2008) possess binary values, if a binary feature is repeated n times, then it should behave like a real-valued feature with its value to be? n?, at least in principle",
            "label": [
                "Method citation"
            ]
        },
        {
            "Number": 15,
            "refer_ID": "P08-1102",
            "refer_sids": [
                35
            ],
            "refer_text": "To compare with others conveniently, we excluded the ones forbidden by the close test regulation of SIGHAN, for example, Pu(C0), indicating whether character C0 is a punctuation.",
            "cite_ID": "C10-1132",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "Inspired by (Jiang et al, 2008), we set the real d Although Table 5 has shown that the proposed all the value of C0 to be 2.0, the value of C-1C0anC0C1 to be 3.0, and the values of all other features to be 1.0 for the character-based discriminative-plus model",
            "label": [
                "Method citation"
            ]
        },
        {
            "Number": 17,
            "refer_ID": "P08-1102",
            "refer_sids": [
                91
            ],
            "refer_text": "We propose a cascaded linear model for joint Chinese word segmentation and partof-speech tagging.",
            "cite_ID": "D12-1046",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "Previous joint models mainly focus on word segmentation and POS tagging task, such as the virtual nodes method (Qian et al2010), cascaded linear model (Jiang et al2008a) ,perceptron (Zhang and Clark, 2008), sub-word based stacked learning (Sun, 2011), re ranking (Jiang et al2008b)",
            "label": [
                "Method citation"
            ]
        }
    ]
}