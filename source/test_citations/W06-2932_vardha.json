{
    "ID": "W06-2932",
    "citations": [
        {
            "Number": 2,
            "refer_ID": "W06-2932",
            "refer_sids": [
                19
            ],
            "refer_text": "The first stage of our system creates an unlabeled parse y for an input sentence x.",
            "cite_ID": "W06-2920",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "Introduce through post-processing ,e.g. through reattachment rules (Bick, 2006) or if the change increases overall parse tree probability (McDonald et al, 2006)",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 3,
            "refer_ID": "W06-2932",
            "refer_sids": [
                36
            ],
            "refer_text": "However, in a two stage system we can incorporate features over the entire output of the unlabeled parser since that structure is fixed as input.",
            "cite_ID": "W06-2920",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "Table 5 shows the official results for submitted parser outputs.31 The two participant groups with the highest total score are McDonald et al (2006) and Nivre et al (2006)",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 4,
            "refer_ID": "W06-2932",
            "refer_sids": [
                57
            ],
            "refer_text": "Performance is measured through unlabeled accuracy, which is the percentage of words that modify the correct head in the dependency graph, and labeled accuracy, which is the percentage of words that modify the correct head and label the dependency edge correctly in the graph.",
            "cite_ID": "W06-2920",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "Even though McDonald et al (2006) and Nivre et al (2006) obtained very similar overall scores, a more detailed look at their performance shows clear differences",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 5,
            "refer_ID": "W06-2932",
            "refer_sids": [
                76
            ],
            "refer_text": "For instance, sequential labeling improves the labeling of 2This difference was much larger for experiments in which gold standard unlabeled dependencies are used. objects from 81.7%/75.6% to 84.2%/81.3% (labeled precision/recall) and the labeling of subjects from 86.8%/88.2% to 90.5%/90.4% for Swedish.",
            "cite_ID": "W08-1007",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "The high est score on parsing German in the CoNLL-X shared task was obtained by the system of McDonald et al (2006) with a LAS of 87.34 based on the TIGER tree bank, but we want to stress that these results are not comparable due to different data sets (anda different policy regarding the inclusion of punctuation) .The constituency versions were evaluated according to the labeled recall (LR), labeled precision (LP) and labeled F-score (LF)",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 6,
            "refer_ID": "W06-2932",
            "refer_sids": [
                54
            ],
            "refer_text": "Based on performance from a held-out section of the training data, we used non-projective parsing algorithms for Czech, Danish, Dutch, German, Japanese, Portuguese and Slovene, and projective parsing algorithms for Arabic, Bulgarian, Chinese, Spanish, Swedish and Turkish.",
            "cite_ID": "W09-1210",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "McDonald et al (2006) use an additional algorithm",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 7,
            "refer_ID": "W06-2932",
            "refer_sids": [
                104
            ],
            "refer_text": "We have presented results showing that the spanning tree dependency parsing framework of McDonald et al. (McDonald et al., 2005b; McDonald and Pereira, 2006) generalizes well to languages other than English.",
            "cite_ID": "W12-3407",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "Regarding the data-driven parsers, we have made use of MaltParser (Nivre et al, 2007b) and MST Parser (McDonald et al, 2006), two state of the art dependency parsers representing two dominant approaches in data-driven dependency parsing, and that have been successfully applied to typologically different languages and tree banks (McDonald and Nivre, 2007)",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 8,
            "refer_ID": "W06-2932",
            "refer_sids": [
                12
            ],
            "refer_text": "In this paper we describe a two-stage discriminative parsing approach consisting of an unlabeled parser and a subsequent edge labeler.",
            "cite_ID": "I08-1012",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "In fact, our approach can also be applied to other parsers, such as (Yamada and Matsumoto, 2003)? s parser, (McDonald et al., 2006)? s parser, and so on",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 9,
            "refer_ID": "W06-2932",
            "refer_sids": [
                57
            ],
            "refer_text": "Performance is measured through unlabeled accuracy, which is the percentage of words that modify the correct head in the dependency graph, and labeled accuracy, which is the percentage of words that modify the correct head and label the dependency edge correctly in the graph.",
            "cite_ID": "N07-1050",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "But whereas the spanning tree parser of McDonald et al (2006) and the pseudo-projective parser of Nivre et al (2006) achieve this performance only with special preorpost-processing,7 the approach presented here derives a labeled non-projective graph in a single incremental process and hence at least has the advantage of simplicity",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 10,
            "refer_ID": "W06-2932",
            "refer_sids": [
                58
            ],
            "refer_text": "These results show that the discriminative spanning tree parsing framework (McDonald et al., 2005b; McDonald and Pereira, 2006) is easily adapted across all these languages.",
            "cite_ID": "N07-1050",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "Moreover, it has better time complexity than the approximate second-order spanning tree parsing of McDonald et al (2006), which has exponential complexity in the worst case (although this does not appear to be a problem in practice)",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 11,
            "refer_ID": "W06-2932",
            "refer_sids": [
                22
            ],
            "refer_text": "An exact projective and an approximate non-projective parsing algorithm are presented, since it is shown that nonprojective dependency parsing becomes NP-hard when features are extended beyond a single edge.",
            "cite_ID": "N07-1050",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "We have shown that, for languages with a7McDonald et al (2006) use post-processing for non projective dependencies and for labeling",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 12,
            "refer_ID": "W06-2932",
            "refer_sids": [
                41
            ],
            "refer_text": "To model this we treat the labeling of the edges (i, j1), ... , (i, jM) as a sequence labeling problem, We use a first-order Markov factorization of the score s(l(i,jm), l(i,jm\ufffd1), i, y, x) in which each factor is the score of labeling the adjacent edges (i, jm) and (i, jm\u22121) in the tree y.",
            "cite_ID": "D07-1122",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "As described in (McDonald et al, 2006), we treat the labeling of dependencies as a sequence labeling problem",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 13,
            "refer_ID": "W06-2932",
            "refer_sids": [
                21
            ],
            "refer_text": "That work extends the maximum spanning tree dependency parsing framework (McDonald et al., 2005a; McDonald et al., 2005b) to incorporate features over multiple edges in the dependency graph.",
            "cite_ID": "W11-0314",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "ULISSE was tested against the output of two really different data? driven parsers: the first? order Maximum Spanning Tree (MST) parser (McDonald et al., 2006) and the DeSR parser (Attardi, 2006) using Support Vector Machine as learning algorithm",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 14,
            "refer_ID": "W06-2932",
            "refer_sids": [
                64
            ],
            "refer_text": "N/P: Allow non-projective/Force projective, S/A: Sequential labeling/Atomic labeling, M/B: Include morphology features/No morphology features. assignment of edge labels instead of individual assignment, and a rich feature set that incorporates morphological properties when available.",
            "cite_ID": "D07-1015",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "5It should be noted that McDonald et al (2006) use a richer feature set that is incomparable to our features",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 16,
            "refer_ID": "W06-2932",
            "refer_sids": [
                21
            ],
            "refer_text": "That work extends the maximum spanning tree dependency parsing framework (McDonald et al., 2005a; McDonald et al., 2005b) to incorporate features over multiple edges in the dependency graph.",
            "cite_ID": "D10-1069",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "The dependency parsers that we compare are the deterministic shift-reduce MaltParser (Nivre et al, 2007) and the second-order minimum spanning tree algorithm based MstParser (McDonald et al, 2006)",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 19,
            "refer_ID": "W06-2932",
            "refer_sids": [
                57
            ],
            "refer_text": "Performance is measured through unlabeled accuracy, which is the percentage of words that modify the correct head in the dependency graph, and labeled accuracy, which is the percentage of words that modify the correct head and label the edge correctly in the graph.",
            "cite_ID": "P08-1108",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "The specific graph-based model studied in this work is that presented by McDonald et al (2006), which factors scores over pairs of arcs (instead of just single arcs) and uses near exhaustive search for unlabeled parsing coupled with a separate classifier to label each arc. We call this system MSTParser, or simply MST for short, which is also the name of the freely available implementation.2 2.3 Transition-Based Models",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 20,
            "refer_ID": "W06-2932",
            "refer_sids": [
                43
            ],
            "refer_text": "For score functions, we use simple dot products between high dimensional feature representations and a weight vector Assuming we have an appropriate feature representation, we can find the highest scoring label sequence with Viterbi\u2019s algorithm.",
            "cite_ID": "P08-1108",
            "cite_maker_sids": [
                0
            ],
            "cite_sids": [
                0
            ],
            "cite_text": "More precisely, dependency arcs (or pairs of arcs) are first represented by a high dimensional feature vector f (i, j, l)? Rk, where f is typically a bi nary feature vector over properties of the arc as well as the surrounding input (McDonald et al, 2005a; McDonald et al, 2006)",
            "label": [
                "Method_Citation"
            ]
        }
    ]
}