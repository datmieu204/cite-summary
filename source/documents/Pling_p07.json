{
    "ID": "Pling_p07",
    "sections": [
        {
            "text": "abstract",
            "number": 0,
            "sents": [
                {
                    "text": "This paper describes a push-the-button MT system combination toolkit.",
                    "sid": 1,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The combination is based on the creation of a lattice made on several confusion networks (CN) connected together.",
                    "sid": 2,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This lattice is then decoded with a token-pass decoder to provide the best and/or n-best outputs.",
                    "sid": 3,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Each CN is built using a modi\ufb01ed version of the TERp tool.",
                    "sid": 4,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The toolkit is made of several scripts along a core program developed in Java.",
                    "sid": 5,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "It is totally con\ufb01gurable and the parameters can be tuned quite easily.",
                    "sid": 6,
                    "ssid": 6,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "introduction",
            "number": "1",
            "sents": [
                {
                    "text": "Machine translation (MT) system combination has taken a great importance these past few years.",
                    "sid": 7,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This is mainly due to the fact that single systems achieved good performance and the possibility of taking the most of their complementarity in a system combination framework is very attractive.",
                    "sid": 8,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Many techniques can be used for system combination.",
                    "sid": 9,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "One concerns hypothesis selection using nbest list reranking based on various features as described in (Hildebrand and Vogel, 2009).",
                    "sid": 10,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Another approach is to consider source text and systems outputs as bitext and train a new SMT system on these data (Chen et al., 2009).",
                    "sid": 11,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In this paper, a system combination based on confusion network (CN) is described.",
                    "sid": 12,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This approach is not new, and numerous publications are available on that subject, see for example, (Rosti et al., 2007); (Shen et al., 2008); (Karakos et al., 2008) and (Leusch et al., 2009).",
                    "sid": 13,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Such an approach is presented in Figure 1.",
                    "sid": 14,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The protocol can be decomposed into three steps : \u00a9 2010 PBML.",
                    "sid": 15,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "All rights reserved.",
                    "sid": 16,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Corresponding author: loic.barrault@gmail.com Cite as: Lo\u00efc Barrault.",
                    "sid": 17,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "MANY: Open Source Machine Translation System Combination.",
                    "sid": 18,
                    "ssid": 18,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The Prague Bulletin of Mathematical Linguistics No. 93, 2010, pp.",
                    "sid": 19,
                    "ssid": 19,
                    "kind_of_tag": "s"
                },
                {
                    "text": "147\u2013155.",
                    "sid": 20,
                    "ssid": 20,
                    "kind_of_tag": "s"
                },
                {
                    "text": "ISBN 97880-9041754-0.",
                    "sid": 21,
                    "ssid": 21,
                    "kind_of_tag": "s"
                },
                {
                    "text": "doi: 10.2478/v10108010-0001-y.",
                    "sid": 22,
                    "ssid": 22,
                    "kind_of_tag": "s"
                },
                {
                    "text": "P 010 System 0 1-best output TERp alignment LM C N best hypo System 1 1-best output TERp CN alignment CN Merge Lattice DECODE output {nbest list System M 1-best output T E R p a l i g n m e n t Figure 1.",
                    "sid": 23,
                    "ssid": 23,
                    "kind_of_tag": "s"
                },
                {
                    "text": "MT system combination.",
                    "sid": 24,
                    "ssid": 24,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Each 1-best outputs are aligned to create as many Confusion Networks which are connected together to form a lattice.",
                    "sid": 25,
                    "ssid": 25,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This lattice is then decoded with a token-pass decoder using a Language Model to produce 1-best and/or n-best hypotheses.",
                    "sid": 26,
                    "ssid": 26,
                    "kind_of_tag": "s"
                },
                {
                    "text": "1.",
                    "sid": 27,
                    "ssid": 27,
                    "kind_of_tag": "s"
                },
                {
                    "text": "1-best hypotheses from all M systems are aligned in order to build confusion networks.",
                    "sid": 28,
                    "ssid": 28,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "all confusion networks are connected into a single lattice.. ",
            "number": "2",
            "sents": [
                {
                    "text": "3.",
                    "sid": 29,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "A language model is used to decode the resulting lattice and the best hypothesis is generated.",
                    "sid": 30,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Section 2.1 describes the alignment process and in particular the new features added to TERp in order to be enable alignment of an hypothesis against a CN.",
                    "sid": 31,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The decoder is presented in section 3.",
                    "sid": 32,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Some example results obtained at the IWSLT\u201909 evaluation campaign are given in section 5.",
                    "sid": 33,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Finally, a description of the toolkit is given in section 6.",
                    "sid": 34,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "2. Hypotheses alignment and confusion network generation.",
                    "sid": 35,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The goal of this step is to put the words provided by di\ufb00erent systems in competition with each other inside a confusion network (Mangu et al., 1999).",
                    "sid": 36,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For each segment, the best hypotheses of M \u2212 1 systems are aligned against the last one used as backbone.",
                    "sid": 37,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "A modi\ufb01ed version of the TERp tool (Snover et al., 2009a)(Snover et al., 2009b) is used to generate a confusion network (see section 2.1 for de tails).",
                    "sid": 38,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This is done by incrementally adding the hypotheses to the CN.",
                    "sid": 39,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The hypotheses are added to the backbone beginning with the nearest (in terms of TER) and ending with the more distant one.",
                    "sid": 40,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This di\ufb00ers from the result of (Rosti et al., 2007) where the nearest hypothesis is computed at each step, which is supposed to be better.",
                    "sid": 41,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "M confusion networks are generated in this way.",
                    "sid": 42,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Then all the confusion networks are connected into a single lattice by adding a \ufb01rst and last node.",
                    "sid": 43,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The probability of the 148 L. Barrault Open Source MT System Combination (147\u2013155) \ufb01rst arcs (later named priors) must re\ufb02ect how well such system provides a well structured hypothesis.",
                    "sid": 44,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "2.1.",
                    "sid": 45,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Modi\ufb01ed TERp.",
                    "sid": 46,
                    "ssid": 18,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The modi\ufb01ed TERp is based on TERp v0.1 and is written in Java.",
                    "sid": 47,
                    "ssid": 19,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Some classes have been modi\ufb01ed and new ones were created to add some functionalities such as alignment between a sentence and a confusion network.",
                    "sid": 48,
                    "ssid": 20,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This has been done by modifying the data structure and extending some heuristic to \ufb01nd better alignment.",
                    "sid": 49,
                    "ssid": 21,
                    "kind_of_tag": "s"
                },
                {
                    "text": "When using relaxed constraints with TERp, the shift heuristics allow a block of words to be moved if it matches (or is a paraphrase of) another block of words somewhere else.",
                    "sid": 50,
                    "ssid": 22,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Shifts are also allowed when a stem or synonym is found somewhere else.",
                    "sid": 51,
                    "ssid": 23,
                    "kind_of_tag": "s"
                },
                {
                    "text": "When considering confusion networks, the same heuristics are applied except that the block of words must match (be a paraphrase, synonyms or stem of) one of the sequence of words represented in the CN.",
                    "sid": 52,
                    "ssid": 24,
                    "kind_of_tag": "s"
                },
                {
                    "text": "An example of such a case is presented in \ufb01gure 2.",
                    "sid": 53,
                    "ssid": 25,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In \ufb01 Is the dinner included ? Match Paraphrase Match Match Supper is included ? the dinner Is included ? supper NULL Sub Ins Sub Sub Match Match Do you have calculated dinner ? Is NULL the dinner included supper ? Do you have NULL calculated Figure 2.",
                    "sid": 54,
                    "ssid": 26,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Incremental alignment with TERp resulting in a confusion network.",
                    "sid": 55,
                    "ssid": 27,
                    "kind_of_tag": "s"
                },
                {
                    "text": "a switch of block of word.",
                    "sid": 56,
                    "ssid": 28,
                    "kind_of_tag": "s"
                },
                {
                    "text": "However, the word supper is aligned with the word the because no rule is used in order to make inside-paraphrase word alignment, yet !",
                    "sid": 57,
                    "ssid": 29,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(see section 6.4 for future features).",
                    "sid": 58,
                    "ssid": 30,
                    "kind_of_tag": "s"
                },
                {
                    "text": "149 PBML 93 JANUARY 2010 In addition to the confusion network generation, the possibility of using scores on words has been added, which can be very useful during the decoding.",
                    "sid": 59,
                    "ssid": 31,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For the moment, these scores must be computed separately from MANY.",
                    "sid": 60,
                    "ssid": 32,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The underlying idea is to provide an option to include con\ufb01dence measure at word level, though it can be computed at any level (see for example, (Ue\ufb00ing and Ney, 2005)).",
                    "sid": 61,
                    "ssid": 33,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In this version of the software, the scores are equal to the priors of the systems.",
                    "sid": 62,
                    "ssid": 34,
                    "kind_of_tag": "s"
                },
                {
                    "text": "However, these values can be modi\ufb01ed in the con\ufb01guration \ufb01le.",
                    "sid": 63,
                    "ssid": 35,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "decoding. ",
            "number": "3",
            "sents": [
                {
                    "text": "The decoder is based on the token pass decoding algorithm (see for example (Young et al., 1989)).",
                    "sid": 64,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The principle of this decoder is to propagate tokens over the lattice and accumulate various scores into a global score for each hypotheses.",
                    "sid": 65,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The scores used to evaluate the hypotheses are the following : \u2022 the system score : this replace the score of the translation model.",
                    "sid": 66,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Until now, the words given by all systems have the same probability which are equal to their priors, but any con\ufb01dence measure can be used at this step.",
                    "sid": 67,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "\u2022 the language model (LM) probability.",
                    "sid": 68,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "\u2022 a fudge factor to balance the probabilities provided in the lattice with regard to those given by the language model.\u2022 a null-arc penalty : this penalty avoids to always go through null-arcs encoun tered in the lattice.",
                    "sid": 69,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "\u2022 a length penalty : this score helps to generate correctly sized hypotheses.",
                    "sid": 70,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The probabilities computed in the decoder can be expressed as follow : log(PW ) = Len(W) \u2211 n=0 [log(Pws (n)) + \u03b1Plm (n)] (1) +Lenpen (W) + Nullpen (W) where Len(W) is the length of the hypothesis, Pws (n) is the score of the nth word in the lattice, Plm (n) is its LM probability, \u03b1 is the fudge factor, Lenpen (W) is the length penalty of the word sequence and Nullpen (W) is the penalty associated with the number of null-arcs crossed to obtain the hypothesis.",
                    "sid": 71,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "At the beginning, only one token is created at the \ufb01rst node of the lattice.",
                    "sid": 72,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Then this token spread over the consecutive nodes, accumulating the score on the arc it crosses, the language model probability of the word sequence generated so far and null or length penalty if applicable.",
                    "sid": 73,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The number of tokens can increase really quickly to cover the whole lattice, and, in order to keep it tractable, only the Nmax best tokens are kept (the others are discarded), where Nmax can be con\ufb01gured in the con\ufb01guration \ufb01le.",
                    "sid": 74,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Other methods to restrict the number of tokens (like pruning based on score or other heuristics) can easily be implemented in this software, but this is not done already.",
                    "sid": 75,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "150 L. Barrault Open Source MT System Combination (147\u2013155) 3.1.",
                    "sid": 76,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Technical details about the token pass decoder.",
                    "sid": 77,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This software is based on the Sphinx4 library and is highly con\ufb01gurable (Walker et al., 2004).",
                    "sid": 78,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The maximum number of tokens being considered during decoding, the fudge factor, the null-arc penalty and the length penalty can all be set within the xml con\ufb01guration \ufb01le.",
                    "sid": 79,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This is useful for tuning (see the con\ufb01g \ufb01le generator description in section 6.2).",
                    "sid": 80,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The probabilities which are manipulated within the decoder are all obtained from the LogMath class which ensures the consistency of the values.",
                    "sid": 81,
                    "ssid": 18,
                    "kind_of_tag": "s"
                },
                {
                    "text": "3.2.",
                    "sid": 82,
                    "ssid": 19,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Language model.",
                    "sid": 83,
                    "ssid": 20,
                    "kind_of_tag": "s"
                },
                {
                    "text": "There are two ways of loading a LM with this software.",
                    "sid": 84,
                    "ssid": 21,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The \ufb01rst solution is to use the LargeTrigramModel class, but as its name tells us, only a 3-gram model can be loaded with this class.",
                    "sid": 85,
                    "ssid": 22,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The second and easiest way is to use a language model hosted on a lm-server.",
                    "sid": 86,
                    "ssid": 23,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This kind of LM can be accessed via the LanguageModelOnServer class which is based on the generic LanguageModel class from the Sphinx4 library.",
                    "sid": 87,
                    "ssid": 24,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This allows us to load a n-gram LM with n higher than 3, which is not possible with a standard LM class in Sphinx4 yet (it is currently being done).",
                    "sid": 88,
                    "ssid": 25,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In addition, the Dictionary interface has been extended in order to be able to load a simple dictionary containing all the words known by the LM (no need to know the di\ufb00erent pronunciations of each words in this case).",
                    "sid": 89,
                    "ssid": 26,
                    "kind_of_tag": "s"
                },
                {
                    "text": "As the language model interface is also written in java and is using the Sphinx4 library, one could easily write a new class to load a LM in a proprietary \ufb01le format.",
                    "sid": 90,
                    "ssid": 27,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "tuning. ",
            "number": "4",
            "sents": [
                {
                    "text": "There is a lot of parameters which can be tuned in MANY.",
                    "sid": 91,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The edit costs of the modi\ufb01ed TERp, the prior costs of each systems in the lattice, the fudge, null-arc penalty and length penalty for the decoder.",
                    "sid": 92,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This can easily been done by generating con\ufb01gu- ration \ufb01les (with the help of genSphinxCon\ufb01g.pl, see section 6.3).",
                    "sid": 93,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Parameters for mod- i\ufb01ed TERp, for the decoder and systems weights are currently tuned together.",
                    "sid": 94,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The separate tuning of TERp and decoder parameters is an ongoing work, and I could not say whether it is preferable or not yet.",
                    "sid": 95,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Any method can then be used to provide new values for these parameters.",
                    "sid": 96,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "As anexample, we are using Condor (Berghen and Bersini, 2005) to optimize those param eters.",
                    "sid": 97,
                    "ssid": 7,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "some example results. ",
            "number": "5",
            "sents": [
                {
                    "text": "MANY software has been used for the IWSLT\u201909 evaluation campaign.",
                    "sid": 98,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Table 1 presents the results obtained with this approach.",
                    "sid": 99,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The SMT system is based on MOSES, 151 PBML 93 JANUARY 2010 the SPE system corresponds to a rule-based system from SYSTRAN whose outputs have been corrected by a SMT system and the Hierarchical is based on Joshua.",
                    "sid": 100,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Sy ste ms Ar ab ic/ E ng lis h D ev 7 Test09.",
                    "sid": 101,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "C hi ne se/ E ng lis h De v7 Test09 S M T C SL M 54 .7 5 50.35 41.",
                    "sid": 102,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "71 36.04 SP E C SL M 48 .13 41.",
                    "sid": 103,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "23 38.53 Hi era rc hi cal 54 .0 0 49.06 39.",
                    "sid": 104,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "78 31.89 S M T CS L M + SP E C SL M + tu ni ng 42.",
                    "sid": 105,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "55 40.14 43.",
                    "sid": 106,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "06 39.46 S M T CS L M + Hi er.",
                    "sid": 107,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "+ tu ni ng 55 .8 9 50.86 57 .0 1 51.74 Table 1.",
                    "sid": 108,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Results of system combination on Dev7 (development) corpus and Test09, the o\ufb03cial test corpus of IWSLT\u201909 evaluation campaign.",
                    "sid": 109,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In these task, the system combination approach yielded +1.39 BLEU on Ar/En and +1.7 BLEU on Zh/En.",
                    "sid": 110,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "One observation is that tuning parameters did not provided better results for Zh/En.",
                    "sid": 111,
                    "ssid": 14,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "software description. ",
            "number": "6",
            "sents": [
                {
                    "text": "The software is available at the following address : http://wwwlium.univlemans.fr/~barrault/MANY 6.1.",
                    "sid": 112,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Data.",
                    "sid": 113,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The software takes several \ufb01les as input (which are supposed to be synchronized1 ) containing the 1-best hypothesis of all systems, one sentence per line.",
                    "sid": 114,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "These hypotheses can contain foreign words if no translation have been found for them, and they will be considered as unknown words during the decoding step.",
                    "sid": 115,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "6.2.",
                    "sid": 116,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Con\ufb01guration \ufb01le.",
                    "sid": 117,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The con\ufb01guration \ufb01le is an xml \ufb01le similar to those used with Sphinx4.",
                    "sid": 118,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "<component name=\"decoder\" type=\"edu.loic.decoder.TokenPassDecoder\"> <property name=\"dictionary\" value=\"dictionary\"/> <property name=\"logMath\" value=\"logMath\"/> <property name=\"logLevel\" value=\"INFO\"/> 1 i.e. each nth line is the translation of the same source sentence 152 L. Barrault Open Source MT System Combination (147\u2013155) <property name=\"lmonserver\" value=\"lmonserver\"/> <property name=\"fudge\" value=\"0.2\"/> <!-- This value is multiplied by 10 in the software --> <property name=\"null_penalty\" value=\"0.3\"/> <property name=\"length_penalty\" value=\"0.5\"/> <!-- This value is multiplied by 10 in the software --> </component> This part allows us to con\ufb01gure the decoder parameters such and more particularly the fudge factor, the null-arc penalty and the length penalty.",
                    "sid": 119,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "<component name=\"lmonserver\" type=\"edu.cmu.sphinx.linguist.language.ngram.LanguageModelOnServer\"> <property name=\"lmserverport\" value=\"1234\"/> <property name=\"lmserverhost\" value=\"machine1\"/> <property name=\"maxDepth\" value=\"4\"/> <property name=\"logMath\" value=\"logMath\"/> </component> This part con\ufb01gures the LM class which will connect to the lm-server hosted on ma- chine1 on port \u201d1234\u201d.",
                    "sid": 120,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The maxDepth \ufb01eld correspond to the depth of the LM loaded on the server.",
                    "sid": 121,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "<component name=\"MANY\" type=\"edu.lium.mt.MANY\"> <property name=\"decoder\" value=\"decoder\"/> <property name=\"terp\" value=\"terp\"/> <property name=\"output\" value=\"output.many\"/> <property name=\"priors\" value=\"4.0e01 4.0e01 2.0e01\"/> <property name=\"hypotheses\" value=\"hyp0.id hyp1.id hyp2.id\" /> <property name=\"hyps_scores\" value=\"hyp0_sc.id hyp1_sc.id hyp2_sc.id\" /> <property name=\"costs\" value=\"1.0 1.0 1.0 1.0 1.0 0.0 1.0\" /> <!-- del stem syn ins sub match shift--> <property name=\"terpParams\" value=\"terp.params\"/> <property name=\"wordnet\" value=\"/opt/mt/WordNet3.0/dict/\"/> <property name=\"shift_word_stop_list\" value=\"/opt/mt/terp/terp.v1/data/shift_word_stop_list.txt\"/> <property name=\"paraphrases\" value=\"/opt/mt/terp/terp.v1/data/phrases.db\"/> </component> This part is the core part.",
                    "sid": 122,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "It con\ufb01gures the various \ufb01les to combine, the costs for TERp, the location of WordNet and the paraphrases table (also for TERp).",
                    "sid": 123,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The priors can be set here and are used in the lattice.",
                    "sid": 124,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "6.3.",
                    "sid": 125,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Scripts.",
                    "sid": 126,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The main script is called Many.sh.",
                    "sid": 127,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Some parameters have to be set inside this script in order to run a system combination experiments.",
                    "sid": 128,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The reader should refer to the readme \ufb01le provided with the software.",
                    "sid": 129,
                    "ssid": 18,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Each input sentence (as well as the corresponding word scores) must have an id which is of the following form : [set][doc.##][sent] The shell script add_id.sh is in charge of adding such an id to the input data (called in the Many.sh script).",
                    "sid": 130,
                    "ssid": 19,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The perl script genSphinxCon\ufb01g.pl is used to generate a new con\ufb01g \ufb01le with speci\ufb01c values.",
                    "sid": 131,
                    "ssid": 20,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This is very useful for generating a new con\ufb01g \ufb01le with parameters estimated by a certain optimization procedure.",
                    "sid": 132,
                    "ssid": 21,
                    "kind_of_tag": "s"
                },
                {
                    "text": "6.4.",
                    "sid": 133,
                    "ssid": 22,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Future features.",
                    "sid": 134,
                    "ssid": 23,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Several features are planned to be added into MANY.",
                    "sid": 135,
                    "ssid": 24,
                    "kind_of_tag": "s"
                },
                {
                    "text": "One is the possibility of exploring all shifts which do not decrease the alignment score instead of using heuris 153 PBML 93 JANUARY 2010 tics.",
                    "sid": 136,
                    "ssid": 25,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This has been done by (Rosti et al., 2009) and provided good results (even though the increasing time of processing was not indicated).",
                    "sid": 137,
                    "ssid": 26,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Another feature would be the intra-paraphrase word alignment.",
                    "sid": 138,
                    "ssid": 27,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Like is presented in \ufb01gure 2, when a paraphrase is found, it appears that the word alignment inside that paraphrase is not always the best.",
                    "sid": 139,
                    "ssid": 28,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In that example, (supper is aligned with the instead of dinner, which would be better.",
                    "sid": 140,
                    "ssid": 29,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This could be easily added using a speci\ufb01c alignment model.",
                    "sid": 141,
                    "ssid": 30,
                    "kind_of_tag": "s"
                },
                {
                    "text": "As mentioned before, the load of a n-gram (whatever is n) language model has to be added.",
                    "sid": 142,
                    "ssid": 31,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In some cases, that can be faster than using a LM server.",
                    "sid": 143,
                    "ssid": 32,
                    "kind_of_tag": "s"
                },
                {
                    "text": "An alternative to the token pass decoder would be the use of Minimum Bayesian Risk decoder applied on the \ufb01nal lattice (MBR-Lattice) like described in (Tromble et al., 2008)",
                    "sid": 144,
                    "ssid": 33,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "discussion. ",
            "number": "7",
            "sents": [
                {
                    "text": "One might notice that the performance of a system combination is highly dependent of the input hypotheses (in terms of number of hypotheses, complementarity of the systems which provide them, and of course quality), the parameters of the alignment module and the language model used to decode the lattice.",
                    "sid": 145,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The tuning of all parameters plays consequently a big role in the quality of this kind of approach.",
                    "sid": 146,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "As an example, in (Rosti et al., 2009), after the creation of the lattice, three iterations of tuning have been done in order to obtain good results.",
                    "sid": 147,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This kind of tuning procedure is not currently implemented in that software, but it is a very important step which should not be underestimated.",
                    "sid": 148,
                    "ssid": 4,
                    "kind_of_tag": "s"
                }
            ]
        }
    ]
}