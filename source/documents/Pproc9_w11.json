{
    "ID": "Pproc9_w11",
    "sections": [
        {
            "text": "abstract",
            "number": 0,
            "sents": [
                {
                    "text": "This research focuses on determining seman\u00ad tic compositionality of word expressions us\u00ad ing word space models (WSMs).",
                    "sid": 1,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We discuss previous works employing WSMs and present differences in the proposed approaches which include types of WSMs, corpora, preprocess\u00ad ing techniques, methods for determining com\u00ad positionality, and evaluation testbeds.",
                    "sid": 2,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We also present results of our own approach for determining the semantic compositionality based on comparing distributional vectors of expressions and their components.",
                    "sid": 3,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The vec\u00ad tors were obtained by Latent Semantic Analy\u00ad sis (LSA) applied to the uk:WaC corpus.",
                    "sid": 4,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Our results outperform those of all the participants in the Distributional Semantics and Composi\u00ad tionality (DISCO) 2011 shared task.",
                    "sid": 5,
                    "ssid": 5,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "introduction",
            "number": "1",
            "sents": [
                {
                    "text": "A word expression is semantically compositional if its meaning can be understood from the literal meaning of its components.",
                    "sid": 6,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Therefore, semanti\u00ad cally compositional expressions involve e.g. \"small island\" or ''hot water\"; on the other hand, seman\u00ad tically non-compositional expressions are e.g. \"red tape\" or \"kick the bucket\".",
                    "sid": 7,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The notion of compositionality is closely related to idiomacy -the higher the compositionality the lower the idiomacy and vice versa (Sag et al., 2002; Baldwin and Kim, 2010).",
                    "sid": 8,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Non-compositional expressions are often referred to as Multiword Expressions (MWEs).",
                    "sid": 9,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Baldwin and Kim (2010) differentiate the following sub-types of Pavel Pecina Charles University in Prague Faculty of Mathematics and Physics Institute of Formal and Applied Linguistics Prague, Czech Republic pecina@ufal.mff.cuni.cz compositionality: lexical, syntactic, semantic, prag\u00ad matic, and statistical.",
                    "sid": 10,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This paper is concerned with semantic compositionality.",
                    "sid": 11,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Compositionality as a feature of word expressions is not discrete.",
                    "sid": 12,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Instead, expressions populate a con\u00ad tinuum between two extremes: idioms and free word combinations (McCarthy et al., 2003; Bannard et al., 2003; Katz, 2006; Fazly, 2007; Baldwin and Kim, 2010; Biemann and Giesbrecht, 2011).",
                    "sid": 13,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Typical ex\u00ad amples of expressions between the two extremes are \"zebra crossing\" or \"blind alley\".",
                    "sid": 14,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Our research in compositionality is motivated by the hypothesis that a special treatment of se\u00ad mantically non-compositional expressions can im\u00ad prove results in various Natural Language Process\u00ad ing (NPL) tasks, as shown for example by Acosta et al.",
                    "sid": 15,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2011), who utilized MWEs in Information Re\u00ad trieval (IR).",
                    "sid": 16,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Besides that, there are other NLP ap\u00ad plications that can benefit from knowing the degree of compositionality of expressions such as machine translation (Carpuat and Diab, 2010), lexicography (Church and Hanks, 1990), word sense disambigua\u00ad tion (Finlayson and Kulkarni, 2011), part-of-speech (POS) tagging and parsing (Seretan, 2008) as listed in Rarnisch (2012).",
                    "sid": 17,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The main goal of this paper is to present an anal\u00ad ysis of previous approaches using WSMs for de\u00ad termining the semantic compositionality of expres\u00ad sions.",
                    "sid": 18,
                    "ssid": 18,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The analysis can be found in Section 2.",
                    "sid": 19,
                    "ssid": 19,
                    "kind_of_tag": "s"
                },
                {
                    "text": "A special attention is paid to the evaluation of the pro\u00ad posed models that is described in Section 3.",
                    "sid": 20,
                    "ssid": 20,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Section 4 presents our first intuitive experimental setup and results ofLSA applied to the DISCO 2011 task.",
                    "sid": 21,
                    "ssid": 21,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Sec\u00ad tion 5 concludes the paper.",
                    "sid": 22,
                    "ssid": 22,
                    "kind_of_tag": "s"
                },
                {
                    "text": "42 Proceedings of the 9th Workshop on Multiword Expressions (MWE 2013), pages 4250, Atlanta, Georgia, 1314 June 2013.",
                    "sid": 23,
                    "ssid": 23,
                    "kind_of_tag": "s"
                },
                {
                    "text": "@2013 Association for Computational Linguistics",
                    "sid": 24,
                    "ssid": 24,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "semantic compositionality of word. ",
            "number": "2",
            "sents": [
                {
                    "text": "Expressions Determined by WSMs Several recent works, including lin (1999), Schone and Jurafsky (2001), Baldwin et al.",
                    "sid": 25,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2003), Mc\u00ad Carthy et al.",
                    "sid": 26,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2003), Katz (2006), Johannsen et al.",
                    "sid": 27,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2011), Reddy et al.",
                    "sid": 28,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2011a), and KrCmar et al.",
                    "sid": 29,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2012), show the ability of methods based on WSMs to capture the degree of semantic compositionality of word expressions.",
                    "sid": 30,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We analyse the proposed meth\u00ad ods and discuss their differences.",
                    "sid": 31,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "As further de\u00ad scribed in detail and summarized in Table 1, the ap\u00ad proaches differ in the type of WSMs, corpora, pre\u00ad processing techniques, methods for determining the compositionality, datasets for evaluation, and meth\u00ad ods of evaluation itself.",
                    "sid": 32,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Our understanding of WSM is in agreement with Sahlgren (2006): \"The word space model is a com\u00ad putational model of word meaning that utilizes the distributional patterns of words collected over large text data to represent semantic similarity between words in terms of spatial proximity\".",
                    "sid": 33,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For more information on WSMs, see e.g. Turney and Pan\u00ad tel (2010), Jurgens and Stevens (2010), or Sahlgren (2006).",
                    "sid": 34,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "WSMs and their parameters WSMs can be built by different algorithms including LSA (Landauer and Dumais, 1997), Hyperspace Analogue to Lan\u00ad guage (HAL) (Lund and Burgess, 1996), Random Indexing (Rl) (Sahlgren, 2005), and Correlated Oc\u00ad currence Analogue to Lexical Semantics (COALS) (Rohde et al., 2005).",
                    "sid": 35,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Every algorithm has its own specifics and can be configured in different ways.",
                    "sid": 36,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The configuration usually involves e.g. the choice of context size, weighting functions, or normaliz\u00ad ing functions.",
                    "sid": 37,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "While Schone and Jurafsky (2001), Baldwin et al.",
                    "sid": 38,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2003), and Katz (2006) addopted LSA-based approaches, Johannsen et al.",
                    "sid": 39,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2011) and Krcmar et al.",
                    "sid": 40,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2012) employ COALS; the others use their own specific WSMs.",
                    "sid": 41,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Corpora and text preprocessing Using differ\u00ad ent corpora and their preprocessing naturally leads to different WSMs.",
                    "sid": 42,
                    "ssid": 18,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The preprocessing can differ e.g. in the choice of used word forms or in re\u00ad moval/retaining of low-frequency words.",
                    "sid": 43,
                    "ssid": 19,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For exam\u00ad ple, while Lin (1999) employs a 125-million-word newspaper corpus, Schone and Jurafsky (2001) use a 6.7-million-word subset of the TREC databases, Baldwin et al.",
                    "sid": 44,
                    "ssid": 20,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2003) base their experiments on 90 million words from the British National Corpus (Burnard, 2000).",
                    "sid": 45,
                    "ssid": 21,
                    "kind_of_tag": "s"
                },
                {
                    "text": "KrCmar et al.",
                    "sid": 46,
                    "ssid": 22,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2012), Johannsen et al.",
                    "sid": 47,
                    "ssid": 23,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2011), and Reddy et al.",
                    "sid": 48,
                    "ssid": 24,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2011a) use the ukWaC corpus, consisting of 1.9 billion words from web texts (Baroni et al., 2009).",
                    "sid": 49,
                    "ssid": 25,
                    "kind_of_tag": "s"
                },
                {
                    "text": "As for preprocessing, Lin (1999) extracts triples with dependency relation\u00ad ships, Baldwin et al.",
                    "sid": 50,
                    "ssid": 26,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2003), Reddy et al.",
                    "sid": 51,
                    "ssid": 27,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2011a), and Krcmar et al.",
                    "sid": 52,
                    "ssid": 28,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2012) concatenate word lemmas with their POS categories.",
                    "sid": 53,
                    "ssid": 29,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Johannsen et al.",
                    "sid": 54,
                    "ssid": 30,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2011) use word lemmas and remove low-frequency words while Reddy et al.",
                    "sid": 55,
                    "ssid": 31,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2011a), for example, keep only frequent content words.",
                    "sid": 56,
                    "ssid": 32,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Methods We have identified three basic methods for determining semantic compositionality: 1) The substitutability-based methods exploit the fact that replacing components of non\u00ad compositional expressions by words which are similar leads to anti-collocations (Pearce, 2002).",
                    "sid": 57,
                    "ssid": 33,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Then, frequency or mutual information of such expressions (anti-collocations) is compared with the frequency or mutual information of the original expressions.",
                    "sid": 58,
                    "ssid": 34,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example, consider expected occur\u00ad rence counts of ''hot dog\" and its anti-collocations such as \"warm dog\" or \"hot terrier''.",
                    "sid": 59,
                    "ssid": 35,
                    "kind_of_tag": "s"
                },
                {
                    "text": "2) The component-based methods, utilized for ex\u00ad ample by Baldwin et al.",
                    "sid": 60,
                    "ssid": 36,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2003) or Johannsen et al.",
                    "sid": 61,
                    "ssid": 37,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2011), compare the distributional characteristics of expressions and their components.",
                    "sid": 62,
                    "ssid": 38,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The context vec\u00ad tors expected to be different from each other are e.g. the vector representing the expression \"hot dog\" and the vector representing the word \"dog\".",
                    "sid": 63,
                    "ssid": 39,
                    "kind_of_tag": "s"
                },
                {
                    "text": "3) The compositionality-based methods compare two vectors of each analysed expression: the true co-occurrence vector of an expression and the vec\u00ad tur obtained from vectors corresponding to the com\u00ad ponents of the expression using a compositional\u00ad ity function (Reddy et al., 2011a).",
                    "sid": 64,
                    "ssid": 40,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The most com\u00ad mon compositionality functions are vector addition or pointwise vector multiplication (Mitchell and La\u00ad pata, 2008).",
                    "sid": 65,
                    "ssid": 41,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example, the vectors for ''hot dog\" and \"hot\"E!l\"dog\" are supposed to be different.",
                    "sid": 66,
                    "ssid": 42,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Evaluation datasets There is still no consensus on how to evaluate models deterntining semantic compositionality.",
                    "sid": 67,
                    "ssid": 43,
                    "kind_of_tag": "s"
                },
                {
                    "text": "However, by examining the dis\u00ad cussed papers, we have observed an increasing ten Pa pe r C or po ra W S M s M et ho ds D at a (ty pe s) E va lu at io n Li n (1 99 9) 12 5 m, tri pl es o w n S Y N V A Ac . di ets ., P/ R Sc ho ne +J ur afs ky (2 00 1) 6.",
                    "sid": 68,
                    "ssid": 44,
                    "kind_of_tag": "s"
                },
                {
                    "text": "7 m T R E C LS A S Y, C Y all ty pe s W N, P/ Rc Ba ld wi n et al.",
                    "sid": 69,
                    "ssid": 45,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2 00 3) B N C +P O S LS A C T N N, V P W N, P C M cC art hy et al.",
                    "sid": 70,
                    "ssid": 46,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2 00 3) B N C + G R o w n C Tn P V M A, W N, di ets ., S Ka tz (2 00 6) G N C LS A C Y P N V M A, P/ R, F m Kr cm ar et al.",
                    "sid": 71,
                    "ssid": 47,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2 01 2) uk W aC +P O S C O A LS S Y A N, V O, S V M A, C R, A P D, C L Jo ha nn se n et al.",
                    "sid": 72,
                    "ssid": 48,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2 01 1) uk W aC C O A LS S Y, C T A N, V O, S V M A, C R, A P D, C L Re dd y et al.",
                    "sid": 73,
                    "ssid": 49,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2 01 1a ) uk W aC +P O S o w n C T, C Y N N M A, S, R 2 Table 1: Overview of experiments applying WSMs to determine semantic compositionality of word expressions.",
                    "sid": 74,
                    "ssid": 50,
                    "kind_of_tag": "s"
                },
                {
                    "text": "BNCBritish National Corpus, GR - grammatical relations, GNCGerman newspaper corpus, TRECTREC corpus; SYsubstitutability-based methods, CT- component-based methods, CTn- component-based methods comparing WSM neighbors of expressions and their components, CYcompositionality-based methods; NVAP c. -noun, verb, adjective, adverb combinations, NN - noun-noun, VP - verb-particles, AN - adjective-noun, VO - verb-object, SV - subject-verb, PV - phrasal-verb, PNV - preposition-noun-verb; diets.",
                    "sid": 75,
                    "ssid": 51,
                    "kind_of_tag": "s"
                },
                {
                    "text": "- dictionaries of idioms, WNWordnet, MA - use of mannally annotated data, S - Spearman correlation, PCPearson correlation, CRSpearman and Kendall correlations, APD - average point difference, CL - classification, P/R - Precision/Recall, P/RcPrecisinn/Recall curves, Fm - F measure, R2 - goodness.",
                    "sid": 76,
                    "ssid": 52,
                    "kind_of_tag": "s"
                },
                {
                    "text": "dency to exploit manually annotated data from a specific corpus, ranging from semantically composi\u00ad tional to non-compositional expressions (McCarthy et al., 2003; Katz, 2006; Johannsen et al., 2011; Reddy et al., 2011a; Krcmar et al., 2012).",
                    "sid": 77,
                    "ssid": 53,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This approach, as opposed to the methods based on dictionaries of MWEs (idioms) or Word\u00ad net (Miller, 1995), has the following advantages: Firstly, the classification of a manually annotated data is not binary but finer-grained, enabling the evaluation to be more detailed.",
                    "sid": 78,
                    "ssid": 54,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Secondly, the low\u00ad coverage problem of dictionaries, which originates for example due to the facts that new MWEs still arise or are domain specific, is avoided.1 For exam\u00ad ple, Lin (1999), Schone and Jurafsky (2001), Bald\u00ad win et al.",
                    "sid": 79,
                    "ssid": 55,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2003) used Wordnet or other dictionary\u00ad type resources.",
                    "sid": 80,
                    "ssid": 56,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "evaluation methods. ",
            "number": "3",
            "sents": [
                {
                    "text": "This section discusses evaluation methods includ\u00ad ing average point difference (APD), Spearman and Kendall correlations, and precision of classifica\u00ad tion (PoC) suggested by Biemann and Giesbrecht (2011); Precision/nBest, RecalllnBest and Preci\u00ad sion/Recall curves proposed by Evert (2005); and Average Precision used by Pecina (2009).",
                    "sid": 81,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Our eval\u00ad uation is based on the English part of the manu\u00ad ally annotated datasets DISCO 2011 (Biemann and Giesbrecht, 2011), further referred to as DISCO-En\u00ad Gold.",
                    "sid": 82,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Disco-En-Gold consists of 349 expressions di\u00ad vided into training (TrainD), validation (ValD), and test data (TestD) manually assigned scores from 0 to 100, indicating the level of compositionality (the lower the score the lower the compositionality and vice versa).",
                    "sid": 83,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The expressions are of the following types: adjective-noun (AN), verb-object (YO), and subject-verb (SV).",
                    "sid": 84,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Based on the numerical scores, the expressions are also classified into three disjoint classes (coarse scores): low, medium, and high com\u00ad positional.2 A sample of the Disco-En-Gold data is presented in Table 2.",
                    "sid": 85,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Comparison of evaluation methods The purpose of the DISCO workshop was to find the best meth\u00ad ods for determining semantic compositionality.",
                    "sid": 86,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The participants were asked to create systems capable of assigning the numerical values closest to the ones assigned by the annotators (Gold values).",
                    "sid": 87,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The pro\u00ad posed APD evaluation measure is calculated as themean difference between the particular systems' val 1The consequence of using a low-coverage dictionary can cause underestimation of the used method since the dictionary does not have to contain MWEs correctly found by that method.",
                    "sid": 88,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "2Several expressions with the numerical scores close to the specified thresholds were not classified into any class.",
                    "sid": 89,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Type Expression Ns Cs EN_ADLNN blue chip 11 low EN_V_QBJ buck trend 14 low EN_ADLNN open source 49 medium EN_V_OBJ take advantage 57 medium EN_ADLNN red squirrel 90 high EN_V_SUBJ student learn 98 high Table 2: A sample of manually annotated expressions from Disco-En-Gold with their numerical scores (Ns) and coarse scores (Cs).",
                    "sid": 90,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "ues and the Gold values assigned to the same expres\u00ad sions.",
                    "sid": 91,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "PoC is defined as the ratio of correct coarse predictions to the number of all the predictions.",
                    "sid": 92,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Following KrCmaf et a!.",
                    "sid": 93,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2012), we argue that for the purpose of comparison of the methods, the values assigned to a set of expressions by a certain model are not as important as is the ranking of the expressions (which is not sensitive to the original distribution of compositionality values).",
                    "sid": 94,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Similarly as Evert (2005), Pecina (2009), and KrCmar et a!.",
                    "sid": 95,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2012) we adopt evaluation based on ranking (al\u00ad though the measures such as PoC or APD might pro\u00ad vide useful information too).",
                    "sid": 96,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Evaluation based on ranking can be realized by measuring ranked correlations (Spearman and Kendall) or Precision/Recall scores and curves com\u00ad monly used e.g. in IR (Manning et a!., 2008).",
                    "sid": 97,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In IR, Precision is defined as the ratio of found rele\u00ad vant documents to all the retrieved documents with regards to a user's query.",
                    "sid": 98,
                    "ssid": 18,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Recall is defined as the ra\u00ad tio of found relevant documents to all the relevant documents in a test set to the user's query.",
                    "sid": 99,
                    "ssid": 19,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The Precision/Recall curve is a curve depicting the de\u00ad pendency of Precision upon Recall.",
                    "sid": 100,
                    "ssid": 20,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Analogously, the scheme can be used for evaluation of the meth\u00ad ods finding semantically non-compositional expres\u00ad sions.",
                    "sid": 101,
                    "ssid": 21,
                    "kind_of_tag": "s"
                },
                {
                    "text": "However, estimation of Recall is not possible without knowledge of the correct class3 for every ex\u00ad pression in a corpus.",
                    "sid": 102,
                    "ssid": 22,
                    "kind_of_tag": "s"
                },
                {
                    "text": "To bypass this, Evert (2005) calcnlates Recall with respect to the set of annotated data divided into non-compositional and composi\u00ad tional classes.",
                    "sid": 103,
                    "ssid": 23,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The Precision/nBest, Recall!nBest, and Precision/Recall curves for the LSA experiment 3A semantically non-compositional expression or a seman\u00ad tically compositional expressions described in the following section are depicted in Figures 1 and 2.",
                    "sid": 104,
                    "ssid": 24,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Evert's (2005) curves allow us to visually com\u00ad pare the results of the methods in more detail.",
                    "sid": 105,
                    "ssid": 25,
                    "kind_of_tag": "s"
                },
                {
                    "text": "To facilitate comparison of several methods, we also suggest using average precision (AP) adopted from Pecina (2009), which reduces information provided by a single Precision/Recall curve to one value.",
                    "sid": 106,
                    "ssid": 26,
                    "kind_of_tag": "s"
                },
                {
                    "text": "AP is defined as a mean Precision at all the values of Recall different from zero.",
                    "sid": 107,
                    "ssid": 27,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "lsa experiment. ",
            "number": "4",
            "sents": [
                {
                    "text": "LSA is WSM based on the Singular Value De\u00ad composition (SVD) factorization (Deerwester et a!., 1990) applied to the co-occurrence matrix.",
                    "sid": 108,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In the matrix, the numbers of word occurrences in speci\u00ad fied contexts4 are stored.",
                    "sid": 109,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The row vectors of the ma\u00ad trix capture the word meanings.5 The idea of using SVD is to project vectors corresponding to the words into a lower-dimensional space and thus bring the vectors of words with similar meaning near to each other.",
                    "sid": 110,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We built LSA WSM and applied the component\u00ad based method to Disco-En-Gold.",
                    "sid": 111,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We used our own modification of the LSA algorithm originally implemented in the S-Space package (Jurgens and Stevens, 2010).",
                    "sid": 112,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The modification lies in treating ex\u00ad pressions and handling stopwords.",
                    "sid": 113,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Specifically, we added vectors for the examined expressions to WSM in such a way that the original vectors for words were preserved.",
                    "sid": 114,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This differentiates our approach e.g. from Baldwin et a!.",
                    "sid": 115,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2003) or Johannsen et a!.",
                    "sid": 116,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2011) who label the expressions ahead of time and build WSMs treating them as single words.",
                    "sid": 117,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Treat\u00ad ing the expressions as the single words affects the WSM vectors of their constituents.",
                    "sid": 118,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "As an example, consider the replacement of occurrences of \"short distance\" by e.g. the EXP#l23 label.",
                    "sid": 119,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This affects the WSM vectors of \"short\" and \"distance\" since the numbers of their occurrences and the numbers of contexts they occur in drops.",
                    "sid": 120,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Consequently, this also affects the methods for determining the compo\u00ad sitionality which are based upon using the vectors of 4The commonly used contexts for words are documents or the preceding and following words in a specified window.",
                    "sid": 121,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "5WSMs exploit Harris' distributional hypothesis (Hatris, 1954), which states that semantically similar words tend to ap\u00ad pear in similar contexts.",
                    "sid": 122,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "expressions' constituents.",
                    "sid": 123,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "As for treating stopwords, we mapped the trigram expressions containing the determiners \"the\", \"a\", or \"an\" as the middle word to the corresponding hi\u00ad gram expressions without the determiners.",
                    "sid": 124,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The intu\u00ad ition is to extract more precise co-occurrence vectors for the YO expressions often containing some inter\u00ad vening determiner.",
                    "sid": 125,
                    "ssid": 18,
                    "kind_of_tag": "s"
                },
                {
                    "text": "As an example, compare the oc\u00ad currences of \"reinvent wheel\" and \"reinvent (deter\u00ad miner) wheel\" in the ukWaC corpus which are 27 and 623, respectively, or the occurrences of \"cross bridge\" and \"cross (determiner) bridge\" being 50 and 1050, respectively.6 We built LSA WSM from the whole ukWaC POS-tagged corpus for all the word lemmas con\u00ad catenated with their POS tags excluding stopwords.",
                    "sid": 126,
                    "ssid": 19,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We treated the following strings as stopwords: the lemmas with frequency below 50 (omitting low\u00ad frequency words), the strings containing two adja\u00ad cent non-letter characters (omitting strings such as web addresses and sequences of e.g. star symbols), and lemmas with a different POS tag from noun, proper noun, adjective, verb, and adverb (omitting closed-class words).",
                    "sid": 127,
                    "ssid": 20,
                    "kind_of_tag": "s"
                },
                {
                    "text": "As contexts, the entire docu\u00ad ments were used.",
                    "sid": 128,
                    "ssid": 21,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The co-occurrence matrix for words was normal\u00ad ized by applying the log-entropy transformation and reduced to 300 dimensions.",
                    "sid": 129,
                    "ssid": 22,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Using these settings, Landauer and Dumais (1997) obtained the best re\u00ad sults.",
                    "sid": 130,
                    "ssid": 23,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Finally, the co-occurrence vectors of expres\u00ad sions were expressed in the lower-dimensional space of words in a manner analogous to how a user's query is being expressed in lower-dimensional space of documents in IR (Berry eta!., 1995).",
                    "sid": 131,
                    "ssid": 24,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The Disco\u00ad En-Gold expressions were sorted in ascending order by the average cosine similarity between the vec\u00ad tors corresponding to the expressions and the vectors corresponding to their components.",
                    "sid": 132,
                    "ssid": 25,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Evaluation We have not tried to find the optimal parameter settings for the LSA-based model yet.",
                    "sid": 133,
                    "ssid": 26,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Therefore, we present the results on the concate\u00ad nation of TrainD with Va!D giving us TrainVa!D and on TestD.",
                    "sid": 134,
                    "ssid": 27,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The expressions \"leading edge\" and \"broken link\" were removed from TestD because they occur in the ukWaC corpus assigned with the 6More precisely, the occurrences were calculated from the POS-tagged parallels of the expressions.",
                    "sid": 135,
                    "ssid": 28,
                    "kind_of_tag": "s"
                },
                {
                    "text": "required POS tags less than 50 times.",
                    "sid": 136,
                    "ssid": 29,
                    "kind_of_tag": "s"
                },
                {
                    "text": "APs with the Spearman and Kendall correlations between the compositionality values assigned by the LSA-based model and the Gold values are depicted in Table 3.",
                    "sid": 137,
                    "ssid": 30,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The Spearman correlations of the LSA model ap\u00ad plied to the whole TrainVa!D and TestD are highly significant with p-values < 0.001.",
                    "sid": 138,
                    "ssid": 31,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For the AP evalu\u00ad ation, the expressions with numerical values less or equal to 50 were classified as non-compositional7 , giving us the ratio of non-compositional expressions in TrainVa!D and TestD equal to 0.26 and 0.20, re\u00ad spectively.",
                    "sid": 139,
                    "ssid": 32,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The Precision/nBest and Recall/nBest graphs corresponding to the LSA-based model ap\u00ad plied to TestD are depicted in Figure 1.",
                    "sid": 140,
                    "ssid": 33,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The Preci\u00ad sion/Recall graphs corresponding to the LSA-based model applied to TrainD and TestD are depicted in Figure 2.",
                    "sid": 141,
                    "ssid": 34,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For comparison, the graphs in Figures 1 and 2 also show the curves corresponding to the evaluation of Pointwise Mutual Information (PM!).8 The co\u00ad occurrence statistics of the expressions in Disco-En\u00ad Gold was extracted from the window of size three, sliding through the whole lemmatized ukWaC cor\u00ad pus.",
                    "sid": 142,
                    "ssid": 35,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Discussion As suggested in Section 3, we com\u00ad pare the results of the methods using Spearman and Kendall correlations, AP, and Everts' curves.",
                    "sid": 143,
                    "ssid": 36,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We present the results of the LSA and PM!",
                    "sid": 144,
                    "ssid": 37,
                    "kind_of_tag": "s"
                },
                {
                    "text": "models alongside the results of the best performing models participating in the DISCO task.",
                    "sid": 145,
                    "ssid": 38,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Namely, Table 3 presents the correlation values of our models, the best performing WSM-based model (Reddy eta!., 2011b), the best performing model based upon as\u00ad sociation measures (Chakraborty eta!., 2011), and random baseline models.",
                    "sid": 146,
                    "ssid": 39,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The poor results achieved by employing PM!",
                    "sid": 147,
                    "ssid": 40,
                    "kind_of_tag": "s"
                },
                {
                    "text": "are similar to the results of random baselines and in ac\u00ad cordance with those of participants of the DISCO workshop (Chakraborty et a!., 2011).",
                    "sid": 148,
                    "ssid": 41,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We hypoth\u00ad esize that the PMI-based model incorrectly assigns low values of semantic compositionality (high val 7Choice of this value can affect the results.",
                    "sid": 149,
                    "ssid": 42,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The value of 50 was chosen since it is the middle value between the manually assigned scores ranging from 0 to 100.",
                    "sid": 150,
                    "ssid": 43,
                    "kind_of_tag": "s"
                },
                {
                    "text": "8PMI is an association measure used to determine the strength of association between two or more words based on their occurrences and co-occurrences in a corpus (Pecina, 2009) . 46 M od el Datasetp A U pAN p-VO p-SV T-AU TAN T-VO T-SV AP-All LS A TrainValD P M I TrainValD baseline TrainValD LSA TestD ReddyWSM TestD StatMix TestD P M I TestD ba sel ine TestD 0 . 4 7 0.54 0.36 0.57 0.32 0.38 0.24 0.44 0.61 0 . 0 20.25 0.29 0.14 0.010.18 0.20 0.10 0.28 0 . 0 0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.26 0 . 5 0 0.50 0.56 0.41 0.35 0.36 0.39 0.30 0.53 0 . 35 - - - 0.24 - - - 0 . 33 - - - 0.23 - - - 0.",
                    "sid": 151,
                    "ssid": 44,
                    "kind_of_tag": "s"
                },
                {
                    "text": "080.07 0.130.080.060.04 0.080.07 0.21 0 . 0 0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.20 Table 3: The values of AP, Spearman (p) and Kendall (r) correlations between the LSA-based and PMI-based model respectively and the Gold data with regards to the expression type.",
                    "sid": 152,
                    "ssid": 45,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Every zero value in the table corresponds to the theoretically achieved mean value of correlation calculated from the infinite number of correlation values between the ranking of scores assigned by the annotators and the rankings of scores being obtained by a random number genarator.",
                    "sid": 153,
                    "ssid": 46,
                    "kind_of_tag": "s"
                },
                {
                    "text": "ReddyWSM stands for the best performing WSM in the DISCO task (Reddy eta!., 2011b).",
                    "sid": 154,
                    "ssid": 47,
                    "kind_of_tag": "s"
                },
                {
                    "text": "StatMix stands for the best performing system based upon association measures (Chakraborty eta!., 2011).",
                    "sid": 155,
                    "ssid": 48,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Ouly pAll and rAil are available for the models explored by Reddy eta!.",
                    "sid": 156,
                    "ssid": 49,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2011b) and Chakraborty eta!.",
                    "sid": 157,
                    "ssid": 50,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2011).",
                    "sid": 158,
                    "ssid": 51,
                    "kind_of_tag": "s"
                },
                {
                    "text": "ues of PMI) to frequently occurring fixed expres\u00ad sions.",
                    "sid": 159,
                    "ssid": 52,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example, we observed that the calculated values of PMI for \"international airport\" and \"reli\u00ad gious belief\" were high.",
                    "sid": 160,
                    "ssid": 53,
                    "kind_of_tag": "s"
                },
                {
                    "text": "To the contrary, our results achieved by employ\u00ad ing the LSA model are statistically significant and better than those of all the participants of the DISCO workshop.",
                    "sid": 161,
                    "ssid": 54,
                    "kind_of_tag": "s"
                },
                {
                    "text": "However, the data set is probably not large enough to provide statistically reliable com\u00ad parison of the methods and it is not clear how re\u00ad liable the dataset itself is (the interannotator agree\u00ad ment was not analyzed) and therefore we can not make any hard conclusions.",
                    "sid": 162,
                    "ssid": 55,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "conclusion. ",
            "number": "5",
            "sents": [
                {
                    "text": "We analysed the previous works applying WSMs for determining the semantic compositionality of ex\u00ad pressions.",
                    "sid": 163,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We discussed and summarized the major\u00ad ity of techniques presented in the papers.",
                    "sid": 164,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Our anal\u00ad ysis reveals a large diversity of approaches which leads to incomparable results (Table 1).",
                    "sid": 165,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Since it has been shown that WSMs can serve as good predic\u00ad tors of semantic compositionality, we aim to create a comparative study of the approaches.",
                    "sid": 166,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Our analysis implies to evaluate the proposed ap\u00ad proaches using human annotated data and evalua\u00ad tion techniques based on ranking.",
                    "sid": 167,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Namely, we sug\u00ad gest using Spearman and Kendall correlations, Pre\u00ad cision!nBest, RecalllnBest, Precision/Recall curves, andAP.",
                    "sid": 168,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Using the suggested evaluation techniques, we present the results of our first experiments exploit\u00ad ing LSA (Figures 1, 2 and Table 3).",
                    "sid": 169,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The results of the LSA-based model, compared with random base\u00ad lines, PMI-based model, and all the WSM-based and statistical-based models proposed by the participants of the DISCO task, are very promising.",
                    "sid": 170,
                    "ssid": 8,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "acknowledgments",
            "number": "",
            "sents": [
                {
                    "text": "We thank to Vft Suchomel for providing the ukWaC corpus and the anonymous reviewers for their helpful comments and suggestions.",
                    "sid": 171,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The re\u00ad search is supported by Advanced Computing and Information Systems (grant no.",
                    "sid": 172,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "SGS2013-029) and by the Czech Science Foundation (grant no.",
                    "sid": 173,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Pl03112/G084).",
                    "sid": 174,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Also, the access to the CERITSC computing facilities provided under the programme Center CERIT Scientific Cloud, part of the Opera\u00ad tional Program Research and Development for Inno\u00ad vations, reg.",
                    "sid": 175,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "no. CZ.",
                    "sid": 176,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "1.05/3.2.00/08.0144 is highly appreciated.",
                    "sid": 177,
                    "ssid": 15,
                    "kind_of_tag": "s"
                }
            ]
        }
    ]
}