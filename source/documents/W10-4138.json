{
    "ID": "W10-4138",
    "sections": [
        {
            "text": "abstract",
            "number": 0,
            "sents": [
                {
                    "text": "This paper presents a Chinese word segmentation system submitted to the closed training evaluations of CIPSSIGHAN-2010 bakeoff.",
                    "sid": 1,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The system uses a conditional random field model with one simple feature called term contributed boundaries (TCB) in addition to the \u201cBI\u201d character-based tagging approach.",
                    "sid": 2,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "TCB can be extracted from unlabeled corpora automatically, and segmentation variations of different domains are expected to be reflected implicitly.",
                    "sid": 3,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The experiment result shows that TCB does improve \u201cBI\u201d tagging domain- independently about 1% of the F1 measure score.",
                    "sid": 4,
                    "ssid": 4,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "introduction",
            "number": "1",
            "sents": [
                {
                    "text": "The CIPSSIGHAN-2010 bakeoff task of Chinese word segmentation is focused on cross- domain texts.",
                    "sid": 5,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The design of data set is challenging particularly.",
                    "sid": 6,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The domain-specific training corpora remain unlabeled, and two of the test corpora keep domains unknown before releasing, therefore it is not easy to apply ordinary machine learning approaches, especially for the closed training evaluations.",
                    "sid": 7,
                    "ssid": 7,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "methodology. ",
            "number": "2",
            "sents": [
                {
                    "text": "2.1 The \u201cBI\u201d Character-Based Tagging of.",
                    "sid": 8,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Conditional Random Field as Baseline The character-based \u201cOBI\u201d tagging of Conditional Random Field (Lafferty et al., 2001) has been widely used in Chinese word segmentation recently (Xue and Shen, 2003; Peng and McCallum, 2004; Tseng et al., 2005).",
                    "sid": 9,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Under the scheme, each character of a word is labeled as \u2018B\u2019 if it is the first character of a multiple-character word, or \u2018I\u2019 otherwise.",
                    "sid": 10,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "If the character is a single-character word itself, \u201cO\u201d will be its label.",
                    "sid": 11,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "As Table 1 shows, the lost of performance is about 1% by replacing \u201cO\u201d with \u201cB\u201d for character-based CRF tagging on the dataset of CIPSSIGHAN-2010 bakeoff task of Chinese word segmentation, thus we choose \u201cBI\u201d as our baseline for simplicity, with this 1% lost bearing in mind.",
                    "sid": 12,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In tables of this paper, SC stands for Simplified Chinese and TC represents for Traditional Chinese.",
                    "sid": 13,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Test corpora of SC and TC are divided into four domains, where suffix A, B, C and D attached, for texts of literature, computer, medicine and finance, respectively.",
                    "sid": 14,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Table 1.",
                    "sid": 15,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "OBI vs. BI; where the lost of F > 1%, such as SC-B, is caused by incorrect English segments that will be discussed in the section 4.",
                    "sid": 16,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "2.2 Term Contributed Boundary.",
                    "sid": 17,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The word boundary and the word frequency are the standard notions of frequency in corpus- based natural language processing, but they lack the correct information about the actual boundary and frequency of a phrase\u2019s occurrence.",
                    "sid": 18,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The distortion of phrase boundaries and frequencies was first observed in the Vodis Corpus when the bigram \u201cRAIL ENQUIRIES\u201d and tri- gram \u201cBRITISH RAIL ENQUIRIES\u201d were examined and reported by O'Boyle (1993).",
                    "sid": 19,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Both of them occur 73 times, which is a large number for such a small corpus.",
                    "sid": 20,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "\u201cENQUIRIES\u201d follows \u201cRAIL\u201d with a very high probability when it is preceded by \u201cBRITISH.\u201d However, when \u201cRAIL\u201d is preceded by words other than \u201cBRITISH,\u201d \u201cENQUIRIES\u201d does not occur, but words like \u201cTICKET\u201d or \u201cJOURNEY\u201d may. Thus, the bigram \u201cRAIL ENQUIRIES\u201d gives a misleading probability that \u201cRAIL\u201d is followed by \u201cENQUIRIES\u201d irrespective of what precedes it.",
                    "sid": 21,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This problem happens not only with word-token corpora but also with corpora in which all the compounds are tagged as units since overlapping N- grams still appear, therefore corresponding solutions such as those of Zhang et al.",
                    "sid": 22,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2006) were proposed.",
                    "sid": 23,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We uses suffix array algorithm to calculate exact boundaries of phrase and their frequencies (Sung et al., 2008), called term contributed boundaries (TCB) and term contributed fre quencies (TCF), respectively, to analogize similarities and differences with the term frequencies (TF).",
                    "sid": 24,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example, in Vodis Corpus, the original TF of the term \u201cRAIL ENQUIRIES\u201d is 73.",
                    "sid": 25,
                    "ssid": 18,
                    "kind_of_tag": "s"
                },
                {
                    "text": "However, the actual TCF of \u201cRAIL ENQUI RIES\u201d is 0, since all of the frequency values are contributed by the term \u201cBRITISH RAIL EN QUIRIES\u201d.",
                    "sid": 26,
                    "ssid": 19,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In this case, we can see that \u2018BRIT ISH RAIL ENQUIRIES\u2019 is really a more frequent term in the corpus, where \u201cRAIL EN QUIRIES\u201d is not.",
                    "sid": 27,
                    "ssid": 20,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Hence the TCB of \u201cBRITISH RAIL ENQUIRIES\u201d is ready for CRF tagging as \u201cBRITISH/TB RAIL/TB ENQUIRIES/TI,\u201d for example.",
                    "sid": 28,
                    "ssid": 21,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "experiments. ",
            "number": "3",
            "sents": [
                {
                    "text": "Besides submitted results, there are several different experiments that we have done.",
                    "sid": 29,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The configuration is about the trade-off between data sparseness and domain fitness.",
                    "sid": 30,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For the sake of OOV issue, TCBs from all the training and test corpora are included in the configuration of submitted results.",
                    "sid": 31,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For potentially better consistency to different types of text, TCBs from the training corpora and/or test corpora are grouped by corresponding domains of test corpora.",
                    "sid": 32,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Table 2 and Table 3 provide the details, where the baseline is the character-based \u201cBI\u201d tagging, and others are \u201cBI\u201d with additional different TCB configurations: TCBall stands for the submitted results; TCBa, TCBb, TCBta, TCBtb, TCBtc, TCBtd represents TCB extracted from the training corpus A, B, and the test corpus A, B, C, D, respectively.",
                    "sid": 33,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Table 2 indicates that F1 measure scores can be improved by TCB about 1%, domain-independently.",
                    "sid": 34,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Table 3 gives a hint of the major contribution of performance is from TCB of each test corpus.",
                    "sid": 35,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "R P F OOV SC-A BI TCBall 0.896 0.907 0.901 0.508 0.917 0.921 0.919 0.699 SC-B BI TCBall 0.850 0.763 0.805 0.327 0.876 0.799 0.836 0.456 SC-C BI TCBall 0.888 0.886 0.887 0.551 0.900 0.896 0.898 0.699 SC-D TC-A BI TCBall 0.888 0.891 0.890 0.419 0.910 0.906 0.908 0.562 BI TCBall 0.856 0.884 0.870 0.674 0.871 0.891 0.881 0.670 TC-B BI TCBall 0.894 0.920 0.907 0.551 0.913 0.917 0.915 0.663 TC-C BI TCBall 0.891 0.914 0.902 0.674 0.900 0.915 0.908 0.668 TC-D BI TCBall 0.908 0.922 0.915 0.722 0.929 0.922 0.925 0.732 Table 2.",
                    "sid": 36,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Baseline vs. Submitted Results Table 3a.",
                    "sid": 37,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Simplified Chinese Domain-specific TCB vs. TCBall Table 4.",
                    "sid": 38,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "F1 measure scores before and after English Problem Fixed Table 3b.",
                    "sid": 39,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Traditional Chinese Domain-specific TCB vs. TCBall",
                    "sid": 40,
                    "ssid": 12,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "error analysis. ",
            "number": "4",
            "sents": [
                {
                    "text": "The most significant type of error in our results is unintentionally segmented English words.",
                    "sid": 41,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Rather than developing another set of tag for English alphabets, we applies post-processing to fix this problem under the restriction of closed training by using only alphanumeric character information.",
                    "sid": 42,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Table 4 compares F1 measure score of the Simplified Chinese experiment results before and after the post-processing.",
                    "sid": 43,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The major difference between gold standards of the Simplified Chinese corpora and the Traditional Chinese corpora is about non-Chinese characters.",
                    "sid": 44,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "All of the alphanumeric and the punctuation sequences are separated from Chinese sequences in the Simplified Chinese corpora, but can be part of the Chinese word segments in the Traditional Chinese corpora.",
                    "sid": 45,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example, a phrase \u201c\u670d\u7528 / simvastatin / \uff08 / statins \u985e / \u7684 / \u4e00 / \u7a2e / \uff09\u201d (\u2018/\u2019 represents the word boundary) from the domain C of the test data cannot be either recognized by \u201cBI\u201d and/or TCB tagging approaches, or post-processed.",
                    "sid": 46,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This is the reason why Table 4 does not come along with Traditional Chinese experiment results.",
                    "sid": 47,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Some errors are due to inconsistencies in the gold standard of non-Chinese character, For ex ample, in the Traditional Chinese corpora, some percentage digits are separated from their per centage signs, meanwhile those percentage signs are connected to parentheses right next to them.",
                    "sid": 48,
                    "ssid": 8,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "conclusion. ",
            "number": "5",
            "sents": [
                {
                    "text": "This paper introduces a simple CRF feature called term contributed boundaries (TCB) for Chinese word segmentation.",
                    "sid": 49,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The experiment result shows that it can improve the basic \u201cBI\u201d tagging scheme about 1% of the F1 measure score, domain-independently.",
                    "sid": 50,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Further tagging scheme for non-Chinese characters are desired for recognizing some sophisticated gold standard of Chinese word segmentation that concatenates alphanumeric characters to Chinese characters.",
                    "sid": 51,
                    "ssid": 3,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "acknowledgement",
            "number": "",
            "sents": [
                {
                    "text": "The CRF model used in this paper is developed based on CRF++, http://crfpp.sourceforge.net/ Term Contributed Boundaries used in this paper are extracted by YASA, http://yasa.newzilla.org/",
                    "sid": 52,
                    "ssid": 4,
                    "kind_of_tag": "s"
                }
            ]
        }
    ]
}