{
    "ID": "W02-1004",
    "sections": [
        {
            "text": "abstract",
            "number": 0,
            "sents": [
                {
                    "text": "This paper demonstrates the substantial empirical success of classi.er combination for the word sense disambiguation task.",
                    "sid": 1,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "It investigates more than 10 classi.er combination methods, including second order classi.er stacking, over 6 major structurally different base classi.ers (enhanced Na\u00efve Bayes, cosine, Bayes Ratio, decision lists, transformation-based learning and maximum variance boosted mix\u00adture models).",
                    "sid": 2,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The paper also includes in-depth per\u00adformance analysis sensitive to properties of the fea\u00adture space and component classi.ers.",
                    "sid": 3,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "When eval\u00aduated on the standard SENSEVAL1 and 2 data sets on 4 languages (English, Spanish, Basque, and Swedish), classi.er combination performance ex\u00adceeds the best published results on these data sets.",
                    "sid": 4,
                    "ssid": 4,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "introduction",
            "number": "1",
            "sents": [
                {
                    "text": "Classi.er combination has been extensively stud\u00adied in the last decade, and has been shown to be successful in improving the performance of diverse NLP applications, including POS tagging (Brill and Wu, 1998; van Halteren et al., 2001), base noun phrase chunking (Sang et al., 2000), parsing (Hen\u00adderson and Brill, 1999) and word sense disambigua\u00adtion (Kilgarriff and Rosenzweig, 2000; Stevenson and Wilks, 2001).",
                    "sid": 5,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "There are several reasons why classi.er combination is useful.",
                    "sid": 6,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "First, by consulting the output of multiple classi.ers, the system will im\u00adprove its robustness.",
                    "sid": 7,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Second, it is possible that the problem can be decomposed into orthogonal feature spaces (e.g. linguistic constraints and word occur\u00adrence statistics) and it is often better to train dif\u00adferent classi.ers in each of the feature spaces and then combine their output, instead of designing a complex system that handles the multimodal infor\u00admation.",
                    "sid": 8,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Third, it has been shown by Perrone and Cooper (1993) that it is possible to reduce the clas\u00adsi.cation error by a factor of .(Nis the number of classi.ers) by combination, if the classi.ers\u2019 errors are uncorrelated and unbiased.",
                    "sid": 9,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The target task studied here is word sense disam\u00adbiguation in the SENSEVAL evaluation framework (Kilgarriff and Palmer, 2000; Edmonds and Cotton, 2001) with comparative tests in English, Spanish, Swedish and Basque lexical-sample sense tagging over a combined sample of 37730 instances of 234 polysemous words.",
                    "sid": 10,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This paper offers a detailed comparative evalu\u00adation and description of the problem of classi.er combination over a structurally and procedurally diverse set of six both well established and orig\u00adinal classi.ers: extended Na\u00efve Bayes, BayesRa\u00adtio, Cosine, non-hierarchical Decision Lists, Trans\u00adformation Based Learning (TBL), and the MMVC classi.ers, brie.y described in Section 4.",
                    "sid": 11,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "These systems have different space-searching strategies, ranging from discriminant functions (BayesRatio) to data likelihood (Bayes, Cosine) to decision rules (TBL, Decision Lists), and therefore are amenable to combination.",
                    "sid": 12,
                    "ssid": 12,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "previous work. ",
            "number": "2",
            "sents": [
                {
                    "text": "Related work in classi.er combination is discussed throughout this article.",
                    "sid": 13,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For the speci.c task of word sense disambiguation, the .rst empirical study was presented in Kilgarriff and Rosenzweig (2000), where the authors combined the output of the par\u00adticipating SENSEVAL1 systems via simple (non\u00adweighted) voting, using either Absolute Majority, Relative Majority, or Unanimous voting.",
                    "sid": 14,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Steven\u00adson and Wilks (2001) presented a classi.er com\u00adbination framework where 3 disambiguation meth\u00adods (simulated annealing, subject codes and selec\u00adtional restrictions) were combined using the TiMBL memory-based approach (Daelemans et al., 1999).",
                    "sid": 15,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Pedersen (2000) presents experiments with an en\u00adsemble of Na\u00efve Bayes classi.ers, which outper\u00adform all previous published results on two ambigu\u00adous words (line and interest).",
                    "sid": 16,
                    "ssid": 4,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "the wsd feature space. ",
            "number": "3",
            "sents": [
                {
                    "text": "The feature space is a critical factor in classi.er de\u00adsign, given the need to fuel the diverse strengths of the component classi.ers.",
                    "sid": 17,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Thus its quality is of\u00adten highly correlated with performance.",
                    "sid": 18,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For this An ancient stone church stands amid the .elds, the sound of bells ...",
                    "sid": 19,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Feat.",
                    "sid": 20,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Type Word POS Lemma Context ancient JJ ancient/J Context stone NN stone/N Context church NNP church/N Context stands VBZ stand/V Context amid IN amid/I Context .elds NN .eld/N Context ...",
                    "sid": 21,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Syntactic (predicate-argument) features SubjectTo stands_Sbj VBZ stand_Sbj/V Modi.er stone_mod JJ ancient_mod/J Ngram collocational features -1 bigram stone_L JJ ancient_L/J +1 bigram stands_R VBZ stand_R/V \u00b11 trigram stone \u2022stands JJ\u2022VBZ stone/J\u2022stands/V ...",
                    "sid": 22,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Figure 1: Example sentence and extracted features from the SENSEVAL2 word church reason, we used a rich feature space based on raw words, lemmas and part-of-speech (POS) tags in a variety of positional and syntactical relationships to the target word.",
                    "sid": 23,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "These positions include traditional unordered bag-of-word context, local bigram and trigram collocations and several syntactic relation\u00adships based on predicate-argument structure.",
                    "sid": 24,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Their use is illustrated on a sample English sentence for the target word church in Figure 1.",
                    "sid": 25,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "While an exten\u00adsive evaluation of feature type to WSD performance is beyond the scope of this paper, Section 6 sketches an analysis of the individual feature contribution to each of the classi.er types.",
                    "sid": 26,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "3.1 Part-of-Speech Tagging and Lemmatization.",
                    "sid": 27,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Part-of-speech tagger availability varied across the languages that are studied here.",
                    "sid": 28,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "An electronically available transformation-based POS tagger (Ngai and Florian, 2001) was trained on standard labeled data for English (Penn Treebank), Swedish (SUC\u00ad1 corpus), and Basque.",
                    "sid": 29,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For Spanish, an minimally supervised tagger (Cucerzan and Yarowsky, 2000) was used.",
                    "sid": 30,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Lemmatization was performed using an existing trie-based supervised models for English, and a combination of supervised and unsupervised methods (Yarowsky and Wicentowski, 2000) for all the other languages.",
                    "sid": 31,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "3.2 Syntactic Features.",
                    "sid": 32,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The syntactic features extracted for a target word depend on the word\u2019s part of speech: \u2022 verbs: the head noun of the verb\u2019s object, par\u00adticle/preposition and prepositional object; \u2022 nouns: the headword of any verb-object, subject-verb or noun-noun relationships iden\u00adti.ed for the target word; \u2022adjectives: the head noun modi.ed by the ad\u00adjective.",
                    "sid": 33,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The extraction process was performed using heuris\u00adtic patterns and regular expressions over the parts-of-speech surrounding the target word1.",
                    "sid": 34,
                    "ssid": 18,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "classi.er models for word sense disambiguation. ",
            "number": "4",
            "sents": [
                {
                    "text": "This section brie.y introduces the 6 classi.er mod\u00adels used in this study.",
                    "sid": 35,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Among these models, the Na\u00efve Bayes variants (NB henceforth) (Pedersen, 1998; Manning and Sch\u00fctze, 1999) and Cosine dif\u00adfer slightly from off-the-shelf versions, and only the differences will be described.",
                    "sid": 36,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "4.1 Vector-based Models: Enhanced Na\u00efve Bayes and Cosine Models.",
                    "sid": 37,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Many of the systems used in this research share a common vector representation, which captures traditional bag-of-words, extended ngram and predicate-argument features in a single data struc\u00adture.",
                    "sid": 38,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In these models, a vector is created for each (dj)'1' document in the collection: d=j'.dj= jWj, where jis the number of times the feature fjappears in document d, Nis the number of words in dand Wjis a weight associated with the feature 2 fj.",
                    "sid": 39,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Confusion between the same word participat\u00ading in multiple feature roles is avoided by append\u00ading the feature values with their positional type (e.g. stands_Sbj, ancient_L are distinct from stands and ancient in unmarked bag-of-words context).",
                    "sid": 40,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The notable difference between the extended models and others described in the literature, aside from the use of more sophisticated features than the traditional bag-of-words, is the variable weight\u00ading of feature types noted above.",
                    "sid": 41,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "These differences yield a boost in the NB performance (relative to ba\u00adsic Na\u00efve Bayes) of between 3.5% (Basque) and 10% (Spanish), with an average improvement of 7.25% over the four languages.",
                    "sid": 42,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "4.2 The BayesRatio Model.",
                    "sid": 43,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The BayesRatio model (BR henceforth) is a vector-based model using the likelihood ratio framework described in Gale et al.",
                    "sid": 44,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(1992): 1The feature extraction on the in English data was per\u00adformed by .rst identifying text chunks, and then using heuris\u00adtics on the chunks to extract the syntactic information.",
                    "sid": 45,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "2The weight Wjdepends on the type of the feature kj: for the bag-of-word features, this weight is inversely proportional to the distance between the target word and the feature, while for predicate-argument and extended ngram features it is a em\u00adpirically estimated weight (on a per language basis).",
                    "sid": 46,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "P(sld) P(s)P(kls) sA=argmax=argmax P(\u2022sld) P(\u2022s)P(kl\u2022s) /Ed where s is the selected sense, ddenotes documents and fdenotes features.",
                    "sid": 47,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "By utilizing the binary ra\u00adtio for k-way modeling of feature probabilities, this approach performs well on tasks where the data is sparse.",
                    "sid": 48,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "4.3 The MMVC Model.",
                    "sid": 49,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The Mixture Maximum Variance Correction classi\u00ad.er (MMVC henceforth) (Cucerzan and Yarowsky, 2002) is a two step classi.er.",
                    "sid": 50,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "First, the sense proba\u00adbility is computed as a linear mixture P(sld)=P(slffd)P(fld).P(slf)P(fld) = /Ed/Ed where the probability P(slw)is estimated from data and P(wld)is computed as a weighted normal\u00adized similarity between the word wand the target word x(also taking into account the distance in the document between wand x).",
                    "sid": 51,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In a second pass, the sense whose variance exceeds a theoretically moti\u00advated threshold is selected as the .nal sense label (for details, see Cucerzan and Yarowsky (2002)).",
                    "sid": 52,
                    "ssid": 18,
                    "kind_of_tag": "s"
                },
                {
                    "text": "4.4 The Discriminative Models.",
                    "sid": 53,
                    "ssid": 19,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Two discriminative models are used in the exper\u00adiments presented in Section 5 -a transformation-based learning system (TBL henceforth) (Brill, 1995; Ngai and Florian, 2001) and a non-hierarchical decision lists system (DL henceforth) (Yarowsky, 1996).",
                    "sid": 54,
                    "ssid": 20,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For prediction, these systems utilize local n-grams around the target word (up to 3 words/lemma/POS to the left/right), bag-of-words and lemma/collocation (\u00b120 words around the tar\u00adget word, grouped by different window sizes) and the syntactic features listed in Section 3.2.",
                    "sid": 55,
                    "ssid": 21,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The TBL system was modi.ed to include redun\u00addant rules that do not improve absolute accuracy on training data in the traditional greedy training al\u00adgorithm, but are nonetheless positively correlated with a particular sense.",
                    "sid": 56,
                    "ssid": 22,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The bene.t of this approach is that predictive but redundant features in training context may appear by themselves in new test con\u00adtexts, improving coverage and increasing TBL base model performance by 12%.",
                    "sid": 57,
                    "ssid": 23,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "models for classi.er combination. ",
            "number": "5",
            "sents": [
                {
                    "text": "One necessary property for success in combining classi.ers is that the errors produced by the com\u00adponent classi.ers should not be positively corre\u00adlated.",
                    "sid": 58,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "On one extreme, if the classi.er outputs are DecisionLists TBL BayesRatio Bayes Cosine MMVC 0.0 0.2 0.4 0.6 0.8 1.0 Figure 2: Empirically-derived classi.er similarity strongly correlated, they will have a very high inter-agreement rate and there is little to be gained from the joint output.",
                    "sid": 59,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "On the other extreme, Perrone and Cooper (1993) show that, if the errors made by the classi.ers are uncorrelated and unbiased, then by considering a classi.er that selects the class that maximizes the posterior class probability average N 1 c=argmaxP( )=argmaxPk( )(1) N k..",
                    "sid": 60,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "the error is reduced by a factor of . This case is mostly of theoretical interest, since in practice all the classi.ers will tend to make errors on the \u201charder\u201d samples.",
                    "sid": 61,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Figure 3(a) shows the classi.er inter-agreement among the six classi.ers presented in Section 4, on the English data.",
                    "sid": 62,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Only two of them, BayesRatio and cosine, have an agreement rate of over 80%3, while the agreement rate can be as low as 63% (BayesRa\u00adtio and TBL).",
                    "sid": 63,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The average agreement is 71.7%.",
                    "sid": 64,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The fact that the classi.ers\u2019 output are not strongly cor\u00adrelated suggests that the differences in performance among them can be systematically exploited to im\u00adprove the overall classi.cation.",
                    "sid": 65,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "All individual clas\u00adsi.ers have high stand-alone performance; each is individually competitive with the best single SEN\u00adSEVAL2 systems and are fortuitously diverse in rel\u00adative performance, as shown in Table 3(b).",
                    "sid": 66,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "A den\u00addogram of the similarity between the classi.ers is shown in Figure 2, derived using maximum linkage hierarchical agglomerative clustering.",
                    "sid": 67,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "5.1 Major Types of Classi.er Combination.",
                    "sid": 68,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "There are three major types of classi.er combina\u00adtion (Xu et al., 1992).",
                    "sid": 69,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The most general type is the case where the classi.ers output a posterior class probability distribution for each sample (which can be interpolated).",
                    "sid": 70,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In the second case, systems only output a set of labels, together with a ordering of preference (likelihood).",
                    "sid": 71,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In the third and most re\u00adstrictive case, the classi.cations consist of just a sin\u00adgle label, without rank or probability.",
                    "sid": 72,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Combining classi.ers in each one of these cases has different properties; the remainder of this section examines models appropriate to each situation.",
                    "sid": 73,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "3The performance is measured using 5-fold cross validation on training data.",
                    "sid": 74,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Bayes Cosine System SENSEVAL1 SENSEVAL2 EN EN ES EU SV Baseline 63.2 48.3 45.9 62.7 46.2 NB 80.4 65.7 67.9 71.2 66.7 BR 79.8 65.3 69.0 69.6 68.0 Cosine 74.0 62.2 65.9 66.0 66.4 DL 79.9 63.2 65.1 70.7 61.5 TBL 80.7 64.4 64.7 69.4 62.7 MMVC 81.1 66.7 66.7 69.7 61.9 Bayes Cosine BayesRatio DL TBL MMVC (b) Individual classi.er performance; best performers are (a) Classi.er inter-agreement on SENSEVAL2 shown in bold English data Figure 3: Individual Classi.er Properties (cross-validation on SENSEVAL training data) 5.2 Combining the Posterior Sense Probability Distributions.",
                    "sid": 75,
                    "ssid": 18,
                    "kind_of_tag": "s"
                },
                {
                    "text": "One of the simplest ways to combine the poste\u00adrior probability distributions is via direct averaging (Equation (1)).",
                    "sid": 76,
                    "ssid": 19,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Surprisingly, this method obtains reasonably good results, despite its simplicity and the fact that is not theoretically motivated under a Bayes framework.",
                    "sid": 77,
                    "ssid": 20,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Its success is highly dependent on the condition that the classi.ers\u2019 errors are un\u00adcorrelated (Tumer and Gosh, 1995).",
                    "sid": 78,
                    "ssid": 21,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The averaging method is a particular case of weighted mixture:4 N P(slxfd)=P(klxfd)\u00b7Pk(slxfd)= k..",
                    "sid": 79,
                    "ssid": 22,
                    "kind_of_tag": "s"
                },
                {
                    "text": "N ,k(xfd)\u00b7Pk(slxfd)(2) k..",
                    "sid": 80,
                    "ssid": 23,
                    "kind_of_tag": "s"
                },
                {
                    "text": "where Ak(dd)is the weight assigned to the clas\u00adsi.er kin the mixture and Pk(slxd)is the poste\u00adrior probability distribution output by classi.er k; for Ak(xd)=we obtain Equation (1).",
                    "sid": 81,
                    "ssid": 24,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The mixture interpolation coef.cients can be computed at different levels of granularity.",
                    "sid": 82,
                    "ssid": 25,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For instance, one can make the assumption that P(klxd)=P(klx)and then the coef.cients will be computed at word level; if P(klxd)=P(k) then the coef.cients will be estimated on the entire data.",
                    "sid": 83,
                    "ssid": 26,
                    "kind_of_tag": "s"
                },
                {
                    "text": "One way to estimate these parameters is by linear regression (Fuhr, 1989): estimate the coef.cients that minimize the mean square error (MSE) . N min e(xfd)-,k(xfd)\u00b7P(\u00b7lxfd) xdk..",
                    "sid": 84,
                    "ssid": 27,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(3) where C(xd)is the target vector of the cor\u00adrect classi.cation of word xin document d: 4Note that we are computing a probability conditioned both on the target word xand the document d, because the docu\u00adments are associated with a particular target word x; this for\u00admalization works mainly for the lexical choice task.",
                    "sid": 85,
                    "ssid": 28,
                    "kind_of_tag": "s"
                },
                {
                    "text": "C(xd)(s)=\u00c6(ssx,d)dard sense of xin dand \u00c6 { \u00c6(x y)= , sx,dbeing the goldstan\u00adthe Kronecker function: .if x =y if x=y As shown in Fuhr (1989), Perrone and Cooper (1993), the solution to the optimization problem (3) can be obtained by solving a linear set of equations.",
                    "sid": 86,
                    "ssid": 29,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The resulting classi.er will have a lower square er\u00adror than the average classi.er (since the average classi.er is a particular case of weighted mixture).",
                    "sid": 87,
                    "ssid": 30,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Another common method to compute the Apa\u00adrameters is by using the Expectation-Maximization (EM) algorithm (Dempster et al., 1977).",
                    "sid": 88,
                    "ssid": 31,
                    "kind_of_tag": "s"
                },
                {
                    "text": "One can estimate the coef.cients such as to max\u00ad imize the log-likelihood of the data, L = xd.xlogP(sx,dlxfd).",
                    "sid": 89,
                    "ssid": 32,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In this particular opti\u00admization problem, the search space is convex, and therefore a solution exists and is unique, and it can be obtained by the usual EM algorithm (see Berger (1996) for a detailed description).",
                    "sid": 90,
                    "ssid": 33,
                    "kind_of_tag": "s"
                },
                {
                    "text": "An alternative method for estimating the parame\u00adters Akis to approximate them with the performance of the kth classi.er (a performance-based combiner) (van Halteren et al., 1998; Sang et al., 2000) Ak(xd)=P(Ck_is_correctlxd)(4) therefore giving more weight to classi.ers that have a smaller classi.cation error (the method will be re\u00adferred to as PB).",
                    "sid": 91,
                    "ssid": 34,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The probabilities in Equation (4) are estimated directly from data, using the maxi\u00admum likelihood principle.",
                    "sid": 92,
                    "ssid": 35,
                    "kind_of_tag": "s"
                },
                {
                    "text": "5.3 Combination based on Order Statistics.",
                    "sid": 93,
                    "ssid": 36,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In cases where there are reasons to believe that the posterior probability distribution output by a clas\u00adsi.er is poorly estimated5, but that the relative or\u00addering of senses matches the truth, a combination 5For instance, in sparse classi.cation spaces, the Na\u00efve Bayes classi.er will assign a probability very close to 1 to the most likely sense, and close to 0 for the other ones.",
                    "sid": 94,
                    "ssid": 37,
                    "kind_of_tag": "s"
                },
                {
                    "text": "strategy based on the relative ranking of sense pos\u00adterior probabilities is more appropriate.",
                    "sid": 95,
                    "ssid": 38,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The sense posterior probability can be computed as Ak(xk)rrnkk(slxd) P(slxd)= k Ak(xk)rrnkk(s'lx d)(5) s'k where the rank of a sense sis inversely proportional to the number of senses that are (strictly) more prob\u00adable than sense s: ( {(r} r '' rankk(slx,d)= slPkslx,dPk(slx,d) + . This method will tend to prefer senses that appear closer to the top of the likelihood list for most of the classi.ers, therefore being more robust both in cases where one classi.er makes a large error and in cases where some classi.ers consistently overestimate the posterior sense probability of the most likely sense.",
                    "sid": 96,
                    "ssid": 39,
                    "kind_of_tag": "s"
                },
                {
                    "text": "5.4 The Classi.er Republic: Voting.",
                    "sid": 97,
                    "ssid": 40,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Some classi.cation methods frequently used in NLP directly minimize the classi.cation error and do not usually provide a probability distribution over classes/senses (e.g. TBL and decision lists).",
                    "sid": 98,
                    "ssid": 41,
                    "kind_of_tag": "s"
                },
                {
                    "text": "There are also situations where the user does not have access to the probability distribution, such as when the available classi.er is a black-box that only outputs the best classi.cation.",
                    "sid": 99,
                    "ssid": 42,
                    "kind_of_tag": "s"
                },
                {
                    "text": "A very common technique for combination in such a case is by vot\u00ading (Brill and Wu, 1998; van Halteren et al., 1998; Sang et al., 2000).",
                    "sid": 100,
                    "ssid": 43,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In the simplest model, each clas\u00adsi.er votes for its classi.cation and the sense that receives the most number of votes wins.",
                    "sid": 101,
                    "ssid": 44,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The behav\u00adior is identical to selecting the sense with the highest posterior probability, computed as Ak(xd)\u00b7\u00c6(ss k(xd)) P(slxd)= k (xd)\u00b7\u00c6(t(x Aks kd))(6) yk where \u00c6is the Kronecker function and s k(xd)is the classi.cation of the kth classi.er.",
                    "sid": 102,
                    "ssid": 45,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The Akco\u00adef.cients can be either equal (in a perfect classi.er democracy), or they can be estimated with any of the techniques presented in Section 5.2.",
                    "sid": 103,
                    "ssid": 46,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Section 6 presents an empirical evaluation of these tech\u00adniques.",
                    "sid": 104,
                    "ssid": 47,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Van Halteren et al.",
                    "sid": 105,
                    "ssid": 48,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(1998) introduce a modi.ed version of voting called TagPair.",
                    "sid": 106,
                    "ssid": 49,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Under this model, the conditional probability that the word sense is s given that classi.er ioutputs sand classi.er jout\u00adputs s2, P(sls i(xd)=ss j(xd)=s2), is com\u00adputed on development data, and the posterior prob\u00adability is estimated as N P(slx,d)e\u00c6(s,sAk(x,d))+\u00c6(s,sA j(x,d)) (7) k..",
                    "sid": 107,
                    "ssid": 50,
                    "kind_of_tag": "s"
                },
                {
                    "text": "j where sc;,j(xfd)=argmaxtP(tlsc;(xfd)fscj(xfd)).",
                    "sid": 108,
                    "ssid": 51,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Each classi.er votes for its classi.cation and every pair of classi.ers votes for the sense that is most likely given the joint classi.cation.",
                    "sid": 109,
                    "ssid": 52,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In the experi\u00adments presented in van Halteren et al.",
                    "sid": 110,
                    "ssid": 53,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(1998), this method was the best performer among the presented methods.",
                    "sid": 111,
                    "ssid": 54,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Van Halteren et al.",
                    "sid": 112,
                    "ssid": 55,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2001) extend this method to arbitrarily long conditioning sequences, obtaining the best published POS tagging results on four corpora.",
                    "sid": 113,
                    "ssid": 56,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "empirical evaluation. ",
            "number": "6",
            "sents": [
                {
                    "text": "To empirically test the combination methods pre\u00adsented in the previous section, we ran experiments on the SENSEVAL1 English data and data from four SENSEVAL2 lexical sample tasks: English(EN), Spanish(ES), Basque(EU) and Swedish(SV).",
                    "sid": 114,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Un\u00adless explicitly stated otherwise, all the results in the following section were obtained by performing 5\u00adfold cross-validation6.",
                    "sid": 115,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "To avoid the potential for over-optimization, a single .nal evaluation system was run once on the otherwise untouched test data, as presented in Section 6.3.",
                    "sid": 116,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The data consists of contexts associated with a speci.c word to be sense tagged (target word); the context size varies from 1 sentence (Spanish) to 5 sentences (English, Swedish).",
                    "sid": 117,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Table 1 presents some statistics collected on the training data for the .ve data sets.",
                    "sid": 118,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Some of the tasks are quite challeng\u00ading (e.g. SENSEVAL2 English task) \u2013 as illustrated by the mean participating systems\u2019 accuracies in Ta\u00adble 5.",
                    "sid": 119,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Outlining the claim that feature selection is im\u00adportant for WSD, Table 2 presents the marginal loss in performance of either only using one of the po\u00adsitional feature classes or excluding one of the po\u00adsitional feature classes relative to the algorithm\u2019s full performance using all available feature classes.",
                    "sid": 120,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "It is interesting to note that the feature-attractive methods (NB,BR,Cosine) depend heavily on the BagOfWords features, while discriminative methods are most dependent on LocalContext features.",
                    "sid": 121,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For an extensive evaluation of factors in.uencing the WSD performance (including representational fea\u00adtures), we refer the readers to Yarowsky and Florian (2002).",
                    "sid": 122,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "6.1 Combination Performance.",
                    "sid": 123,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Table 3 shows the .negrained sense accuracy (per\u00adcent of exact correct senses) results of running the 6When parameters needed to be estimated, a 31-1 split was used: the systems were trained on three parts, parameters esti\u00admated on the fourth (in a round-robin fashion) and performance tested on the .fth; special care was taken such that no \u201ctest\u201d data was used in training classi.ers or parameter estimation.",
                    "sid": 124,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "SE1 SENSEVAL2 EN EN ES EU SV #words 42 73 39 40 40 #samples 12479 8611 4480 3444 8716 avg #senses/word 11.3 10.7 4.9 4.8 11.1 avg #samples/sense 26.21 9.96 23.4 17.9 19.5 Table 1: Training set characteristics Performance drop relative to full system (%) NB Cosine BR TBL DL BoW Ftrs Only -6.44.84.86.03.2 Local Ftrs Only -18.411.56.11.53.3 Syntactic Ftrs Only -28.114.95.45.44.8 No BoW Ftrs14.78.15.30.5* -2.0 No Local Ftrs3.50.8* -2.22.94.5 No Syntactic Ftrs1.10.8* -1.31.02.3 Table 2: Individual feature type contribution to perfor\u00admance.",
                    "sid": 125,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Fields marked with *indicate that the difference in performance was not statistically signi.cant at a 0.01 level (paired McNemar test).",
                    "sid": 126,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "classi.er combination methods for 5 classi.ers, NB (Na\u00efve Bayes), BR (BayesRatio), TBL, DL and MMVC, including the average classi.er accuracy and the best classi.cation accuracy.",
                    "sid": 127,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Before examin\u00ading the results, it is worth mentioning that the meth\u00adods which estimate parameters are doing so on a smaller training size (3/5, to be precise), and this can have an effect on how well the parameters are estimated.",
                    "sid": 128,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "After the parameters are estimated, how\u00adever, the interpolation is done between probability distributions that are computed on 4/5 of the train\u00ading data, similarly to the methods that do not esti\u00admate any parameters.",
                    "sid": 129,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The unweighted averaging model of probability interpolation (Equation (1)) performs well, obtain\u00ading over 1% mean absolute performance over the best classi.er7, the difference in performance is statistically signi.cant in all cases except Swedish and Spanish.",
                    "sid": 130,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Of the classi.er combination tech\u00adniques, rank-based combination and performance-based voting perform best.",
                    "sid": 131,
                    "ssid": 18,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Their mean 2% absolute improvement over the single best classi.er is signif\u00adicant in all languages.",
                    "sid": 132,
                    "ssid": 19,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Also, their accuracy improve\u00adment relative to uniform-weight probability interpo\u00adlation is statistically signi.cant in aggregate and for all languages except Basque (where there is gener\u00adally a small difference among all classi.ers).",
                    "sid": 133,
                    "ssid": 20,
                    "kind_of_tag": "s"
                },
                {
                    "text": "To ensure that we bene.t from the performance improvement of each of the stronger combination methods and also to increase robustness, a .nal av\u00aderaging method is applied to the output of the best performing combiners (creating a stacked classi\u00ad.er).",
                    "sid": 134,
                    "ssid": 21,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The last line in Table 3 shows the results ob\u00adtained by averaging the rank-based, EM-vote and 7The best individual classi.er differs with language, as shown in Figure 3(b).",
                    "sid": 135,
                    "ssid": 22,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Method SE1 SENSEVAL2 EN EN ES EU SV Individual Classi.ers Mean Acc 79.5 65.0 66.6 70.4 65.9 Best Acc 81.1 66.7 68.8 71.2 68.0 Probability Interpolation Averaging 82.7 68.0 69.3 72.2 68.16 MSE 82.8 68.1 69.7 71.0 69.2 EM 82.7 68.4 69.6 72.1 69.1 PB 82.8 68.0 69.4 72.2 68.7 Rank-based Combination rank 83.1 68.6 71.0 72.1 70.3 Count-based Combination (Voting) Simple Vote 82.8 68.1 70.9 72.1 70.0 TagPair 82.9 68.3 70.9 72.1 70.0 EM 83.0 68.4 70.5 71.7 70.0 PB 83.1 68.5 70.8 72.0 70.3 Stacking (Meta-Combination) Prob.",
                    "sid": 136,
                    "ssid": 23,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Interp.",
                    "sid": 137,
                    "ssid": 24,
                    "kind_of_tag": "s"
                },
                {
                    "text": "83.2 68.6 71.0 72.3 70.4 Table 3: Classi.er combination accuracy over 5 base classi.ers: NB, BR, TBL, DL, MMVC.",
                    "sid": 138,
                    "ssid": 25,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Best perform\u00ading methods are shown in bold.",
                    "sid": 139,
                    "ssid": 26,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Estimation Level word POS ALL Interp Accuracy 68.1 68.2 68.0 68.4 CrossEntropy 1.623 1.635 1.646 1.632 Table 4: Accuracy for different EM-weighted probability interpolation models for SENSEVAL2 PB-vote methods\u2019 output.",
                    "sid": 140,
                    "ssid": 27,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The difference in perfor\u00admance between the stacked classi.er and the best classi.er is statistically signi.cant for all data sets at a signi.cance level of at least -5, as measured by a paired McNemar test.",
                    "sid": 141,
                    "ssid": 28,
                    "kind_of_tag": "s"
                },
                {
                    "text": "One interesting observation is that for all meth\u00adods of A-parameter estimation (EM, PB and uniform weighting) the count-based and rank-based strate\u00adgies that ignore relative probability magnitudes out\u00adperform their equivalent combination models using probability interpolation.",
                    "sid": 142,
                    "ssid": 29,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This is especially the case when the base classi.er scores have substantially different ranges or variances; using relative ranks effectively normalizes for such differences in model behavior.",
                    "sid": 143,
                    "ssid": 30,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For the three methods that estimate the interpo\u00adlation weights \u2013 MSE, EM and PB \u2013 three vari\u00adants were investigated.",
                    "sid": 144,
                    "ssid": 31,
                    "kind_of_tag": "s"
                },
                {
                    "text": "These were distinguished by the granularity at which the weights are estimated: at word level (Ak(xd)=Ak(x)), at POS level (Ak(xd)=Ak(Pas(x))) and over the entire train\u00ading set (Ak(xd)=Ak).",
                    "sid": 145,
                    "ssid": 32,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Table 4 displays the results obtained by estimating the parameters using EM at different sample granularities for the SENSEVAL2 English data.",
                    "sid": 146,
                    "ssid": 33,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The number in the last column is ob\u00adtained by interpolating the .rst three systems.",
                    "sid": 147,
                    "ssid": 34,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Also displayed is cross-entropy, a measure of how well English Spanish Swedish Basque Senseval2 dataset (a) Performance drop when eliminating one classi.er (marginal performance contribution) 1020 40 50 80 Percent of available training data (b) Performance drop when eliminating one classifer, versus training data size Figure 4: Individual basic classi.ers\u2019 contribution to the .nal classi.er combination performance.",
                    "sid": 148,
                    "ssid": 35,
                    "kind_of_tag": "s"
                },
                {
                    "text": "the combination classi.er estimates the sense prob s abilities, C=-) P(slxd).",
                    "sid": 149,
                    "ssid": 36,
                    "kind_of_tag": "s"
                },
                {
                    "text": "x,dP(sx,d 6.2 Individual Systems Contribution to Combination.",
                    "sid": 150,
                    "ssid": 37,
                    "kind_of_tag": "s"
                },
                {
                    "text": "An interesting issue pertaining to classi.er combi\u00adnation is what is the marginal contribution to .nal combined performance of the individual classi.er.",
                    "sid": 151,
                    "ssid": 38,
                    "kind_of_tag": "s"
                },
                {
                    "text": "A suitable measure of this contribution is the dif\u00adference in performance between a combination sys\u00adtem\u2019s behavior with and without the particular clas\u00adsi.er.",
                    "sid": 152,
                    "ssid": 39,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The more negative the accuracy difference on omission, the more valuable the classi.er is to the ensemble system.",
                    "sid": 153,
                    "ssid": 40,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Figure 4(a) displays the drop in performance ob\u00adtained by eliminating in turn each classi.er from the 6-way combination, across four languages, while Figure 4(b) shows the contribution of each classi.er on the SENSEVAL2 English data for different train\u00ading sizes (10%-80%)8.",
                    "sid": 154,
                    "ssid": 41,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Note that the classi.ers with the greatest marginal contribution to the combined system performance are not always the best single performing classi.ers (Table 3(b)), but those with the most effective original exploitation of the com\u00admon feature space.",
                    "sid": 155,
                    "ssid": 42,
                    "kind_of_tag": "s"
                },
                {
                    "text": "On average, the classi.er that contributes the most to the combined system\u2019s per\u00adformance is the TBL classi.er, with an average im\u00adprovement of .66%across the 4 languages.",
                    "sid": 156,
                    "ssid": 43,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Also, note that TBL and DL offer the greatest marginal contribution on smaller training sizes (Figure 4(b)).",
                    "sid": 157,
                    "ssid": 44,
                    "kind_of_tag": "s"
                },
                {
                    "text": "6.3 Performance on Test Data.",
                    "sid": 158,
                    "ssid": 45,
                    "kind_of_tag": "s"
                },
                {
                    "text": "At all points in this article, experiments have been based strictly on the original SENSEVAL1 and SEN\u00adSEVAL2 training sets via cross-validation.",
                    "sid": 159,
                    "ssid": 46,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The of\u00ad.cial SENSEVAL1 and SENSEVAL2 test sets were 8The latter graph is obtained by sampling repeatedly a prespeci.ed ratio of training samples from 3 of the 5 cross-validation splits, and testing on the other 2.",
                    "sid": 160,
                    "ssid": 47,
                    "kind_of_tag": "s"
                },
                {
                    "text": "unused and unexamined during experimentation to avoid any possibility of indirect optimization on this data.",
                    "sid": 161,
                    "ssid": 48,
                    "kind_of_tag": "s"
                },
                {
                    "text": "But to provide results more readily compara\u00adble to the of.cial benchmarks, a single consensus system was created for each language using linear average stacking on the top three classi.er combi\u00adnation methods in Table 3 for conservative robust\u00adness.",
                    "sid": 162,
                    "ssid": 49,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The .nal frozen consensus system for each language was applied once to the SENSEVAL test sets.",
                    "sid": 163,
                    "ssid": 50,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The .negrained results are shown in Table 5.",
                    "sid": 164,
                    "ssid": 51,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For each language, the single new stacked com\u00adbination system outperforms the best previously re\u00adported SENSEVAL results on the identical test data9.",
                    "sid": 165,
                    "ssid": 52,
                    "kind_of_tag": "s"
                },
                {
                    "text": "As far as we know, they represent the best published results for any of these .ve SENSEVAL tasks..",
                    "sid": 166,
                    "ssid": 53,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "conclusion. ",
            "number": "7",
            "sents": [
                {
                    "text": "In conclusion, we have presented a comparative evaluation study of combining six structurally and procedurally different classi.ers utilizing a rich common feature space.",
                    "sid": 167,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Various classi.er combi\u00adnation methods, including count-based, rank-based and probability-based combinations are described and evaluated.",
                    "sid": 168,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The experiments encompass super\u00advised lexical sample tasks in four diverse languages: English, Spanish, Swedish, and Basque.",
                    "sid": 169,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "9To evaluate systems on the full disambiguation task, it is appropriate to compare them on their accuracy at 100% test-data coverage, which is equivalent to system recall in the of.\u00adcial SENSEVAL scores.",
                    "sid": 170,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "However, it can also be useful to con\u00adsider performance on only the subset of data for which a sys\u00adtem is con.dent enough to answer, measured by the secondary measure precision.",
                    "sid": 171,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "One useful byproduct of the CBV method is the con.dence it assigns to each sample, which we measured by the number of classi.ers that voted for the sample.",
                    "sid": 172,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "If one restricts system output to only those test instances where all participating classi.ers agree, consensus system performance is 83.4% precision at a recall of 43%, for an F-measure of 56.7 on the SENSEVAL2 English lexical sample task.",
                    "sid": 173,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This outper\u00adforms the two supervised SENSEVAL2 systems that only had partial coverage, which exhibited 82.9% precision at a recall of 28% (F=41.9) and 66.5% precision at 34.4% recall (F=47.9).",
                    "sid": 174,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "SENSEVAL1 English SENSEVAL2 Sense Classi.cation Accuracy English Spanish Swedish Basque Mean Of.cial SENSEVAL Systems Accuracy 73.1.2.9 55.7.5.3 59.6.5.0 58.4.6.6 74.4.1.8 Best Previously Published SENSEVAL Accuracy 77.1% 64.2% 71.2% 70.1% 75.7% Best Individual Classi.er Accuracy 77.1% 62.5% 69.6% 68.6% 75.6% New (Stacking) Accuracy 79.7% 66.5% 72.4% 71.9% 76.7% Table 5: Final Performance (Frozen Systems) on SENSEVAL Lexical Sample WSD Test Data The experiments show substantial variation in single classi.er performance across different lan\u00adguages and data sizes.",
                    "sid": 175,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "They also show that this variation can be successfully exploited by 10 differ\u00adent classi.er combination methods (and their meta-voting consensus), each of which outperforms both the single best classi.er system and standard classi\u00ad.er combination models on each of the 4 focus lan\u00adguages.",
                    "sid": 176,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Furthermore, when the stacking consensus systems were frozen and applied once to the other\u00adwise untouched test sets, they substantially outper\u00adformed all previously known SENSEVAL1 and SEN\u00adSEVAL2 results on 4 languages, obtaining the best published results on these data sets.",
                    "sid": 177,
                    "ssid": 11,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "acknowledgements. ",
            "number": "8",
            "sents": [
                {
                    "text": "The authors would like to thank Noah Smith for his comments on an earlier version of this paper, and the anonymous reviewers for their useful comments.",
                    "sid": 178,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This work was supported by NSF grant IIS9985033 and ONR/MURI contract N0001401-10685.",
                    "sid": 179,
                    "ssid": 2,
                    "kind_of_tag": "s"
                }
            ]
        }
    ]
}