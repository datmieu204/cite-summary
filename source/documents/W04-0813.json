{
    "ID": "W04-0813",
    "sections": [
        {
            "text": "abstract",
            "number": 0,
            "sents": [
                {
                    "text": "Our group participated in the Basque and En\u00adglish lexical sample tasks in Senseval3.",
                    "sid": 1,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "A language-speci.c feature set was de.ned for Basque.",
                    "sid": 2,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Four di.erent learning algorithms were applied, and also a method that combined their outputs.",
                    "sid": 3,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Before submission, the performance of the methods was tested for each task on the Senseval3 training data using cross validation.",
                    "sid": 4,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Finally, two systems were submitted for each language: the best single algorithm and the best ensemble.",
                    "sid": 5,
                    "ssid": 5,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "introduction",
            "number": "1",
            "sents": [
                {
                    "text": "Our group (BCU, Basque Country University), participated in the Basque and English lexical sample tasks in Senseval3.",
                    "sid": 6,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We applied 4 di.er\u00adent learning algorithms (Decision Lists, Naive Bayes, Vector Space Model, and Support Vector Machines), and also a method that combined their outputs.",
                    "sid": 7,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "These algorithms were previously tested and tuned on the Senseval2 data for En\u00adglish.",
                    "sid": 8,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Before submission, the performance of the methods was tested for each task on the Senseval3 training data using 10 fold cross val\u00adidation.",
                    "sid": 9,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Finally, two systems were submitted for each language, the best single algorithm and the best ensemble in cross-validation.",
                    "sid": 10,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The main di.erence between the Basque and English systems was the feature set.",
                    "sid": 11,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "A rich set of features was used for English, includ\u00ading syntactic dependencies and domain infor\u00admation, extracted with di.erent tools, and also from external resources like WordNet Domains (Magnini and Cavagli\u00b4a, 2000).",
                    "sid": 12,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The features for Basque were di.erent, as Basque is an agglu\u00adtinative language, and syntactic information is given by in.ectional su.xes.",
                    "sid": 13,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We tried to rep\u00adresent this information in local features, relying on the analysis of a deep morphological analyzer developed in our group (Aduriz et al., 2000).",
                    "sid": 14,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In order to improve the performance of the al\u00adgorithms, di.erent smoothing techniques were David Martinez IXA NLP Group Basque Country University Donostia, Spain davidm@si.ehu.es tested on the English Senseval2 lexical sam\u00adple data (Agirre and Martinez, 2004), and ap\u00adplied to Senseval3.",
                    "sid": 15,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "These methods helped to obtain better estimations for the features, and to avoid the problem of 0 counts Decision Lists and Naive Bayes.",
                    "sid": 16,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This paper is organized as follows.",
                    "sid": 17,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The learn\u00ading algorithms are .rst introduced in Section 2, and Section 3 describes the features applied to each task.",
                    "sid": 18,
                    "ssid": 18,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In Section 4, we present the exper\u00adiments performed on training data before sub\u00admission; this section also covers the .nal con.g\u00aduration of each algorithm, and the performance obtained on training data.",
                    "sid": 19,
                    "ssid": 19,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Finally, the o.cial results in Senseval3 are presented and discussed in Section 5.",
                    "sid": 20,
                    "ssid": 20,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "learning algorithms. ",
            "number": "2",
            "sents": [
                {
                    "text": "The algorithms presented in this section rely on features extracted from the context of the target word to make their decisions.",
                    "sid": 21,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The Decision List (DL) algorithm is de\u00adscribed in (Yarowsky, 1995b).",
                    "sid": 22,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In this algorithm the sense with the highest weighted feature is se\u00adlected, as shown below.",
                    "sid": 23,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We can avoid undeter\u00admined values by discarding features that have a 0 probability in the divisor.",
                    "sid": 24,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "More sophisticated smoothing techniques have also been tried (cf.",
                    "sid": 25,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Section 4).",
                    "sid": 26,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Pr(sk|fi) arg max w(sk,fi)= log( .) k =k Pr(sj|fi) j The Naive Bayes (NB) algorithm is based on the conditional probability of each sense given the features in the context.",
                    "sid": 27,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "It also re\u00adquires smoothing.",
                    "sid": 28,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "m arg max P(sk) .i=1 P(fi|sk) k For the Vector Space Model (V) algo\u00adrithm, we represent each occurrence context as a vector, where each feature will have a 1 or 0 SENSEVAL3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text, Barcelona, Spain, July 2004 Association for Computational Linguistics value to indicate the occurrence/absence of the feature.",
                    "sid": 29,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For each sense in training, one cen\u00adtroid vector is obtained.",
                    "sid": 30,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "These centroids are compared with the vectors that represent test\u00ading examples, by means of the cosine similarity function.",
                    "sid": 31,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The closest centroid is used to assign its sense to the testing example.",
                    "sid": 32,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "No smooth\u00ading is required to apply this algorithm, but it is possible to use smoothed values.",
                    "sid": 33,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Regarding Support Vector Machines (SVM) we utilized SVM-Light (Joachims, 1999), a public distribution of SVM.",
                    "sid": 34,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Linear ker\u00adnels were applied, and the soft margin (C) was estimated per each word (cf.",
                    "sid": 35,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Section 4).",
                    "sid": 36,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "3Features 3.1 Features for English.",
                    "sid": 37,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We relied onanextensive setoffeatures of di.erent types, obtained by means of di.erent tools and resources.",
                    "sid": 38,
                    "ssid": 18,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The features used can be grouped in four groups: Local collocations: bigrams and trigrams formed with the words around the target.",
                    "sid": 39,
                    "ssid": 19,
                    "kind_of_tag": "s"
                },
                {
                    "text": "These features are constituted with lemmas, word-forms, or PoS tags1 . Other local features are those formed with the previous/posterior lemma/word-form in the context.",
                    "sid": 40,
                    "ssid": 20,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Syntactic dependencies: syntactic depen\u00addencies were extracted using heuristic patterns, and regular expressions de.ned with the PoS tags around the target2 . The following rela\u00adtions were used: object, subject, noun-modi.er, preposition, and sibling.",
                    "sid": 41,
                    "ssid": 21,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Bag-of-words features:we extract the lemmas of the content words in the whole con\u00adtext, and in a \u00b14-word window around the tar\u00adget.",
                    "sid": 42,
                    "ssid": 22,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We also obtain salient bigrams in the con\u00adtext, with the methods and the software de\u00adscribed in (Pedersen, 2001).",
                    "sid": 43,
                    "ssid": 23,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Domain features: The WordNet Domains resource was used to identify the most relevant domains in the context.",
                    "sid": 44,
                    "ssid": 24,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Following the relevance formula presented in (Magnini and Cavagli\u00b4a, 2000), we de.ned 2 feature types: (1) the most relevant domain, and (2) a list of domains above a prede.ned threshold3 . Other experiments us\u00ading domains from SUMO, the EuroWordNet 1The PoS tagging was performed with the fnTBL toolkit(Ngai andFlorian, 2001).",
                    "sid": 45,
                    "ssid": 25,
                    "kind_of_tag": "s"
                },
                {
                    "text": "2This software was kindly provided by David Yarowsky\u2019s group, from Johns Hopkins University.",
                    "sid": 46,
                    "ssid": 26,
                    "kind_of_tag": "s"
                },
                {
                    "text": "3 The software to obtain the relevant domains was kindly provided by Gerard Escudero\u2019s group, from Uni\u00adversitat Politecnica de Catalunya top-ontology, and WordNet\u2019s Semantic Fields were performed, but these features were dis\u00adcarded from the .nal set.",
                    "sid": 47,
                    "ssid": 27,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Basque is an agglutinative language, and syn\u00adtactic information is given by in.ectional suf\u00ad.xes.",
                    "sid": 48,
                    "ssid": 28,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The morphological analysis of the text is a necessary previous step in order to select in\u00adformative features.",
                    "sid": 49,
                    "ssid": 29,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The data provided by the task organization includes information about the lemma, declension case, and PoS for the par\u00adticipating systems.",
                    "sid": 50,
                    "ssid": 30,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Our group used directly the output of the parser (Aduriz et al., 2000), which includes some additional features: number, de\u00adterminer mark, ambiguous analyses and elliptic words.",
                    "sid": 51,
                    "ssid": 31,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For a few examples, the morphological analysis was not available, due to parsing errors.",
                    "sid": 52,
                    "ssid": 32,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In Basque, the determiner, the number and the declension case are appended to the last el\u00adement of the phrase.",
                    "sid": 53,
                    "ssid": 33,
                    "kind_of_tag": "s"
                },
                {
                    "text": "When de.ning our fea\u00adture set for Basque, we tried to introduce the same knowledge that is represented by features that work well for English.",
                    "sid": 54,
                    "ssid": 34,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We will describe our feature set with an example: for the phrase \u201delizaren arduradunei\u201d (which means \u201dto the directors of the church\u201d) we get the following analysis from our analyzer: eliza |-ren |arduradun |-ei church |of the |director |to the +pl. The order of the words is the inverse in En\u00adglish.",
                    "sid": 55,
                    "ssid": 35,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We extract the following information for each word: elizaren: Lemma: eliza (church) PoS: noun Declension Case: genitive (of) Number: singular Determiner mark: yes arduradunei: Lemma: arduradun (director) PoS: noun Declension Case: dative (to) Number: plural Determiner mark: yes We will assume that eliza (church) is the target word.",
                    "sid": 56,
                    "ssid": 36,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Words and lemmas are shown in lowercase and the other information in up\u00adpercase.",
                    "sid": 57,
                    "ssid": 37,
                    "kind_of_tag": "s"
                },
                {
                    "text": "As local features we de.ned di.erent types of unigrams, bigrams, trigrams and a window of \u00b14 words.",
                    "sid": 58,
                    "ssid": 38,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The unigrams were con\u00adstructed combining word forms, lemmas, case, number, and determiner mark.",
                    "sid": 59,
                    "ssid": 39,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We de.ned 4 kinds of unigrams: Uni wf0 elizaren Uni wf1 eliza SING+DET Uni wf2 eliza GENITIVE Uni wf3 eliza SING+DET GENITIVE As for English, we de.ned bigrams based on word forms, lemmas and parts-of-speech.",
                    "sid": 60,
                    "ssid": 40,
                    "kind_of_tag": "s"
                },
                {
                    "text": "But in order to simulate the bigrams and trigrams used for English, we de.ned di.erent kinds of features.",
                    "sid": 61,
                    "ssid": 41,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For word forms, we distinguished two cases: using the text string (Big wf0), or using the tags from the analysis (Big wf1).",
                    "sid": 62,
                    "ssid": 42,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The word form bigrams for the example are shown below.",
                    "sid": 63,
                    "ssid": 43,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In thecase of the featuretype\u201cBig wf1\u201d, the information is split in three features: Big wf0 elizaren arduradunei Big wf1 eliza GENITIVE Big wf1 GENITIVE arduradun PLUR+DET Big wf1 arduradun PLUR+DET DATIVE Similarly, depending on the use of the de\u00adclension case, we de.ned three kinds of bigrams basedonlemmas: Big lem0 eliza arduradun Big lem1 eliza GENITIVE Big lem1 GENITIVE arduradun Big lem1 arduradun DATIVE Big lem2 eliza GENITIVE Big lem2 arduradun DATIVE The bigrams constructed using Part-of\u00adspeech are illustrated below.",
                    "sid": 64,
                    "ssid": 44,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We included the declension case as if it was another PoS: Big pos1 NOUN GENITIVE Big pos1 GENITIVE NOUN Big pos1 NOUN DATIVE Trigrams are built similarly, by combining the information from three consecutive words.",
                    "sid": 65,
                    "ssid": 45,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We also used as local features all the content words in a window of \u00b14 words around the target.",
                    "sid": 66,
                    "ssid": 46,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Fi\u00adnally, as global features we took all the con\u00adtent lemmas appearing in the context, which was constituted by the target sentence and the two previous and posterior sentences.",
                    "sid": 67,
                    "ssid": 47,
                    "kind_of_tag": "s"
                },
                {
                    "text": "One di.cult case to model in Basque is the el\u00adlipsis.",
                    "sid": 68,
                    "ssid": 48,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example, the word \u201celizakoa\u201d means \u201cthe one from the church\u201d.",
                    "sid": 69,
                    "ssid": 49,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We were able to extract this information from our analyzer and we represented it in the features, using a special symbol in place of the elliptic word.",
                    "sid": 70,
                    "ssid": 50,
                    "kind_of_tag": "s"
                },
                {
                    "text": "4 Experiments on training data.",
                    "sid": 71,
                    "ssid": 51,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The algorithms that we applied were .rst tested on the Senseval2 lexical sample task for En\u00adglish.",
                    "sid": 72,
                    "ssid": 52,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The best versions were then evaluated by 10 fold cross-validation on the Senseval3 data, both for Basque and English.",
                    "sid": 73,
                    "ssid": 53,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We also used the training data in cross-validation to tune the pa\u00adrameters, such as the smoothed frequencies, or the soft margin for SVM.",
                    "sid": 74,
                    "ssid": 54,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In this section we will describe .rst the parameters of each method (including the smoothing procedure), and then the cross-validation results on the Senseval3 training data.",
                    "sid": 75,
                    "ssid": 55,
                    "kind_of_tag": "s"
                },
                {
                    "text": "4.1 Methods and Parameters.",
                    "sid": 76,
                    "ssid": 56,
                    "kind_of_tag": "s"
                },
                {
                    "text": "DL: On Senseval2 data, we observed that DL improved signi.cantly its performance with a smoothing technique based on (Yarowsky, 1995a).",
                    "sid": 77,
                    "ssid": 57,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For our implementation, the smoothed probabilities were obtained by grouping the ob\u00adservations by raw frequencies and feature types.",
                    "sid": 78,
                    "ssid": 58,
                    "kind_of_tag": "s"
                },
                {
                    "text": "As this method seems sensitive to the feature types and the amount of examples, we tested 3 DL versions: DL smooth (using smoothed probabilities), DL .xed (replacing 0 counts with 0.1), and DL discard (discarding features ap\u00adpearing with only one sense).",
                    "sid": 79,
                    "ssid": 59,
                    "kind_of_tag": "s"
                },
                {
                    "text": "NB: We applied a simple smoothing method presented in (Ng, 1997), where zero counts are replaced by the probability of the given sense divided by the number of examples.",
                    "sid": 80,
                    "ssid": 60,
                    "kind_of_tag": "s"
                },
                {
                    "text": "V: The same smoothing method used for NB was applied for vectors.",
                    "sid": 81,
                    "ssid": 61,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For Basque, two ver\u00adsions were tested: as the Basque parser can re\u00adturn ambiguous analyses, partial weights are as\u00adsigned to the features in the context, and we can chose to use these partial weights (p), or assign the full weight to all features (f).",
                    "sid": 82,
                    "ssid": 62,
                    "kind_of_tag": "s"
                },
                {
                    "text": "SVM: No smoothing was applied.",
                    "sid": 83,
                    "ssid": 63,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We esti\u00admated the soft margin using a greedy process in cross-validation on the training data per each word.",
                    "sid": 84,
                    "ssid": 64,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Combination: Single voting was used, where each system voted for its best ranked sense, and the most voted sense was chosen.",
                    "sid": 85,
                    "ssid": 65,
                    "kind_of_tag": "s"
                },
                {
                    "text": "More sophisticate schemes like ranked voting, were tried on Senseval2 data, but the results did not improve.",
                    "sid": 86,
                    "ssid": 66,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We tested combinations of the 4 algorithms, leaving one out, and the two best.",
                    "sid": 87,
                    "ssid": 67,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The best results were obtained combining 3 methods (leave one out).",
                    "sid": 88,
                    "ssid": 68,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Method Recall vector 73,9 SVM 73,5 DL smooth 69,4 NB 69,4 DL .xed 65,6 DL discard 65,4 MFS 57,1 Table 1: Single systems (English) in cross-validation, sorted by recall.",
                    "sid": 89,
                    "ssid": 69,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Combination Recall SVM-vector-DL smooth-NB SVM-vector-DL .xedNB SVM-vector-DL smooth SVM-vector-DL .xed SVM-vector-NB SVMDL smooth-NB SVMDL .xedNB SVM-vector 73,2 72,7 74,0 73,8 73,6 72,4 71,3 73,1 Table 2: Combined systems (English) in cross-validation, best recall in bold.",
                    "sid": 90,
                    "ssid": 70,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Method Recall SVM 71,1 NB 68,5 vector(f) 66,8 DL smooth 65,9 DL .xed 65,2 vector(p) 65,0 DL discard 60,7 MFS 53,0 Table 3: Single systems (Basque) in cross-validation, sorted by recall.",
                    "sid": 91,
                    "ssid": 71,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Combination Recall SVM-vector-DL smooth-NB SVM-vector-DL .xedNB SVM-vector-DL smooth SVM-vector-DL .xed SVM-vector-NB SVMDL smooth-NB SVMDL .xedNB SVM-vector SVMNB 70,6 71,1 70,6 70,8 71,1 70,2 70,5 69,0 69,8 Table 4: Combined systems (Basque) in cross-validation, best recall in bold.",
                    "sid": 92,
                    "ssid": 72,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Only vector(f) was used for combination.",
                    "sid": 93,
                    "ssid": 73,
                    "kind_of_tag": "s"
                },
                {
                    "text": "4.2 Results on English Training Data.",
                    "sid": 94,
                    "ssid": 74,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The results using cross-validation on the Senseval3 data are shown in Table 1 for single systems, and in Table 2 for combined methods.",
                    "sid": 95,
                    "ssid": 75,
                    "kind_of_tag": "s"
                },
                {
                    "text": "All the algorithms have full-coverage (for En\u00adglish and Basque), therefore the recall and the precision are the same.",
                    "sid": 96,
                    "ssid": 76,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The most frequent sense (MFS) baseline is also provided, and it is easily beaten by all the algorithms.",
                    "sid": 97,
                    "ssid": 77,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We have to note that these .gures are consis\u00adtent with the performance we observed in the Senseval2 data, where the vector method is the best performing single system, and the best combination is SVM-vector-DL smooth.",
                    "sid": 98,
                    "ssid": 78,
                    "kind_of_tag": "s"
                },
                {
                    "text": "There is a small gain when combining 3 systems, which we expected would be higher.",
                    "sid": 99,
                    "ssid": 79,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We submitted the best single system, and the best combination for this task.",
                    "sid": 100,
                    "ssid": 80,
                    "kind_of_tag": "s"
                },
                {
                    "text": "4.3 Results on Basque Training Data.",
                    "sid": 101,
                    "ssid": 81,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The performance on the Senseval3 Basque training data is given in Table 1 for single sys\u00adtems, and in Table 2 for combined methods.",
                    "sid": 102,
                    "ssid": 82,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In this case, the vector method, and DL smooth obtain lower performance in relation to other methods.",
                    "sid": 103,
                    "ssid": 83,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This can be due to the type of fea\u00adtures used, which have not been tested as ex\u00adtensively as for English.",
                    "sid": 104,
                    "ssid": 84,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In fact, it could hap\u00adpen that some features contribute mostly noise.",
                    "sid": 105,
                    "ssid": 85,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Also, the domain tag of the examples, which could provide useful information, was not used.",
                    "sid": 106,
                    "ssid": 86,
                    "kind_of_tag": "s"
                },
                {
                    "text": "There is no improvement when combining dif\u00adferent systems, and the result of the combina\u00adtion of 4 systems is unusually high in relation to the English experiments.",
                    "sid": 107,
                    "ssid": 87,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We also submit\u00adted two systems for this task: the best single method in cross-validation (SVM), and the best 3-method combination (SVM-vector-NB).",
                    "sid": 108,
                    "ssid": 88,
                    "kind_of_tag": "s"
                },
                {
                    "text": "5 Results and Conclusions.",
                    "sid": 109,
                    "ssid": 89,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Table 5 shows the performance obtained by our systems and the winning system in the Senseval\u00ad3 evaluation.",
                    "sid": 110,
                    "ssid": 90,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We can see that we are very close to the best algorithms in both languages.",
                    "sid": 111,
                    "ssid": 91,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The recall of our systems is 1.2%-1.9% lower than cross-validation for every system and task, which is not surprising when we change the set\u00adting.",
                    "sid": 112,
                    "ssid": 92,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The combination of methods is useful for English, where we improve the recall in 0.3%, reaching 72.3%.",
                    "sid": 113,
                    "ssid": 93,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The di.erence is statistically signi.cant according to McNemar\u2019s test.",
                    "sid": 114,
                    "ssid": 94,
                    "kind_of_tag": "s"
                },
                {
                    "text": "However, the combination of methods does not improve the results in the the Basque task, where the SVM method alone provides better Table 5: O.cial results for the English and Basque lexical tasks (recall).",
                    "sid": 115,
                    "ssid": 95,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Task Code Method Rec.",
                    "sid": 116,
                    "ssid": 96,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Eng.",
                    "sid": 117,
                    "ssid": 97,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Eng.",
                    "sid": 118,
                    "ssid": 98,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Eng.",
                    "sid": 119,
                    "ssid": 99,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Senseval3 Best BCU comb BCUenglish ? SVM-vector-DL smooth vector 72,9 72,3 72,0 Basq.",
                    "sid": 120,
                    "ssid": 100,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Senseval3 Best ? 70,4 Basq.",
                    "sid": 121,
                    "ssid": 101,
                    "kind_of_tag": "s"
                },
                {
                    "text": "BCUbasque SVM 69,9 Basq.",
                    "sid": 122,
                    "ssid": 102,
                    "kind_of_tag": "s"
                },
                {
                    "text": "BCUBasque comb SVM-vector\u00ad 69,5 NB results (69.9% recall).",
                    "sid": 123,
                    "ssid": 103,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In this case the di.erence is not signi.cant applying McNemar\u2019s test.",
                    "sid": 124,
                    "ssid": 104,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Our disambiguation procedure shows a sim\u00adilar behavior on the Senseval2 and Senseval3 data for English (both in cross-validation and in the testing part), where the ensemble works best, followed by the vector model.",
                    "sid": 125,
                    "ssid": 105,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This did not apply to the Basque dataset, where some algorithms seem to perform below the expecta\u00adtions.",
                    "sid": 126,
                    "ssid": 106,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For future work, we plan to study better the Basque feature set and include new features, such as domain tags.",
                    "sid": 127,
                    "ssid": 107,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Overall, the ensemble of algorithms provides a more robust system for WSD, and is able to achieve state-of-the-art performance.",
                    "sid": 128,
                    "ssid": 108,
                    "kind_of_tag": "s"
                },
                {
                    "text": "6Acknowledgements We wish to thank both David Yarowsky\u2019s group, from Johns Hopkins University, and Gerard Es\u00adcudero\u2019s group, from Universitat Politecnica de Catalunya, for providing us software for the ac\u00adquisition of features.",
                    "sid": 129,
                    "ssid": 109,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This research has been partially funded by the European Commission (MEANING IST2001-34460).",
                    "sid": 130,
                    "ssid": 110,
                    "kind_of_tag": "s"
                }
            ]
        }
    ]
}