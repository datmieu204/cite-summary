{
    "ID": "W02-0812",
    "sections": [
        {
            "text": "abstract",
            "number": 0,
            "sents": [
                {
                    "text": "This paper presents an evaluation of an ensemble\u2013based system that participated in the English and Spanish lexical sample tasks of SENSEVAL2.",
                    "sid": 1,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The system com\u00adbines decision trees of unigrams, bigrams, and co\u2013occurrences into a single classi\u00ad.er.",
                    "sid": 2,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The analysis is extended to include the SENSEVAL1 data.",
                    "sid": 3,
                    "ssid": 3,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "introduction",
            "number": "1",
            "sents": [
                {
                    "text": "There were eight Duluth systems that participated in the English and Spanish lexical sample tasks of SENSEVAL2.",
                    "sid": 4,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "These systems were all based on the combination of lexical features with standard ma\u00adchine learning algorithms.",
                    "sid": 5,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The most accurate of these systems proved to be Duluth3 for English and Duluth8 for Spanish.",
                    "sid": 6,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "These only differ with respect to minor language speci.c issues, so we refer to them generically as Duluth38, except when the lan\u00adguage distinction is important.",
                    "sid": 7,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Duluth38 is an ensemble approach that assigns a sense to an instance of an ambiguous word by taking a vote among three bagged decision trees.",
                    "sid": 8,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Each tree is learned from a different view of the training ex\u00adamples associated with the target word.",
                    "sid": 9,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Each view of the training examples is based on one of the fol\u00adlowing three types of lexical features: single words, two word sequences that occur anywhere within the context of the word being disambiguated, and two word sequences made up of this target word and an\u00adother word within one or two positions.",
                    "sid": 10,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "These fea\u00adtures are referred to as unigrams, bigrams, and co\u2013 occurrences.",
                    "sid": 11,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The focus of this paper is on determining if the member classi.ers in the Duluth38 ensemble are complementary or redundant with each other and with other participating systems.",
                    "sid": 12,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Two classi.ers are complementary if they disagree on a substantial number of disambiguation decisions and yet attain comparable levels of overall accuracy.",
                    "sid": 13,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Classi.ers are redundant if they arrive at the same disambigua\u00adtion decisions for most instances of the ambiguous word.",
                    "sid": 14,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "There is little advantage in creating an ensem\u00adble of redundant classi.ers, since they will make the same disambiguation decisions collectively as they would individually.",
                    "sid": 15,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "An ensemble can only improve upon the accuracy of its member classi.ers if they are complementary to each other, and the errors of one classi.er are offset by the correct judgments of others.",
                    "sid": 16,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This paper continues with a description of the lexical features that make up the Duluth38 system, and then pro.les the SENSEVAL1 and SENSEVAL\u00ad2 lexical sample data that is used in this evaluation.",
                    "sid": 17,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "There are two types of analysis presented.",
                    "sid": 18,
                    "ssid": 18,
                    "kind_of_tag": "s"
                },
                {
                    "text": "First, the accuracy of the member classi.ers in the Duluth38 ensemble are evaluated individually and in pair\u00adwise combinations.",
                    "sid": 19,
                    "ssid": 19,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Second, the agreement between Duluth38 and the top two participating systems in SENSEVAL1 and SENSEVAL2 is compared.",
                    "sid": 20,
                    "ssid": 20,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This paper concludes with a review of the origins of our approach.",
                    "sid": 21,
                    "ssid": 21,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Since the focus here is on analysis, imple\u00admentation level details are not extensively discussed.",
                    "sid": 22,
                    "ssid": 22,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Such descriptions can be found in (Pedersen, 2001b) or (Pedersen, 2002).",
                    "sid": 23,
                    "ssid": 23,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "lexical features. ",
            "number": "2",
            "sents": [
                {
                    "text": "Unigram features represent words that occur .ve or more times in the training examples associated with a given target word.",
                    "sid": 24,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "A stop\u2013list is used to eliminate high frequency function words as features.",
                    "sid": 25,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example, if the target word is water and the training example is I water the .owering .owers, the unigrams water, .owering and .owers are eval\u00aduated as possible unigram features.",
                    "sid": 26,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "No stemming or other morphological processing is performed, so .owering and .owers are considered as distinct uni\u00adgrams.",
                    "sid": 27,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "I and the are not considered as possible fea\u00adtures since they are included in the stop\u2013list.",
                    "sid": 28,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Bigram features represent two word sequences that occur two or more times in the training exam\u00adples associated with a target word, and have a log\u2013 likelihood value greater than or equal to 6.635.",
                    "sid": 29,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This corresponds to a p\u2013value of 0.01, which indicates that according to the log\u2013likelihood ratio there is a 99% probability that the words that make up this bi-gram are not independent.",
                    "sid": 30,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "If we are disambiguating channel and have the training example Go to the channel quickly, then the three bigrams Go to, the channel, and channel quickly will be considered as possible features.",
                    "sid": 31,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "to the is not included since both words are in the stop\u2013 list.",
                    "sid": 32,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Co\u2013occurrence features are de.ned to be a pair of words that include the target word and another word within one or two positions.",
                    "sid": 33,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "To be selected as a feature, a co\u2013occurrence must occur two or more times in the lexical sample training data, and have a log\u2013likelihood value of 2.706, which corresponds to a p\u2013value of 0.10.",
                    "sid": 34,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "A slightly higher p\u2013value is used for the co\u2013occurrence features, since the volume of data is much smaller than is available for the bigram features.",
                    "sid": 35,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "If we are disambiguating art and have the training example He and I like art of a certain period,we evaluate I art, like art, art of, and art a as possible co\u2013occurrence features.",
                    "sid": 36,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "All of these features are binary, and indicate if the designated unigram, bigram, or co\u2013occurrence ap\u00adpears in the context with the ambiguous word.",
                    "sid": 37,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Once the features are identi.ed from the training examples using the methods described above, the decision tree learner selects from among those features to deter\u00admine which are most indicative of the sense of the ambiguous word.",
                    "sid": 38,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Decision tree learning is carried out with the Weka J48 algorithm (Witten and Frank, 2000), which is a Java implementation of the classic C4.5 decision tree learner (Quinlan, 1986).",
                    "sid": 39,
                    "ssid": 16,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "experimental data. ",
            "number": "3",
            "sents": [
                {
                    "text": "The English lexical sample for SENSEVAL1 is made up of 35 words, six of which are used in mul\u00adtiple parts of speech.",
                    "sid": 40,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The training examples have been manually annotated based on the HECTOR sense inventory.",
                    "sid": 41,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "There are 12,465 training exam\u00adples, and 7,448 test instances.",
                    "sid": 42,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This corresponds to what is known as the trainable lexical sample in the SENSEVAL1 of.cial results.",
                    "sid": 43,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The English lexical sample for SENSEVAL2 con\u00adsists of 73 word types, each of which is associ\u00adated with a single part of speech.",
                    "sid": 44,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "There are 8,611 sense\u2013tagged examples provided for training, where each instance has been manually assigned a Word-Net sense.",
                    "sid": 45,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The evaluation data for the English lexi\u00adcal sample consists of 4,328 held out test instances.",
                    "sid": 46,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "TheSpanishlexicalsamplefor SENSEVAL2con\u00adsists of 39 word types.",
                    "sid": 47,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "There are 4,480 training ex\u00adamples that have been manually tagged with senses from Euro-WordNet.",
                    "sid": 48,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The evaluation data consists of 2,225 test instances.",
                    "sid": 49,
                    "ssid": 10,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "system results. ",
            "number": "4",
            "sents": [
                {
                    "text": "This section (and Table 1) summarizes the per\u00adformance of the top two participating systems in SENSEVAL1 and SENSEVAL2, as well as the Du\u00adluth3 and Duluth8 systems.",
                    "sid": 50,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Also included are base\u00adline results for a decision stump and a majority clas\u00adsi.er.",
                    "sid": 51,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "A decision stump is simply a one node deci\u00adsion tree based on a co\u2013occurrence feature, while the majority classi.er assigns the most frequent sense in the training data to every occurrence of that word in the test data.",
                    "sid": 52,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Results are expressed using accuracy, which is computed by dividing the total number of correctly disambiguated test instances by the total number of test instances.",
                    "sid": 53,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Of.cial results from SENSEVAL are reported using precision and recall, so these are con\u00adverted to accuracy to provide a consistent point of comparison.",
                    "sid": 54,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We utilize .ne grained scoring, where a word is considered correctly disambiguated only if it is assigned exactly the sense indicated in the man\u00adually created gold standard.",
                    "sid": 55,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "IntheEnglishlexicalsampletaskof SENSEVAL1 the two most accurate systems overall were hopkins\u00adrevised (77.1%) and etspu-revised (75.6%).",
                    "sid": 56,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The Duluth systems did not participate in this exercise, but have been evaluated using the same data after the fact.",
                    "sid": 57,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The Duluth3 system reaches accuracy of 70.3%.",
                    "sid": 58,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The simple majority classi.er attains accu\u00adracy of 56.4%.",
                    "sid": 59,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In the English lexical sample task of SENSEVAL\u00ad2 the two most accurate systems were JHU(R) (64.2%) and SMUls (63.8%).",
                    "sid": 60,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Duluth3 attains an ac\u00adcuracy of 57.3%, while a simple majority classi.er attains accuracy of 47.4%.",
                    "sid": 61,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In the Spanish lexical sample task of SENSEVAL\u00ad2 the two most accurate systems were JHU(R) (68.1%) and stanfordcs224n (66.9%).",
                    "sid": 62,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Duluth8 has accuracy of 61.2%, while a simple majority classi\u00ad.er attains accuracy of 47.4%.",
                    "sid": 63,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The top two systems from the .rst and sec\u00adond SENSEVAL exercises represent a wide range of strategies that we can only hint at here.",
                    "sid": 64,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The SMUls English lexical sample system is perhaps the most distinctive in that it incorporates information from WordNet, the source of the sense distinctions in SENSEVAL2.",
                    "sid": 65,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The hopkins-revised, JHU(R), and stanfordcs224n systems use supervised algorithms that learn classi.ers from a rich combination of syn\u00adtactic and lexical features.",
                    "sid": 66,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The etspu-revised sys\u00adtem may be the closest in spirit to our own, since it creates an ensemble of two Naive Bayesian classi\u00ad.ers, where one is based on topical context and the other on local context.",
                    "sid": 67,
                    "ssid": 18,
                    "kind_of_tag": "s"
                },
                {
                    "text": "More detailed description of the SENSEVAL1 and SENSEVAL2 systems and lexical samples can be found in (Kilgarriff and Palmer, 2000) and (Ed\u00admonds and Cotton, 2001), respectively.",
                    "sid": 68,
                    "ssid": 19,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "decomposition of ensembles. ",
            "number": "5",
            "sents": [
                {
                    "text": "The three bagged decision trees that make up Du\u00adluth38 are evaluated both individually and as pair\u00adwise ensembles.",
                    "sid": 69,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In Table 1 and subsequent discus\u00adsion, we refer to the individual bagged decision trees based on unigrams, bigrams and co\u2013occurrences as U, B, and C, respectively.",
                    "sid": 70,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We designate ensembles that consist of two or three bagged decision trees by Table 1: Accuracy in Lexical Sample Tasks system accuracy correct English SENSEVAL1 hopkins-revised 77.1% 5,742.4 etspu-revised 75.6% 5,630.7 UC 71.3% 5,312.8 UBC 70.3% 5,233.9 BC 70.1% 5,221.7 UB 69.5% 5,176.0 C 69.0% 5,141.8 B 68.1% 5,074.7 U 63.6% 4,733.7 stump 60.7% 4,521.0 majority 56.4% 4,200.0 English SENSEVAL2 JHU(R) 64.2% 2,778.6 SMUls 63.8% 2,761.3 UBC 57.3% 2,480.7 UC 57.2% 2,477.5 BC 56.7% 2,452.0 C 56.0% 2,423.7 UB 55.6% 2,406.0 B 54.4% 2,352.9 U 51.7% 2,238.2 stump 50.0% 2,165.8 majority 47.4% 2,053.3 Spanish SENSEVAL2 JHU(R) 68.1% 1,515.2 stanfordcs224n 66.9% 1,488.5 UBC 61.2% 1,361.3 BC 60.1% 1,337.0 UC 59.4% 1,321.9 UB 59.0% 1,312.5 B 58.6% 1,303.7 C 58.6% 1,304.2 stump 52.6% 1,171.0 U 51.5% 1,146.0 majority 47.4% 1,053.7 using the relevant combinations of letters.",
                    "sid": 71,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For exam\u00adple, UBC refers to a three member ensemble consist\u00ading of unigram (U), bigram (B), and co\u2013occurrence (C) decision trees, while BC refers to a two member ensemble of bigram (B) and co-occurrence (C) deci\u00adsion trees.",
                    "sid": 72,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Note of course that UBC is synonymous with Duluth38.",
                    "sid": 73,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Table 1 shows that Duluth38 (UBC) achieves ac\u00adcuracy signi.cantly better than the lower bounds represented by the majority classi.er and the de\u00adcision stump, and comes within seven percentage points of the most accurate systems in each of the three lexical sample tasks.",
                    "sid": 74,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "However, UBC does not signi.cantly improve upon all of its member clas\u00adsi.ers, suggesting that the ensemble is made up of redundant rather than complementary classi.ers.",
                    "sid": 75,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In general the accuracies of the bigram (B) and co\u2013occurrence (C) decision trees are never signi.\u00adcantly different than the accuracy attained by the en\u00adsembles of which they are members (UB, BC, UC, and UBC), nor are they signi.cantly different from each other.",
                    "sid": 76,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This is an intriguing result, since the co\u2013occurrences represent a much smaller feature set than bigrams, which are in turn much smaller than the unigram feature set.",
                    "sid": 77,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Thus, the smallest of our feature sets is the most effective.",
                    "sid": 78,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This may be due to the fact that small feature sets are least likely to suf\u00adfer from fragmentation during decision tree learning.",
                    "sid": 79,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Of the three individual bagged decision trees U, B, and C, the unigram tree (U) is signi.cantly less accurate for all three lexical samples.",
                    "sid": 80,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "It is only slightly more accurate than the decision stump for both English lexical samples, and is less accurate than the decision stump in the Spanish task.",
                    "sid": 81,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The relatively poor performance of unigrams can be accounted for by the large number of possible features.",
                    "sid": 82,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Unigram features consist of all words not in the stop\u2013list that occur .ve or more times in the training examples for a word.",
                    "sid": 83,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The decision tree learner must search through a very large feature space, and under such circumstances may fall vic\u00adtim to fragmentation.",
                    "sid": 84,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Despite these results, we are not prepared to dis\u00admiss the use of ensembles or unigram decision trees.",
                    "sid": 85,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "An ensemble of unigram and co\u2013occurrence de\u00adcision trees (UC) results in greater accuracy than any other lexical decision tree for the English SENSEVAL1 lexical sample, and is essentially tied with the most accurate of these approaches (UBC) in the English SENSEVAL2 lexical sample.",
                    "sid": 86,
                    "ssid": 18,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In princi\u00adple unigrams and co\u2013occurrence features are com\u00adplementary, since unigrams represent topical con\u00adtext, and co\u2013occurrences represent local context.",
                    "sid": 87,
                    "ssid": 19,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This follows the line of reasoning developed by (Leacock et al., 1998) in formulating their ensemble of Naive Bayesian classi.ers for word sense disam\u00adbiguation.",
                    "sid": 88,
                    "ssid": 20,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Adding the bigram decision tree (B) to the ensem\u00adble of the unigram and co\u2013occurrence decision trees (UC) to create UBC does not result in signi.cant improvements in accuracy for the any of the lexical samples.",
                    "sid": 89,
                    "ssid": 21,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This re.ects the fact that the bigram and co\u2013occurrence feature sets can be redundant.",
                    "sid": 90,
                    "ssid": 22,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Bi-grams are two word sequences that occur anywhere within the context of the ambiguous word, while co\u2013occurrences are bigrams that include the target word and a word one or two positions away.",
                    "sid": 91,
                    "ssid": 23,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Thus, any consecutive two word sequence that includes the word to be disambiguated and has a log\u2013likelihood ratio greater than the speci.ed threshold will be con\u00adsidered both a bigram and a co\u2013occurrence.",
                    "sid": 92,
                    "ssid": 24,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Despite the partial overlap between bigrams and co\u2013occurrences, we believe that retaining them as separate feature sets is a reasonable idea.",
                    "sid": 93,
                    "ssid": 25,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We have observed that an ensemble of multiple decision trees where each is learned from a representation of the training examples that has a small number of fea\u00adtures is more accurate than a single decision tree that is learned from one large representation of the training examples.",
                    "sid": 94,
                    "ssid": 26,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example, we mixed the bi-gram and co\u2013occurrence features into a single fea\u00adture set, and then learned a single bagged decision tree from this representation of the training exam\u00adples.",
                    "sid": 95,
                    "ssid": 27,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We observed drops in accuracy in both the Spanish and English SENSEVAL2 lexical sample tasks.",
                    "sid": 96,
                    "ssid": 28,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For Spanish it falls from 59.4% to 58.2%, and for English it drops from 57.2% to 54.9%.",
                    "sid": 97,
                    "ssid": 29,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Interest\u00adingly enough, this mixed feature set of bigrams and co\u2013occurrences results in a slight increase over an ensemble of the two in the SENSEVAL1 data, rising from 71.3% to 71.5%.",
                    "sid": 98,
                    "ssid": 30,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "agreement among systems. ",
            "number": "6",
            "sents": [
                {
                    "text": "The results in Table 1 show that UBC and its mem\u00adber classi.ers perform at levels of accuracy signif\u00adicantly higher than the majority classi.er and de\u00adcision stumps, and approach the level of some of the more accurate systems.",
                    "sid": 99,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This poses an intrigu\u00ading possibility.",
                    "sid": 100,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "If UBC is making complementary errors to those other systems, then it might be pos\u00adsible to combine these systems to achieve an even higher level of accuracy.",
                    "sid": 101,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The alternative is that the decision trees based on lexical features are largely redundant with these other systems, and that there is a hard core of test instances that are resistant to disambiguation by any of these systems.",
                    "sid": 102,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We performed a series of pairwise comparisons to establish the degree to which these systems agree.",
                    "sid": 103,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We included the two most accurate participating sys\u00adtems from each of the three lexical sample tasks, along with UBC, a decision stump, and a majority classi.er.",
                    "sid": 104,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In Table 2 the column labeled \u201cboth\u201d shows the percentage and count of test instances where both systems are correct, the column labeled \u201cone\u201d shows the percentage and count where only one of the two systems is correct, and the column labeled \u201cnone\u201d shows how many test instances were not correctly disambiguated by either system.",
                    "sid": 105,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We note that in the pairwise comparisons there is a high level of agreement for the instances that both systems were able to disambiguate, regardless of the systems in\u00advolved.",
                    "sid": 106,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Forexample,intheSENSEVAL1resultsthe three pairwise comparisons among UBC, hopkins\u00adrevised, and etspu-revised all show that approxi\u00admately 65% of the test instances are correctly dis\u00adambiguated by both systems.",
                    "sid": 107,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The same is true for the English and Spanish lexical sample tasks in SENSEVAL2, where each pairwise comparison re\u00adsults in agreement in approximately half the test in\u00adstances.",
                    "sid": 108,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Next we extend this study of agreement to a three\u2013 way comparison between UBC, hopkins-revised, and etspu-revised for the SENSEVAL1 lexical sam\u00adple.",
                    "sid": 109,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "There are 4,507 test instances where all three systems agree (60.5%), and 973 test instances (13.1%) that none of the three is able to get correct.",
                    "sid": 110,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "These are remarkably similar values to the pair\u2013wise comparisons, suggesting that there is a fairly consis\u00adtent number of test instances that all three systems handle in the same way.",
                    "sid": 111,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "When making a .ve\u2013way comparison that includes these three systems and the decision stump and the majority classi.er, the num Table 2: System Pairwise Agreement system pair both one zero ber of test instances that no system can disambiguate 7 Duluth38 Background English SENSEVAL1 hopkins etspu 67.8% 17.1% 12.1% 5,045 1,274 1,126 UBC hopkins 64.8% 18.3% 17.0% 4,821 1,361 1,263 UBC etspu 64.4% 17.4% 18.2% 4,795 1,295 1,355 stump majority 53.4% 13.7% 32.9% 3,974 1,022 2,448 English SENSEVAL2 JHU(R) SMUls 50.4% 27.3% 22.3% 2,180 1,183 965 UBC JHU(R) 49.2% 24.1% 26.8% 2,127 1,043 1,158 UBC SMUls 47.2% 27.5% 25.2% 2,044 1,192 1,092 stump majority 45.2% 11.8% 43.0% 1,955 511 1,862 Spanish SENSEVAL2 JHU(R) cs224n 52.9% 29.3% 17.8% 1,177 651 397 UBC cs224n 52.8% 23.2% 24.0% 1,175 517 533 UBC JHU(R) 48.3% 33.5% 18.2% 1,074 746 405 stump majority 45.4% 20.4% 34.2% 1,011 453 761 correctly drops to 888, or 11.93%.",
                    "sid": 112,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This is interest\u00ading in that it shows there are nearly 100 test instances that are only disambiguated correctly by the decision stump or the majority classi.er, and not by any of the other three systems.",
                    "sid": 113,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This suggests that very simple classi.ers are able to resolve some test instances that more complex techniques miss. The agreement when making a three way compar\u00adison between UBC, JHU(R), and SMUls in the En\u00adglish SENSEVAL2 lexical sample drops somewhat from the pair\u2013wise levels.",
                    "sid": 114,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "There are 1,791 test in\u00adstances that all three systems disambiguate correctly (41.4%) and 828 instances that none of these sys\u00adtems get correct (19.1%).",
                    "sid": 115,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "When making a .ve way comparison between these three systems, the deci\u00adsion stump and the majority classi.er, there are 755 test instances (17.4%) that no system can resolve.",
                    "sid": 116,
                    "ssid": 18,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This shows that these three systems are performing somewhat differently, and do not agree as much as the SENSEVAL1 systems.",
                    "sid": 117,
                    "ssid": 19,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The agreement when making a three way com\u00adparison between UBC, JHU(R), and cs224n in the Spanish lexical sample task of SENSEVAL2 re\u00admains fairly consistent with the pairwise compar\u00adisons.",
                    "sid": 118,
                    "ssid": 20,
                    "kind_of_tag": "s"
                },
                {
                    "text": "There are 960 test instances that all three systems get correct (43.2%), and 308 test instances where all three systems failed (13.8%).",
                    "sid": 119,
                    "ssid": 21,
                    "kind_of_tag": "s"
                },
                {
                    "text": "When mak\u00ading a .ve way comparison between these three sys\u00adtems and the decision stump and the majority classi\u00ad.er, there were 237 test instances (10.7%) where no systems was able to resolve the sense.",
                    "sid": 120,
                    "ssid": 22,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Here again we see three systems that are handling quite a few test instances in the same way.",
                    "sid": 121,
                    "ssid": 23,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Finally, the number of cases where neither the de\u00adcision stump nor the majority classi.er is correct varies from 33% to 43% across the three lexical sam\u00adples.",
                    "sid": 122,
                    "ssid": 24,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This suggests that the optimal combination of a majority classi.er and decision stump could attain overall accuracy between 57% and 66%, which is comparable with some of the better results for these lexical samples.",
                    "sid": 123,
                    "ssid": 25,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Of course, how to achieve such an optimal combination is an open question.",
                    "sid": 124,
                    "ssid": 26,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This is still an interesting point, since it suggests that there is a relatively large number of test instances that require fairly minimal information to disambiguate successfully.",
                    "sid": 125,
                    "ssid": 27,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The origins of Duluth38 can be found in an ensem\u00adble approach based on multiple Naive Bayesian clas\u00adsi.ers that perform disambiguation via a majority vote (Pedersen, 2000).",
                    "sid": 126,
                    "ssid": 28,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Each member of the ensem\u00adble is based on unigram features that occur in vary\u00ading sized windows of context to the left and right of the ambiguous word.",
                    "sid": 127,
                    "ssid": 29,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The sizes of these windows are 0, 1, 2, 3, 4, 5, 10, 25, and 50 words to the left and to the right, essentially forming bags of words to the left and right.",
                    "sid": 128,
                    "ssid": 30,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The accuracy of this ensemble disam\u00adbiguating the nouns interest (89%) and line (88%) is as high as any previously published results.",
                    "sid": 129,
                    "ssid": 31,
                    "kind_of_tag": "s"
                },
                {
                    "text": "How\u00adever, each ensemble consists of 81 Naive Bayesian classi.ers, making it dif.cult to determine which features and classi.ers were contributing most sig\u00adni.cantly to disambiguation.",
                    "sid": 130,
                    "ssid": 32,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The frustration with models that lack an intuitive interpretation led to the development of decision trees based on bigram features (Pedersen, 2001a).",
                    "sid": 131,
                    "ssid": 33,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This is quite similar to the bagged decision trees of bigrams (B) presented here, except that the ear\u00adlier work learns a single decision tree where training examples are represented by the top 100 ranked bi-grams, according to the log\u2013likelihood ratio.",
                    "sid": 132,
                    "ssid": 34,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This earlier approach was evaluated on the SENSEVAL\u00ad1 data and achieved an overall accuracy of 64%, whereas the bagged decision tree presented here achieves an accuracy of 68% on that data.",
                    "sid": 133,
                    "ssid": 35,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Our interest in co\u2013occurrence features is inspired by (Choueka and Lusignan, 1985), who showed that humans determine the meaning of ambiguous words largely based on words that occur within one or two positions to the left and right.",
                    "sid": 134,
                    "ssid": 36,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Co\u2013occurrence features, generically de.ned as bigrams where one of the words is the target word and the other oc\u00adcurs within a few positions, have been widely used in computational approaches to word sense disam\u00adbiguation.",
                    "sid": 135,
                    "ssid": 37,
                    "kind_of_tag": "s"
                },
                {
                    "text": "When the impact of mixed feature sets on disambiguation is analyzed, co\u2013occurrences usu\u00adally prove to contribute signi.cantly to overall ac\u00adcuracy.",
                    "sid": 136,
                    "ssid": 38,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This is certainly our experience, where the co\u2013occurrence decision tree (C) is the most accurate of the individual lexical decision trees.",
                    "sid": 137,
                    "ssid": 39,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Likewise, (Ng and Lee, 1996) report overall accuracy for the noun interest of 87%, and .nd that that when their feature set only consists of co\u2013occurrence features the accuracy only drops to 80%.",
                    "sid": 138,
                    "ssid": 40,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Our interest in bigrams was indirectly motivated by (Leacock et al., 1998), who describe an ensem\u00adble approach made up of local context and topical context.",
                    "sid": 139,
                    "ssid": 41,
                    "kind_of_tag": "s"
                },
                {
                    "text": "They suggest that topical context can be represented by words that occur anywhere in a win\u00addow of context, while local contextual features are words that occur within close proximity to the target word.",
                    "sid": 140,
                    "ssid": 42,
                    "kind_of_tag": "s"
                },
                {
                    "text": "They show that in disambiguating the adjec\u00adtive hard and the verb serve that the local context is most important, while for the noun line the topical context is most important.",
                    "sid": 141,
                    "ssid": 43,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We believe that statisti\u00adcally signi.cant bigrams that occur anywhere in the window of context can serve the same role, in that such a two word sequence is likely to carry heavy semantic (topical) or syntactic (local) weight.",
                    "sid": 142,
                    "ssid": 44,
                    "kind_of_tag": "s"
                },
                {
                    "text": "8 Conclusion.",
                    "sid": 143,
                    "ssid": 45,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This paper analyzes the performance of the Duluth3 and Duluth8 systems that participated in the English and Spanish lexical sample tasks in SENSEVAL\u00ad 2.",
                    "sid": 144,
                    "ssid": 46,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We .nd that an ensemble offers very limited improvement over individual decision trees based on lexical features.",
                    "sid": 145,
                    "ssid": 47,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Co\u2013occurrence decision trees are more accurate than bigram or unigram decision trees, and are nearly as accurate as the full ensemble.",
                    "sid": 146,
                    "ssid": 48,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This is an encouraging result, since the number of co\u2013occurrence features is relatively small and easy to learn from compared to the number of bigram or unigram features..",
                    "sid": 147,
                    "ssid": 49,
                    "kind_of_tag": "s"
                },
                {
                    "text": "9 Acknowledgments.",
                    "sid": 148,
                    "ssid": 50,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This work has been partially supported by a National Science Foundation Faculty Early CAREER Devel\u00adopment award (#0092784).",
                    "sid": 149,
                    "ssid": 51,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The Duluth38 system (and all other Du\u00adluth systems that participated in SENSEVAL2) can be downloaded from the author\u2019s web site: http://www.d.umn.edu/\u02dctpederse/code.html.",
                    "sid": 150,
                    "ssid": 52,
                    "kind_of_tag": "s"
                }
            ]
        }
    ]
}