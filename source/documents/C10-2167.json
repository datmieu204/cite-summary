{
    "ID": "C10-2167",
    "sections": [
        {
            "text": "abstract",
            "number": 0,
            "sents": [
                {
                    "text": "An important task of opinion mining is to extract people\u2019s opinions on features of an entity.",
                    "sid": 1,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example, the sentence, \u201cI love the GPS function of Motorola Droid\u201d expresses a positive opinion on the \u201cGPS function\u201d of the Motorola phone.",
                    "sid": 2,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "\u201cGPS function\u201d is the feature.",
                    "sid": 3,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This paper focuses on mining features.",
                    "sid": 4,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Double propagation is a state-of-the-art technique for solving the problem.",
                    "sid": 5,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "It works well for medium-size corpora.",
                    "sid": 6,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "However, for large and small corpora, it can result in low precision and low recall.",
                    "sid": 7,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "To deal with these two problems, two improvements based on part-whole and \u201cno\u201d patterns are introduced to increase the recall.",
                    "sid": 8,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Then feature ranking is applied to the extracted feature candidates to improve the precision of the top-ranked candidates.",
                    "sid": 9,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We rank feature candidates by feature importance which is determined by two factors: feature relevance and feature frequency.",
                    "sid": 10,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The problem is formulated as a bipartite graph and the well-known web page ranking algorithm HITS is used to find important features and rank them high.",
                    "sid": 11,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Experiments on diverse real-life datasets show promising results.",
                    "sid": 12,
                    "ssid": 12,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "introduction",
            "number": "1",
            "sents": [
                {
                    "text": "In recent years, opinion mining or sentiment analysis (Liu, 2010; Pang and Lee, 2008) has been an active research area in NLP.",
                    "sid": 13,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "One task is to extract people\u2019s opinions expressed on features of entities (Hu and Liu, 2004).",
                    "sid": 14,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example, the sentence, \u201cThe picture of this camera is amazing\u201d, expresses a positive opinion on the picture of the camera.",
                    "sid": 15,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "\u201cpicture\u201d is the feature.",
                    "sid": 16,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "How to extract features from a corpus is an important problem.",
                    "sid": 17,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "There are several studies on feature extraction (e.g., Hu and Liu, 2004, Popescu and Etzioni, 2005, Kobayashi et al., 2007, Scaffidi et al., 2007, Stoyanov and Cardie.",
                    "sid": 18,
                    "ssid": 18,
                    "kind_of_tag": "s"
                },
                {
                    "text": "2008, Wong et al., 2008, Qiu et al., 2009).",
                    "sid": 19,
                    "ssid": 19,
                    "kind_of_tag": "s"
                },
                {
                    "text": "However, this problem is far from being solved.",
                    "sid": 20,
                    "ssid": 20,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Double Propagation (Qiu et al., 2009) is a state-of-the-art unsupervised technique for solving the problem.",
                    "sid": 21,
                    "ssid": 21,
                    "kind_of_tag": "s"
                },
                {
                    "text": "It mainly extracts noun features, and works well for medium-size corpora.",
                    "sid": 22,
                    "ssid": 22,
                    "kind_of_tag": "s"
                },
                {
                    "text": "But for large corpora, this method can introduce a great deal of noise (low precision), and for small corpora, it can miss important features.",
                    "sid": 23,
                    "ssid": 23,
                    "kind_of_tag": "s"
                },
                {
                    "text": "To deal with these two problems, we propose a new feature mining method, which enhances that in (Qiu et al., 2009).",
                    "sid": 24,
                    "ssid": 24,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Firstly, two improvements based on part-whole patterns and \u201cno\u201d patterns are introduced to increase recall.",
                    "sid": 25,
                    "ssid": 25,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Part-whole or meronymy is an important semantic relation in NLP, which indicates that one or more objects are parts of another object.",
                    "sid": 26,
                    "ssid": 26,
                    "kind_of_tag": "s"
                },
                {
                    "text": "1462 Coling 2010: Poster Volume, pages 1462\u20131470, Beijing, August 2010 For example, the phrase \u201cthe engine of the car\u201d contains the part-whole relation that \u201cengine\u201d is part of \u201ccar\u201d.",
                    "sid": 27,
                    "ssid": 27,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This relation is very useful for feature extraction, because if we know one object is part of a product class, this object should be a feature.",
                    "sid": 28,
                    "ssid": 28,
                    "kind_of_tag": "s"
                },
                {
                    "text": "\u201cno\u201d pattern is another extraction pattern.",
                    "sid": 29,
                    "ssid": 29,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Its basic form is the word \u201cno\u201d followed by a noun/noun phrase, for instance, \u201cno noise\u201d.",
                    "sid": 30,
                    "ssid": 30,
                    "kind_of_tag": "s"
                },
                {
                    "text": "People often express their short comments or opinions on features using this pattern.",
                    "sid": 31,
                    "ssid": 31,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Both types of patterns can help find features missed by double propagation.",
                    "sid": 32,
                    "ssid": 32,
                    "kind_of_tag": "s"
                },
                {
                    "text": "As for the low precision problem, we present a feature ranking approach to tackle it.",
                    "sid": 33,
                    "ssid": 33,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We rank feature candidates based on their importance which consists of two factors: feature relevance and feature frequency.",
                    "sid": 34,
                    "ssid": 34,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The basic idea of feature importance ranking is that if a feature candidate is correct and frequently mentioned in a corpus, it should be ranked high; otherwise it should be ranked low in the final result.",
                    "sid": 35,
                    "ssid": 35,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Feature frequency is the occurrence frequency of a feature in a corpus, which is easy to obtain.",
                    "sid": 36,
                    "ssid": 36,
                    "kind_of_tag": "s"
                },
                {
                    "text": "However, assessing feature relevance is challenging.",
                    "sid": 37,
                    "ssid": 37,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We model the problem as a bipartite graph and use the well-known web page ranking algorithm HITS (Kleinberg, 1999) to find important features and rank them high.",
                    "sid": 38,
                    "ssid": 38,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Our experimental results show superior performances.",
                    "sid": 39,
                    "ssid": 39,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In practical applications, we believe that ranking is also important for feature mining because ranking can help users to discover important features from the extracted hundreds of fine-grained candidate features efficiently.",
                    "sid": 40,
                    "ssid": 40,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "related work. ",
            "number": "2",
            "sents": [
                {
                    "text": "Hu and Liu (2004) proposed a technique based on association rule mining to extract product features.",
                    "sid": 41,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The main idea is that people often use the same words when they comment on the same product features.",
                    "sid": 42,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Then frequent itemsets of nouns in reviews are likely to be product features while the infrequent ones are less likely to be product features.",
                    "sid": 43,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This work also introduced the idea of using opinion words to find additional (often infrequent) features.",
                    "sid": 44,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Popescu and Etzioni (2005) investigated the same problem.",
                    "sid": 45,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Their algorithm requires that the product class is known.",
                    "sid": 46,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The algorithm determines whether a noun/noun phrase is a feature by computing the pointwise mutual information (PMI) score between the phrase and class- specific discriminators, e.g., \u201cof xx\u201d, \u201cxx has\u201d, \u201cxx comes with\u201d, etc., where xx is a product class.",
                    "sid": 47,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This work first used part-whole patterns for feature mining, but it finds part-whole based features by searching the Web.",
                    "sid": 48,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Querying the Web is time-consuming.",
                    "sid": 49,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In our method, we use predefined part-whole relation patterns to extract features in a domain corpus.",
                    "sid": 50,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "These patterns are domain-independent and fairly accurate.",
                    "sid": 51,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Following the initial work in (Hu and Liu 2004), several researchers have further explored the idea of using opinion words in product feature mining.",
                    "sid": 52,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "A dependency based method was proposed in (Zhuang et al., 2006) for a movie review analysis application.",
                    "sid": 53,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Qiu et al.",
                    "sid": 54,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "(2009) proposed a double propagation method, which exploits certain syntactic relations of opinion words and features, and propagates through both opinion words and features iteratively.",
                    "sid": 55,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The extraction rules are designed based on different relations between opinion words and features, and among opinion words and features themselves.",
                    "sid": 56,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Dependency grammar was adopted to describe these relations.",
                    "sid": 57,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In (Wang and Wang, 2008), another bootstrapping method was proposed.",
                    "sid": 58,
                    "ssid": 18,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In (Kobayashi et al. 2007), a pattern mining method was used.",
                    "sid": 59,
                    "ssid": 19,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The patterns are relations between feature and opinion pairs (they call aspect-evaluation pairs).",
                    "sid": 60,
                    "ssid": 20,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The patterns are mined from a large corpus using pattern mining.",
                    "sid": 61,
                    "ssid": 21,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Statistics from the corpus are used to determine the confidence scores of the extraction.",
                    "sid": 62,
                    "ssid": 22,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In general information extraction, there are two approaches: rule-based and statistical.",
                    "sid": 63,
                    "ssid": 23,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Early extraction systems are mainly based on rules (e.g., Riloff, 1993).",
                    "sid": 64,
                    "ssid": 24,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In statistical methods, the most popular models are Hidden Markov Models (HMM) (Rabiner, 1989), Maximum Entropy Models (ME) (Chieu et al., 2002) and Conditional Random Fields (CRF) (Lafferty et al., 2001).",
                    "sid": 65,
                    "ssid": 25,
                    "kind_of_tag": "s"
                },
                {
                    "text": "CRF has been shown to be the most effective method.",
                    "sid": 66,
                    "ssid": 26,
                    "kind_of_tag": "s"
                },
                {
                    "text": "It was used in (Stoyanov et al., 2008).",
                    "sid": 67,
                    "ssid": 27,
                    "kind_of_tag": "s"
                },
                {
                    "text": "However, a limitation of CRF is that it only captures local patterns rather than long range patterns.",
                    "sid": 68,
                    "ssid": 28,
                    "kind_of_tag": "s"
                },
                {
                    "text": "It has been shown in (Qiu et al., 2009) that many feature and opinion word pairs have long range dependencies.",
                    "sid": 69,
                    "ssid": 29,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Experimental results in (Qiu et al., 2009) indicate that CRF does not perform well.",
                    "sid": 70,
                    "ssid": 30,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Other related works on feature extraction mainly use topic modeling to capture topics in reviews (Mei et al., 2007).",
                    "sid": 71,
                    "ssid": 31,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In (Su et al., 2008), the authors also proposed a clustering based method with mutual reinforcement to identify features.",
                    "sid": 72,
                    "ssid": 32,
                    "kind_of_tag": "s"
                },
                {
                    "text": "However, topic modeling or clustering is only able to find some general/rough features, and has difficulty in finding fine-grained or precise features, which is more related to information extraction.",
                    "sid": 73,
                    "ssid": 33,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "the proposed method. ",
            "number": "3",
            "sents": [
                {
                    "text": "As discussed in the introduction section, our proposed method deals with the problems of double propagation.",
                    "sid": 74,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "So let us give a short explanation why double propagation can cause problems in large or small corpora.",
                    "sid": 75,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Double propagation assumes that features are nouns/noun phrases and opinion words are adjectives.",
                    "sid": 76,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "It is shown that opinion words are usually associated with features in some ways.",
                    "sid": 77,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Thus, opinion words can be recognized by identified features, and features can be identified by known opinion words.",
                    "sid": 78,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The extracted opinion words and features are utilized to identify new opinion words and new features, which are used again to extract more opinion words and features.",
                    "sid": 79,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This propagation or bootstrapping process ends when no more opinion words or features can be found.",
                    "sid": 80,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The biggest advantage of the method is that it requires no additional resources except an initial seed opinion lexicon, which is readily available (Wilson et al., 2005, Ding et al., 2008).",
                    "sid": 81,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Thus it is domain independent and unsupervised, avoiding laborious and time- consuming work of labeling data for supervised learning methods.",
                    "sid": 82,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "It works well for medium\u2013 size corpora.",
                    "sid": 83,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "But for large corpora, this method may extract many nouns/noun phrases which are not features.",
                    "sid": 84,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The precision of the method thus drops.",
                    "sid": 85,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The reason is that during propagation, adjectives which are not opinionated will be extracted as opinion words, e.g., \u201centire\u201d and \u201ccurrent\u201d.",
                    "sid": 86,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "These adjectives are not opinion words but they can modify many kinds of nouns/noun phrases, thus leading to extracting wrong features.",
                    "sid": 87,
                    "ssid": 14,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Iteratively, more and more noises may be introduced during the process.",
                    "sid": 88,
                    "ssid": 15,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The other problem is that for certain domains, some important features do not have opinion words modifying them.",
                    "sid": 89,
                    "ssid": 16,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example, in reviews of mattresses, a reviewer may say \u201cThere is a valley on my mattress\u201d, which implies a nega tive opinion because \u201cvalley\u201d is undesirable for a mattress.",
                    "sid": 90,
                    "ssid": 17,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Obviously, \u201cvalley\u201d is a feature, but \u201cvalley\u201d may not be described by any opinion adjective, especially for a small corpus.",
                    "sid": 91,
                    "ssid": 18,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Double propagation is not applicable in this situation.",
                    "sid": 92,
                    "ssid": 19,
                    "kind_of_tag": "s"
                },
                {
                    "text": "To deal with the problem, we propose a novel method to mine features, which consists of two steps: feature extraction and feature ranking.",
                    "sid": 93,
                    "ssid": 20,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For feature extraction, we still adopt the double propagation idea to populate feature candidates.",
                    "sid": 94,
                    "ssid": 21,
                    "kind_of_tag": "s"
                },
                {
                    "text": "But two improvements based on part-whole relation patterns and a \u201cno\u201d pattern are made to find features which double propagation cannot find.",
                    "sid": 95,
                    "ssid": 22,
                    "kind_of_tag": "s"
                },
                {
                    "text": "They can solve part of the recall problem.",
                    "sid": 96,
                    "ssid": 23,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For feature ranking, we rank feature candidates by feature importance.",
                    "sid": 97,
                    "ssid": 24,
                    "kind_of_tag": "s"
                },
                {
                    "text": "A part-whole pattern indicates one object is part of another object.",
                    "sid": 98,
                    "ssid": 25,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For the previous example \u201cThere is a valley on my mattress\u201d, we can find that it contains a part-whole relation between \u201cvalley\u201d and \u201cmattress\u201d.",
                    "sid": 99,
                    "ssid": 26,
                    "kind_of_tag": "s"
                },
                {
                    "text": "\u201cvalley\u201d belongs to \u201cmattress\u201d, which is indicated by the preposition \u201con\u201d.",
                    "sid": 100,
                    "ssid": 27,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Note that \u201cvalley\u201d is not actually a part of mattress, but an effect on the mattress.",
                    "sid": 101,
                    "ssid": 28,
                    "kind_of_tag": "s"
                },
                {
                    "text": "It is called a pseudo part-whole relation.",
                    "sid": 102,
                    "ssid": 29,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For simplicity, we will not distinguish it from an actual part-whole relation because for our feature mining task, they have little difference.",
                    "sid": 103,
                    "ssid": 30,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In this case, \u201cnoun1 on noun2\u201d is a good indicative pattern which implies noun1 is part of noun2.",
                    "sid": 104,
                    "ssid": 31,
                    "kind_of_tag": "s"
                },
                {
                    "text": "So if we know \u201cmattress\u201d is a class concept, we can infer that \u201cvalley\u201d is a feature for \u201cmattress\u201d.",
                    "sid": 105,
                    "ssid": 32,
                    "kind_of_tag": "s"
                },
                {
                    "text": "There are many phrase or sentence patterns representing this type of semantic relation which was studied in (Girju et al, 2006).",
                    "sid": 106,
                    "ssid": 33,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Beside part-whole patterns, \u201cno\u201d pattern is another important and specific feature indicator in opinion documents.",
                    "sid": 107,
                    "ssid": 34,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We introduce these patterns in detail in Sections 3.2 and 3.3.",
                    "sid": 108,
                    "ssid": 35,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Now let us deal with the first problem: noise.",
                    "sid": 109,
                    "ssid": 36,
                    "kind_of_tag": "s"
                },
                {
                    "text": "With opinion words, part-whole and \u201cno\u201d patterns, we have three feature indicators at hands, but all of them are ambiguous, which means that they are not hard rules.",
                    "sid": 110,
                    "ssid": 37,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We will inevitably extract wrong features (also called noises) byusing them.",
                    "sid": 111,
                    "ssid": 38,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Pruning noises from feature candi dates is a hard task.",
                    "sid": 112,
                    "ssid": 39,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Instead, we propose a new angle for solving this problem: feature ranking.",
                    "sid": 113,
                    "ssid": 40,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The basic idea is that we rank the extracted feature candidates by feature importance.",
                    "sid": 114,
                    "ssid": 41,
                    "kind_of_tag": "s"
                },
                {
                    "text": "If a feature candidate is correct and important, it should be ranked high.",
                    "sid": 115,
                    "ssid": 42,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For unimportant feature or noise, it should be ranked low in the final result.",
                    "sid": 116,
                    "ssid": 43,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Ranking is also very useful in practice.",
                    "sid": 117,
                    "ssid": 44,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In a large corpus, we may extract hundreds of fine- grained features.",
                    "sid": 118,
                    "ssid": 45,
                    "kind_of_tag": "s"
                },
                {
                    "text": "But the user often only cares about those important ones, which should be ranked high.",
                    "sid": 119,
                    "ssid": 46,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We identified two major factors affecting the feature importance: one is feature relevance and the other is feature frequency.",
                    "sid": 120,
                    "ssid": 47,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Feature relevance: it describes how possible a feature candidate is a correct feature.",
                    "sid": 121,
                    "ssid": 48,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We find that there are three strong clues to indicate feature relevance in a corpus.",
                    "sid": 122,
                    "ssid": 49,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The first clue is that a correct feature is often modified by multiple opinion words (adjectives or adverbs).",
                    "sid": 123,
                    "ssid": 50,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example, in the mattress domain, \u201cdelivery\u201d is modified by \u201cquick\u201d \u201ccumbersome\u201d and \u201ctimely\u201d.",
                    "sid": 124,
                    "ssid": 51,
                    "kind_of_tag": "s"
                },
                {
                    "text": "It shows that reviewers put emphasis on the word \u201cdelivery\u201d.",
                    "sid": 125,
                    "ssid": 52,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Thus we can infer that \u201cdelivery\u201d is a possible feature.",
                    "sid": 126,
                    "ssid": 53,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The second clue is that a feature could be extracted by multiple part-whole patterns.",
                    "sid": 127,
                    "ssid": 54,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example, in the car domain, if we find following two phrases, \u201cthe engine of the car\u201d and \u201cthe car has a big engine\u201d, we can infer that \u201cengine\u201d is a feature for car, because both phrases contain part-whole relations to indicate \u201cengine\u201d is a part of \u201ccar\u201d.",
                    "sid": 128,
                    "ssid": 55,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The third clue is the combination of opinion word modification, part-whole pattern extraction and \u201cno\u201d pattern extraction.",
                    "sid": 129,
                    "ssid": 56,
                    "kind_of_tag": "s"
                },
                {
                    "text": "That is, if a feature candidate is not only modified by opinion words but also extracted by part-whole or \u201cno\u201d patterns, we can infer that it is a feature with high confidence.",
                    "sid": 130,
                    "ssid": 57,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example, for sentence \u201cthere is a bad hole in the mattress\u201d, it strongly indicates that \u201chole\u201d is a feature for a mattress because it is modified by opinion word \u201cbad\u201d and also in the part-whole pattern.",
                    "sid": 131,
                    "ssid": 58,
                    "kind_of_tag": "s"
                },
                {
                    "text": "What is more, we find that there is a mutual enforcement relation between opinion words, part- whole and \u201cno\u201d patterns, and features.",
                    "sid": 132,
                    "ssid": 59,
                    "kind_of_tag": "s"
                },
                {
                    "text": "If an adjective modifies many correct features, it is highly possible to be a good opinion word.",
                    "sid": 133,
                    "ssid": 60,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Similarly, if a feature candidate can be extracted by many opinion words, part-whole patterns, or \u201cno\u201d pattern, it is also highly likely to be a correct feature.",
                    "sid": 134,
                    "ssid": 61,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This indicates that the Web page ranking algorithm HITS is applicable.",
                    "sid": 135,
                    "ssid": 62,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Feature frequency: This is another important factor affecting feature ranking.",
                    "sid": 136,
                    "ssid": 63,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Feature frequency has been considered in (Hu and Liu, 2004; BlairGoldensohn et al., 2008).",
                    "sid": 137,
                    "ssid": 64,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We consider a feature f1 to be more important than fea ture f2 if f1 appears more frequently than f2 in opinion documents.",
                    "sid": 138,
                    "ssid": 65,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In practice, it is desirable to rank those frequent features higher than infrequent features.",
                    "sid": 139,
                    "ssid": 66,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The reason is that missing a frequently mentioned feature in opinion mining is bad, but missing a rare feature is not a big issue.",
                    "sid": 140,
                    "ssid": 67,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Combining the above factors, we propose a new feature mining method.",
                    "sid": 141,
                    "ssid": 68,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Experiments show good results on diverse real-life datasets.",
                    "sid": 142,
                    "ssid": 69,
                    "kind_of_tag": "s"
                },
                {
                    "text": "3.1 Double Propagation.",
                    "sid": 143,
                    "ssid": 70,
                    "kind_of_tag": "s"
                },
                {
                    "text": "As we described above, double propagation is based on the observation that there are natural relations between opinion words and features due to the fact that opinion words are often used to modify features.",
                    "sid": 144,
                    "ssid": 71,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Furthermore, it is observed that opinion words and features themselves have relations in opinionated expressions too (Qiu et al., 2009).",
                    "sid": 145,
                    "ssid": 72,
                    "kind_of_tag": "s"
                },
                {
                    "text": "These relations can be identified via a dependency parser (Lin, 1998) based on the dependency grammar.",
                    "sid": 146,
                    "ssid": 73,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The identification of the relations is the key to feature extraction.",
                    "sid": 147,
                    "ssid": 74,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Dependency grammar: It describes the dependency relations between words in a sentence.",
                    "sid": 148,
                    "ssid": 75,
                    "kind_of_tag": "s"
                },
                {
                    "text": "After parsed by a dependency parser, words in a sentence are linked to each other by a certain relation.",
                    "sid": 149,
                    "ssid": 76,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For a sentence, \u201cThe camera has a good lens\u201d, \u201cgood\u201d is the opinion word and \u201clens\u201d is the feature of camera.",
                    "sid": 150,
                    "ssid": 77,
                    "kind_of_tag": "s"
                },
                {
                    "text": "After parsing, we can find that \u201cgood\u201d depends on \u201clens\u201d with relation mod.",
                    "sid": 151,
                    "ssid": 78,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Here mod means that \u201cgood\u201d is the adjunct modifier for \u201clens\u201d.",
                    "sid": 152,
                    "ssid": 79,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In some cases, an opinion word and a feature are not directly dependent, but they directly depend on a same word.",
                    "sid": 153,
                    "ssid": 80,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example, from the sentence \u201cThe lens is nice\u201d, we can find that both feature \u201clens\u201d and opinion word \u201cnice\u201d depend on the verb \u201cis\u201d with the relation s and pred respectively.",
                    "sid": 154,
                    "ssid": 81,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Here s means that \u201clens\u201d is the surface subject of \u201cis\u201d while pred means that \u201cnice\u201d is the predicate of the \u201cis\u201d clause.",
                    "sid": 155,
                    "ssid": 82,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In (Qiu et al., 2009), it defines two categories of dependency relations to summarize all types of dependency relations between two words, which are illustrated in Figure 1.",
                    "sid": 156,
                    "ssid": 83,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Arrows are used to represent dependencies.",
                    "sid": 157,
                    "ssid": 84,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Direct relations: It represents that one word depends on the other word directly or they both depend on a third word directly, shown in (a) and (b) of Figure 1.",
                    "sid": 158,
                    "ssid": 85,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In (a), B depends on A directly, and in (b) they both directly depend on D. Indirect relation: It represents that one word depends on the other word through other words or they both depend on a third word indirectly.",
                    "sid": 159,
                    "ssid": 86,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example, in (c) of Figure 1, B depends on A through D; in (d) of Figure 1, A depends on D through I1 while B depends on D through I2.",
                    "sid": 160,
                    "ssid": 87,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For some complicated situations, there can be more than one I1 or I2.",
                    "sid": 161,
                    "ssid": 88,
                    "kind_of_tag": "s"
                },
                {
                    "text": "A D B A B (a) (b) A D D I1 I2 B A B (c) (d) Fig.1 Different relations between A and B Parsing indirect relations is error-prone for Web corpora.",
                    "sid": 162,
                    "ssid": 89,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Thus we only use direct relation to extract opinion words and feature candidates in our application.",
                    "sid": 163,
                    "ssid": 90,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For detailed extraction rules, please refer to the paper (Qiu et al., 2009).",
                    "sid": 164,
                    "ssid": 91,
                    "kind_of_tag": "s"
                },
                {
                    "text": "3.2 Part-whole relation.",
                    "sid": 165,
                    "ssid": 92,
                    "kind_of_tag": "s"
                },
                {
                    "text": "As we discussed above, a part-whole relation is a good indicator for features if the class concept word (the \u201cwhole\u201d part) is known.",
                    "sid": 166,
                    "ssid": 93,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example, the compound nominal \u201ccar hood\u201d contains the part-whole relation.",
                    "sid": 167,
                    "ssid": 94,
                    "kind_of_tag": "s"
                },
                {
                    "text": "If we know \u201ccar\u201d is the class concept word, then we can infer that \u201chood\u201d is a feature for car.",
                    "sid": 168,
                    "ssid": 95,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Part-whole patterns occur frequently in text and are expressed by a variety of lexico-syntactic structures (Girju et al, 2006; Popescu and Etzioni, 2005).",
                    "sid": 169,
                    "ssid": 96,
                    "kind_of_tag": "s"
                },
                {
                    "text": "There are two types of lexico-syntactic structures conveying part-whole relations: unambiguous structure and ambiguous structure.",
                    "sid": 170,
                    "ssid": 97,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The unambiguous structure clearly indicates a part-whole relation.",
                    "sid": 171,
                    "ssid": 98,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example, for sentences \u201cthe camera consists of lens, body and power cord.\u201d and \u201cthe bed was made of wood\u201d.",
                    "sid": 172,
                    "ssid": 99,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In these cases, the detection of the patterns leads to the discovery of real part-whole relations.",
                    "sid": 173,
                    "ssid": 100,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We can easily find features of the camera and the bed.",
                    "sid": 174,
                    "ssid": 101,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Unfortunately, this kind of patterns is not very frequent in a corpus.",
                    "sid": 175,
                    "ssid": 102,
                    "kind_of_tag": "s"
                },
                {
                    "text": "However, there are many ambiguous expressions that are explicit but convey part-whole relations only in some contexts.",
                    "sid": 176,
                    "ssid": 103,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example, for two phrases \u201cvalley on the mattress\u201d and \u201ctoy on the mattress\u201d, \u201cvalley\u201d is a part of \u201cmattress\u201d whereas \u201ctoy\u201d is not a part of \u201cmattress\u201d.",
                    "sid": 177,
                    "ssid": 104,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Our idea is to use both the unambiguous and ambiguous patterns.",
                    "sid": 178,
                    "ssid": 105,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Although ambiguous patterns may bring some noise, we can rank them low in the ranking procedure.",
                    "sid": 179,
                    "ssid": 106,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The following two kinds of patterns are what we have utilized for feature extraction.",
                    "sid": 180,
                    "ssid": 107,
                    "kind_of_tag": "s"
                },
                {
                    "text": "3.2.1 Phrase pattern In this case, the part-whole relation exists in a phrase.",
                    "sid": 181,
                    "ssid": 108,
                    "kind_of_tag": "s"
                },
                {
                    "text": "NP + Prep + CP: noun/noun phrase (NP) contains the part word and the class concept phrase (CP) contains the whole word.",
                    "sid": 182,
                    "ssid": 109,
                    "kind_of_tag": "s"
                },
                {
                    "text": "They are connected by the preposition word (Prep).",
                    "sid": 183,
                    "ssid": 110,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example, \u201cbattery of the camera\u201d is an instance of this pattern where NP (battery) is the part noun and CP (camera) is the whole noun.",
                    "sid": 184,
                    "ssid": 111,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For our application, we only use three specific prepositions: \u201cof\u201d, \u201cin\u201d and \u201con\u201d.",
                    "sid": 185,
                    "ssid": 112,
                    "kind_of_tag": "s"
                },
                {
                    "text": "CP + with + NP: likewise, CP is the class concept phrase, and NP is the noun/noun phrase.",
                    "sid": 186,
                    "ssid": 113,
                    "kind_of_tag": "s"
                },
                {
                    "text": "They are connected by the word \u201cwith\u201d.",
                    "sid": 187,
                    "ssid": 114,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Here NP is likely to be a feature.",
                    "sid": 188,
                    "ssid": 115,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example, in a phrase, \u201cmattress with a cover\u201d, \u201ccover\u201d is a feature for mattress.",
                    "sid": 189,
                    "ssid": 116,
                    "kind_of_tag": "s"
                },
                {
                    "text": "NP CP or CP NP: noun/noun phase (NP) and class concept phrase (CP) forms a compound word.",
                    "sid": 190,
                    "ssid": 117,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example, \u201cmattress pad\u201d.",
                    "sid": 191,
                    "ssid": 118,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Here \u201cpad\u201d is a feature of \u201cmattress\u201d.",
                    "sid": 192,
                    "ssid": 119,
                    "kind_of_tag": "s"
                },
                {
                    "text": "3.2.2 Sentence pattern In these patterns, the part-whole relation is indicated in a sentence.",
                    "sid": 193,
                    "ssid": 120,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The patterns contain specific verbs.",
                    "sid": 194,
                    "ssid": 121,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The part word and the whole word can be found inside noun phrases or prepositional phrases which contain specific prepositions.",
                    "sid": 195,
                    "ssid": 122,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We utilize the following patterns in our application.",
                    "sid": 196,
                    "ssid": 123,
                    "kind_of_tag": "s"
                },
                {
                    "text": "\u201cCP Verb NP\u201d: CP is the class concept phrase that contains the whole word, NP is the noun phrase that contains the part word and the verb is restricted and specific.",
                    "sid": 197,
                    "ssid": 124,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example, in a sentence, \u201cthe phone has a big screen\u201d, we can infer that \u201cscreen\u201d is a feature for \u201cphone\u201d, which is a class concept.",
                    "sid": 198,
                    "ssid": 125,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In sentence patterns, verbs play an important role.",
                    "sid": 199,
                    "ssid": 126,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We use indicative verbs to find part-whole relations in a sentence, i.e., \u201chas\u201d, \u201chave\u201d \u201cinclude\u201d \u201ccontain\u201d \u201cconsist\u201d, \u201ccomprise\u201d and so on (Girju et al, 2006).",
                    "sid": 200,
                    "ssid": 127,
                    "kind_of_tag": "s"
                },
                {
                    "text": "It is worth mentioning that in order to use part-whole relations, the class concept word for is the set of pages (or nodes) and E is the set of directed edges (or links).",
                    "sid": 201,
                    "ssid": 128,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We use L to denote the adjacency matrix of the graph.",
                    "sid": 202,
                    "ssid": 129,
                    "kind_of_tag": "s"
                },
                {
                    "text": "a corpus is needed, which is fairly easy to find because the noun with the most frequent occur \u072e\u0bdc\u0bdd \u0d4c \u1244\u0373 \u0745\u0742 \u123a\u0745\u01e1 \u0746\u123b \u05d0 \u0727 \u0372 \u074b\u0750\u0744\u0741\u074e\u0753\u0745\u074f\u0741 (1) rences in a corpus is always the class concept word based on our experiments.",
                    "sid": 203,
                    "ssid": 130,
                    "kind_of_tag": "s"
                },
                {
                    "text": "3.3 \u201cno\u201d Pattern Let the authority score of the page i be A(i), and the hub score of page i be H(i).",
                    "sid": 204,
                    "ssid": 131,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The mutual reinforcing relationship of the two scores is represented as follows: Besides opinion word and part-whole relation, \u201cno\u201d pattern is also an important pattern indicating features in a corpus.",
                    "sid": 205,
                    "ssid": 132,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Here \u201cno\u201d represents \u0723\u123a\u0745\u123b \u0d4c \u03c3\u123a\u0bdd\u01e1\u0bdc\u123b\u05d0\u0bbe \u072a\u123a\u0746\u123b \u072a\u123a\u0745\u123b \u0d4c \u03c3\u123a\u0bdc\u01e1\u0bdd\u123b\u05d0\u0bbe \u0723\u123a\u0746\u123b (2) (3) word no.",
                    "sid": 206,
                    "ssid": 133,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The basic form of the pattern is \u201cno\u201d word followed by noun/noun phrase.",
                    "sid": 207,
                    "ssid": 134,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This simple pattern actually is very useful to feature extraction.",
                    "sid": 208,
                    "ssid": 135,
                    "kind_of_tag": "s"
                },
                {
                    "text": "It is a specific pattern for product reviews and forum posts.",
                    "sid": 209,
                    "ssid": 136,
                    "kind_of_tag": "s"
                },
                {
                    "text": "People often express their comments or opinions on features by this short pattern.",
                    "sid": 210,
                    "ssid": 137,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For example, in a mattress domain, people always say that \u201cno noise\u201d and \u201cno indentation\u201d.",
                    "sid": 211,
                    "ssid": 138,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Here \u201cnoise\u201d and \u201cindentation\u201d are all features for the mattress.",
                    "sid": 212,
                    "ssid": 139,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We discover that this pattern is frequently used in corpora and a very good indicator for features with a fairly high precision.",
                    "sid": 213,
                    "ssid": 140,
                    "kind_of_tag": "s"
                },
                {
                    "text": "But we have to take care of the some fixed \u201cno\u201d expression, like \u201cno problem\u201d \u201cno offense\u201d.",
                    "sid": 214,
                    "ssid": 141,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In these cases, \u201cproblem\u201d and \u201coffense\u201d should not be regarded as features.",
                    "sid": 215,
                    "ssid": 142,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We have a list of such words, which are manually compiled.",
                    "sid": 216,
                    "ssid": 143,
                    "kind_of_tag": "s"
                },
                {
                    "text": "3.4 Bipartite Graph and HITS Algorithm.",
                    "sid": 217,
                    "ssid": 144,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Hyperlink-induced topic search (HITS) is a link analysis algorithm that rates Web pages.",
                    "sid": 218,
                    "ssid": 145,
                    "kind_of_tag": "s"
                },
                {
                    "text": "As discussed in the introduction section, we can apply the HITS algorithm to compute feature relevance for ranking.",
                    "sid": 219,
                    "ssid": 146,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Before illustrating how HITS can be applied to our scenario, let us first give a brief introduction to HITS.",
                    "sid": 220,
                    "ssid": 147,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Given a broad search query q, HITS sends the query to a search engine system, and then collects k (k = 200 in the original paper) highest ranked pages, which are assumed to be highly relevant to the search query.",
                    "sid": 221,
                    "ssid": 148,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This set is called the root set R; then it grows R by including any page pointed to a page in R, then forms a base set S. HITS then works on the pages in S. It assigns every page in S an authority score and a hub score.",
                    "sid": 222,
                    "ssid": 149,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Let the number of pages to be studied be n. We use G = (V, E) to denote the (directed) link graph of S. V We can write them in a matrix form.",
                    "sid": 223,
                    "ssid": 150,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We use A to denote the column vector with all the authority scores, A = (A(1), A(2), \u2026, A(n))T, and use H to denote the column vector with all the hub scores, H = (H(1), H(2), \u2026, H(n))T, \u06ef \u0d4c \u072e\u0bcd \u06f6 (4) \u06f6 \u0d4c \u072e\u06ef (5) To solve the problem, the widely used method is power iteration, which starts with some random values for the vectors, e.g., A0 = H0 = (1, 1, 1, \u20261,).",
                    "sid": 224,
                    "ssid": 151,
                    "kind_of_tag": "s"
                },
                {
                    "text": "It then continues to compute iteratively until the algorithm converges.",
                    "sid": 225,
                    "ssid": 152,
                    "kind_of_tag": "s"
                },
                {
                    "text": "From the formulas, we can see that the authority score estimates the importance of the content of the page, and the hub score estimates the values of its links to other pages.",
                    "sid": 226,
                    "ssid": 153,
                    "kind_of_tag": "s"
                },
                {
                    "text": "An authority score is computed as the sum of the scaled hub scores that point to that page.",
                    "sid": 227,
                    "ssid": 154,
                    "kind_of_tag": "s"
                },
                {
                    "text": "A hub score is the sum of the scaled authority scores of the pages it points to.",
                    "sid": 228,
                    "ssid": 155,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The key idea of HITS is that a good hub points to many good authorities and a good authority is pointed by many good hubs.",
                    "sid": 229,
                    "ssid": 156,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Thus, authorities and hubs have a mutual reinforcement relationship.",
                    "sid": 230,
                    "ssid": 157,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For our scenario, we have three strong clues for features in a corpus: opinion words, part- whole patterns, and the \u201cno\u201d pattern.",
                    "sid": 231,
                    "ssid": 158,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Although all these three clues are not hard rules, there exist mutual enforcement relations between them.",
                    "sid": 232,
                    "ssid": 159,
                    "kind_of_tag": "s"
                },
                {
                    "text": "If an adjective modify many features, it is highly likely to be a good opinion word.",
                    "sid": 233,
                    "ssid": 160,
                    "kind_of_tag": "s"
                },
                {
                    "text": "If a feature candidate is modified by many opinion words, it is likely to be a genuine feature.",
                    "sid": 234,
                    "ssid": 161,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The same goes with part-whole patterns, the \u201cno\u201d pattern, or the combination for these three clues.",
                    "sid": 235,
                    "ssid": 162,
                    "kind_of_tag": "s"
                },
                {
                    "text": "This kind of mutual enforcement relation can be naturally modeled in the HITS framework.",
                    "sid": 236,
                    "ssid": 163,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Applying the HITS algorithm: Based on the key idea of HITS algorithm and feature indicators, we can apply the HITS algorithm to obtain the feature relevance ranking.",
                    "sid": 237,
                    "ssid": 164,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Features act as authorities and feature indicators act as hubs.",
                    "sid": 238,
                    "ssid": 165,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Different from the general HITS algorithm, features only have authority scores and feature indicators only have hub scores in our case.",
                    "sid": 239,
                    "ssid": 166,
                    "kind_of_tag": "s"
                },
                {
                    "text": "They form a directed bipartite graph, which is illustrated in Figure 2.",
                    "sid": 240,
                    "ssid": 167,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We can run the HITS algorithm on this bipartite graph.",
                    "sid": 241,
                    "ssid": 168,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The basic idea is that if a feature candidate has a high authority score, it must be a highly-relevant feature.",
                    "sid": 242,
                    "ssid": 169,
                    "kind_of_tag": "s"
                },
                {
                    "text": "If a feature indicator has a high hub score, it must be a good feature indicator.",
                    "sid": 243,
                    "ssid": 170,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Feature Indicators Features Fig.",
                    "sid": 244,
                    "ssid": 171,
                    "kind_of_tag": "s"
                },
                {
                    "text": "2 Relations between feature indicators and features 3.5 Feature Ranking.",
                    "sid": 245,
                    "ssid": 172,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Although the HITS algorithm can rank features by feature relevance, the final ranking is not only determined by relevance.",
                    "sid": 246,
                    "ssid": 173,
                    "kind_of_tag": "s"
                },
                {
                    "text": "As we discussed before, feature frequency is another important factor affecting the final ranking.",
                    "sid": 247,
                    "ssid": 174,
                    "kind_of_tag": "s"
                },
                {
                    "text": "It is highly desirable to rank those correct and frequent features at top because they are more important than the infrequent ones in opinion mining (or even other applications).",
                    "sid": 248,
                    "ssid": 175,
                    "kind_of_tag": "s"
                },
                {
                    "text": "With this in mind, we put everything together to present the final algorithm that we use.",
                    "sid": 249,
                    "ssid": 176,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We use two steps: Step 1: Compute feature score using HITS without considering frequency.",
                    "sid": 250,
                    "ssid": 177,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Initially, we use three feature indicators to populate feature candidates, which form a directed bipartite graph.",
                    "sid": 251,
                    "ssid": 178,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Each feature candidate acts as an authority node in the graph; each feature indicator acts as a hub node.",
                    "sid": 252,
                    "ssid": 179,
                    "kind_of_tag": "s"
                },
                {
                    "text": "For node s in the graph, we let \u072a\u0be6 be the hub score and \u0723\u0be6 be the authority score.",
                    "sid": 253,
                    "ssid": 180,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Then, we initialize \u072a\u0be6 and \u0723\u0be6 to 1 for all nodes in the graph.",
                    "sid": 254,
                    "ssid": 181,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We update the scores of \u072a\u0be6 and \u0723\u0be6 until they converge using power iteration.",
                    "sid": 255,
                    "ssid": 182,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Finally, we normalize \u0723\u0be6 and compute the score S for a feature.",
                    "sid": 256,
                    "ssid": 183,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Step 2: The final score function considering the feature frequency is given in Equation (6).",
                    "sid": 257,
                    "ssid": 184,
                    "kind_of_tag": "s"
                },
                {
                    "text": "\u0735 \u0d4c \u0735\u123a\u0742\u123b\u008e\u0091\u0089 \u123a \u0742\u074e\u0741\u074d\u123a\u0742\u123b\u123b (6) where \u0742\u074e\u0741\u074d\u123a\u0742\u123b is the frequency count of ture \u0742, and S(f) is the authority score of the candidate feature f. The idea is to push the frequent candidate features up by multiplying the log of frequency.",
                    "sid": 258,
                    "ssid": 185,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Log is taken in order to reduce the effect of big frequency count numbers.",
                    "sid": 259,
                    "ssid": 186,
                    "kind_of_tag": "s"
                },
                {
                    "text": "4 Experiments This section evaluates the proposed method.",
                    "sid": 260,
                    "ssid": 187,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We first describe the data sets, evaluation metrics and then the experimental results.",
                    "sid": 261,
                    "ssid": 188,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We also compare our method with the double propagation method given in (Qiu et al., 2009).",
                    "sid": 262,
                    "ssid": 189,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Sets We used four diverse data sets to evaluate our techniques.",
                    "sid": 263,
                    "ssid": 190,
                    "kind_of_tag": "s"
                },
                {
                    "text": "They were obtained from a commercial company that provides opinion mining services.",
                    "sid": 264,
                    "ssid": 191,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Table 1 shows the domains (based on their names) and the number of sentences in each data set (\u201cSent.\u201d means the sentence).",
                    "sid": 265,
                    "ssid": 192,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The data in \u201cCars\u201d and \u201cMattress\u201d are product reviews extracted from some online review sites.",
                    "sid": 266,
                    "ssid": 193,
                    "kind_of_tag": "s"
                },
                {
                    "text": "\u201cPhone\u201d and \u201cLCD\u201d are forum discussion posts extracted from some online forum sites.",
                    "sid": 267,
                    "ssid": 194,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We split each review/post into sentences and the sentences are POS-tagged using the Brill\u2019s tag- ger (Brill, 1995).",
                    "sid": 268,
                    "ssid": 195,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The tagged sentences are the input to our system.",
                    "sid": 269,
                    "ssid": 196,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Data Sets Cars Mattress Phone LCD # of Sent.",
                    "sid": 270,
                    "ssid": 197,
                    "kind_of_tag": "s"
                },
                {
                    "text": "2223 13233 15168 1783 Table 1.",
                    "sid": 271,
                    "ssid": 198,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Experimental data sets 4.2 Evaluation.",
                    "sid": 272,
                    "ssid": 199,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Metrics Besides precision and recall, we adopt the precision@N metric for experimental evaluation (Liu, 2006).",
                    "sid": 273,
                    "ssid": 200,
                    "kind_of_tag": "s"
                },
                {
                    "text": "It gives the percentage of correct features that are among the top N feature candidates in a ranked list.",
                    "sid": 274,
                    "ssid": 201,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We compare our method\u2019s results with those of double propagation which ranks extracted candidates only by occurrence frequency.",
                    "sid": 275,
                    "ssid": 202,
                    "kind_of_tag": "s"
                },
                {
                    "text": "ResultsWe first compare our results with double propa gation on recall and precision for different corpus sizes.",
                    "sid": 276,
                    "ssid": 203,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The results are presented in Tables 2, 3, and 4 for the four data sets.",
                    "sid": 277,
                    "ssid": 204,
                    "kind_of_tag": "s"
                },
                {
                    "text": "They show the precision and recall of 1000, 2000, and 3000 sentences from these data sets.",
                    "sid": 278,
                    "ssid": 205,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We did not try more sentences because manually checking the recall and precision becomes prohibitive.",
                    "sid": 279,
                    "ssid": 206,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Note that there are less than 3000 sentences for \u201cCars\u201d and \u201cLCD\u201d data sets.",
                    "sid": 280,
                    "ssid": 207,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Thus, the columns for \u201cCars\u201d and \u201cLCD\u201d are empty in Table 4.",
                    "sid": 281,
                    "ssid": 208,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In the Tables, \u201cDP\u201d represents the double propagation method; \u201cOurs\u201d represents our proposed method; \u201cPr\u201d represents precision, and \u201cRe\u201d represents recall.",
                    "sid": 282,
                    "ssid": 209,
                    "kind_of_tag": "s"
                },
                {
                    "text": "the extracted feature candidates based on frequency for the double propagation method (DP).",
                    "sid": 283,
                    "ssid": 210,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Using occurrence frequency is the natural way to rank features.",
                    "sid": 284,
                    "ssid": 211,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The more frequent a feature occurs in a corpus, the more important it is. However, frequency-based ranking assumes the extracted candidates are correct features.",
                    "sid": 285,
                    "ssid": 212,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The tables show that our proposed method (Ours) outperforms double propagation considerably.",
                    "sid": 286,
                    "ssid": 213,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The reason is that some highly-frequent feature candidates extracted by double propagation are not correct features.",
                    "sid": 287,
                    "ssid": 214,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Our method considers the feature relevance as an important factor.",
                    "sid": 288,
                    "ssid": 215,
                    "kind_of_tag": "s"
                },
                {
                    "text": "So it produces much better rankings.",
                    "sid": 289,
                    "ssid": 216,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Cars Mattress Phone LCD DP 0.84 0.81 0.64 0.68 Ours 0.94 0.90 0.76 0.76 Table 2.",
                    "sid": 290,
                    "ssid": 217,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Results of 1000 sentences Table 5.",
                    "sid": 291,
                    "ssid": 218,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Precision at top 50 Table 3.",
                    "sid": 292,
                    "ssid": 219,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Results of 2000 sentences Table 6.",
                    "sid": 293,
                    "ssid": 220,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Precision at top 100 Table 4.",
                    "sid": 294,
                    "ssid": 221,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Results of 3000 sentences From the tables, we can see that for corpora in all domains, our method outperforms double propagation on recall with only a small loss in precision.",
                    "sid": 295,
                    "ssid": 222,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In data sets for \u201cPhone\u201d and \u201cMattress\u201d, the precisions are even better.",
                    "sid": 296,
                    "ssid": 223,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We also find that with the increase of the data size, the recall gap between the two methods becomes smaller gradually and the precisions of both methods also drop.",
                    "sid": 297,
                    "ssid": 224,
                    "kind_of_tag": "s"
                },
                {
                    "text": "However, in this case, feature ranking plays an important role in discovering important features.",
                    "sid": 298,
                    "ssid": 225,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Ranking comparison between the two methods is shown in Tables 5, 6, and 7, which give the precisions of top 50, 100 and 200 results respectively.",
                    "sid": 299,
                    "ssid": 226,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Note that the experiments reported in these tables were run on the whole data sets.",
                    "sid": 300,
                    "ssid": 227,
                    "kind_of_tag": "s"
                },
                {
                    "text": "There were no more results for the \u201cLCD\u201d data beyond top 200 as there were only a limited number of features discussed in the data.",
                    "sid": 301,
                    "ssid": 228,
                    "kind_of_tag": "s"
                },
                {
                    "text": "So the column for \u201cLCD\u201d in Table 7 is empty.",
                    "sid": 302,
                    "ssid": 229,
                    "kind_of_tag": "s"
                },
                {
                    "text": "We rank Table 7.",
                    "sid": 303,
                    "ssid": 230,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Precision at top 200 5 Conclusion.",
                    "sid": 304,
                    "ssid": 231,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Feature extraction for entities is an important task for opinion mining.",
                    "sid": 305,
                    "ssid": 232,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The paper proposed a new method to deal with the problems of the state-of-the-art double propagation method for feature extraction.",
                    "sid": 306,
                    "ssid": 233,
                    "kind_of_tag": "s"
                },
                {
                    "text": "It first uses part-whole and \u201cno\u201d patterns to increase recall.",
                    "sid": 307,
                    "ssid": 234,
                    "kind_of_tag": "s"
                },
                {
                    "text": "It then ranks the extracted feature candidates by feature importance, which is determined by two factors: feature relevance and feature frequency.",
                    "sid": 308,
                    "ssid": 235,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The Web page ranking algorithm HITS was applying to compute feature relevance.",
                    "sid": 309,
                    "ssid": 236,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Experimental results using diverse real-life datasets show promising results.",
                    "sid": 310,
                    "ssid": 237,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In our future work, apart from improving the current methods, we also plan to study the problem of extracting features that are verbs or verb phrases.",
                    "sid": 311,
                    "ssid": 238,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "acknowledgement",
            "number": "",
            "sents": [
                {
                    "text": "This work was funded by a HP Labs Innovation Research Program Award (CW165044).",
                    "sid": 312,
                    "ssid": 239,
                    "kind_of_tag": "s"
                }
            ]
        }
    ]
}