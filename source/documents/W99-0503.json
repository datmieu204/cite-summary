{
    "ID": "W99-0503",
    "sections": [
        {
            "text": "abstract",
            "number": 0,
            "sents": [
                {
                    "text": "We report a number of computational ex\u00ad periments in supervised learnig whose goal IS to automatically classify a set of verbs mto lexrcal semantic classes, based on frequency drstrrbut1on approx1mat1ons of grammatical features extracted from a very large annotated corpus D1strrbutrons of five syntactic features that approx1mate trans1trv1ty alternations and thematic role ass1gnments are sufficient to reduce error rate by 56% over chance We conclude that corpus data IS a usable repos1tory of verb class mformation, and that corpus\u00ad drrven extractiOn of grammatical features IS a promismg methodology for automatic lexical acquisition",
                    "sid": 1,
                    "ssid": 1,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "introduction",
            "number": "1",
            "sents": [
                {
                    "text": "Recent years have Witnessed a shift m grammar de\u00ad velopment methodology, from craftmg large gram\u00ad mars, to annotation of corpora Correspondmgly, there has been a change from developmg rule-based parsers to developmg stat1st1cal methods for mduc\u00ad mg grammatical knowledge from annotated corpus data The sh1ft has mostly occurred because bu!ld\u00ad mg wrde-coverage grammars 1s t1meconsummg, er\u00ad ror prone, and difficult The same can be sa1d for craftmg the nch lexrcal representatiOns that are a central component of hngu1strc knowledge, and re\u00ad search m automatic le-..1cal acqu1s1t1on has sought to address th1s ((Dorr and Jones, 1996, Dorr, 1997), among others) Yet there have been few attempts to learn fine-gramed lexical classificatiOns from the sta\u00ad tistical analysiS of d1stnbutwnal data, analogously to the mduct1on of syntactic knowledge (though see, e g, (Brent, 1993, Klavans and Chodorow, 1992, Resml.., 1992)) In th1s paper.",
                    "sid": 2,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "we propose uth an approach for the automatic classlficatwn of \\erb mto lex1cal semantic classes 1 We can express the Issues raised by th1s approach as follows Wh1ch hngu1st1c d1stmctwns among le\\.Ical classes can we e\\.pect to find m a corpus>",
                    "sid": 3,
                    "ssid": 3,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "how easily can we extract the frequency drstn\u00ad. ",
            "number": "2",
            "sents": [
                {
                    "text": "butlons that approx1mate the relevant hngutstiC properties?",
                    "sid": 4,
                    "ssid": 1,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "wh1ch frequency d1stnbut1ons work best to dls\u00ad. ",
            "number": "3",
            "sents": [
                {
                    "text": "tmgmsh the verb classes?",
                    "sid": 5,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "In explormg these quest1ons, we focus on verb clas\u00ad Sificatwn for several reasons Verbs are very Impor\u00ad tant sources of knowledge m many language eng1neermg tasks, and the relat10nsh1ps among verbs ap\u00ad pear to play a maJor role m the orgamzatwn and use of this knowledge h.nowledge about verb classe 1s cruc1al for lexical acqu1srt10n m support of language generatiOn and machme translatiOn (Dorr, 1997) and document clC!bsrficatwn (Klavans and Kan, 1998), :yet manual class1ficatwn of large numbers of verb'S 1s a d1fficult and resource mtens1ve task (Levm, 1993 MJ!ler et a!",
                    "sid": 6,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": ", 1990, Dang et al , 1998) To address these 1ssues, we suggest that one can tram an automatic classifier for verbs on the bast'S of stattst1cal apprm..",
                    "sid": 7,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "tmatwns to verb dtatheses We use drathesesalternattOns m the e\\.presswn of the ar\u00ad guments of the verb-followmg Levm and Dorr, for two reasons Fnst, verb dratheses are syntacttc cue'> 1 We are aware that a d!stnbuttonal approach rests on one strong assumptiOn regardmg the nature of the repre\u00ad sentatiOns under study semantic not10ns and syntact1c notions are correlated, at least m part Tlus assumptton IS under debate (Bnscoe and Copestake, 1995, Levm, 1993, Dorr and Jones, 1996, Dorr, 1997), but we adopt 1t here w1thout further d1scuss1on 15 to semantic classes, hence they can be more eas1ly captured by corpus-based techn ques Second, usmg verb diatheses reduces no1se There IS a certam con\u00ad sensus (Bnscoe and Copestake, 1995, Pustejovsky, 1995, Palmer, 1999) that verb d1atheses are regular sense extensions Hence focussmg on th1s type of classlficatton allows one to abstract from the prob\u00ad lem of word sense d1sambiguatton and treat residual differences m word senses as no1se m the classifica\u00ad tiOn task We present an m-depth case study, m wh1ch we apply machme learmng techn ques to automatically class1fy a set of verbs based on d1stnbutwns of gram\u00ad matical md1cators of diatheses, extracted from a very large corpus We look at three very mterest\u00ad mg classes of verbs unergat1ves, unaccusat1ves, and object-drop verbs (Levm, 1993) These are mterest\u00ad mg classes because they all participate m the transi\u00ad tiVIty alternatiOn, and they are m1n1mal pa1rs- that 1s, a small number of well-defined d1stmct10ns differ\u00ad entiate then transltlve/mtransJtlve behaviOr Thus, we expect the d1fferences m the1r d1stnbutwns to be small, entallmg a fine-gramed d1scrlmmatwn task that prov1des a challengmg testbed for automat1c class1ficat10n The spec1fic theoretical questwn we mvest1gate IS whether the factors underlymg the verb class d!s\u00ad tmcttons are reflected m the statistical d1stnbut10ns of lex1cal features related to diatheses presented by the mdivJdual verbs m the corpus In domg th1s, we address the questwns above by determmmg what are the lex1cal features that could d1stmgmsh the behav\u00ad Ior of the classes of verbs wtth respect to the relevant diatheses, 'Nh1ch of those features can be gleaned from the corpus, and wh1ch of those, once the sta\u00ad tistical d1stnbut10ns are available, can be used suc\u00ad cessfully by an automatic classifier In Initial work (Stevenson and Merlo, 1999), \\\\e found that hngmst1cally mot1vated features that d1s\u00ad tmgu1sh the verb classes can be extracted from an annotated, and m one case parsed, corpus These features are sufficient to almost halve the error rate compared to chance (45% reductwn) m auto\u00ad matic verb class1ficat10n, suggestmg that dtstnbu\u00ad twnal data provtdes knowledge useful to the classt\u00ad ficatwn of verbs The focus of our ongmal studj was thP demonstration m pnnctple of IPc>\u2022nmg verb classes from frequency d1stnbutwns of syntactic fea\u00ad tures, and an analysis of the relative contnbutwn of the vanous features to learnmg Th1s paper turns to the Important ne\\.t steps of rephcatmg our find\u00ad mgs usmg other trammg methods and learnmg al\u00ad gonthms, and analyzmg the performance on each of the three classes of verbs Th1s more detalied anal\u00ad ysis of accuracy w1thm each class 111 turn leads to the development of a new dtstnbutwnal featme m\u00ad tended to 1m prove dJscrlmmabthty among t\\\\O of the classes The addttiOn of the ne\\\\ feature successfully reduces the error rate of ou1 Initial results m classi\u00ad ficatiOn by 19%, for a 56% overall reductiOn m error rate compared to chance 2 Determining the.",
                    "sid": 8,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Features In th1s sectwn, we present mottvatwn for the llllttal features that we mvest1gated m terms of thetr wle m learnmg the verb classes \\Ve first present the lmgmst1cally denved features then turn toe\\ tdence from e\\.penmental psychohngutsttcs to e\\.tend the set of potenttally relevant features 2.1 Features of the Vetb.",
                    "sid": 9,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Classes The three verb classes under mvesttgatwnunerga\u00ad tJves, unaccusattves, and object-drop - dtffer 111 the properttes of the1r transtttve/mtranstttve alterna\u00ad tiOns, wh1ch are exemphfied below Unergat1 ve ( 1a) The horse raced past the barn ( 1b) The Jockey raced the horse past the batn Unaccusat1 ve (2a) The butter melted m the pan (2b) The cook melted the butter m the panObject drop (3a) The boy washed the hall (3b) The boy washed The sentences m ( 1) use an unergattve Vl't b. weed Unergattves are mt1anstttve actton verbs whose tran\u00ad SitiVe form ts the causattve counterpart of the m\u00ad transttlve form Thus, the subject of the mttanst\u00ad tne (1a) becomes the obJect of the transttl\\e (lb) (Brousseau and Rttter 1991, Hale and h.ejset 1993 Levm and Rappaport Hovav, 1995) The sentences m (2) use an unaccusattve verb, melt :cl (_ nac\u00ad cusattves are mtranstttve change of statl' \\et bs (2a) hke unergattves, the transttl\\e countetpart fot thh<' verbs ts also causattve (2b) The sentenc<'tn ( J) use an obJect-dlOp vet b u\u00b7u hed, thee vet b-; ha1 c a non-causatne tran ttl\\e/mtranstttve altettM\\lon tn 11 luch the obJect ts stmplopttonal Both unergattves and unaccusatn I'S hm e a causative transtttve form.",
                    "sid": 10,
                    "ssid": 6,
                    "kind_of_tag": "s"
                },
                {
                    "text": "but dtffer tn the semanttc roles that they asstgn to the parttctpants m thl' e1 ent descnbed In an mtranstttve unetgattve, the ubJect ts an 1\\.gent {the doer of the event), and Ill an tnttan\u00ad stttve unaccusattve, the subject ts a Theme (ome\u00ad thmg affected by the event) The role asstgnments to the correspondmg semanttc arguments of the t1an\u00ad stttve forms-t e , the duect obJects-;:ue th<> amc 16 wtth the additiOn of a Causal Agent (the causer of the event) as subject m both cases Object-drop verbs s1mply assign Agent to the subject and Theme to the optiOnal object We expect the dlffermg semantic role assignments of the verb classes to be reflected m their syntac\u00ad tic behaviOr, and consequently m the distributiOnal data we collect from a corpus The three classes can be characterized by their occurrence m two alter\u00ad natiOns the transittve/mtransitive alternatiOn and the causative alternatiOn Unergatives are dJstm\u00ad gUished from the other classes m bemg rare m the transitive form (see (Stevenson and Merlo, 1997) for an e\\.planatiOn of this fact) Both unergattves and unaccusat1ves are distmgUished from object-drop m bemg causatiVe m the1r transitive form, and sun\u00ad tlarly we expect th1s to be reflected m amount of detectable causat1ve use Furthermore, smce the causative IS a transitive use, and the transitive use of unergat1ves 1s expected to be rare, causatlvity should pnmanly distmgUish unaccusatives from object\u00ad drops In conclusion, we expect the definmg features of the verb classes-the mtransitive/transitive and causatiVe alternatiOns-to lead to distribUtiOnal dif\u00ad ferences m the observed usages of the verbs m these alternatiOns 2 2 Psycholingwstlcally Relevant Features The verbs under study not only differ m their thematic properties, they also differ m their pro\u00ad cessmg properties Because these verbs can occur both m a transitive and an mtransittve form, they have been particularly studied m the conte\\.t of the mam verb/reduced relative (MV /RR) ambigUity Il\u00ad lustrated below (Bever, 1970) The horse raced past the barn fell The verb weed can be mterpreted as either a past tense mam verb, or as a past participle wtthm a re\u00ad duced relat1ve clause (1 e , the horse (that was] raced past the barn) Because fellts the mam verb, the I e\u00ad duced relative InterpretatiOn of raced IS reqUired for a coherent analysts of the complete sentence But the mam verb mterpretatton of raced 1s so strongly preferred that people expenence great dtfficulty at the verb fell.",
                    "sid": 11,
                    "ssid": 7,
                    "kind_of_tag": "s"
                },
                {
                    "text": "unable to mtegrate It w1th the Inter\u00ad pretatiOn that has been developed to that pomt However, the reduced relat1ve mterpretatton ts not dtfficult for all verbs, as m the follO\\ mg example The boy washed m the tub was angry The dtfference m ease of mterpretmg the tesolu\u00ad tiOns of thts ambtgmty has been shown to be sen\u00ad stttve to both frequency dtfferenttals (MacDonald 1994, Trueswell, 1996) and to verb class d1stmct10ns (Stevenson and Merlo, 1997, F1ltp et al , 1999) Constder the features that dtstmgutsh the t\\\\O 1 e \u00ad olutiOns of the Mv /RR ambtgutty MV The horse raced past the barn quickly RR The horse raced past the barn fell In the maiO verb resolutiOn, the ambiguous verb raced IS used m Its mtransttlve form, wh1le m the re\u00ad duced relat1ve, It IS used m 1ts transitive, causative form These features correspond directly to the definmg alternatiOns of the three verb classes un\u00ad der study (mtransttlve/transittve, causattve) -\\ddt\u00ad tlOnally, we see that other related featureto t hPse usages serve to dtstmgutsh the two resolut10ns of the ambiguity The mam verb form IS active and a mam verb part-of-speech (labeled as VBD by automatic POS taggers), by contrast, the reduced relatne foun IS passive and a past participle (tagged as \\ B:'-1) Smce these features (acttvefpasstve and VBD/\\'BN) are related to the mtranstttve/transttlve alte111at10 n, we expect them to also exhibit dtstrtbutlOnal differ\u00ad ences among the verb classes Specifically, \\\\e e\\.pect the unergattves to yteld a htgher proportiOn of actl\\e and \\tBD usage, smce, as noted above, the tianstt1 ve use of unergattves IS rare 3 Frequency Distributions of the.",
                    "sid": 12,
                    "ssid": 8,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Features We assume that currently available large co1po1a are a reasonable approximatiOn to language (Pul\u00ad lum, 1996) Usmg a combmed corpus of 65mtlhon words, we measured the relative frequenc} d1stnbu\u00ad tiOns of the four hngUisttc features (VBD/\\ B\\ ac\u00ad tive/passive, mtranstttve/transtttve, causatt\\P/non\u00ad causattve) over a sample of verbfrom the thtPe Ie,\u00ad tcal semantic classes 3 1 Matenals \\Ve chose a set of 20 verbs from each class based pit\u00ad mat tly on the classtficatiOn of verbs m ( Le\\ m 191).3) (see AppendiX A.)",
                    "sid": 13,
                    "ssid": 9,
                    "kind_of_tag": "s"
                },
                {
                    "text": "The unetgattves ate marmet of motiOn verbs The unaccusatnes ate \\erbs of thitnge of state The object-drop verbs are un pectfted ob\u00ad ject alternatiOn verbs The vetbs \\\\ere selected f10m Le\\m's classes based on thetr absolute ftequPnc FUI thermore, they do not generally shO\\ m l\\ f' de\u00ad pat tures from the mtended verb sense Ill the co1 pu., (Though note that there are only 19 unaccu att\\ f''> because rzpped.",
                    "sid": 14,
                    "ssid": 10,
                    "kind_of_tag": "s"
                },
                {
                    "text": "\\ luch \\\\as tnittally counted 111 thP unaccusattves.",
                    "sid": 15,
                    "ssid": 11,
                    "kind_of_tag": "s"
                },
                {
                    "text": "was then e\\cluded from the anal\\\u00ad SIS as It occurred mostly 1n a dtfferent usagp 111 tl;e corpus, as a ve1 b plus pat t1cle ) Most of the ve 1 b can occur Ill the transtttve and m the pa lve Earh verb presents the arne f01m m the stmple pat and m the past patttctple In order to Simphf} the count mg procedure, we made the assumptiOn that counts on this smgle verb form would appro\\.Imate the dis\u00ad tnbutiOn of the features across all forms of the verb Most counts were performed on the tagged version of the Brown Corpus and on the portiOn of the Wall Street Journal distributed by the ACL/DCI (years 1987, 1988, 1989), a combmed corpus m excess of 65 mdhon words, With the exceptiOn of causativ\u00ad Ity which was counted only for the 1988 year of the WSJ, a corpus of 29 million words 3 2 Method We counted the occurrences of each verb token m a transitive or mtiansltlve use (INTR), m an act1ve or passive use (ACT), m a past paiticlple or s1mple past use (vao), and m a causative or non-causat1ve use ( CAUS) More prec1sely, features were counted as follows INTR a verb occurrence was counted as trans1t1ve 1f Immediately followed by a nommal group, else 1t was counted as mtrans1t1ve ACT mam verbs (tagged VBD) were counted as active, partiCiples (tagged vBN) counted as actiVe If the closest precedmg aux1hary was have, as passive 1f the closest precedmg aux1liary was be VBD occurrences tagged VBD were s1mple past, VBN were past partiCiple (Each of the above three counts was normalized over all occurrences of the verb, y1eldmg a smgle relat1ve frequency measure for each verb for that fea\u00ad ture) CAUS The causative feature was approximated by the followmg steps FirSt, for each verb, all cooc\u00ad cumng subjects and objects were e\\.tracted from a parsed corpus (Collms, 1997) Then the propor\u00ad d1menswn, the set of 59 vectors constitute the data for our machme learnmg expenments Template (verb, VBD, ACT, INTR, CAliS, class) Example (opened, 79, 91, 31, 16, unacc] Our goal was to determme whether automatic clas\u00ad SificatiOn techmques could determme the class of a verb from the dtstnbutwnal properties represented m this vector In related work (Stevenson and Merlo, 1999) 11e descnbe lllltial unsupervised and superv1sed lea1 n111o- e\\.penments on th1s data, and d1scuss the contllbutlOn of the four different features (the frequenL} d1s\u00ad tnbutwns) to accuracy m verb classificatiOn In th 1s paper, we extend the work m several \\\\ays Fu-,t, 11e report further analys1s of rephcat10ns of our uut1al supervised learnmg results Next, we demonstrate s1miiar performance usmg different trammg methods and learmng algonthms, md1catmg that the perfor\u00ad mance IS mdependent of the particular learmng ap\u00ad proach Furthermore, these additiOnal expenments allow us to evaluate the performance separately on each of the three verb classes Fmally, based on th1s evaluatwn, we suggest a new feature to better d1s\u00ad tmgUish the thematic properties of the classes, and present experimental results showmg that Its use 1m\u00ad proves our origmal accuracy rate 4.1 lnit1al Experiments Imt1al experiments were earned out usmg a decision tree mductwn algonthm, the C5 0 system available from http / jwww rulequest com/ (Qumlan, 1992), to automatically create a classificatiOn program ftom a trammg set of verb vecto1s w1th known classlf1ca\u00ad 2 tiOn of overlap bet....,een the two mult1sets of nouns tJOn In our earhe1 e\\.pellments 11e ran 10-fold was calculated, meant to capture the causat1ve al\u00ad ternatiOn, \\here the subject of the mtrans1t1ve can occur as the object of the transitive \\ve define overlap as the largest mult1set of elements belong\u00ad mg to both the subjects and the object mult1sets, eg {a,a,a,b}n {a}= {a,a,a} The proportiOn IS the rat1o between the 0\\erlap and the sum of the subject and object mult1sets (For \\.ample, for the s1mple sets above, the ratiO would be 3/5 or 60 ) All ral\\ and normalized corpus data a1e available from the authors, and more deta1l concernmg data collectiOn can be found m (Stevenson and !Vlerlo, 1999) cross-vahdatwns repeated 10 times he1e 11e tepeat the CJossvahdatwns 50 t1mes.",
                    "sid": 16,
                    "ssid": 12,
                    "kind_of_tag": "s"
                },
                {
                    "text": "and the numbe1s 1e\u00ad p01 ted are averages over all the 1un'3 3 Table 1 shows the re'3ult'> of our e\\.penment'> 011 the four features we counted m the co1po1 a (\\so ACT, I'<TR, CAUS), as well as all three-featu1e '>ubsets of those four The basel me (chance) pe1 fo1 mance 111 thl'3 task 1s 33 8%, smce the1e are 59 lector'> and 2 The S)stem generates both decision trees and rule sets fm use m classification Smce the d1fferenct 111 per_ fonnance between the t\\\\O IS ne\\er sigmficant \\le report here on!}",
                    "sid": 17,
                    "ssid": 13,
                    "kind_of_tag": "s"
                },
                {
                    "text": "the results usmg the extracted rules The rules prov1de a confidence level for each classificatiOn 11 hJCh IS unavailable With the decision tree data structure 3",
                    "sid": 18,
                    "ssid": 14,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "experiments in verb classification. ",
            "number": "4",
            "sents": [
                {
                    "text": "The frequency d1stnbut10ns of the verb alternatiOn features y1eld a vector for each verb that reprebents the relat1ve frequency values for the verb on each .\\ 10-fold cross-vahdat10n means that the S\\ stem randomly divides the data mto 10 parts, and runs 10 times on a different 90%-traimng-data/ 10%-test-data spht, y1eldmg an average accuracy and standard enor Th1s procedure IS then repeated for 50 different random diVISions of the.",
                    "sid": 19,
                    "ssid": 1,
                    "kind_of_tag": "s"
                },
                {
                    "text": "data and accurac) and standard error are agam averaged across the 50 runs II Features Ace% SE% II II Classes Percent -\\ccuracy II II All Classes 61 o 11 Table 1 Percentage Accuracy (Ace%) and Standard Error (SE%) of C5 0 (33 8% baseline) 3 poss1ble classes (That 1s, ass1gmng one of the two most common classes-of 20 verbs each-to all cases would yield 20 out of 59 correct, or 33 8% ) As seen m the table, classificatiOn based on the four fea\u00ad tures performs at 63 7%, or 30% over chance The true mean of the sample cross-vahdatiOnS hes Within plus or mmus two standard errors of the reported mean (df=49, t=2 01, p< 05) In all cases, the range 1s plus or mmus 1 0 or 1 2, y1eldmg a very nai\u00ad row predicted accuracy range Furthermore, we per\u00ad formed t-tests companng the results of the 50 cross\u00ad validatiOns for each of the different feature subsets All pairs were s1gmficantly different (p< 05) except for the results usmg all four features (first row m the table) and those excludmg ACT (second row m the table) We conclude that all features except ACT contnbute pOSitively to classificatiOn performance, and that ACT does not degrade performance In our rephcat10ns, then, we focus on all four features 4 2 Rephcat10n with Different Trammg and Learmng Methods There are conceptual and practical reasons for m\u00ad vestlgatmg the performance of other trammg ap\u00ad proaches and learnmg algonthms apphed to our verb d1stnbut10n data Conceptually.",
                    "sid": 20,
                    "ssid": 2,
                    "kind_of_tag": "s"
                },
                {
                    "text": "1t IS des1rable to know whether a particular learnmg algonthm or trammg techmque affects the level of performance Practically, different methods enable us to evalu\u00ad ate more eas1ly the performance of the classificatiOn method w1thm each verb class (When we run re\u00ad peated cross-validatiOns With t {:'5 0.",
                    "sid": 21,
                    "ssid": 3,
                    "kind_of_tag": "s"
                },
                {
                    "text": "system, we don't have access to the accuracy rate for each class, the sy<>tem only outputs an overall mean error rate ) To preview, we find that the different trammg and learnmg methods we tned alL gave similar perfor\u00ad mance to our ongmal results, and m addition al\u00ad lowed us to evaluate the accuracy w1thm each verb class In one set of expenments, we used the same C5 0 system, but employed a trammg and testmg method\u00ad ology that used a smgle holdout case We held om a smgle verb vector, tramed on the remammg .58 cases, then tested the resultmg cla<>slfier on the Table 2 Percentage Accuracy of C5 0 Wtth Smgle HoldOut Trammg smgle holdout case, and recorded the co!tect and ass1gned classes for that verb Th1s was then 1 e\u00ad peated for each of the 59 ve1 bs Th1s approach }1elds both an overall accuracy rate (when the tesultare averaged across all 59 tnals), as well as p!O\\ 1dmg the data necessary for determmmg accuracy f01 each verb class (because Y<e have the classificatiOn of each verb when 1t 1s the test case) The results a1e pre\u00ad sented m Table 2 The overall accuracy IS a little less than that ach1eved w1th the 10-fold cross-vdhdatwn methodology (61 0% versus 63 7%) However.",
                    "sid": 22,
                    "ssid": 4,
                    "kind_of_tag": "s"
                },
                {
                    "text": "we can see clearly now that the unergat1ve verbare classified w1th much greater accuracy (75%), wlule the unaccusattve and object-drop verbs are class1fied w1th much lower accuracy (57 9% and 50% respec\u00ad tively) The d!stnbutiOnal features we have appear to be much better at d1stmgmshmg unergat1ves than una.ccusatJve or object-drop verbs To test th1s directly under our ongmal t1ammg assumptiOns, we ran two different expenment-s, u::.\u00ad mg 10-fold cross-validatiOn repeated 10 tane\u00bb The first expeument tested the ab1lity of the classtfiet to d1stmgmsh between unergatlves and the other (\\\\O verb types, wrthout havmg to dtstmgursh bet\\\\een the latter two The data mcluded the 20 unerga\u00ad tive verbs and a random sample of 10 unaccu5attve and 10 object-drop verbs, 10 different random am\u00ad pies were selected to form 10 such data set In these data sets, the \\erbs were labeled as unerga\u00ad tt ve or \"other\" The basel me (chance) clas tficatton accuracy fot th1s data ts 50%, the mean acrut ac\\ ach1eved across all data sets was i8 5% (standard e;\u00ad !Or 0 8%), a srzable Improvement o\\er chance The second e\\.peument \\\\as mtended to deter mmP ltm\\ well the classifier can d1stmgut\u00bbh. unaccu->att'e from object-drop verbs The data consrsted of one et that mcluded all the unaccusatrve and object-drop verbs, w1th no unergat1ves Because there ate only 19 unaccusat1ve verbs, the basehne accuracy 1ate 1s 51% (20/39), here the classrfier achreved an dCC'uracy only slightly above chance, at 58 3% (standard er10r 1 8%) These results, summanzed m Table 3 rlea.rlY confirm the h1gher accuracy of cla5 tfymg unergattv verbs wtth the current feature set Thts pattern of results \\\\as tepeated unc!Pt \"\\PI) Classes Ace% SE% II Classes I VBD I ACT I INTR I CAUS II Unergat1ve vs Other 78 5 08 Unerg vs Unacc *** *** * *** Unaccusat1ve vs ObjectDrop 58 3 1 8 Table 3 Percentage Accuracy (Ace%) and Standard Error (SE%) of C5 0 (5051% baseline) Unerg vs ObjDrop *** *** Unacc vs ObjDrop ns ns *** p$ 001 ** p< 01 * p$ 05 *** * ** * II Classes PCA% FMP% II II ns non-s1gmficant Table 5 S1gmficance Levels ofT-Tests Comparmg Feature Values Between Verb Classes Table 4 Percentage Accuracy of PCA (PCA%) and Feature Map (FMP%) Neural Networks different type of learnmg algorithm as well We per\u00ad formed a set of neural network expenments, usmg NeuroSolutwns 3 0 (see http/ jwww nd com), and report here on the networks that achieve the best performance on our data These are prmc1pal com\u00ad ponents analysis and automatic feature map net\u00ad works, which are essentially feed-forward percep\u00ad trons w1th preprocessmg umts that transform the ex1stmg features mto a more useful format In our tests, both methods performed best overall when there were no hidden layer umts, and the networks were tramed for 1000 epochs The mean accuracy rates of 10-fold cross-vahdatwns With these param\u00ad eter settmgs are summanzed m Table 4 Agam, the overall percentage accuracy ISm the low sixties, w1th better performance on the unergat1ves than on the other two verb classes, the difference was particu\u00ad larly stnkmg w1th the PCA networks Th1s overall pattern doesn't change w1th further trammg, m fact, trammg up to 10,000 epochs resulted m very low accuracy (of 45%) for either unaccusat1ves, object\u00ad drops, or both To summanze, followmg a different trammg ap\u00ad proach \\Hth C5 0 (the smgle holdout method), and applymg very different learnmg approaches (two kmds of neural networks), resulted m smula1 O\\er\u00ad all performance to our ongmal C5 0 results Th15 md1cates that the accurac) achieved IS at lea.5t somewhat mdependent of specific learnmg or tram\u00ad mg techmques Moreover, these different methods, along with experiments directly testmg unergat1ve versus unaccusativefobject-drop classificatwn, allow us to examme more closely where the resultmg clas\u00ad sifiers have the most senous problems In d.ll cases, the accuracy IS best for unergat1ves, and the accu\u00ad racy of unaccusat1ves, object-drops, or both, IS de\u00ad graded If thts performance IS mdeed a reliable mdt catwn of the mherent discnnunabiiity of the distn\u00ad butwnal data, then we must e\\.amme more closely the properties of the data Itself to understand (and potentially Improve) the performance 4 3 DJscr1mmatmg UnaccusatJve and ObJect-Drop Verbs To understand why the data d1scnmmates unerga\u00ad tives reasonably well, but not unaccusat1ves and object-drops, we need to directly test the discnm\u00ad mabihty of the features across the classes We do so by usmg t-tests to compare the values of the differ\u00ad ent features-VBD, ACT, INTR, CAUS-for unergat1ve and unaccusattve verbs, unergatlve and object-drop verbs, and unaccusat1ve and object-drop verbs In each case, the t-test ts gtvmg the hkehhood that the two sets of values-e g , the VBD feature values for unergattves and for unaccusatives-are dra\\lrn from different populatiOns Table 5 shows that d.ll seto; of features are s1g,mficantly different for unerg,at1ve and unaccusattve verbs, and for unergat1ve and object\u00ad drop verbs Hm\\ever, only INTR and CAUS a1e sig\u00ad mficantly different for unaccusat1ve and object-diOp verbs, md1catmg that we need additiOnal fectlUle5 that have different values across these two clas5es In SectiOn 2 1, we noted the d1ffenng semantic role assignments for the verb classes, and hypothesized that these differences would affect the expre'5siOn of syntactic features that a1e countable m a co1 pus For e\\.ample, the c -I.LS feature approximates seman\u00ad tic role mfounat1on bj encodmg, the 0\\erlap bet\\\\een nouns that can occu1 111 the -,ubject and obJPCt po\u00ad SitiOns of a cau-,ative \\el b He1e \\\\e '>ug,g,e'>t anothe1 featUie, that of animacy of subject, that 1s mtended to dtstmgUish nouns that recetve an Agent role f10m those that receive a Theme role Recall that object\u00ad drop verbs assign Agent to their subject m both the trans1t1ve aRd mtranstttve alternatwns, wh1le unac\u00ad cusatives asstgn Agent to their subject only m the transitive, and Theme m the mtrans1t1ve \\Ve P\\.pect then that object-drop verbs will occur more often with an ammate subject '\\/ote ag,am that \\\\P are Features VBO ACT INTR CAUS VBO ACT INTR CAUS PRO Ace% SE% 63 7 06 70 7 04 wtthm the verb classes of thts new set of features to see whether accuracy has also tmproved for unerg,a\u00ad ttve verbs 5 C o n c l u s i o n s Table 6 Percentage Accuracy (Ace%) and Standard Error (SE%) of C5 0, Wtth and Wtthout New PRO Feature, All Verb Classes (33 8% baselme) makmg use of frequency dtstnbuttons-the clatm ts not that only Agents can be ammate, but rather that nouns that recetve the Agent role wtll more often be ammate than nouns that recetve the Theme role A problem wtth a feature ltke ammacy ts that tt requtres etther manual determmat10n of the ammacy of extracted subjects, or reference to an on-hne re\u00ad source such as WordNet for determmmg antmacy To approxtmate ammacy wtth a feature that can be extracted automattcally, and wtthout reference to a resource external to the corpus, we mstead count pronouns (other than zt) m subject posttton The assumptton ts that the words I, we 1 you, she 1 he, and they most often refer to ammate enttttes The values for the new feature, PRO, were determm.ed \u00b7 \u00b7 by automatically extractmg all subJect/verb tuples mcludmg our 59 examples verbs (from the WSJ88 parsed corpus), and computmg the rat10 of occur\u00ad rences of pronouns to all subjects We agam apply t-tests to our new data to deter\u00ad rome whether the sets of PRO values dtffer across the verb classes Interestmgly, we find that the PRO values for unaccusattve verbs (the only class to as\u00ad stgn Theme role to the subject tn one of tts alterna\u00ad tiOns) are stgmficantly dtffetent from those for both unergattve and object-drop verbs (p< 05) More\u00ad over, the PRO values for unergattve and object-drop verbs (whose subjects are Agents m both alterna\u00ad tiOns) are not stgmficantly dtfferent Thts pattern confirms the abtltty of the feature to capture the themattc dtstmctton bet.,.,een unaccusattve verbs and the other two classes Table 6 shows the result of applymg C5 0 (10-fold cross-vahdatton repeated 50 ttmes) to the three-\\\\ay classtficatton task usmg the PRO feature m conjunc\u00ad tiOn wtth the four prevtous features -\\ccuracy tm\u00ad proves to over 70%, a teductton m the etrot rate of almost 20% due to thts smgle ne\\v feature :\\Iote\u00ad over, classtfymg the unaccusattve a.1object-drop verbs usmg the new feature m conJunctiOn wtth the prev10us four leads to accuracy of over 68% (com\u00ad pared to 58% wtthout PRO) We conclude that thts feature IS tmportant m dtstmgmshmg unaccusattve and object-drop verbs, and likely contnbutes to the Improvement m the three-way classtficatton because of thts Future work will exam me the pet fot mance In thts paper, we have presented an m-depth case study, m wh1ch we mvest1gate vanous machme learn\u00ad mg techmques to automatically class1fy a set of verbs, based on dtstrtbutiOnal features e\\.tracted from a very large corpus Results show that a small number of lmgmsttcally mottvated grammatical fea\u00ad tures are suffictent to reduce the error rate bv 11101e than 50% ovez chance, acluevmg a 70% a cutacy rate m a three-way classtficatton tash.",
                    "sid": 23,
                    "ssid": 5,
                    "kind_of_tag": "s"
                },
                {
                    "text": "Tim leads us to conclude that corpus data ts a usable repost\u00ad tory of verb class mformatton On one hand \\\\e ob\u00ad serve that semantiC properties of verb classe( uch as causattvzty, or ammacy of subject) may be use\u00ad fully approxtmated through countable syntacttc fea\u00ad tures Even wtth some nOise, lexzcal properttes are reflected m the corpus robustly enough to postttvely contnbute m classtficatzon On the other hand, how\u00ad ever, we remark that deep hngUistzc analysts cannot be eltmmated-m our approach, 1t ts embedded 111 the selectton of the features to count We also thmk that usmg lmguzstlcally motzvated features makes the approach very effective and eastly scalable we report a 56% reductton m error rate, w1th only five features that are relatively stratghtforward to count",
                    "sid": 24,
                    "ssid": 6,
                    "kind_of_tag": "s"
                }
            ]
        },
        {
            "text": "acknowledgements",
            "number": "",
            "sents": [
                {
                    "text": "Thts research was partly sponsored by the S\\HS-> Na\u00adtiOnal Sctence Foundatton, under fello\\ slup 8210 46569 to Paola :Vlerlo, by the US Nattonal Sctence Found at ton, under grants #9702331 and #918 322 to Suzanne Stevenson, and by the Infounatton ')c1ences Counctl of Rutgers Umverszty \\'ve thank Martha Palmer for gettmg us started on tlus \\\\ ork and :\\hchael Collins for gtvmg us access to the out\u00ad put of hts parser We gratefully acknowledge the help of h.tva Dtckmson, \\\\ ho calculated not maltza\u00ad ttons of the corpus data Appendix A The une1gatnes are manner of motion \\erh Jtm1 pul ruohed, marched, !taped floated, raced, lwrl!cd uan\u00ad dered, vaulted, paraded, galloped, glzded, hz!..ed hvpptd Jogged, ocooted, ocurned, ol..zpped, tzptoed, trotted The unaccusati\\eS are verbs of change of state opened, exploded, flooded, dzsoolved, cracked, hmdtned bozled, melted, fractured, oolzdzfied, collapoed cooled folded, wzdened, changed, cleared, dzvzded, >lllllnered stabzlzzed The object-dtop verbs are unspecified object alter\u00ad natiOn verbs played, pmnted, kzc!..ed, carved, reaptd, washed, danced, yelled, typed, !..nttted borrowed rnh r &ted, orgamzed, rented, sketched, cleaned, packed, stud\u00ad zed, swallowed, called",
                    "sid": 25,
                    "ssid": 7,
                    "kind_of_tag": "s"
                }
            ]
        }
    ]
}