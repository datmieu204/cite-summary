{
    "ID": "P98-1081",
    "citations": [
        {
            "Number": 2,
            "refer_ID": "P98-1081",
            "refer_sids": [
                116,
                117
            ],
            "refer_text": "A next step is to examine them in pairs.We can investigate all situations where one tagger suggests T1 and the other T2 and estimate the probability that in this situation the tag should actually be Tx.",
            "cite_ID": "W01-0712",
            "cite_maker_sids": [
                130
            ],
            "cite_sids": [
                130
            ],
            "cite_text": "And .nally, TAGPAIR uses classi.cation pair weights based on the probability of a classi.cation for some predicted classi.cation pair (van Halteren et al., 1998).",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 3,
            "refer_ID": "P98-1081",
            "refer_sids": [
                80,
                89
            ],
            "refer_text": "In order to see whether combination of the component tuggers is likely to lead to improvements of tagging quality, we first examine the results of the individual taggers when applied to Tune.We accept that we are measuring quality in relation to a specific tagging",
            "cite_ID": "W01-0712",
            "cite_maker_sids": [
                135
            ],
            "cite_sids": [
                134,
                135
            ],
            "cite_text": "Like Van Halteren et al.(1998), we evaluated two features combinations.",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 5,
            "refer_ID": "P98-1081",
            "refer_sids": [
                116,
                117,
                124
            ],
            "refer_text": "A next step is to examine them in pairs.We can investigate all situations where one tagger suggests T1 and the other T2 and estimate the probability that in this situation the tag should actually be Tx.When used on Test, the pairwise voting strategy (TagPair) clearly outperforms the other voting strategies, 8 but does not yet approach the level where all tying majority votes are handled correctly (98.31%).",
            "cite_ID": "W02-1004",
            "cite_maker_sids": [
                105
            ],
            "cite_sids": [
                105,
                106,
                107,
                108,
                109,
                110,
                111
            ],
            "cite_text": "Van Halteren et al.(1998) introduce a modi.ed version of voting called TagPair.Under this model, the conditional probability that the word sense is s given that classi.er ioutputs sand classi.er jout\u00adputs s2, P(sls i(xd)=ss j(xd)=s2), is com\u00adputed on development data, and the posterior prob\u00adability is estimated as N P(slx,d)e\u00c6(s,sAk(x,d))+\u00c6(s,sA j(x,d)) (7) k..j where sc;,j(xfd)=argmaxtP(tlsc;(xfd)fscj(xfd)).Each classi.er votes for its classi.cation and every pair of classi.ers votes for the sense that is most likely given the joint classi.cation.In the experi\u00adments presented in van Halteren et al.(1998), this method was the best performer among the presented methods.",
            "label": [
                "Results_Citation"
            ]
        },
        {
            "Number": 7,
            "refer_ID": "P98-1081",
            "refer_sids": [
                100,
                102,
                116,
                118
            ],
            "refer_text": "The most democratic option is to give each tagger one vote (Majority).This can be general quality, e.g. each tagger votes its overall precision (TotPrecision), or quality in relation to the current situation, e.g. each tagger votes its precision on the suggested tag (Tag- Precision).A next step is to examine them in pairs.When combining the taggers, every tagger pair is taken in turn and allowed to vote (with the probability described above) for each possible tag, i.e. not just the ones suggested by the component taggers.",
            "cite_ID": "E99-1025",
            "cite_maker_sids": [
                118
            ],
            "cite_sids": [
                117,
                118
            ],
            "cite_text": "We consider three voting strategies suggested by van Halteren et al.(1998): equal vote, where each classifier's vote is weighted equally, overall accuracy, where the weight depends on the overall accuracy of a classifier, and pair'wise voting.",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 9,
            "refer_ID": "P98-1081",
            "refer_sids": [
                100
            ],
            "refer_text": "The most democratic option is to give each tagger one vote (Majority).",
            "cite_ID": "P06-2060",
            "cite_maker_sids": [
                35
            ],
            "cite_sids": [
                35
            ],
            "cite_text": "Halteren et al (1998) compare a number of voting methods including a Majority Vote scheme with other combination methods for part of speech tagging.",
            "label": [
                "Aim_Citation"
            ]
        },
        {
            "Number": 10,
            "refer_ID": "P98-1081",
            "refer_sids": [
                158
            ],
            "refer_text": "Our experiment shows that, at least for the task at hand, combination of several different systems allows us to raise the performance ceiling for data driven systems.",
            "cite_ID": "A00-1024",
            "cite_maker_sids": [
                43
            ],
            "cite_sids": [
                42,
                43
            ],
            "cite_text": "Thirdly, this approach is compatible with in\u00ad corporating multiple components of the same type to improve performance (cf.(van Halteren et al., 1998) who found that combining the results of several part of speech taggers increased performance).",
            "label": [
                "Results_Citation"
            ]
        },
        {
            "Number": 11,
            "refer_ID": "P98-1081",
            "refer_sids": [
                101,
                102
            ],
            "refer_text": "However, it appears more useful to give more weight to taggers which have proved their quality.This can be general quality, e.g. each tagger votes its overall precision (TotPrecision), or quality in relation to the current situation, e.g. each tagger votes its precision on the suggested tag (Tag- Precision).",
            "cite_ID": "W05-1518",
            "cite_maker_sids": [
                10
            ],
            "cite_sids": [
                10,
                11
            ],
            "cite_text": "Combination techniques have been successfully applied to part of speech tagging (van Halteren et al., 1998; Brill and Wu, 1998; van Halteren et al., 2001).In both cases the investigators were able to achieve significant improvements over the previous best tagging results.",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 12,
            "refer_ID": "P98-1081",
            "refer_sids": [
                145,
                146,
                147
            ],
            "refer_text": "The most important observation is that every combination (significantly) outperforms the combination of any strict subset of its components.Also of note is the improvement yielded by the best combination.The pairwise voting system, using all four individual taggers, scores 97.92% correct on Test, a 19.1% reduction in error rate over the best individual system, viz.",
            "cite_ID": "W05-1518",
            "cite_maker_sids": [
                82
            ],
            "cite_sids": [
                81,
                82,
                83
            ],
            "cite_text": "Van Halteren et al.(1998) have generalized this approach for higher number of classifiers in their TotPrecision voting method.The vote of each classifier (parser) is weighted by their respective accuracy.",
            "label": [
                "Results_Citation"
            ]
        },
        {
            "Number": 13,
            "refer_ID": "P98-1081",
            "refer_sids": [
                101,
                102
            ],
            "refer_text": "However, it appears more useful to give more weight to taggers which have proved their quality.This can be general quality, e.g. each tagger votes its overall precision (TotPrecision), or quality in relation to the current situation, e.g. each tagger votes its precision on the suggested tag (Tag- Precision).",
            "cite_ID": "W05-1518",
            "cite_maker_sids": [
                90
            ],
            "cite_sids": [
                90
            ],
            "cite_text": "Parallel to (van Halteren et al., 1998), we ran experiments with two stacked classifiers, Memory-Based, and Decision-Tree-Based.",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 14,
            "refer_ID": "P98-1081",
            "refer_sids": [
                130,
                137
            ],
            "refer_text": "The first choice for this is to use a Memory- Based second level learner.To examine if the overtraining effects are specific to this particular second level classifier, we also used the C5.0 system, a commercial version of the well-known program C4.5 (Quinlan 1993) for the induction of decision trees, on the same training material.",
            "cite_ID": "W05-1518",
            "cite_maker_sids": [
                111
            ],
            "cite_sids": [
                111
            ],
            "cite_text": "In all experiments, the TotPrecision voting scheme of (van Halteren et al., 1998) has been used.",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 15,
            "refer_ID": "P98-1081",
            "refer_sids": [
                116,
                117
            ],
            "refer_text": "A next step is to examine them in pairs.We can investigate all situations where one tagger suggests T1 and the other T2 and estimate the probability that in this situation the tag should actually be Tx.",
            "cite_ID": "W00-0733",
            "cite_maker_sids": [
                26
            ],
            "cite_sids": [
                26
            ],
            "cite_text": "The most advanced voting method ex\u00ad amines output values of pairs of classifiers and assigns weights to tags based on how often they appear with this pair in the tuning data (Tag\u00ad Pair, Van Halteren et al., (1998)).",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 16,
            "refer_ID": "P98-1081",
            "refer_sids": [
                94,
                101
            ],
            "refer_text": "Simple Voting There are many ways in which the results of the component taggers can be combined, selecting a single tag from the set proposed by these taggers.However, it appears more useful to give more weight to taggers which have proved their quality.",
            "cite_ID": "W00-0733",
            "cite_maker_sids": [
                18
            ],
            "cite_sids": [
                18,
                19,
                20
            ],
            "cite_text": "We will evaluate nine different methods for combining the output of our five chunkers (Van Halteren et al., 1998).Five are so-called voting methods.They assign weights to the output of the individual systems and use these weights to determine the most probable output tag.",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 17,
            "refer_ID": "P98-1081",
            "refer_sids": [
                129
            ],
            "refer_text": "The second stage can be provided with the first level outputs, and with additional information, e.g. about the original input pattern.",
            "cite_ID": "W00-0733",
            "cite_maker_sids": [
                32
            ],
            "cite_sids": [
                32
            ],
            "cite_text": "For this purpose we have used the part-of-speech tag of the cur\u00ad rent word as compressed representation of the first stage input (Van Halteren et al., 1998).",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 18,
            "refer_ID": "P98-1081",
            "refer_sids": [
                136,
                145,
                146,
                147,
                161
            ],
            "refer_text": "This is most likely an overtraining effect: Tune is probably too small to collect case bases which can leverage the stacking effect convincingly, especially since only 7.51% of the second stage material shows disagreement between the featured tags.The most important observation is that every combination (significantly) outperforms the combination of any strict subset of its components.Also of note is the improvement yielded by the best combination.The pairwise voting system, using all four individual taggers, scores 97.92% correct on Test, a 19.1% reduction in error rate over the best individual system, viz.Regardless of such closer investigation, we feel that our results are encouraging enough to extend our investigation of combination, starting with additional component taggers and selection strategies, and going on to shifts to other tagsets and/or languages.",
            "cite_ID": "J01-2002",
            "cite_maker_sids": [
                40
            ],
            "cite_sids": [
                40,
                41,
                42
            ],
            "cite_text": "First experiments (van Halteren, Zavrel, and Daelemans 1998; Brill and Wu 1998) demonstrated the basic validity of the approach for tagging, with the error rate of the best combiner being 19.1% lower than that of the best individual tagger (van Halteren, Zavrel, and Daelemans 1998).However, these experiments were restricted to a single language, a single tagset and, more importantly, a limited amount of training data for the combiners.This led us to perform further, more extensive, 1In previous work (van Halteren, Zavrel, and Daelemans 1998), we were unable to confirm the latter half of the hypothesis unequivocally.",
            "label": [
                "Results_Citation"
            ]
        },
        {
            "Number": 19,
            "refer_ID": "P98-1081",
            "refer_sids": [
                75,
                90,
                136
            ],
            "refer_text": "The second part, Tune, consists of 10% of the data (every ninth utterance, 114479 tokens) and is used to select the best tagger parameters where applicable and to develop the combination methods.All Taggers Correct 92.49 Majority Correct (31,211) 4.34 Correct Present, No Majority 1.37 (22,1111) Minority Correct (13,121) 1.01 All Taggers Wrong 0.78 Table 1: Tagger agreement on Tune.This is most likely an overtraining effect: Tune is probably too small to collect case bases which can leverage the stacking effect convincingly, especially since only 7.51% of the second stage material shows disagreement between the featured tags.",
            "cite_ID": "J01-2002",
            "cite_maker_sids": [
                183
            ],
            "cite_sids": [
                183,
                184,
                185,
                186
            ],
            "cite_text": "Compare this to the \"tune\" set in van Halteren, Zavrel, and Daelemans (1998).This consisted of 114K.tokens, but, because of a 92.5% agreement over all four taggers, it yielded less than 9K tokens of useful training material to resolve disagreements.This was suspected to be the main reason for the relative lack of performance by the more sophisticated combiners.",
            "label": [
                "Implication_Citation"
            ]
        },
        {
            "Number": 20,
            "refer_ID": "P98-1081",
            "refer_sids": [
                3,
                4,
                125
            ],
            "refer_text": "Four well-known tagger generators (Hidden Markov Model, Memory-Based, Transformation Rules and Maximum Entropy) are trained on the same corpus data.After comparison, their outputs are combined using several voting strategies and second stage classifiers.Stacked classifiers From the measurements so far it appears that the use of more detailed information leads to a better accuracy improvement.",
            "cite_ID": "J01-2002",
            "cite_maker_sids": [
                570
            ],
            "cite_sids": [
                570,
                571,
                573
            ],
            "cite_text": "For part-of-speech tagging, a significant increase in accuracy through combining the output of different taggers was first demonstrated in van Halteren, Zavrel, and Daelemans (1998) and Brill and Wu (1998).In both approaches, different tagger gen\u00ad erators were applied to the same training data and their predictions combined using different combination methods, including stacking.As we now apply the methods of van Halteren, Zavrel, and Daelemans (1998) to WSJ as well, it is easier to make a comparison.",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 21,
            "refer_ID": "P98-1081",
            "refer_sids": [
                116,
                117,
                127,
                128,
                134
            ],
            "refer_text": "A next step is to examine them in pairs.We can investigate all situations where one tagger suggests T1 and the other T2 and estimate the probability that in this situation the tag should actually be Tx.The practice of feeding the outputs of a number of classifiers as features for a next learner sit is significantly better than the runner-up (Precision-Recall) with p=0.is usually called stacking (Wolpert 1992).Surprisingly, none of the Memory-Based based methods reaches the quality of TagPair.",
            "cite_ID": "J01-2002",
            "cite_maker_sids": [
                102
            ],
            "cite_sids": [
                102,
                103,
                104
            ],
            "cite_text": "One of the best methods for tagger combination in (van Halteren, Zavrel, and Daele\u00ad mans 1998) is the TagPair method.It looks at all situations where one tagger suggests tag1 and the other tag2 and estimates the probability that in this situation the tag should actually be tagx.Although it is presented as a variant of voting in that paper, it is in fact also a stacked classifier, because it does not necessarily select one of the tags suggested by the component taggers.",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 22,
            "refer_ID": "P98-1081",
            "refer_sids": [
                124,
                134
            ],
            "refer_text": "When used on Test, the pairwise voting strategy (TagPair) clearly outperforms the other voting strategies, 8 but does not yet approach the level where all tying majority votes are handled correctly (98.31%).Surprisingly, none of the Memory-Based based methods reaches the quality of TagPair.",
            "cite_ID": "J01-2002",
            "cite_maker_sids": [
                487
            ],
            "cite_sids": [
                487,
                488
            ],
            "cite_text": "The most important result that has undergone a change between van Halteren, Zavrel, and Daelemans (1998) and our current experiments is the relative accuracy of TagPair and stacked systems such as MBL.Where TagPair used to be significantly better than MBL, the roles are now well reversed.",
            "label": [
                "Results_Citation"
            ]
        },
        {
            "Number": 23,
            "refer_ID": "P98-1081",
            "refer_sids": [
                63
            ],
            "refer_text": "The data we use for our experiment consists of the tagged LOB corpus (Johansson 1986).",
            "cite_ID": "J01-2002",
            "cite_maker_sids": [
                176
            ],
            "cite_sids": [
                176
            ],
            "cite_text": "The first is the LOB corpus (Johansson 1986), which we used in the earlier experiments as well (van Halteren, Zavrel, and Daelemans 1998) and which has proved to be a good testing ground.",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 24,
            "refer_ID": "P98-1081",
            "refer_sids": [
                3,
                107
            ],
            "refer_text": "Four well-known tagger generators (Hidden Markov Model, Memory-Based, Transformation Rules and Maximum Entropy) are trained on the same corpus data.Table 2: Accuracy of individual taggers and combination methods.",
            "cite_ID": "J01-2002",
            "cite_maker_sids": [
                309
            ],
            "cite_sids": [
                309
            ],
            "cite_text": "In van Halteren, Zavrel, and Daelemans (1998) we used a straightforward im\u00ad plementation of HMM's, which turned out to have the worst accuracy of the four competing methods.",
            "label": [
                "Results_Citation"
            ]
        },
        {
            "Number": 25,
            "refer_ID": "P98-1081",
            "refer_sids": [
                130,
                134,
                137,
                138
            ],
            "refer_text": "The first choice for this is to use a Memory- Based second level learner.Surprisingly, none of the Memory-Based based methods reaches the quality of TagPair.To examine if the overtraining effects are specific to this particular second level classifier, we also used the C5.0 system, a commercial version of the well-known program C4.5 (Quinlan 1993) for the induction of decision trees, on the same training material.1\u00b0 Because C5.0 prunes the decision tree, the overfitting of training material (Tune) is less than with Memory-Based learning, but the results on Test are also worse.",
            "cite_ID": "J01-2002",
            "cite_maker_sids": [
                398
            ],
            "cite_sids": [
                398
            ],
            "cite_text": "With LOB and a single 114K tune set (van Halteren, Zavrel, and Daelemans 1998), both MBL and Decision Trees degraded significantly when adding context, and MBL degraded when adding the word",
            "label": [
                "Results_Citation"
            ]
        }
    ]
}