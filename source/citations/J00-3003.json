{
    "ID": "J00-3003",
    "citations": [
        {
            "Number": 1,
            "refer_ID": "J00-3003",
            "refer_sids": [
                214,
                358,
                392,
                394
            ],
            "refer_text": "The importance of the Markov assumption for the discourse grammar is that we can now view the whole system of discourse grammar and local utterance-based likelihoods as a kth-order hidden Markov model (HMM) (Rabiner and Juang 1986).We conducted preliminary experiments to assess how neural networks compare to decision trees for the type of data studied here.Table 9 Combined utterance classification accuracies (chance = 35%).Discourse Grammar Accuracy (%) Prosody Recognizer Combined None 38.9 42.8 56.5 Unigram 48.3 61.8 62.4 Bigram 49.7 64.3 65.0 Table 10 Accuracy (in %) for individual and combined models for two subtasks, using uniform priors (chance = 50%).",
            "cite_ID": "W13-4047",
            "cite_maker_sids": [
                13
            ],
            "cite_sids": [
                13,
                14
            ],
            "cite_text": "(Stolcke et al., 2000) use HMMs for dialogue modelling, where sequences of observations correspond to sequences of dialogue act types.They also explore the performance with decision trees and neural networks and report their highest accuracy at 65% on the Switchboard corpus.",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 2,
            "refer_ID": "J00-3003",
            "refer_sids": [
                68,
                71
            ],
            "refer_text": "For the speech recognition task, our framework provides a mathematically principled way to condition the speech recognizer on conversation context through dialogue structure, as well as on nonlexical information correlated with DA identity.Second, we present results obtained with this approach on a large, widely available corpus of spontaneous conversational speech.",
            "cite_ID": "W12-1634",
            "cite_maker_sids": [
                12
            ],
            "cite_sids": [
                12
            ],
            "cite_text": "To date, the majority of work on dialogue act modeling has addressed spoken dialogue (Samuel et al., 1998; Stolcke et al., 2000; Surendran and Levow, 2006; Bangalore et al., 2008; Sridhar et al., 2009; Di Eugenio et al., 2010).",
            "label": [
                "Aim_Citation"
            ]
        },
        {
            "Number": 3,
            "refer_ID": "J00-3003",
            "refer_sids": [
                188,
                192
            ],
            "refer_text": "The computation of likelihoods P(EIU ) depends on the types of evidence used.Prosodic features-Evidence is given by the acoustic features F capturing various aspects of pitch, duration, energy, etc., of the speech signal; the associated likelihoods are P(F I U).",
            "cite_ID": "W12-1634",
            "cite_maker_sids": [
                18
            ],
            "cite_sids": [
                18
            ],
            "cite_text": "Previous research has leveraged prosodic cues (Sridhar et al., 2009; Stolcke et al., 2000) and facial expressions (Boyer et al., 2011) for automatic dialogue act classification, but other types of nonverbal cues remain unexplored.",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 4,
            "refer_ID": "J00-3003",
            "refer_sids": [
                64,
                68
            ],
            "refer_text": "The goal of this article is twofold: On the one hand, we aim to present a comprehensive framework for modeling and automatic classification of DAs, founded on well-known statistical methods.For the speech recognition task, our framework provides a mathematically principled way to condition the speech recognizer on conversation context through dialogue structure, as well as on nonlexical information correlated with DA identity.",
            "cite_ID": "W10-1012",
            "cite_maker_sids": [
                185
            ],
            "cite_sids": [
                185
            ],
            "cite_text": "There have also been Dialogue Acts modeling approaches for automatic tagging and recognition of conversational speech (Stolcke et al., 2000) and related work in corpus linguistics where machine learning techniques have been used to find conversational patterns in spoken transcripts of dialogue corpus (Shawar and Atwell, 2005).",
            "label": [
                "Aim_Citation"
            ]
        },
        {
            "Number": 5,
            "refer_ID": "J00-3003",
            "refer_sids": [
                155,
                156
            ],
            "refer_text": "A backchannel is a short utterance that plays discourse-structuring roles, e.g., indicating that the speaker should go on talking.These are usually referred to in the conversation analysis literature as \"continuers\" and have been studied extensively (Jefferson 1984; Schegloff 1982; Yngve 1970).",
            "cite_ID": "W13-4011",
            "cite_maker_sids": [
                1
            ],
            "cite_sids": [
                1,
                2
            ],
            "cite_text": "Conversational feedback is mostly performedthrough short utterances such as yeah, mh, okaynot produced by the main speaker but by one ofthe other participants of a conversation.Such utterances are among the most frequent in conversational data (Stolcke et al., 2000).",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 6,
            "refer_ID": "J00-3003",
            "refer_sids": [
                38
            ],
            "refer_text": "Tag STATEMENT BACKCHANNEL/ACKNOWLEDGE OPINION ABANDONED/UNINTERPRETABLE AGREEMENT/ACCEPT APPRECIATION YEs-No-QUESTION NONVERBAL YES ANSWERS CONVENTIONAL-CLOSING WH-QUESTION NO ANSWERS RESPONSE ACKNOWLEDGMENT HEDGE DECLARATIVE YES-No-QuESTION OTHER BACKCHANNEL-QUESTION QUOTATION SUMMARIZE/REFORMULATE AFFIRMATIVE NON-YES ANSWERS ACTION-DIRECTIVE COLLABORATIVE COMPLETION REPEAT-PHRASE OPEN-QUESTION RHETORICAL-QUESTIONS HOLD BEFORE ANSWER/AGREEMENT REJECT NEGATIVE NON-NO ANSWERS SIGNAL-NON-UNDERSTANDING OTHER ANSWERS CONVENTIONAL-OPENING OR-CLAUSE DISPREFERRED ANSWERS 3RD-PARTY-TALK OFFERS, OPTIONS ~ COMMITS SELF-TALK D OWNPLAYER MAYBE/AcCEPT-PART TAG-QUESTION DECLARATIVE WH-QUESTION APOLOGY THANKING Example % Me, I'm in the legal department.",
            "cite_ID": "W01-1627",
            "cite_maker_sids": [
                18
            ],
            "cite_sids": [
                18
            ],
            "cite_text": "Previous research has leveraged prosodic cues (Sridhar et al., 2009; Stolcke et al., 2000) and facial expressions (Boyer et al., 2011) for automatic dialogue act classification, but other types of nonverbal cues remain unexplored.",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 7,
            "refer_ID": "J00-3003",
            "refer_sids": [
                21,
                22,
                27
            ],
            "refer_text": "The ability to model and automatically detect discourse structure is an important step toward understanding spontaneous dialogue. While there is hardly consensus on exactly how discourse structure should be described, some agreement exists that a useful first level of analysis involves the identification of dialogue acts (DAs).Thus, DAs can be thought of as a tag set that classifies utterances according to a combination of pragmatic, semantic, and syntactic criteria.",
            "cite_ID": "N13-1099",
            "cite_maker_sids": [
                18
            ],
            "cite_sids": [
                17,
                18
            ],
            "cite_text": "Dialog act (DA) annotations and tagging, inspiredby the speech act theory of Austin (1975) and Searle(1976), have been used in the NLP community to understand and model dialog.Initial work was done onspoken interactions (see for example (Stolcke et al.,2000)).",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 8,
            "refer_ID": "J00-3003",
            "refer_sids": [
                64,
                67,
                81
            ],
            "refer_text": "The goal of this article is twofold: On the one hand, we aim to present a comprehensive framework for modeling and automatic classification of DAs, founded on well-known statistical methods.However, our framework generalizes earlier models, giving us a clean probabilistic approach for performing DA classification from unreliable words and nonlexical evidence.The domain we chose to model is the Switchboard corpus of human-human conversational telephone speech (Godfrey, Holliman, and McDaniel 1992) distributed by the Linguistic Data Consortium.",
            "cite_ID": "H01-1001",
            "cite_maker_sids": [
                95
            ],
            "cite_sids": [
                95,
                96
            ],
            "cite_text": "dialogue acts such as statements, questions, backchannels, ... are detected using a language model based detec\u00adtor trained on Switchboard similar to Stolcke et al.(2000",
            "label": [
                "Aim_Citation"
            ]
        },
        {
            "Number": 9,
            "refer_ID": "J00-3003",
            "refer_sids": [
                66,
                214,
                215
            ],
            "refer_text": "For example, our model draws on the use of DA n-grams and the hidden Markov models of conversation present in earlier work, such as Nagata and Morimoto (1993, 1994) and Woszczyna and Waibel (1994) (see Section 7).The importance of the Markov assumption for the discourse grammar is that we can now view the whole system of discourse grammar and local utterance-based likelihoods as a kth-order hidden Markov model (HMM) (Rabiner and Juang 1986).The HMM states correspond to DAs, observations correspond to utterances, transition probabilities are given by the discourse grammar (see Section 4), and observation probabilities are given by the local likelihoods P(Eil Ui).",
            "cite_ID": "N06-2021",
            "cite_maker_sids": [
                66
            ],
            "cite_sids": [
                64,
                65,
                66
            ],
            "cite_text": "The HMM has been widely used in many tagging problems.Stolcke et al.(Stolcke et al., 2000) used it for dialog act classification, where each utterance (or dialog act) is used as the observation.",
            "label": [
                "Aim_Citation"
            ]
        },
        {
            "Number": 10,
            "refer_ID": "J00-3003",
            "refer_sids": [
                32,
                33
            ],
            "refer_text": "Interactional dominance (Linell 1990) might be measured more accurately using DA distributions than with simpler techniques, and could serve as an indicator of the type or genre of discourse at hand.In all these cases, DA labels would enrich the available input for higher-level processing of the spoken words.",
            "cite_ID": "W12-1616",
            "cite_maker_sids": [
                6
            ],
            "cite_sids": [
                6
            ],
            "cite_text": "By representing a higher level intention of utterancesduring human conversation, dialogue act labels arebeing used to enrich the information provided byspoken words (Stolcke et al., 2000).",
            "label": [
                "Method_Citation"
            ]
        }
    ]
}