{
    "ID": "C10-1045",
    "citations": [
        {
            "Number": 1,
            "refer_ID": "C10-1045",
            "refer_sids": [
                270
            ],
            "refer_text": "6 Joint Segmentation and Parsing.",
            "cite_ID": "D12-1046",
            "cite_maker_sids": [
                39
            ],
            "cite_sids": [
                39
            ],
            "cite_text": "Joint segmentation and parsing was also investigated for Arabic (Green and Manning, 2010).",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 2,
            "refer_ID": "C10-1045",
            "refer_sids": [
                270
            ],
            "refer_text": "6 Joint Segmentation and Parsing.",
            "cite_ID": "J13-1007",
            "cite_maker_sids": [
                72
            ],
            "cite_sids": [
                72
            ],
            "cite_text": "Indeed, we have used it to solve the problem of parsing while recovering null elements in both English and Chinese (Cai, Chiang, and Goldberg 2011), and others have used it for the joint segmentation and parsing of Arabic (Green and Manning 2010).",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 3,
            "refer_ID": "C10-1045",
            "refer_sids": [
                275
            ],
            "refer_text": "But gold segmentation is not available in application settings, so a segmenter and parser are arranged in a pipeline.",
            "cite_ID": "J13-1007",
            "cite_maker_sids": [
                148
            ],
            "cite_sids": [
                148,
                149
            ],
            "cite_text": "One possible solution to the unobserved word-sequence problem is a pipeline system in which an initial model is in charge of token-segmentation, and the output of the initial model is fed as the input to a second stage parser.This is a popular approach in parsing systems for Arabic and Chinese (Jiang, Huang, and Liu 2009; Green and Manning 2010).",
            "label": [
                "Results_Citation"
            ]
        },
        {
            "Number": 4,
            "refer_ID": "C10-1045",
            "refer_sids": [
                270
            ],
            "refer_text": "6 Joint Segmentation and Parsing.",
            "cite_ID": "J13-1007",
            "cite_maker_sids": [
                479
            ],
            "cite_sids": [
                479,
                480
            ],
            "cite_text": "This is by now a fairly standard representation for multiple morphological segmentations of Hebrew utterances (Adler 2001; Bar-Haim, Sima\u00e2\u20ac\u2122an, and Winter 2005; Adler 2007; Cohen and Smith 2007; Goldberg, Adler, and Elhadad 2008; Goldberg and Tsarfaty 2008; Goldberg and Elhadad 2011).It is also used for Arabic (Green and Manning 2010)",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 5,
            "refer_ID": "C10-1045",
            "refer_sids": [
                6
            ],
            "refer_text": "Finally, we show that in application settings, the absence of gold segmentation lowers parsing performance by 2\u00e2\u20ac\u201c5% F1.",
            "cite_ID": "J13-1007",
            "cite_maker_sids": [
                511
            ],
            "cite_sids": [
                510,
                511
            ],
            "cite_text": "Lattice parsing was explored in the context of parsing of speech signals by Chappelier et al.(1999), Sima\u00e2\u20ac\u2122an (1999), and Hall (2005), and in the context of joint word-segmentation and syntactic disambiguation in Cohen and Smith (2007), Goldberg and Tsarfaty (2008), and Green and Manning (2010).",
            "label": [
                "Results_Citation"
            ]
        },
        {
            "Number": 6,
            "refer_ID": "C10-1045",
            "refer_sids": [
                24
            ],
            "refer_text": "Finally, we provide a realistic eval uation in which segmentation is performed both in a pipeline and jointly with parsing (\u00c2\u00a76).",
            "cite_ID": "J13-1007",
            "cite_maker_sids": [
                670
            ],
            "cite_sids": [
                670
            ],
            "cite_text": "Recently, Green and Manning (2010) report on an extensive set of experiments with several kinds of tree annotations and refinements, and report parsing accuracies of 79% F1 using the Stanford-parser and 82% F1 using the PCFG-LA BerkeleyParser, both when assuming gold word segmentation.",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 7,
            "refer_ID": "C10-1045",
            "refer_sids": [
                24,
                289,
                308
            ],
            "refer_text": "Finally, we provide a realistic eval uation in which segmentation is performed both in a pipeline and jointly with parsing (\u00a76).Parent Head Modif er Dir # gold F1 Label # gold F1 NP NP TAG R 946 0.54 ADJP 1216 59.45 S S S R 708 0.57 SBAR 2918 69.81 NP NP ADJ P R 803 0.64 FRAG 254 72.87 NP NP N P R 2907 0.66 VP 5507 78.83 NP NP SBA R R 1035 0.67 S 6579 78.91 NP NP P P R 2713 0.67 PP 7516 80.93 VP TAG P P R 3230 0.80 NP 34025 84.95 NP NP TAG L 805 0.85 ADVP 1093 90.64 VP TAG SBA R R 772 0.86 WHN P 787 96.00 S VP N P L 961 0.87 (a) Major phrasal categories (b) Major POS categories (c) Ten lowest scoring (Collins, 2003)-style dependencies occurring more than 700 times Table 8: Per category performance of the Berkeley parser on sentence lengths \u2264 70 (dev set, gold segmentation).Table 9: Dev set results for sentences of length \u2264 70.",
            "cite_ID": "J13-1007",
            "cite_maker_sids": [
                672
            ],
            "cite_sids": [
                672
            ],
            "cite_text": "The best reported results for parsing Arabic when the gold word segmentation is not known, however, are obtained using a pipeline model in which a tagger and word-segmenter is applied prior to a manually state-split constituency parser, resulting in an F-score of 79% F1 (for sentences of up to 70 words) (Green and Manning 2010).",
            "label": [
                "Results_Citation"
            ]
        },
        {
            "Number": 8,
            "refer_ID": "C10-1045",
            "refer_sids": [
                11
            ],
            "refer_text": "To investigate the influence of these factors, we analyze Modern Standard Arabic (henceforth MSA, or simply \u201cArabic\u201d) because of the unusual opportunity it presents for comparison to English parsing results.",
            "cite_ID": "J13-1008",
            "cite_maker_sids": [
                195
            ],
            "cite_sids": [
                195
            ],
            "cite_text": "As for work on Arabic (MSA), results have been reported on the PATB (Kulick, Gabbard, and Marcus 2006; Diab 2007; Green and Manning 2010)",
            "label": [
                "Aim_Citation"
            ]
        },
        {
            "Number": 9,
            "refer_ID": "C10-1045",
            "refer_sids": [
                21,
                22,
                53,
                141
            ],
            "refer_text": "Next we show that the ATB is similar to other tree- banks in gross statistical terms, but that annotation consistency remains low relative to English (\u00a73).We then use linguistic and annotation insights to develop a manually annotated grammar for Arabic (\u00a74).When the maSdar lacks a determiner, the constituent as a whole resem bles the ubiquitous annexation construct \ufffd ?f iDafa.mark- ContainsVerb is especially effective for distinguishing root S nodes of equational sentences.",
            "cite_ID": "J13-1008",
            "cite_maker_sids": [
                196
            ],
            "cite_sids": [
                196
            ],
            "cite_text": "Recently, Green and Manning (2010) analyzed the PATB for annotation consistency, and introduced an enhanced split-state constituency grammar, including labels for short idafa constructions and verbal or equational clauses.",
            "label": [
                "Results_Citation",
                "Method_Citation"
            ]
        },
        {
            "Number": 10,
            "refer_ID": "C10-1045",
            "refer_sids": [
                64
            ],
            "refer_text": "We propose a limit of 70 words for Arabic parsing evaluations.",
            "cite_ID": "J13-1008",
            "cite_maker_sids": [
                665
            ],
            "cite_sids": [
                665
            ],
            "cite_text": "For better comparison with work of others, we adopt the suggestion made by Green and Manning (2010) to evaluate the parsing quality on sentences up to 70 tokens long.",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 11,
            "refer_ID": "C10-1045",
            "refer_sids": [
                116,
                117
            ],
            "refer_text": "In our grammar, features are realized as annotations to basic category labels.We start with noun features since written Arabic contains a very high proportion of NPs.",
            "cite_ID": "J13-1009",
            "cite_maker_sids": [
                190
            ],
            "cite_sids": [
                190
            ],
            "cite_text": "The Arabic grammar features come from Green and Manning (2010), which contains an ablation study similar to Table 2.",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 12,
            "refer_ID": "C10-1045",
            "refer_sids": [
                128
            ],
            "refer_text": "8 We use head-finding rules specified by a native speaker.",
            "cite_ID": "J13-1009",
            "cite_maker_sids": [
                193
            ],
            "cite_sids": [
                193
            ],
            "cite_text": "For Arabic, we use the head-finding rules from Green and Manning (2010).",
            "label": [
                "Results_Citation"
            ]
        },
        {
            "Number": 13,
            "refer_ID": "C10-1045",
            "refer_sids": [
                312
            ],
            "refer_text": "By establishing significantly higher parsing baselines, we have shown that Arabic parsing performance is not as poor as previously thought, but remains much lower than English.",
            "cite_ID": "J13-1009",
            "cite_maker_sids": [
                316
            ],
            "cite_sids": [
                316
            ],
            "cite_text": "We previously showed that the \u00e2\u20ac\u0153Kulick\u00e2\u20ac\u009d tag set is very effective for basic Arabic parsing (Green and Manning 2010).",
            "label": [
                "Results_Citation"
            ]
        },
        {
            "Number": 14,
            "refer_ID": "C10-1045",
            "refer_sids": [
                301
            ],
            "refer_text": "Table 9 shows that MADA produces a high quality segmentation, and that the effect of cascading segmentation errors on parsing is only 1.92% F1.",
            "cite_ID": "J13-1009",
            "cite_maker_sids": [
                397
            ],
            "cite_sids": [
                397
            ],
            "cite_text": "We previously showed that segmentation errors decrease Arabic parsing accuracy by about 2.0% F1 (Green and Manning 2010).",
            "label": [
                "Results_Citation"
            ]
        },
        {
            "Number": 15,
            "refer_ID": "C10-1045",
            "refer_sids": [
                11
            ],
            "refer_text": "To investigate the influence of these factors, we analyze Modern Standard Arabic (henceforth MSA, or simply \u201cArabic\u201d) because of the unusual opportunity it presents for comparison to English parsing results.",
            "cite_ID": "J13-1009",
            "cite_maker_sids": [
                406
            ],
            "cite_sids": [
                406
            ],
            "cite_text": "We previously showed optimal Berkeley parser (Petrov et al. 2006) pa- rameterizations for both the Arabic (Green and Manning 2010) and French (Green et al. 2011) data sets",
            "label": [
                "Aim_Citation"
            ]
        },
        {
            "Number": 17,
            "refer_ID": "C10-1045",
            "refer_sids": [
                11
            ],
            "refer_text": "To investigate the influence of these factors, we analyze Modern Standard Arabic (henceforth MSA, or simply \u201cArabic\u201d) because of the unusual opportunity it presents for comparison to English parsing results.",
            "cite_ID": "P11-1159",
            "cite_maker_sids": [
                109
            ],
            "cite_sids": [
                109
            ],
            "cite_text": "Recently, Green and Manning (2010) analyzed the PATB for annotation consistency",
            "label": [
                "Aim_Citation"
            ]
        },
        {
            "Number": 18,
            "refer_ID": "C10-1045",
            "refer_sids": [
                11
            ],
            "refer_text": "To investigate the influence of these factors, we analyze Modern Standard Arabic (henceforth MSA, or simply \u201cArabic\u201d) because of the unusual opportunity it presents for comparison to English parsing results.",
            "cite_ID": "P11-2037",
            "cite_maker_sids": [
                34
            ],
            "cite_sids": [
                34
            ],
            "cite_text": "We allow the parser to produce empty elements by means of lattice-parsing (Chappelier et al., 1999), a general processing community (Hall, 2005; Chappelier et al., 1999), and was recently applied to the task of joint clitic-segmentation and syntactic-parsing in Hebrew (Goldberg and Tsarfaty, 2008; Goldberg and Elhadad, 2011) and Arabic (Green and Manning, 2010).",
            "label": [
                "Aim_Citation"
            ]
        },
        {
            "Number": 19,
            "refer_ID": "C10-1045",
            "refer_sids": [
                72
            ],
            "refer_text": "We show that noun-noun vs. discourse-level coordination ambiguity in Arabic is a significant source of parsing errors (Table 8c).",
            "cite_ID": "P11-2122",
            "cite_maker_sids": [
                7
            ],
            "cite_sids": [
                7
            ],
            "cite_text": "Recent work has therefore focused on the importance of detecting errors in the treebank (Green and Manning, 2010)",
            "label": [
                "Results_Citation"
            ]
        },
        {
            "Number": 20,
            "refer_ID": "C10-1045",
            "refer_sids": [
                21
            ],
            "refer_text": "Next we show that the ATB is similar to other tree- banks in gross statistical terms, but that annotation consistency",
            "cite_ID": "P11-2122",
            "cite_maker_sids": [
                73
            ],
            "cite_sids": [
                73
            ],
            "cite_text": "Green and Manning (2010) discuss annotation consistency in the Penn Arabic Treebank (ATB)",
            "label": [
                "Results_Citation"
            ]
        },
        {
            "Number": 21,
            "refer_ID": "C10-1045",
            "refer_sids": [
                72
            ],
            "refer_text": "We show that noun-noun vs. discourse-level coordination ambiguity in Arabic is a significant source of parsing errors (Table 8c).",
            "cite_ID": "P11-2122",
            "cite_maker_sids": [
                109
            ],
            "cite_sids": [
                109
            ],
            "cite_text": "Measuring recall is tricky, even using the errors identified in Green and Manning (2010) as \u00e2\u20ac\u0153gold\u00e2\u20ac\u009d errors.",
            "label": [
                "Results_Citation"
            ]
        },
        {
            "Number": 22,
            "refer_ID": "C10-1045",
            "refer_sids": [
                277,
                279
            ],
            "refer_text": "Lattice parsing (Chappelier et al., 1999) is an alternative to a pipeline that prevents cascading errors by placing all segmentation options into the parse chart.We extend the Stanford parser to accept pre-generated lattices, where each word is represented as a finite state automaton.",
            "cite_ID": "P11-2124",
            "cite_maker_sids": [
                18
            ],
            "cite_sids": [
                18
            ],
            "cite_text": "Recently, Green and Manning (2010) demonstrated the effectiveness of lattice-parsing for parsing Arabic.",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 23,
            "refer_ID": "C10-1045",
            "refer_sids": [
                0
            ],
            "refer_text": "Better Arabic Parsing: Baselines, Evaluations, and Analysis",
            "cite_ID": "P12-1016",
            "cite_maker_sids": [
                196
            ],
            "cite_sids": [
                196
            ],
            "cite_text": "The data was pre-processed with packages from the Stanford Arabic parser (Green and Manning, 2010).",
            "label": [
                "Aim_Citation"
            ]
        },
        {
            "Number": 24,
            "refer_ID": "C10-1045",
            "refer_sids": [
                24
            ],
            "refer_text": "Finally, we provide a realistic eval uation in which segmentation is performed both in a pipeline and jointly with parsing (\u00a76).",
            "cite_ID": "P12-2002",
            "cite_maker_sids": [
                12
            ],
            "cite_sids": [
                12
            ],
            "cite_text": "One can either select a segmentation path prior to parsing, or, as has been recently argued, one can let the parser pick a segmentation jointly with decoding (Tsarfaty, 2006; Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008; Green and Manning, 2010).",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 25,
            "refer_ID": "C10-1045",
            "refer_sids": [
                0
            ],
            "refer_text": "Better Arabic Parsing: Baselines, Evaluations, and Analysis",
            "cite_ID": "P12-2002",
            "cite_maker_sids": [
                34
            ],
            "cite_sids": [
                34,
                35
            ],
            "cite_text": "2 The complete set of analyses for this word is provided in Goldberg and Tsarfaty (2008).Examples for similar phenomena in Arabic may be found in Green and Manning (2010).",
            "label": [
                "Aim_Citation"
            ]
        },
        {
            "Number": 26,
            "refer_ID": "C10-1045",
            "refer_sids": [
                24,
                277,
                279
            ],
            "refer_text": "Lattice parsing (Chappelier et al., 1999) is an alternative to a pipeline that prevents cascading errors by placing all segmentation options into the parse chart.We extend the Stanford parser to accept pre-generated lattices, where each word is represented as a finite state automaton.Finally, we provide a realistic eval uation in which segmentation is performed both in a pipeline and jointly with parsing (\u00a76).",
            "cite_ID": "P12-2002",
            "cite_maker_sids": [
                39
            ],
            "cite_sids": [
                38,
                39
            ],
            "cite_text": "In practice, a statistical component is required to decide on the correct morphological segmentation, that is, to pick out the correct path through the lattice.This may be done based on linear local context (Adler and Elhadad, 2006; Shacham and Wintner, 2007; Bar-haim et al., 2008; Habash and Rambow, 2005), or jointly with parsing (Tsarfaty, 2006; Goldberg and Tsarfaty, 2008; Green and Manning, 2010).",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 27,
            "refer_ID": "C10-1045",
            "refer_sids": [
                153
            ],
            "refer_text": "Preprocessing the raw trees improves parsing performance considerably.9 We first discard all trees dominated by X, which indicates errors and non-linguistic text.",
            "cite_ID": "W13-4904",
            "cite_maker_sids": [
                115
            ],
            "cite_sids": [
                115
            ],
            "cite_text": "Following Green and Manning (2010) and others, sentences headed by X nodes are deleted",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 28,
            "refer_ID": "C10-1045",
            "refer_sids": [
                301
            ],
            "refer_text": "Table 9 shows that MADA produces a high quality segmentation, and that the effect of cascading segmentation errors on parsing is only 1.92% F1.",
            "cite_ID": "W13-4904",
            "cite_maker_sids": [
                234
            ],
            "cite_sids": [
                234
            ],
            "cite_text": "Green and Manning (2010) obtain the opposite result in their Arabic parsing experiments, with the lattice parser underperforming the pipeline system by over 3 points (76.01 F1 vs 79.17 F1).",
            "label": [
                "Results_Citation"
            ]
        },
        {
            "Number": 29,
            "refer_ID": "C10-1045",
            "refer_sids": [
                301
            ],
            "refer_text": "Table 9 shows that MADA produces a high quality segmentation, and that the effect of cascading segmentation errors on parsing is only 1.92% F1.",
            "cite_ID": "W13-4904",
            "cite_maker_sids": [
                244
            ],
            "cite_sids": [
                244
            ],
            "cite_text": "Green and Manning (2010) find that using automatic tokenization provided by MADA (Habash et al., 2009) instead of gold tokenization results in a 1.92% F score drop in their constituent parsing work.",
            "label": [
                "Results_Citation"
            ]
        },
        {
            "Number": 31,
            "refer_ID": "C10-1045",
            "refer_sids": [
                166,
                167
            ],
            "refer_text": "The intuition here is that the role of a discourse marker can usually be de 9 Both the corpus split and pre-processing code are avail-.able at http://nlp.stanford.edu/projects/arabic.shtml.",
            "cite_ID": "W13-4917",
            "cite_maker_sids": [
                260
            ],
            "cite_sids": [
                260
            ],
            "cite_text": "The Stanford Arabic Phrase Structure Treebank In order to stay compatible with the state of the art, we provide the constituency data set with most of the pre-processing steps of Green and Manning (2010)",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 32,
            "refer_ID": "C10-1045",
            "refer_sids": [
                154
            ],
            "refer_text": "At the phrasal level, we remove all function tags and traces.",
            "cite_ID": "W13-4917",
            "cite_maker_sids": [
                262
            ],
            "cite_sids": [
                262
            ],
            "cite_text": "We finally remove all traces, but, unlike Green and Manning (2010), we keep all function tags.",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 33,
            "refer_ID": "C10-1045",
            "refer_sids": [
                12
            ],
            "refer_text": "The Penn Arabic Treebank (ATB) syntactic guidelines (Maamouri et al., 2004) were purposefully borrowed without major modification from English (Marcus et al., 1993).",
            "cite_ID": "W13-4917",
            "cite_maker_sids": [
                218
            ],
            "cite_sids": [
                218
            ],
            "cite_text": "Data Sets The Arabic data set contains two tree- banks derived from the LDC Penn Arabic Treebanks (PATB) (Maamouri et al., 2004b):11 the Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009), a dependency treebank, and the Stanford version of the PATB (Green and Manning, 2010)",
            "label": [
                "Method_Citation"
            ]
        }
    ]
}