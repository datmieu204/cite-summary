{
    "ID": "D09-1023",
    "citations": [
        {
            "Number": 1,
            "refer_ID": "D09-1023",
            "refer_sids": [
                17
            ],
            "refer_text": "We compare lexical phrase and dependency syntax features, as well as a novel com 2 To date, QG has been used for word alignment (Smith and Eisner, 2006), adaptation and projection in parsing (Smith and Eisner, 2009), and various monolingual recognition and scoring tasks (Wang et al., 2007; Das and Smith, 2009); this paper represents its first application to MT. 219 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 219228, Singapore, 67 August 2009.",
            "cite_ID": "D09-1086",
            "cite_maker_sids": [
                78
            ],
            "cite_sids": [
                78
            ],
            "cite_text": "In that paper, QG was applied to word alignment and has since found applications in question answering (Wang et al., 2007), paraphrase detection (Das and Smith, 2009), and machine translation (Gimpel and Smith, 2009).",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 3,
            "refer_ID": "D09-1023",
            "refer_sids": [
                17
            ],
            "refer_text": "We compare lexical phrase and dependency syntax features, as well as a novel com 2 To date, QG has been used for word alignment (Smith and Eisner, 2006), adaptation and projection in parsing (Smith and Eisner, 2009), and various monolingual recognition and scoring tasks (Wang et al., 2007; Das and Smith, 2009); this paper represents its first application to MT. 219 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 219228, Singapore, 67 August 2009.",
            "cite_ID": "D11-1044",
            "cite_maker_sids": [
                1
            ],
            "cite_sids": [
                1
            ],
            "cite_text": "We present a quasi-synchronous dependency grammar (Smith and Eisner, 2006) for machine translation in which the leaves of the tree are phrases rather than words as in previous work (Gimpel and Smith, 2009).",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 4,
            "refer_ID": "D09-1023",
            "refer_sids": [
                17
            ],
            "refer_text": "We compare lexical phrase and dependency syntax features, as well as a novel com 2 To date, QG has been used for word alignment (Smith and Eisner, 2006), adaptation and projection in parsing (Smith and Eisner, 2009), and various monolingual recognition and scoring tasks (Wang et al., 2007; Das and Smith, 2009); this paper represents its first application to MT. 219 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 219228, Singapore, 67 August 2009.",
            "cite_ID": "D11-1044",
            "cite_maker_sids": [
                16
            ],
            "cite_sids": [
                16
            ],
            "cite_text": "Quasi-synchronous grammar (QG) provides this backbone (Smith and Eisner, 2006); we describe a coarse-to-fine approach for decoding within this framework, advancing substantially over earlier QG machine translation systems (Gimpel and Smith, 2009).",
            "label": [
                "Result_Citation"
            ]
        },
        {
            "Number": 5,
            "refer_ID": "D09-1023",
            "refer_sids": [
                17
            ],
            "refer_text": "We compare lexical phrase and dependency syntax features, as well as a novel com 2 To date, QG has been used for word alignment (Smith and Eisner, 2006), adaptation and projection in parsing (Smith and Eisner, 2009), and various monolingual recognition and scoring tasks (Wang et al., 2007; Das and Smith, 2009); this paper represents its first application to MT. 219 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 219228, Singapore, 67 August 2009.",
            "cite_ID": "D11-1044",
            "cite_maker_sids": [
                23
            ],
            "cite_sids": [
                23
            ],
            "cite_text": "We previously applied quasi-synchronous grammar to machine translation (Gimpel and Smith, 2009), but that system performed translation fundamentally at the word level.",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 6,
            "refer_ID": "D09-1023",
            "refer_sids": [
                17
            ],
            "refer_text": "We compare lexical phrase and dependency syntax features, as well as a novel com 2 To date, QG has been used for word alignment (Smith and Eisner, 2006), adaptation and projection in parsing (Smith and Eisner, 2009), and various monolingual recognition and scoring tasks (Wang et al., 2007; Das and Smith, 2009); this paper represents its first application to MT. 219 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 219228, Singapore, 67 August 2009.",
            "cite_ID": "D11-1044",
            "cite_maker_sids": [
                41
            ],
            "cite_sids": [
                41
            ],
            "cite_text": "We denote this grammar by Gs,s ; its (weighted) language is the set of translations of s. Quasi-synchronous grammar makes no restrictions on the form of the target monolingual grammar, though dependency grammars have been used in most previous applications of QG (Wang et al., 2007; Das and Smith, 2009; Smith and Eisner, 2009), including previous work in MT (Smith and Eisner, 2006; Gimpel and Smith, 2009).",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 7,
            "refer_ID": "D09-1023",
            "refer_sids": [
                260
            ],
            "refer_text": "Our novel decoder is based on efficient DP-based QG lattice parsing extended to handle non-local features using generic techniques that also support efficient parameter estimation.",
            "cite_ID": "D11-1044",
            "cite_maker_sids": [
                146
            ],
            "cite_sids": [
                146
            ],
            "cite_text": "For a QPDG model, decoding consists of finding the highest-scoring tuple (t, , , , a) for an in put sentence s and its parse s, i.e., finding the most probable derivation under the s/s-specific grammar Gs,s . We follow Gimpel and Smith (2009) in constructing a lattice to represent Gs,s and using lattice parsing to search for the best derivation, but we construct the lattice differently and employ a coarse-to- fine strategy (Petrov, 2009) to speed up decoding.",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 9,
            "refer_ID": "D09-1023",
            "refer_sids": [
                204
            ],
            "refer_text": "We use one feature for each of the configurations in (Smith and Eisner, 2006), adding 7 additional features that score configura Phrase Syntactic Features: features: +f att  f val +f qg (base) (target) (tree-to-tree) (base) 0.3727 0.4458 0.4424 +f phr 0.4682 0.4971 0.5142 Table 4: Feature set comparison (BLEU).",
            "cite_ID": "Pjournal",
            "cite_maker_sids": [
                79
            ],
            "cite_sids": [
                79
            ],
            "cite_text": "(2007) ArEn[UN, NIST 06][L] SL:lexical, morphological and syntactic features Gimpel and Smith (2009) DeEn[BTEC][S] SL and TL:syntactic features from dependency trees Proposed DTM2 model Proposed MT model En English, Fr French, De German, Zh Chinese, Ar Arabic, CPH Canadian Parliament Hansards, UN United Nations, BTEC basic travel expression corpus, FST finite state transducer Table 5 Related research integrating context into word alignment models Authors SLTL[DS][S/L] Contextual features Integrated into Berger et al.",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 10,
            "refer_ID": "D09-1023",
            "refer_sids": [
                1
            ],
            "refer_text": "We present a machine translation framework that can incorporate arbitrary features of both input and output sentences.",
            "cite_ID": "Pjournal",
            "cite_maker_sids": [
                139
            ],
            "cite_sids": [
                139
            ],
            "cite_text": "Gimpel and Smith (2009) present an MT framework based on lattice parsing with a quasi-synchronous grammar that can incorporate arbitrary features from both source and target sentences (Table 5).",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 12,
            "refer_ID": "D09-1023",
            "refer_sids": [
                123
            ],
            "refer_text": "Figure 1: Decoding as lattice parsing, with the highest-scoring translation denoted by black lattice arcs (others are grayed out) and thicker blue arcs forming a dependency tree over them.",
            "cite_ID": "Pproc_d09",
            "cite_maker_sids": [
                205
            ],
            "cite_sids": [
                205
            ],
            "cite_text": "Gimpel & Smith (2009; 2011) treat translation as a monolingual dependency parsing problem, creating a dependency structure over the translation during decoding.",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 16,
            "refer_ID": "D09-1023",
            "refer_sids": [
                11
            ],
            "refer_text": "Here we take first steps toward such a universal decoder, making the following contributions:Arbitrary feature model (2): We define a sin gle, direct log-linear translation model (Papineni et al., 1997; Och and Ney, 2002) that encodes most popular MT features and can be used to encode any features on source and target sentences, dependency trees, and alignments.",
            "cite_ID": "W10-1730-parscit",
            "cite_maker_sids": [
                17
            ],
            "cite_sids": [
                17
            ],
            "cite_text": "Log-linear translation models (instead of MLE) with rich feature sets are used also in (Ittycheriah and Roukos, 2007) and (Gimpel andSmith, 2009); the idea can be traced back to (Pap ineni et al., 1997).",
            "label": [
                "Method_Citation"
            ]
        },
        {
            "Number": 18,
            "refer_ID": "D09-1023",
            "refer_sids": [
                254
            ],
            "refer_text": "Our findings show that phrase features and dependency syntax produce complementary improvements to translation quality, that tree-to- tree configurations (a new feature in MT) are helpful for translation, and that substantial gains can be obtained by permitting certain types of non- isomorphism.",
            "cite_ID": "W11-2139",
            "cite_maker_sids": [
                37
            ],
            "cite_sids": [
                37
            ],
            "cite_text": "On the other hand, it has been shown that incorporating syntactic information in the form of features can lead to improved performance (Chiang, 2010; Gimpel and Smith, 2009; Marton and Resnik, 2008).",
            "label": [
                "Result_Citation"
            ]
        },
        {
            "Number": 20,
            "refer_ID": "D09-1023",
            "refer_sids": [
                191
            ],
            "refer_text": "Our decoding framework allows us to perform many experiments with the same feature representation and inference algorithms, including combining and comparing phrase-based and syntax-based features and examining how isomorphism constraints of synchronous formalisms affect translation output.",
            "cite_ID": "N10-1040",
            "cite_maker_sids": [
                6
            ],
            "cite_sids": [
                6
            ],
            "cite_text": "Many translation models use such knowledge before decoding (Xia and McCord, 2004) and during decoding (Birch et al., 2007; Gimpel and Smith, 2009; Koehn and Hoang, 2007; Chiang et al., 2009), but they are limited to simpler features for practical reasons, often restricted to conditioning left-to- right on the target sentence.",
            "label": [
                "Method_Citation"
            ]
        }
    ]
}